{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, activation='relu'):\n",
    "    \"\"\"UNET convolution block containing Conv2D -> BatchNorm -> Activation\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Keras/tensorflow tensor input.\n",
    "        filters: Int. Number of filters.\n",
    "        kernel_size: Int. Kernel size of convolutions.\n",
    "        activation: String. Activation used convolution.\n",
    "\n",
    "    # Returns\n",
    "        Keras/tensorflow tensor.\n",
    "    \"\"\"\n",
    "    kwargs = {'use_bias': False, 'kernel_initializer': 'he_uniform'}\n",
    "    x = Conv2D(filters, kernel_size, (1, 1), 'same', **kwargs)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsample_block(x, filters, branch):\n",
    "    \"\"\"UNET upsample block. This block upsamples ``x``, concatenates a\n",
    "    ``branch`` tensor and applies two convolution blocks:\n",
    "    Upsample -> Concatenate -> 2 x ConvBlock.\n",
    "\n",
    "    # Arguments\n",
    "        x: Keras/tensorflow tensor.\n",
    "        filters: Int. Number of filters\n",
    "        branch: Tensor to be concatated to the upsamples ``x`` tensor.\n",
    "\n",
    "    # Returns\n",
    "        A Keras tensor.\n",
    "    \"\"\"\n",
    "    x = UpSampling2D(size=2)(x)\n",
    "    x = Concatenate(axis=3)([x, branch])\n",
    "    x = convolution_block(x, filters)\n",
    "    x = convolution_block(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "# def transpose_block(x, filters, branch):\n",
    "#     \"\"\"UNET transpose block. This block upsamples ``x``, concatenates a\n",
    "#     ``branch`` tensor and applies two convolution blocks:\n",
    "#     Conv2DTranspose -> Concatenate -> 2 x ConvBlock.\n",
    "\n",
    "#     # Arguments\n",
    "#         x: Keras/tensorflow tensor.\n",
    "#         filters: Int. Number of filters\n",
    "#         branch: Tensor to be concatated to the upsamples ``x`` tensor.\n",
    "\n",
    "#     # Returns\n",
    "#         A Keras tensor.\n",
    "#     \"\"\"\n",
    "#     x = Conv2DTranspose(filters, 4, (2, 2), 'same', use_bias=False)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Concatenate(axis=3)([x, branch])\n",
    "#     x = convolution_block(x, filters)\n",
    "#     return x\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    \"\"\"Freezes gradient pass for the entire model\n",
    "\n",
    "    # Arguments:\n",
    "        model: Keras/tensorflow model\n",
    "\n",
    "    # Returns:\n",
    "        A Keras/tensorflow model\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_tensors(model, layer_names):\n",
    "    \"\"\"Gets all the tensor outputs of the given layer names.\n",
    "\n",
    "    # Arguments\n",
    "        model: Keras/tensorflow model.\n",
    "        layer_names: List of strings which each string is a layer name.\n",
    "\n",
    "    # Returns\n",
    "        List of Keras tensors.\n",
    "    \"\"\"\n",
    "    tensors = []\n",
    "    for layer_name in layer_names:\n",
    "        tensors.append(model.get_layer(layer_name).output)\n",
    "    return model, tensors\n",
    "\n",
    "\n",
    "def build_backbone(BACKBONE, shape, branch_names, weights,\n",
    "                   frozen=False, input_tensor=None):\n",
    "    \"\"\"Builds ``BACKBONE`` class for UNET model.\n",
    "\n",
    "    # Arguments\n",
    "        BACKBONE: Class for instantiating a backbone model\n",
    "        shape: List of integers: ``(H, W, num_channels)``.\n",
    "        branch_names: List of strings containing layer names of ``BACKBONE()``.\n",
    "        weights: String or ``None``.\n",
    "        frozen: Boolean. If True ``BACKBONE()`` updates are frozen.\n",
    "        input_tensor: Input tensor. If given ``shape`` is overwritten and this\n",
    "            tensor is used instead as input.\n",
    "\n",
    "    # Returns\n",
    "    \"\"\"\n",
    "    kwargs = {'include_top': False, 'input_shape': shape, 'weights': weights}\n",
    "    if input_tensor is not None:\n",
    "        kwargs.pop('input_shape')\n",
    "        kwargs['input_tensor'] = input_tensor\n",
    "    backbone = BACKBONE(**kwargs)\n",
    "\n",
    "    if frozen:\n",
    "        backbone = freeze_model(backbone)\n",
    "\n",
    "    backbone, branch_tensors = get_tensors(backbone, branch_names)\n",
    "    return backbone, branch_tensors\n",
    "\n",
    "\n",
    "def build_UNET(num_classes, backbone, branch_tensors,\n",
    "               decoder, decoder_filters, activation, name):\n",
    "    \"\"\"Build UNET with a given ``backbone`` model.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: Integer used for output number of channels.\n",
    "        backbone: Instantiated backbone model.\n",
    "        branch_tensors: List of tensors from ``backbone`` model\n",
    "        decoder: Function used for upsampling and decoding the output.\n",
    "        decoder_filters: List of integers used in each application of decoder.\n",
    "        activation: Output activation of the model.\n",
    "        name: String. indicating the name of the model.\n",
    "\n",
    "    # Returns\n",
    "        A UNET Keras/tensorflow model.\n",
    "    \"\"\"\n",
    "    inputs, x = backbone.input, backbone.output\n",
    "    if isinstance(backbone.layers[-1], MaxPooling2D):\n",
    "        x = convolution_block(x, 512)\n",
    "        x = convolution_block(x, 512)\n",
    "\n",
    "    for branch, filters in zip(branch_tensors, decoder_filters):\n",
    "        x = decoder(x, filters, branch)\n",
    "\n",
    "    kwargs = {'use_bias': True, 'kernel_initializer': 'glorot_uniform'}\n",
    "    x = Conv2D(num_classes, 3, (1, 1), 'same', **kwargs)(x)\n",
    "    outputs = Activation(activation, name='masks')(x)\n",
    "    model = Model(inputs, outputs, name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "def UNET(input_shape, num_classes, branch_names, BACKBONE, weights,\n",
    "         freeze_backbone=False, activation='sigmoid', decoder_type='upsample',\n",
    "         decoder_filters=[256, 128, 64, 32, 16], input_tensor=None,\n",
    "         name='UNET'):\n",
    "    \"\"\"Build a generic UNET model with a given ``BACKBONE`` class.\n",
    "\n",
    "    # Arguments\n",
    "        input_shape: List of integers: ``(H, W, num_channels)``.\n",
    "        num_classes: Integer used for output number of channels.\n",
    "        branch_names: List of strings containing layer names of ``BACKBONE()``.\n",
    "        BACKBONE: Class for instantiating a backbone model\n",
    "        weights: String indicating backbone weights e.g.\n",
    "            ''imagenet'', ``None``.\n",
    "        freeze_backbone: Boolean. If True ``BACKBONE()`` updates are frozen.\n",
    "        decoder_type: String indicating decoding function e.g.\n",
    "            ''upsample ''transpose''.\n",
    "        decoder_filters: List of integers used in each application of decoder.\n",
    "        activation: Output activation of the model.\n",
    "        input_tensor: Input tensor. If given ``shape`` is overwritten and this\n",
    "            tensor is used instead as input.\n",
    "        name: String. indicating the name of the model.\n",
    "\n",
    "    # Returns\n",
    "        A UNET Keras/tensorflow model.\n",
    "    \"\"\"\n",
    "    args = [BACKBONE, input_shape, branch_names,\n",
    "            weights, freeze_backbone, input_tensor]\n",
    "    backbone, branch_tensors = build_backbone(*args)\n",
    "    if decoder_type == 'upsample':\n",
    "        decoder = upsample_block\n",
    "    if decoder_type == 'transpose':\n",
    "        decoder = transpose_block\n",
    "\n",
    "    model = build_UNET(num_classes, backbone, branch_tensors, decoder,\n",
    "                       decoder_filters, activation, name)\n",
    "    return model\n",
    "\n",
    "\n",
    "# def UNET_VGG16(num_classes=1, input_shape=(224, 224, 3), weights='imagenet',\n",
    "#                freeze_backbone=False, activation='sigmoid',\n",
    "#                decoder_type='upsample',\n",
    "#                decode_filters=[256, 128, 64, 32, 16]):\n",
    "#     \"\"\"Build a UNET model with a ``VGG16`` backbone.\n",
    "\n",
    "#     # Arguments\n",
    "#         input_shape: List of integers: ``(H, W, num_channels)``.\n",
    "#         num_classes: Integer used for output number of channels.\n",
    "#         branch_names: List of strings containing layer names of ``BACKBONE()``.\n",
    "#         BACKBONE: Class for instantiating a backbone model\n",
    "#         weights: String indicating backbone weights e.g.\n",
    "#             ''imagenet'', ``None``.\n",
    "#         freeze_backbone: Boolean. If True ``BACKBONE()`` updates are frozen.\n",
    "#         decoder_type: String indicating decoding function e.g.\n",
    "#             ''upsample ''transpose''.\n",
    "#         decoder_filters: List of integers used in each application of decoder.\n",
    "#         activation: Output activation of the model.\n",
    "#         input_tensor: Input tensor. If given ``shape`` is overwritten and this\n",
    "#             tensor is used instead as input.\n",
    "#         name: String. indicating the name of the model.\n",
    "\n",
    "#     # Returns\n",
    "#         A UNET-VGG16 Keras/tensorflow model.\n",
    "#     \"\"\"\n",
    "#     VGG16_branches = ['block5_conv3', 'block4_conv3', 'block3_conv3',\n",
    "#                       'block2_conv2', 'block1_conv2']\n",
    "#     return UNET(input_shape, num_classes, VGG16_branches, VGG16, weights,\n",
    "#                 freeze_backbone, activation, decoder_type, decode_filters,\n",
    "#                 name='UNET-VGG16')\n",
    "\n",
    "\n",
    "# def UNET_VGG19(num_classes=1, input_shape=(224, 224, 3), weights='imagenet',\n",
    "#                freeze_backbone=False, activation='sigmoid',\n",
    "#                decoder_type='upsample',\n",
    "#                decode_filters=[256, 128, 64, 32, 16]):\n",
    "#     \"\"\"Build a UNET model with a ``VGG19`` backbone.\n",
    "\n",
    "#     # Arguments\n",
    "#         input_shape: List of integers: ``(H, W, num_channels)``.\n",
    "#         num_classes: Integer used for output number of channels.\n",
    "#         branch_names: List of strings containing layer names of ``BACKBONE()``.\n",
    "#         BACKBONE: Class for instantiating a backbone model\n",
    "#         weights: String indicating backbone weights e.g.\n",
    "#             ''imagenet'', ``None``.\n",
    "#         freeze_backbone: Boolean. If True ``BACKBONE()`` updates are frozen.\n",
    "#         decoder_type: String indicating decoding function e.g.\n",
    "#             ''upsample ''transpose''.\n",
    "#         decoder_filters: List of integers used in each application of decoder.\n",
    "#         activation: Output activation of the model.\n",
    "#         input_tensor: Input tensor. If given ``shape`` is overwritten and this\n",
    "#             tensor is used instead as input.\n",
    "#         name: String. indicating the name of the model.\n",
    "\n",
    "#     # Returns\n",
    "#         A UNET-VGG19 Keras/tensorflow model.\n",
    "#     \"\"\"\n",
    "\n",
    "    # VGG19_branches = ['block5_conv4', 'block4_conv4', 'block3_conv4',\n",
    "    #                   'block2_conv2', 'block1_conv2']\n",
    "    # return UNET(input_shape, num_classes, VGG19_branches, VGG19, weights,\n",
    "    #             freeze_backbone, activation, decoder_type, decode_filters,\n",
    "    #             name='UNET-VGG19')\n",
    "\n",
    "\n",
    "def UNET_RESNET50(num_classes=1, input_shape=(224, 224, 3), weights='imagenet',\n",
    "                  freeze_backbone=False, activation='sigmoid',\n",
    "                  decoder_type='upsample',\n",
    "                  decode_filters=[256, 128, 64, 32, 16]):\n",
    "    \"\"\"Build a UNET model with a ``RESNET50V2`` backbone.\n",
    "\n",
    "    # Arguments\n",
    "        input_shape: List of integers: ``(H, W, num_channels)``.\n",
    "        num_classes: Integer used for output number of channels.\n",
    "        branch_names: List of strings containing layer names of ``BACKBONE()``.\n",
    "        BACKBONE: Class for instantiating a backbone model\n",
    "        weights: String indicating backbone weights e.g.\n",
    "            ''imagenet'', ``None``.\n",
    "        freeze_backbone: Boolean. If True ``BACKBONE()`` updates are frozen.\n",
    "        decoder_type: String indicating decoding function e.g.\n",
    "            ''upsample ''transpose''.\n",
    "        decoder_filters: List of integers used in each application of decoder.\n",
    "        activation: Output activation of the model.\n",
    "        input_tensor: Input tensor. If given ``shape`` is overwritten and this\n",
    "            tensor is used instead as input.\n",
    "        name: String. indicating the name of the model.\n",
    "\n",
    "    # Returns\n",
    "        A UNET-RESNET50V2 Keras/tensorflow model.\n",
    "    \"\"\"\n",
    "    RESNET50_branches = ['conv4_block6_1_relu', 'conv3_block4_1_relu',\n",
    "                         'conv2_block3_1_relu', 'conv1_conv', 'input_resnet50']\n",
    "    input_tensor = Input(input_shape, name='input_resnet50')\n",
    "    return UNET(input_shape, num_classes, RESNET50_branches, ResNet50V2,\n",
    "                weights, freeze_backbone, activation, decoder_type,\n",
    "                decode_filters, input_tensor, 'UNET-RESNET50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_3 = UNET_RESNET50(input_shape=(224, 224, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET-RESNET50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_resnet50 (InputLayer)    [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_resnet50[0][0]']         \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 14, 14, 2048  0          ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 14, 14, 2304  0           ['up_sampling2d_5[0][0]',        \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 14, 14, 256)  5308416     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 14, 14, 256)  589824      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_6[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 28, 28, 128)  442368      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 28, 28, 128)  147456      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 28, 28, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_7[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 56, 56, 64)   110592      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 56, 56, 64)  256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 56, 56, 64)   36864       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 56, 56, 64)  256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_15[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_8[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 112, 112, 32  36864       ['concatenate_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 112, 112, 32  128        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 112, 112, 32  9216        ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 112, 112, 32  128        ['conv2d_18[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_17[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 224, 224, 35  0           ['up_sampling2d_9[0][0]',        \n",
      "                                )                                 'input_resnet50[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 224, 224, 16  5040        ['concatenate_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 224, 224, 16  64         ['conv2d_19[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_18[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 224, 224, 16  2304        ['activation_18[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 224, 224, 16  64         ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_19[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 224, 224, 1)  145         ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,257,857\n",
      "Trainable params: 30,210,433\n",
      "Non-trainable params: 47,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET-RESNET50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_resnet50 (InputLayer)    [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['input_resnet50[0][0]']         \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_10[0][0]',       \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_11[0][0]',       \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 14, 14, 2048  0          ['post_relu[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 14, 14, 2304  0           ['up_sampling2d_15[0][0]',       \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 14, 14, 256)  5308416     ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 14, 14, 256)  589824      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_16 (UpSampling2D  (None, 28, 28, 256)  0          ['activation_31[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 28, 28, 384)  0           ['up_sampling2d_16[0][0]',       \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 28, 28, 128)  442368      ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 28, 28, 128)  512        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 28, 28, 128)  147456      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 28, 28, 128)  512        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_17 (UpSampling2D  (None, 56, 56, 128)  0          ['activation_33[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 56, 56, 192)  0           ['up_sampling2d_17[0][0]',       \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 56, 56, 64)   110592      ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 56, 56, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 56, 56, 64)   36864       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 56, 56, 64)  256         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_18 (UpSampling2D  (None, 112, 112, 64  0          ['activation_35[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 112, 112, 12  0           ['up_sampling2d_18[0][0]',       \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 112, 112, 32  36864       ['concatenate_18[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 112, 112, 32  128        ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 112, 112, 32  9216        ['activation_36[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 112, 112, 32  128        ['conv2d_40[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_19 (UpSampling2D  (None, 224, 224, 32  0          ['activation_37[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 224, 224, 36  0           ['up_sampling2d_19[0][0]',       \n",
      "                                )                                 'input_resnet50[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 224, 224, 16  5184        ['concatenate_19[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 224, 224, 16  64         ['conv2d_41[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 224, 224, 16  2304        ['activation_38[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 224, 224, 16  64         ['conv2d_42[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 224, 224, 1)  145         ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 30,213,713\n",
      "Non-trainable params: 47,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_4 = UNET_RESNET50(input_shape=(224, 224, 4), weights=None)\n",
    "unet_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "import shutil\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufllige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            # Transformation in \"channels_last\"-Format\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            # Erstellen einer zustzlichen Achse um Tensor-Dimension zu erreichen\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            # Skalierung der Werte\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "# Definition des Dice-Koeffizienten\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# Ableitung einer zu minimierenden Loss-Funktion aus Dice-Koeffzient\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Rckgngig machen der Normalisierung zur korrekten Anzeige der Bilder\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    # Speicherpfade der verschiedenen Architekturen\n",
    "    model_dict = {\n",
    "        'BN': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    # Auswahl der Architektur entsprechend der verwendeten Variante\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    # Laden der JSON\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    # Laden des Modells aus JSON\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulsst, werden immer die selben zufllig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    # entsprechend der Variante mssen Gewichte unterschiedlich gesetzt werden\n",
    "    if model_type == 'BN':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufllige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufllige Gewichte fr den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste fr neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zustzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfgen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # fr den 2. Convolution-layer passt die shape nicht, bleibt daher unberhrt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufllige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufllige Gewichte fr den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste fr neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zustzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfgen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # fr den 2. Convolution-layer passt die shape nicht, bleibt daher unberhrt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # bernehmen der RGB Gewichte fr 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen fr den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte knnen bernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # bernehmen der RGB Gewichte fr 1. Convolution-layer, IR Gewichte zufllig\n",
    "    if option == 'RNDM':\n",
    "        # Leere Liste fr aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren ber geladene Gewichte und zufllige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Fr 1. Conv-Layer stimmt shape nicht berein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte fr RGB-Channel werden bernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen berein und knnen bernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufgen der zuflligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zustzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen fr den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer fr RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste fr aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die spter bersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere ber Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden fr diesen Layer, iteriere ber diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese knnen daher nicht bernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # fr die brigen Layer werden die Gewichte bernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zuflligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass gendert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass gendert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass gendert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind fr erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False):\n",
    "    # Anzahl der trainierbaren Encoder Layer, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= 27\n",
    "\n",
    "    # Encoder bleibt grtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM']:\n",
    "\n",
    "    # Fr das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafr werden die Layer jetzt rckwrts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # fr train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass gendert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, output_folder_prefix, do_early_stop):\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{output_folder_prefix}_logger/{model_name}'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + '.log')\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logger_path, histogram_freq=1)\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger, tensorboard_callback]\n",
    "\n",
    "    if do_early_stop:\n",
    "        early_stop =  tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_binary_iou',\n",
    "                    min_delta=0,\n",
    "                    patience=40,\n",
    "                    verbose=1,\n",
    "                    mode='max',\n",
    "                    )\n",
    "\n",
    "        callbacks.append(early_stop)  \n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def combine_log_files(output_folder_prefix, model_name):\n",
    "    # Zusammenfhren der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "    filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "    with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "        # spezifizieren des Delimiters fr Excel in erster Zeile\n",
    "        outfile.write('sep=,\\n')\n",
    "\n",
    "        for i, fname in enumerate(filenames):\n",
    "            with open(fname) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                for j, row in enumerate(reader):\n",
    "                    # berspringen des 2. Headers\n",
    "                    if i == 1 and j == 0:\n",
    "                        continue\n",
    "\n",
    "                    delimiter = ','\n",
    "                    list_to_string = delimiter.join(row)\n",
    "                    list_to_string += '\\n'\n",
    "\n",
    "                    outfile.write(list_to_string)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Mae des inputs\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zustzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BN',\n",
    "    'RNDM': 'BN',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zustzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0.9 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren whrend erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch whrend des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 1\n",
    "fine_tune_epochs = 1\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "model_name = f'Tensorboard_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}_e{total_epochs}'\n",
    "\n",
    "# Prfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'tensorboard_runs'\n",
    "\n",
    "unet = unet_4 #load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_resnet50 trainable weights: 0 trainable: False\n",
      "1 conv1_pad trainable weights: 0 trainable: False\n",
      "2 conv1_conv trainable weights: 2 trainable: True\n",
      "3 pool1_pad trainable weights: 0 trainable: False\n",
      "4 pool1_pool trainable weights: 0 trainable: False\n",
      "5 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "6 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "7 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "8 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "9 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "10 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "11 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "12 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "13 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "14 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "15 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "16 conv2_block1_out trainable weights: 0 trainable: False\n",
      "17 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "18 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "19 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "20 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "21 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "22 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "23 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "24 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "25 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "26 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "27 conv2_block2_out trainable weights: 0 trainable: False\n",
      "28 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "29 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "30 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "31 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "32 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "33 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "34 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "35 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "36 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "37 max_pooling2d_9 trainable weights: 0 trainable: False\n",
      "38 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "39 conv2_block3_out trainable weights: 0 trainable: False\n",
      "40 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "41 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "42 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "43 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "44 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "45 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "46 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "47 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "48 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "49 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "50 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "51 conv3_block1_out trainable weights: 0 trainable: False\n",
      "52 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "53 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "54 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "55 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "56 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "57 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "58 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "59 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "60 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "61 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "62 conv3_block2_out trainable weights: 0 trainable: False\n",
      "63 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "64 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "65 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "66 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "67 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "68 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "69 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "70 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "71 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "72 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "73 conv3_block3_out trainable weights: 0 trainable: False\n",
      "74 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "75 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "76 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "77 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "78 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "79 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "80 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "81 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "82 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "83 max_pooling2d_10 trainable weights: 0 trainable: False\n",
      "84 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "85 conv3_block4_out trainable weights: 0 trainable: False\n",
      "86 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "87 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "88 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "89 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "90 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "91 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "92 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "93 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "94 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "95 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "96 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "97 conv4_block1_out trainable weights: 0 trainable: False\n",
      "98 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "99 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "100 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "101 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "102 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "103 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "104 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "105 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "106 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "107 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "108 conv4_block2_out trainable weights: 0 trainable: False\n",
      "109 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "110 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "111 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "112 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "113 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "114 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "115 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "116 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "117 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "118 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "119 conv4_block3_out trainable weights: 0 trainable: False\n",
      "120 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "121 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "122 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "123 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "124 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "125 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "126 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "127 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "128 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "129 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "130 conv4_block4_out trainable weights: 0 trainable: False\n",
      "131 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "132 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "133 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "134 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "135 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "136 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "137 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "138 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "139 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "140 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "141 conv4_block5_out trainable weights: 0 trainable: False\n",
      "142 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "143 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "144 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "145 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "146 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "147 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "148 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "149 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "150 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "151 max_pooling2d_11 trainable weights: 0 trainable: False\n",
      "152 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "153 conv4_block6_out trainable weights: 0 trainable: False\n",
      "154 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "155 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "156 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "157 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "158 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "159 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "160 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "161 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "162 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "163 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "164 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "165 conv5_block1_out trainable weights: 0 trainable: False\n",
      "166 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "167 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "168 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "169 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "170 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "171 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "172 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "173 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "174 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "175 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "176 conv5_block2_out trainable weights: 0 trainable: False\n",
      "177 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "178 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "179 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "180 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "181 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "182 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "183 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "184 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "185 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "186 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "187 conv5_block3_out trainable weights: 0 trainable: False\n",
      "188 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "189 post_relu trainable weights: 0 trainable: False\n",
      "190 up_sampling2d_15 trainable weights: 0 trainable: False\n",
      "191 concatenate_15 trainable weights: 0 trainable: False\n",
      "192 conv2d_33 trainable weights: 0 trainable: False\n",
      "193 batch_normalization_30 trainable weights: 0  trainable:  False  training:  False\n",
      "194 activation_30 trainable weights: 0 trainable: False\n",
      "195 conv2d_34 trainable weights: 0 trainable: False\n",
      "196 batch_normalization_31 trainable weights: 0  trainable:  False  training:  False\n",
      "197 activation_31 trainable weights: 0 trainable: False\n",
      "198 up_sampling2d_16 trainable weights: 0 trainable: False\n",
      "199 concatenate_16 trainable weights: 0 trainable: False\n",
      "200 conv2d_35 trainable weights: 0 trainable: False\n",
      "201 batch_normalization_32 trainable weights: 0  trainable:  False  training:  False\n",
      "202 activation_32 trainable weights: 0 trainable: False\n",
      "203 conv2d_36 trainable weights: 0 trainable: False\n",
      "204 batch_normalization_33 trainable weights: 0  trainable:  False  training:  False\n",
      "205 activation_33 trainable weights: 0 trainable: False\n",
      "206 up_sampling2d_17 trainable weights: 0 trainable: False\n",
      "207 concatenate_17 trainable weights: 0 trainable: False\n",
      "208 conv2d_37 trainable weights: 0 trainable: False\n",
      "209 batch_normalization_34 trainable weights: 0  trainable:  False  training:  False\n",
      "210 activation_34 trainable weights: 0 trainable: False\n",
      "211 conv2d_38 trainable weights: 0 trainable: False\n",
      "212 batch_normalization_35 trainable weights: 0  trainable:  False  training:  False\n",
      "213 activation_35 trainable weights: 0 trainable: False\n",
      "214 up_sampling2d_18 trainable weights: 0 trainable: False\n",
      "215 concatenate_18 trainable weights: 0 trainable: False\n",
      "216 conv2d_39 trainable weights: 0 trainable: False\n",
      "217 batch_normalization_36 trainable weights: 0  trainable:  False  training:  False\n",
      "218 activation_36 trainable weights: 0 trainable: False\n",
      "219 conv2d_40 trainable weights: 0 trainable: False\n",
      "220 batch_normalization_37 trainable weights: 0  trainable:  False  training:  False\n",
      "221 activation_37 trainable weights: 0 trainable: False\n",
      "222 up_sampling2d_19 trainable weights: 0 trainable: False\n",
      "223 concatenate_19 trainable weights: 0 trainable: False\n",
      "224 conv2d_41 trainable weights: 0 trainable: False\n",
      "225 batch_normalization_38 trainable weights: 0  trainable:  False  training:  False\n",
      "226 activation_38 trainable weights: 0 trainable: False\n",
      "227 conv2d_42 trainable weights: 0 trainable: False\n",
      "228 batch_normalization_39 trainable weights: 0  trainable:  False  training:  False\n",
      "229 activation_39 trainable weights: 0 trainable: False\n",
      "230 conv2d_43 trainable weights: 0 trainable: False\n",
      "231 masks trainable weights: 0 trainable: False\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.6308 - binary_iou: 0.4578 - true_positives: 116883688.0000 - false_positives: 103902480.0000 - true_negatives: 84674000.0000 - false_negatives: 14060605.0000 - precision: 0.5294 - recall: 0.8926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/tensorboard_runs_checkpoints\\Tensorboard_AVG_rgbDrop_0.9_earlyStop_False_e2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/tensorboard_runs_checkpoints\\Tensorboard_AVG_rgbDrop_0.9_earlyStop_False_e2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 390ms/step - loss: 0.3773 - accuracy: 0.6308 - binary_iou: 0.4578 - true_positives: 116883688.0000 - false_positives: 103902480.0000 - true_negatives: 84674000.0000 - false_negatives: 14060605.0000 - precision: 0.5294 - recall: 0.8926 - val_loss: 0.3050 - val_accuracy: 0.7243 - val_binary_iou: 0.5674 - val_true_positives: 40389644.0000 - val_false_positives: 24565220.0000 - val_true_negatives: 36370928.0000 - val_false_negatives: 4645926.0000 - val_precision: 0.6218 - val_recall: 0.8968\n",
      "0 input_resnet50 trainable weights: 0 trainable: False\n",
      "1 conv1_pad trainable weights: 0 trainable: False\n",
      "2 conv1_conv trainable weights: 2 trainable: True\n",
      "3 pool1_pad trainable weights: 0 trainable: False\n",
      "4 pool1_pool trainable weights: 0 trainable: False\n",
      "5 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "6 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "7 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "8 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "9 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "10 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "11 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "12 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "13 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "14 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "15 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "16 conv2_block1_out trainable weights: 0 trainable: False\n",
      "17 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "18 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "19 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "20 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "21 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "22 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "23 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "24 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "25 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "26 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "27 conv2_block2_out trainable weights: 0 trainable: False\n",
      "28 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "29 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "30 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "31 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "32 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "33 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "34 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "35 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "36 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "37 max_pooling2d_9 trainable weights: 0 trainable: False\n",
      "38 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "39 conv2_block3_out trainable weights: 0 trainable: False\n",
      "40 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "41 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "42 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "43 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "44 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "45 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "46 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "47 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "48 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "49 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "50 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "51 conv3_block1_out trainable weights: 0 trainable: False\n",
      "52 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "53 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "54 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "55 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "56 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "57 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "58 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "59 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "60 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "61 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "62 conv3_block2_out trainable weights: 0 trainable: False\n",
      "63 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "64 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "65 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "66 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "67 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "68 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "69 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "70 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "71 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "72 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "73 conv3_block3_out trainable weights: 0 trainable: False\n",
      "74 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "75 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "76 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "77 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "78 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "79 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "80 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "81 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "82 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "83 max_pooling2d_10 trainable weights: 0 trainable: False\n",
      "84 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "85 conv3_block4_out trainable weights: 0 trainable: False\n",
      "86 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "87 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "88 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "89 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "90 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "91 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "92 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "93 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "94 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "95 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "96 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "97 conv4_block1_out trainable weights: 0 trainable: False\n",
      "98 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "99 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "100 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "101 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "102 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "103 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "104 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "105 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "106 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "107 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "108 conv4_block2_out trainable weights: 0 trainable: False\n",
      "109 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "110 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "111 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "112 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "113 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "114 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "115 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "116 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "117 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "118 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "119 conv4_block3_out trainable weights: 0 trainable: False\n",
      "120 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "121 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "122 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "123 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "124 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "125 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "126 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "127 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "128 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "129 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "130 conv4_block4_out trainable weights: 0 trainable: False\n",
      "131 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "132 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "133 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "134 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "135 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "136 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "137 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "138 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "139 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "140 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "141 conv4_block5_out trainable weights: 0 trainable: False\n",
      "142 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "143 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "144 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "145 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "146 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "147 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "148 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "149 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "150 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "151 max_pooling2d_11 trainable weights: 0 trainable: False\n",
      "152 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "153 conv4_block6_out trainable weights: 0 trainable: False\n",
      "154 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "155 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "156 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "157 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "158 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "159 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "160 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "161 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "162 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "163 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "164 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "165 conv5_block1_out trainable weights: 0 trainable: False\n",
      "166 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "167 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "168 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "169 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "170 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "171 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "172 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "173 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "174 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "175 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "176 conv5_block2_out trainable weights: 0 trainable: False\n",
      "177 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "178 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "179 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "180 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "181 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "182 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "183 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "184 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "185 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "186 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "187 conv5_block3_out trainable weights: 0 trainable: False\n",
      "188 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "189 post_relu trainable weights: 0 trainable: False\n",
      "190 up_sampling2d_15 trainable weights: 0 trainable: False\n",
      "191 concatenate_15 trainable weights: 0 trainable: False\n",
      "192 conv2d_33 trainable weights: 0 trainable: False\n",
      "193 batch_normalization_30 trainable weights: 0  trainable:  False  training:  False\n",
      "194 activation_30 trainable weights: 0 trainable: False\n",
      "195 conv2d_34 trainable weights: 0 trainable: False\n",
      "196 batch_normalization_31 trainable weights: 0  trainable:  False  training:  False\n",
      "197 activation_31 trainable weights: 0 trainable: False\n",
      "198 up_sampling2d_16 trainable weights: 0 trainable: False\n",
      "199 concatenate_16 trainable weights: 0 trainable: False\n",
      "200 conv2d_35 trainable weights: 0 trainable: False\n",
      "201 batch_normalization_32 trainable weights: 0  trainable:  False  training:  False\n",
      "202 activation_32 trainable weights: 0 trainable: False\n",
      "203 conv2d_36 trainable weights: 0 trainable: False\n",
      "204 batch_normalization_33 trainable weights: 0  trainable:  False  training:  False\n",
      "205 activation_33 trainable weights: 0 trainable: False\n",
      "206 up_sampling2d_17 trainable weights: 0 trainable: False\n",
      "207 concatenate_17 trainable weights: 0 trainable: False\n",
      "208 conv2d_37 trainable weights: 0 trainable: False\n",
      "209 batch_normalization_34 trainable weights: 0  trainable:  False  training:  False\n",
      "210 activation_34 trainable weights: 0 trainable: False\n",
      "211 conv2d_38 trainable weights: 0 trainable: False\n",
      "212 batch_normalization_35 trainable weights: 0  trainable:  False  training:  False\n",
      "213 activation_35 trainable weights: 0 trainable: False\n",
      "214 up_sampling2d_18 trainable weights: 0 trainable: False\n",
      "215 concatenate_18 trainable weights: 0 trainable: False\n",
      "216 conv2d_39 trainable weights: 0 trainable: False\n",
      "217 batch_normalization_36 trainable weights: 0  trainable:  False  training:  False\n",
      "218 activation_36 trainable weights: 0 trainable: False\n",
      "219 conv2d_40 trainable weights: 0 trainable: False\n",
      "220 batch_normalization_37 trainable weights: 0  trainable:  False  training:  False\n",
      "221 activation_37 trainable weights: 0 trainable: False\n",
      "222 up_sampling2d_19 trainable weights: 0 trainable: False\n",
      "223 concatenate_19 trainable weights: 0 trainable: False\n",
      "224 conv2d_41 trainable weights: 0 trainable: False\n",
      "225 batch_normalization_38 trainable weights: 0  trainable:  False  training:  False\n",
      "226 activation_38 trainable weights: 0 trainable: False\n",
      "227 conv2d_42 trainable weights: 0 trainable: False\n",
      "228 batch_normalization_39 trainable weights: 0  trainable:  False  training:  False\n",
      "229 activation_39 trainable weights: 0 trainable: False\n",
      "230 conv2d_43 trainable weights: 0 trainable: False\n",
      "231 masks trainable weights: 0 trainable: False\n",
      "Epoch 2/2\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.7290 - binary_iou: 0.5735 - true_positives: 116230416.0000 - false_positives: 71682888.0000 - true_negatives: 116692384.0000 - false_negatives: 14915096.0000 - precision: 0.6185 - recall: 0.8863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/tensorboard_runs_checkpoints\\Tensorboard_AVG_rgbDrop_0.9_earlyStop_False_e2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/tensorboard_runs_checkpoints\\Tensorboard_AVG_rgbDrop_0.9_earlyStop_False_e2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 81s 392ms/step - loss: 0.3048 - accuracy: 0.7290 - binary_iou: 0.5735 - true_positives: 116230416.0000 - false_positives: 71682888.0000 - true_negatives: 116692384.0000 - false_negatives: 14915096.0000 - precision: 0.6185 - recall: 0.8863 - val_loss: 0.2936 - val_accuracy: 0.7324 - val_binary_iou: 0.5776 - val_true_positives: 40054312.0000 - val_false_positives: 23304420.0000 - val_true_negatives: 37558056.0000 - val_false_negatives: 5054918.0000 - val_precision: 0.6322 - val_recall: 0.8879\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix, early_stop)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "# Kopie der ursprnglichen Log, da Fine-tuning-Log sie berschreibt\n",
    "shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= initial_epochs)\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_path = f'../output/{output_folder_prefix}_logger/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logger_path logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_4.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
