{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auszuführen mit Environment \"tf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importe & Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "import shutil\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufällige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            # Transformation in \"channels_last\"-Format\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            # Erstellen einer zusätzlichen Achse um Tensor-Dimension zu erreichen\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            # Skalierung der Werte\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "# Definition des Dice-Koeffizienten\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# Ableitung einer zu minimierenden Loss-Funktion aus Dice-Koeffzient\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Rückgängig machen der Normalisierung zur korrekten Anzeige der Bilder\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    # Speicherpfade der verschiedenen Architekturen\n",
    "    model_dict = {\n",
    "        'BN': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    # Auswahl der Architektur entsprechend der verwendeten Variante\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    # Laden der JSON\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    # Laden des Modells aus JSON\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulässt, werden immer die selben zufällig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    # entsprechend der Variante müssen Gewichte unterschiedlich gesetzt werden\n",
    "    if model_type == 'BN':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte können übernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte zufällig\n",
    "    if option == 'RNDM':\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren über geladene Gewichte und zufällige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Für 1. Conv-Layer stimmt shape nicht überein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte für RGB-Channel werden übernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen überein und können übernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufügen der zufälligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zusätzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer für RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die später übersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere über Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden für diesen Layer, iteriere über diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese können daher nicht übernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # für die übrigen Layer werden die Gewichte übernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zufälligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind für erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False):\n",
    "    # Anzahl der trainierbaren Encoder Layer, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= 27\n",
    "\n",
    "    # Encoder bleibt größtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM']:\n",
    "\n",
    "    # Für das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafür werden die Layer jetzt rückwärts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # für train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, output_folder_prefix, do_early_stop):\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{output_folder_prefix}_logger/{model_name}'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + '.log')\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "    if do_early_stop:\n",
    "        early_stop =  tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_binary_iou',\n",
    "                    min_delta=0,\n",
    "                    patience=40,\n",
    "                    verbose=1,\n",
    "                    mode='max',\n",
    "                    )\n",
    "\n",
    "        callbacks.append(early_stop)  \n",
    "\n",
    "    return callbacks\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuchsreihe Freeze-From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 233s 546ms/step - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288 - val_loss: 0.1324 - val_accuracy: 0.7237 - val_binary_iou: 0.5219 - val_true_positives: 17575076.0000 - val_false_positives: 1821869.0000 - val_true_negatives: 59114264.0000 - val_false_negatives: 27460492.0000 - val_precision: 0.9061 - val_recall: 0.3902\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.1008 - accuracy: 0.8260 - binary_iou: 0.6955 - true_positives: 101502720.0000 - false_positives: 25956264.0000 - true_negatives: 162417888.0000 - false_negatives: 29643882.0000 - precision: 0.7964 - recall: 0.7740 - val_loss: 0.3162 - val_accuracy: 0.5801 - val_binary_iou: 0.2986 - val_true_positives: 944899.0000 - val_false_positives: 370912.0000 - val_true_negatives: 60533532.0000 - val_false_negatives: 44122376.0000 - val_precision: 0.7181 - val_recall: 0.0210\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834 - val_loss: 0.1000 - val_accuracy: 0.8302 - val_binary_iou: 0.6984 - val_true_positives: 31970022.0000 - val_false_positives: 4808101.0000 - val_true_negatives: 56008240.0000 - val_false_negatives: 13185362.0000 - val_precision: 0.8693 - val_recall: 0.7080\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 137s 343ms/step - loss: 0.0970 - accuracy: 0.8354 - binary_iou: 0.7095 - true_positives: 102972568.0000 - false_positives: 24451394.0000 - true_negatives: 163957824.0000 - false_negatives: 28139152.0000 - precision: 0.8081 - recall: 0.7854 - val_loss: 0.1056 - val_accuracy: 0.8190 - val_binary_iou: 0.6918 - val_true_positives: 38703920.0000 - val_false_positives: 12815742.0000 - val_true_negatives: 48088272.0000 - val_false_negatives: 6363783.0000 - val_precision: 0.7512 - val_recall: 0.8588\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0961 - accuracy: 0.8378 - binary_iou: 0.7132 - true_positives: 103382480.0000 - false_positives: 24086258.0000 - true_negatives: 164319424.0000 - false_negatives: 27732654.0000 - precision: 0.8110 - recall: 0.7885 - val_loss: 0.1097 - val_accuracy: 0.8059 - val_binary_iou: 0.6742 - val_true_positives: 39755736.0000 - val_false_positives: 15181283.0000 - val_true_negatives: 45644488.0000 - val_false_negatives: 5390192.0000 - val_precision: 0.7237 - val_recall: 0.8806\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0937 - accuracy: 0.8421 - binary_iou: 0.7197 - true_positives: 104078240.0000 - false_positives: 23499364.0000 - true_negatives: 164992912.0000 - false_negatives: 26950208.0000 - precision: 0.8158 - recall: 0.7943 - val_loss: 0.1153 - val_accuracy: 0.7939 - val_binary_iou: 0.6582 - val_true_positives: 41479488.0000 - val_false_positives: 18216578.0000 - val_true_negatives: 42647984.0000 - val_false_negatives: 3627668.0000 - val_precision: 0.6948 - val_recall: 0.9196\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0933 - accuracy: 0.8443 - binary_iou: 0.7231 - true_positives: 104509376.0000 - false_positives: 23135430.0000 - true_negatives: 165270080.0000 - false_negatives: 26605972.0000 - precision: 0.8188 - recall: 0.7971 - val_loss: 0.1052 - val_accuracy: 0.8228 - val_binary_iou: 0.6981 - val_true_positives: 40455752.0000 - val_false_positives: 14088869.0000 - val_true_negatives: 46733252.0000 - val_false_negatives: 4693854.0000 - val_precision: 0.7417 - val_recall: 0.8960\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024 - val_loss: 0.0954 - val_accuracy: 0.8371 - val_binary_iou: 0.7186 - val_true_positives: 40248520.0000 - val_false_positives: 12413144.0000 - val_true_negatives: 48463540.0000 - val_false_negatives: 4846510.0000 - val_precision: 0.7643 - val_recall: 0.8925\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0901 - accuracy: 0.8508 - binary_iou: 0.7330 - true_positives: 105533640.0000 - false_positives: 22092700.0000 - true_negatives: 166309040.0000 - false_negatives: 25585432.0000 - precision: 0.8269 - recall: 0.8049 - val_loss: 0.1245 - val_accuracy: 0.7245 - val_binary_iou: 0.5193 - val_true_positives: 16856334.0000 - val_false_positives: 888026.0000 - val_true_negatives: 59925316.0000 - val_false_negatives: 28302036.0000 - val_precision: 0.9500 - val_recall: 0.3733\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0893 - accuracy: 0.8526 - binary_iou: 0.7359 - true_positives: 105886944.0000 - false_positives: 21818420.0000 - true_negatives: 166548864.0000 - false_negatives: 25266544.0000 - precision: 0.8292 - recall: 0.8074 - val_loss: 0.1029 - val_accuracy: 0.8326 - val_binary_iou: 0.7124 - val_true_positives: 40830816.0000 - val_false_positives: 13431411.0000 - val_true_negatives: 47404960.0000 - val_false_negatives: 4304522.0000 - val_precision: 0.7525 - val_recall: 0.9046\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0876 - accuracy: 0.8564 - binary_iou: 0.7417 - true_positives: 106360520.0000 - false_positives: 21117784.0000 - true_negatives: 167273232.0000 - false_negatives: 24769200.0000 - precision: 0.8343 - recall: 0.8111 - val_loss: 0.1123 - val_accuracy: 0.8113 - val_binary_iou: 0.6824 - val_true_positives: 41546704.0000 - val_false_positives: 16377837.0000 - val_true_negatives: 44430472.0000 - val_false_negatives: 3616706.0000 - val_precision: 0.7173 - val_recall: 0.9199\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0871 - accuracy: 0.8573 - binary_iou: 0.7432 - true_positives: 106628432.0000 - false_positives: 21060946.0000 - true_negatives: 167308336.0000 - false_negatives: 24523056.0000 - precision: 0.8351 - recall: 0.8130 - val_loss: 0.1330 - val_accuracy: 0.7197 - val_binary_iou: 0.5101 - val_true_positives: 16018910.0000 - val_false_positives: 714509.0000 - val_true_negatives: 60247680.0000 - val_false_negatives: 28990608.0000 - val_precision: 0.9573 - val_recall: 0.3559\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166 - val_loss: 0.0904 - val_accuracy: 0.8501 - val_binary_iou: 0.7374 - val_true_positives: 39858736.0000 - val_false_positives: 10601939.0000 - val_true_negatives: 50232448.0000 - val_false_negatives: 5278578.0000 - val_precision: 0.7899 - val_recall: 0.8831\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0849 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107398296.0000 - false_positives: 20543202.0000 - true_negatives: 167856336.0000 - false_negatives: 23722896.0000 - precision: 0.8394 - recall: 0.8191 - val_loss: 0.1110 - val_accuracy: 0.8005 - val_binary_iou: 0.6440 - val_true_positives: 26109266.0000 - val_false_positives: 2097758.0000 - val_true_negatives: 58726144.0000 - val_false_negatives: 19038536.0000 - val_precision: 0.9256 - val_recall: 0.5783\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0847 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107239304.0000 - false_positives: 20393872.0000 - true_negatives: 168027744.0000 - false_negatives: 23859782.0000 - precision: 0.8402 - recall: 0.8180 - val_loss: 0.0989 - val_accuracy: 0.8373 - val_binary_iou: 0.7068 - val_true_positives: 31232048.0000 - val_false_positives: 3293441.0000 - val_true_negatives: 57497820.0000 - val_false_negatives: 13948394.0000 - val_precision: 0.9046 - val_recall: 0.6913\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215 - val_loss: 0.0895 - val_accuracy: 0.8523 - val_binary_iou: 0.7406 - val_true_positives: 39827064.0000 - val_false_positives: 10344540.0000 - val_true_negatives: 50490480.0000 - val_false_negatives: 5309619.0000 - val_precision: 0.7938 - val_recall: 0.8824\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211 - val_loss: 0.0852 - val_accuracy: 0.8639 - val_binary_iou: 0.7554 - val_true_positives: 37170488.0000 - val_false_positives: 6445220.0000 - val_true_negatives: 54378644.0000 - val_false_negatives: 7977376.0000 - val_precision: 0.8522 - val_recall: 0.8233\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 131s 327ms/step - loss: 0.0821 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108301392.0000 - false_positives: 19837088.0000 - true_negatives: 168606352.0000 - false_negatives: 22776036.0000 - precision: 0.8452 - recall: 0.8262 - val_loss: 0.1531 - val_accuracy: 0.7313 - val_binary_iou: 0.5348 - val_true_positives: 18643914.0000 - val_false_positives: 1994139.0000 - val_true_negatives: 58851064.0000 - val_false_negatives: 26482600.0000 - val_precision: 0.9034 - val_recall: 0.4131\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0818 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108285344.0000 - false_positives: 19770572.0000 - true_negatives: 168614816.0000 - false_negatives: 22850008.0000 - precision: 0.8456 - recall: 0.8258 - val_loss: 0.1024 - val_accuracy: 0.8322 - val_binary_iou: 0.7115 - val_true_positives: 40046760.0000 - val_false_positives: 12674211.0000 - val_true_negatives: 48147576.0000 - val_false_negatives: 5103174.0000 - val_precision: 0.7596 - val_recall: 0.8870\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0813 - accuracy: 0.8676 - binary_iou: 0.7596 - true_positives: 108523808.0000 - false_positives: 19610268.0000 - true_negatives: 168706416.0000 - false_negatives: 22680374.0000 - precision: 0.8470 - recall: 0.8271 - val_loss: 0.0870 - val_accuracy: 0.8546 - val_binary_iou: 0.7357 - val_true_positives: 33240562.0000 - val_false_positives: 3608494.0000 - val_true_negatives: 57325588.0000 - val_false_negatives: 11797062.0000 - val_precision: 0.9021 - val_recall: 0.7381\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 132s 330ms/step - loss: 0.0808 - accuracy: 0.8688 - binary_iou: 0.7614 - true_positives: 108646064.0000 - false_positives: 19449168.0000 - true_negatives: 168965888.0000 - false_negatives: 22459632.0000 - precision: 0.8482 - recall: 0.8287 - val_loss: 0.0867 - val_accuracy: 0.8618 - val_binary_iou: 0.7540 - val_true_positives: 38839240.0000 - val_false_positives: 8306769.0000 - val_true_negatives: 52484908.0000 - val_false_negatives: 6340797.0000 - val_precision: 0.8238 - val_recall: 0.8597\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0805 - accuracy: 0.8692 - binary_iou: 0.7619 - true_positives: 108503840.0000 - false_positives: 19143860.0000 - true_negatives: 169210224.0000 - false_negatives: 22662762.0000 - precision: 0.8500 - recall: 0.8272 - val_loss: 0.0967 - val_accuracy: 0.8472 - val_binary_iou: 0.7338 - val_true_positives: 40768900.0000 - val_false_positives: 11939663.0000 - val_true_negatives: 49015408.0000 - val_false_negatives: 4247704.0000 - val_precision: 0.7735 - val_recall: 0.9056\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 132s 333ms/step - loss: 0.0795 - accuracy: 0.8707 - binary_iou: 0.7643 - true_positives: 108716080.0000 - false_positives: 18938558.0000 - true_negatives: 169478768.0000 - false_negatives: 22387304.0000 - precision: 0.8516 - recall: 0.8292 - val_loss: 0.1078 - val_accuracy: 0.8230 - val_binary_iou: 0.6988 - val_true_positives: 41153548.0000 - val_false_positives: 14788690.0000 - val_true_negatives: 46060360.0000 - val_false_negatives: 3969113.0000 - val_precision: 0.7356 - val_recall: 0.9120\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0801 - accuracy: 0.8702 - binary_iou: 0.7636 - true_positives: 108823816.0000 - false_positives: 19210666.0000 - true_negatives: 169220608.0000 - false_negatives: 22265680.0000 - precision: 0.8500 - recall: 0.8301 - val_loss: 0.0927 - val_accuracy: 0.8444 - val_binary_iou: 0.7203 - val_true_positives: 32952966.0000 - val_false_positives: 4359997.0000 - val_true_negatives: 56526712.0000 - val_false_negatives: 12132058.0000 - val_precision: 0.8832 - val_recall: 0.7309\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0790 - accuracy: 0.8721 - binary_iou: 0.7667 - true_positives: 109167728.0000 - false_positives: 18871536.0000 - true_negatives: 169501680.0000 - false_negatives: 21979664.0000 - precision: 0.8526 - recall: 0.8324 - val_loss: 0.0850 - val_accuracy: 0.8600 - val_binary_iou: 0.7507 - val_true_positives: 38290392.0000 - val_false_positives: 8004973.0000 - val_true_negatives: 52842848.0000 - val_false_negatives: 6833502.0000 - val_precision: 0.8271 - val_recall: 0.8486\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0791 - accuracy: 0.8710 - binary_iou: 0.7649 - true_positives: 108841576.0000 - false_positives: 18948360.0000 - true_negatives: 169474752.0000 - false_negatives: 22256104.0000 - precision: 0.8517 - recall: 0.8302 - val_loss: 0.0908 - val_accuracy: 0.8506 - val_binary_iou: 0.7392 - val_true_positives: 41490552.0000 - val_false_positives: 12217507.0000 - val_true_negatives: 48650728.0000 - val_false_negatives: 3612923.0000 - val_precision: 0.7725 - val_recall: 0.9199\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.8688 - val_binary_iou: 0.7620 - val_true_positives: 36486688.0000 - val_false_positives: 5333113.0000 - val_true_negatives: 55582152.0000 - val_false_negatives: 8569759.0000 - val_precision: 0.8725 - val_recall: 0.8098\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.8727 - val_binary_iou: 0.7702 - val_true_positives: 38349988.0000 - val_false_positives: 6743923.0000 - val_true_negatives: 54133528.0000 - val_false_negatives: 6744254.0000 - val_precision: 0.8504 - val_recall: 0.8504\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348 - val_loss: 0.0788 - val_accuracy: 0.8748 - val_binary_iou: 0.7732 - val_true_positives: 38262152.0000 - val_false_positives: 6452901.0000 - val_true_negatives: 54439296.0000 - val_false_negatives: 6817371.0000 - val_precision: 0.8557 - val_recall: 0.8488\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0770 - accuracy: 0.8750 - binary_iou: 0.7714 - true_positives: 109860424.0000 - false_positives: 18651358.0000 - true_negatives: 169709808.0000 - false_negatives: 21299248.0000 - precision: 0.8549 - recall: 0.8376 - val_loss: 0.1144 - val_accuracy: 0.8331 - val_binary_iou: 0.7128 - val_true_positives: 40152272.0000 - val_false_positives: 12796243.0000 - val_true_negatives: 48135368.0000 - val_false_negatives: 4887845.0000 - val_precision: 0.7583 - val_recall: 0.8915\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351 - val_loss: 0.0760 - val_accuracy: 0.8774 - val_binary_iou: 0.7753 - val_true_positives: 36616788.0000 - val_false_positives: 4558136.0000 - val_true_negatives: 56358976.0000 - val_false_negatives: 8437822.0000 - val_precision: 0.8893 - val_recall: 0.8127\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0768 - accuracy: 0.8754 - binary_iou: 0.7720 - true_positives: 109704112.0000 - false_positives: 18303342.0000 - true_negatives: 170015376.0000 - false_negatives: 21497948.0000 - precision: 0.8570 - recall: 0.8361 - val_loss: 0.0893 - val_accuracy: 0.8511 - val_binary_iou: 0.7392 - val_true_positives: 40275688.0000 - val_false_positives: 11033940.0000 - val_true_negatives: 49917440.0000 - val_false_negatives: 4744650.0000 - val_precision: 0.7850 - val_recall: 0.8946\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0759 - accuracy: 0.8769 - binary_iou: 0.7744 - true_positives: 109680688.0000 - false_positives: 17862716.0000 - true_negatives: 170521232.0000 - false_negatives: 21456152.0000 - precision: 0.8599 - recall: 0.8364 - val_loss: 0.1278 - val_accuracy: 0.7639 - val_binary_iou: 0.5848 - val_true_positives: 21954286.0000 - val_false_positives: 1845093.0000 - val_true_negatives: 58996816.0000 - val_false_negatives: 23175526.0000 - val_precision: 0.9225 - val_recall: 0.4865\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0763 - accuracy: 0.8771 - binary_iou: 0.7746 - true_positives: 109722248.0000 - false_positives: 17865852.0000 - true_negatives: 170533120.0000 - false_negatives: 21399564.0000 - precision: 0.8600 - recall: 0.8368 - val_loss: 0.0804 - val_accuracy: 0.8689 - val_binary_iou: 0.7605 - val_true_positives: 35240620.0000 - val_false_positives: 4020838.0000 - val_true_negatives: 56843064.0000 - val_false_negatives: 9867173.0000 - val_precision: 0.8976 - val_recall: 0.7813\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0752 - accuracy: 0.8781 - binary_iou: 0.7763 - true_positives: 109918400.0000 - false_positives: 17765496.0000 - true_negatives: 170650224.0000 - false_negatives: 21186664.0000 - precision: 0.8609 - recall: 0.8384 - val_loss: 0.0844 - val_accuracy: 0.8658 - val_binary_iou: 0.7554 - val_true_positives: 35053628.0000 - val_false_positives: 4161809.0000 - val_true_negatives: 56692608.0000 - val_false_negatives: 10063672.0000 - val_precision: 0.8939 - val_recall: 0.7769\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0756 - accuracy: 0.8780 - binary_iou: 0.7762 - true_positives: 109991488.0000 - false_positives: 17822768.0000 - true_negatives: 170557728.0000 - false_negatives: 21148782.0000 - precision: 0.8606 - recall: 0.8387 - val_loss: 0.0847 - val_accuracy: 0.8642 - val_binary_iou: 0.7593 - val_true_positives: 40863752.0000 - val_false_positives: 10137314.0000 - val_true_negatives: 50722208.0000 - val_false_negatives: 4248468.0000 - val_precision: 0.8012 - val_recall: 0.9058\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0755 - accuracy: 0.8783 - binary_iou: 0.7766 - true_positives: 110056080.0000 - false_positives: 17851890.0000 - true_negatives: 170569152.0000 - false_negatives: 21043648.0000 - precision: 0.8604 - recall: 0.8395 - val_loss: 0.0940 - val_accuracy: 0.8438 - val_binary_iou: 0.7149 - val_true_positives: 30703540.0000 - val_false_positives: 2279773.0000 - val_true_negatives: 58713400.0000 - val_false_negatives: 14274987.0000 - val_precision: 0.9309 - val_recall: 0.6826\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0748 - accuracy: 0.8801 - binary_iou: 0.7794 - true_positives: 110202584.0000 - false_positives: 17466404.0000 - true_negatives: 170994736.0000 - false_negatives: 20856996.0000 - precision: 0.8632 - recall: 0.8409 - val_loss: 0.0782 - val_accuracy: 0.8715 - val_binary_iou: 0.7644 - val_true_positives: 35198112.0000 - val_false_positives: 3698824.0000 - val_true_negatives: 57161548.0000 - val_false_negatives: 9913227.0000 - val_precision: 0.9049 - val_recall: 0.7802\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0746 - accuracy: 0.8794 - binary_iou: 0.7784 - true_positives: 110242680.0000 - false_positives: 17726232.0000 - true_negatives: 170747120.0000 - false_negatives: 20804768.0000 - precision: 0.8615 - recall: 0.8412 - val_loss: 0.0825 - val_accuracy: 0.8634 - val_binary_iou: 0.7571 - val_true_positives: 39490388.0000 - val_false_positives: 8987308.0000 - val_true_negatives: 52010136.0000 - val_false_negatives: 5483891.0000 - val_precision: 0.8146 - val_recall: 0.8781\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0738 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110744256.0000 - false_positives: 17311324.0000 - true_negatives: 171002512.0000 - false_negatives: 20462732.0000 - precision: 0.8648 - recall: 0.8440 - val_loss: 0.0911 - val_accuracy: 0.8514 - val_binary_iou: 0.7390 - val_true_positives: 39461084.0000 - val_false_positives: 10119243.0000 - val_true_negatives: 50764184.0000 - val_false_negatives: 5627177.0000 - val_precision: 0.7959 - val_recall: 0.8752\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0740 - accuracy: 0.8811 - binary_iou: 0.7813 - true_positives: 110620672.0000 - false_positives: 17410712.0000 - true_negatives: 170911776.0000 - false_negatives: 20577528.0000 - precision: 0.8640 - recall: 0.8432 - val_loss: 0.0893 - val_accuracy: 0.8568 - val_binary_iou: 0.7480 - val_true_positives: 40675372.0000 - val_false_positives: 10765509.0000 - val_true_negatives: 50123008.0000 - val_false_negatives: 4407833.0000 - val_precision: 0.7907 - val_recall: 0.9022\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0741 - accuracy: 0.8810 - binary_iou: 0.7810 - true_positives: 110477176.0000 - false_positives: 17368754.0000 - true_negatives: 171013616.0000 - false_negatives: 20661116.0000 - precision: 0.8641 - recall: 0.8424 - val_loss: 0.0915 - val_accuracy: 0.8609 - val_binary_iou: 0.7545 - val_true_positives: 41110948.0000 - val_false_positives: 10759448.0000 - val_true_negatives: 50124624.0000 - val_false_negatives: 3976692.0000 - val_precision: 0.7926 - val_recall: 0.9118\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110759184.0000 - false_positives: 17434206.0000 - true_negatives: 170991264.0000 - false_negatives: 20336120.0000 - precision: 0.8640 - recall: 0.8449 - val_loss: 0.0767 - val_accuracy: 0.8763 - val_binary_iou: 0.7738 - val_true_positives: 36665456.0000 - val_false_positives: 4793163.0000 - val_true_negatives: 56202104.0000 - val_false_negatives: 8311005.0000 - val_precision: 0.8844 - val_recall: 0.8152\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0732 - accuracy: 0.8824 - binary_iou: 0.7833 - true_positives: 110589928.0000 - false_positives: 17049368.0000 - true_negatives: 171352096.0000 - false_negatives: 20529470.0000 - precision: 0.8664 - recall: 0.8434 - val_loss: 0.3467 - val_accuracy: 0.6217 - val_binary_iou: 0.3609 - val_true_positives: 5513703.0000 - val_false_positives: 492476.0000 - val_true_negatives: 60369508.0000 - val_false_negatives: 39596012.0000 - val_precision: 0.9180 - val_recall: 0.1222\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0728 - accuracy: 0.8823 - binary_iou: 0.7831 - true_positives: 110610448.0000 - false_positives: 17153838.0000 - true_negatives: 171295808.0000 - false_negatives: 20460704.0000 - precision: 0.8657 - recall: 0.8439 - val_loss: 0.1083 - val_accuracy: 0.8334 - val_binary_iou: 0.7133 - val_true_positives: 40344744.0000 - val_false_positives: 12932603.0000 - val_true_negatives: 47975588.0000 - val_false_negatives: 4718782.0000 - val_precision: 0.7573 - val_recall: 0.8953\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448 - val_loss: 0.0720 - val_accuracy: 0.8834 - val_binary_iou: 0.7860 - val_true_positives: 37677948.0000 - val_false_positives: 4890033.0000 - val_true_negatives: 55932928.0000 - val_false_negatives: 7470800.0000 - val_precision: 0.8851 - val_recall: 0.8345\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7851 - true_positives: 110872664.0000 - false_positives: 16952142.0000 - true_negatives: 171421840.0000 - false_negatives: 20274174.0000 - precision: 0.8674 - recall: 0.8454 - val_loss: 0.0791 - val_accuracy: 0.8718 - val_binary_iou: 0.7701 - val_true_positives: 39755304.0000 - val_false_positives: 8201396.0000 - val_true_negatives: 52630668.0000 - val_false_negatives: 5384339.0000 - val_precision: 0.8290 - val_recall: 0.8807\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0720 - accuracy: 0.8844 - binary_iou: 0.7866 - true_positives: 111036360.0000 - false_positives: 16833284.0000 - true_negatives: 171542160.0000 - false_negatives: 20108824.0000 - precision: 0.8684 - recall: 0.8467 - val_loss: 0.0752 - val_accuracy: 0.8761 - val_binary_iou: 0.7749 - val_true_positives: 37911000.0000 - val_false_positives: 6057223.0000 - val_true_negatives: 54926472.0000 - val_false_negatives: 7077021.0000 - val_precision: 0.8622 - val_recall: 0.8427\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473 - val_loss: 0.0718 - val_accuracy: 0.8838 - val_binary_iou: 0.7886 - val_true_positives: 39486004.0000 - val_false_positives: 6718828.0000 - val_true_negatives: 54175552.0000 - val_false_negatives: 5591349.0000 - val_precision: 0.8546 - val_recall: 0.8760\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0711 - accuracy: 0.8859 - binary_iou: 0.7891 - true_positives: 111437792.0000 - false_positives: 16779652.0000 - true_negatives: 171621232.0000 - false_negatives: 19682034.0000 - precision: 0.8691 - recall: 0.8499 - val_loss: 0.0789 - val_accuracy: 0.8750 - val_binary_iou: 0.7750 - val_true_positives: 39677440.0000 - val_false_positives: 7832372.0000 - val_true_negatives: 53050432.0000 - val_false_negatives: 5411455.0000 - val_precision: 0.8351 - val_recall: 0.8800\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0723 - accuracy: 0.8840 - binary_iou: 0.7860 - true_positives: 110917688.0000 - false_positives: 16858026.0000 - true_negatives: 171550656.0000 - false_negatives: 20194422.0000 - precision: 0.8681 - recall: 0.8460 - val_loss: 0.0761 - val_accuracy: 0.8785 - val_binary_iou: 0.7793 - val_true_positives: 38523632.0000 - val_false_positives: 6267567.0000 - val_true_negatives: 54571044.0000 - val_false_negatives: 6609449.0000 - val_precision: 0.8601 - val_recall: 0.8536\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.0713 - accuracy: 0.8857 - binary_iou: 0.7888 - true_positives: 111161040.0000 - false_positives: 16627165.0000 - true_negatives: 171846624.0000 - false_negatives: 19886010.0000 - precision: 0.8699 - recall: 0.8483 - val_loss: 0.0784 - val_accuracy: 0.8712 - val_binary_iou: 0.7654 - val_true_positives: 36260056.0000 - val_false_positives: 4831201.0000 - val_true_negatives: 56061988.0000 - val_false_negatives: 8818443.0000 - val_precision: 0.8824 - val_recall: 0.8044\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0713 - accuracy: 0.8850 - binary_iou: 0.7875 - true_positives: 110992376.0000 - false_positives: 16666216.0000 - true_negatives: 171785184.0000 - false_negatives: 20076980.0000 - precision: 0.8694 - recall: 0.8468 - val_loss: 0.0749 - val_accuracy: 0.8792 - val_binary_iou: 0.7783 - val_true_positives: 36636472.0000 - val_false_positives: 4348723.0000 - val_true_negatives: 56539000.0000 - val_false_negatives: 8447519.0000 - val_precision: 0.8939 - val_recall: 0.8126\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0712 - accuracy: 0.8865 - binary_iou: 0.7901 - true_positives: 111404088.0000 - false_positives: 16538362.0000 - true_negatives: 171853856.0000 - false_negatives: 19724452.0000 - precision: 0.8707 - recall: 0.8496 - val_loss: 0.0919 - val_accuracy: 0.8460 - val_binary_iou: 0.7183 - val_true_positives: 30782204.0000 - val_false_positives: 1975765.0000 - val_true_negatives: 58874352.0000 - val_false_negatives: 14339410.0000 - val_precision: 0.9397 - val_recall: 0.6822\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0705 - accuracy: 0.8877 - binary_iou: 0.7921 - true_positives: 111597744.0000 - false_positives: 16313104.0000 - true_negatives: 172038480.0000 - false_negatives: 19571406.0000 - precision: 0.8725 - recall: 0.8508 - val_loss: 0.0778 - val_accuracy: 0.8731 - val_binary_iou: 0.7718 - val_true_positives: 39438596.0000 - val_false_positives: 7786716.0000 - val_true_negatives: 53084064.0000 - val_false_negatives: 5662343.0000 - val_precision: 0.8351 - val_recall: 0.8745\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0707 - accuracy: 0.8871 - binary_iou: 0.7910 - true_positives: 111379944.0000 - false_positives: 16308250.0000 - true_negatives: 172061968.0000 - false_negatives: 19770506.0000 - precision: 0.8723 - recall: 0.8493 - val_loss: 0.0848 - val_accuracy: 0.8574 - val_binary_iou: 0.7399 - val_true_positives: 33218982.0000 - val_false_positives: 3312352.0000 - val_true_negatives: 57644400.0000 - val_false_negatives: 11795967.0000 - val_precision: 0.9093 - val_recall: 0.7380\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0705 - accuracy: 0.8872 - binary_iou: 0.7912 - true_positives: 111304640.0000 - false_positives: 16271008.0000 - true_negatives: 172181952.0000 - false_negatives: 19763074.0000 - precision: 0.8725 - recall: 0.8492 - val_loss: 0.0780 - val_accuracy: 0.8788 - val_binary_iou: 0.7815 - val_true_positives: 40363296.0000 - val_false_positives: 8102494.0000 - val_true_negatives: 52768896.0000 - val_false_negatives: 4737019.0000 - val_precision: 0.8328 - val_recall: 0.8950\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0703 - accuracy: 0.8879 - binary_iou: 0.7923 - true_positives: 111497272.0000 - false_positives: 16185796.0000 - true_negatives: 172192080.0000 - false_negatives: 19645634.0000 - precision: 0.8732 - recall: 0.8502 - val_loss: 0.0729 - val_accuracy: 0.8834 - val_binary_iou: 0.7850 - val_true_positives: 36861128.0000 - val_false_positives: 4175830.0000 - val_true_negatives: 56752168.0000 - val_false_negatives: 8182607.0000 - val_precision: 0.8982 - val_recall: 0.8183\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0702 - accuracy: 0.8878 - binary_iou: 0.7922 - true_positives: 111428296.0000 - false_positives: 16189002.0000 - true_negatives: 172243248.0000 - false_negatives: 19660228.0000 - precision: 0.8731 - recall: 0.8500 - val_loss: 0.0748 - val_accuracy: 0.8787 - val_binary_iou: 0.7808 - val_true_positives: 39858764.0000 - val_false_positives: 7576542.0000 - val_true_negatives: 53255492.0000 - val_false_negatives: 5280936.0000 - val_precision: 0.8403 - val_recall: 0.8830\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0699 - accuracy: 0.8884 - binary_iou: 0.7932 - true_positives: 111605032.0000 - false_positives: 16211818.0000 - true_negatives: 172253808.0000 - false_negatives: 19450116.0000 - precision: 0.8732 - recall: 0.8516 - val_loss: 0.0724 - val_accuracy: 0.8823 - val_binary_iou: 0.7848 - val_true_positives: 38025824.0000 - val_false_positives: 5357245.0000 - val_true_negatives: 55475288.0000 - val_false_negatives: 7113354.0000 - val_precision: 0.8765 - val_recall: 0.8424\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514 - val_loss: 0.0719 - val_accuracy: 0.8857 - val_binary_iou: 0.7920 - val_true_positives: 40008660.0000 - val_false_positives: 6950614.0000 - val_true_negatives: 53851884.0000 - val_false_negatives: 5160537.0000 - val_precision: 0.8520 - val_recall: 0.8858\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111832104.0000 - false_positives: 16087610.0000 - true_negatives: 172342992.0000 - false_negatives: 19257988.0000 - precision: 0.8742 - recall: 0.8531 - val_loss: 0.0860 - val_accuracy: 0.8592 - val_binary_iou: 0.7425 - val_true_positives: 33238404.0000 - val_false_positives: 3034032.0000 - val_true_negatives: 57809696.0000 - val_false_negatives: 11889571.0000 - val_precision: 0.9164 - val_recall: 0.7365\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111810888.0000 - false_positives: 16032721.0000 - true_negatives: 172367728.0000 - false_negatives: 19309438.0000 - precision: 0.8746 - recall: 0.8527 - val_loss: 0.0795 - val_accuracy: 0.8735 - val_binary_iou: 0.7676 - val_true_positives: 35400352.0000 - val_false_positives: 3689432.0000 - val_true_negatives: 57161040.0000 - val_false_negatives: 9720906.0000 - val_precision: 0.9056 - val_recall: 0.7846\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0695 - accuracy: 0.8884 - binary_iou: 0.7933 - true_positives: 111689736.0000 - false_positives: 16202075.0000 - true_negatives: 172186048.0000 - false_negatives: 19442862.0000 - precision: 0.8733 - recall: 0.8517 - val_loss: 0.0758 - val_accuracy: 0.8776 - val_binary_iou: 0.7791 - val_true_positives: 39693812.0000 - val_false_positives: 7559088.0000 - val_true_negatives: 53310804.0000 - val_false_negatives: 5407998.0000 - val_precision: 0.8400 - val_recall: 0.8801\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0689 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 111939024.0000 - false_positives: 15899358.0000 - true_negatives: 172475312.0000 - false_negatives: 19207072.0000 - precision: 0.8756 - recall: 0.8535 - val_loss: 0.1359 - val_accuracy: 0.7880 - val_binary_iou: 0.6222 - val_true_positives: 24266056.0000 - val_false_positives: 1582781.0000 - val_true_negatives: 59243448.0000 - val_false_negatives: 20879408.0000 - val_precision: 0.9388 - val_recall: 0.5375\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 428ms/step - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537 - val_loss: 0.0701 - val_accuracy: 0.8880 - val_binary_iou: 0.7950 - val_true_positives: 39279140.0000 - val_false_positives: 6042733.0000 - val_true_negatives: 54825964.0000 - val_false_negatives: 5823879.0000 - val_precision: 0.8667 - val_recall: 0.8709\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0688 - accuracy: 0.8901 - binary_iou: 0.7960 - true_positives: 111865480.0000 - false_positives: 15830442.0000 - true_negatives: 172532208.0000 - false_negatives: 19292612.0000 - precision: 0.8760 - recall: 0.8529 - val_loss: 0.0774 - val_accuracy: 0.8784 - val_binary_iou: 0.7808 - val_true_positives: 40402348.0000 - val_false_positives: 8221260.0000 - val_true_negatives: 52680000.0000 - val_false_negatives: 4668108.0000 - val_precision: 0.8309 - val_recall: 0.8964\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0690 - accuracy: 0.8891 - binary_iou: 0.7944 - true_positives: 111709696.0000 - false_positives: 15976760.0000 - true_negatives: 172388368.0000 - false_negatives: 19445922.0000 - precision: 0.8749 - recall: 0.8517 - val_loss: 0.0803 - val_accuracy: 0.8730 - val_binary_iou: 0.7725 - val_true_positives: 40478668.0000 - val_false_positives: 8900463.0000 - val_true_negatives: 52034368.0000 - val_false_negatives: 4558195.0000 - val_precision: 0.8198 - val_recall: 0.8988\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0688 - accuracy: 0.8902 - binary_iou: 0.7962 - true_positives: 111886672.0000 - false_positives: 15776121.0000 - true_negatives: 172563696.0000 - false_negatives: 19294172.0000 - precision: 0.8764 - recall: 0.8529 - val_loss: 0.0752 - val_accuracy: 0.8810 - val_binary_iou: 0.7845 - val_true_positives: 39947648.0000 - val_false_positives: 7431002.0000 - val_true_negatives: 53413960.0000 - val_false_negatives: 5179119.0000 - val_precision: 0.8432 - val_recall: 0.8852\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0691 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111791048.0000 - false_positives: 16044969.0000 - true_negatives: 172387392.0000 - false_negatives: 19297388.0000 - precision: 0.8745 - recall: 0.8528 - val_loss: 0.0951 - val_accuracy: 0.8679 - val_binary_iou: 0.7649 - val_true_positives: 40768648.0000 - val_false_positives: 9800652.0000 - val_true_negatives: 51205848.0000 - val_false_negatives: 4196562.0000 - val_precision: 0.8062 - val_recall: 0.9067\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0686 - accuracy: 0.8903 - binary_iou: 0.7963 - true_positives: 112000912.0000 - false_positives: 15904758.0000 - true_negatives: 172459744.0000 - false_negatives: 19155282.0000 - precision: 0.8757 - recall: 0.8540 - val_loss: 0.0771 - val_accuracy: 0.8741 - val_binary_iou: 0.7688 - val_true_positives: 35527912.0000 - val_false_positives: 3736203.0000 - val_true_negatives: 57103272.0000 - val_false_negatives: 9604338.0000 - val_precision: 0.9048 - val_recall: 0.7872\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0678 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112179992.0000 - false_positives: 15409854.0000 - true_negatives: 173029520.0000 - false_negatives: 18901586.0000 - precision: 0.8792 - recall: 0.8558 - val_loss: 0.0724 - val_accuracy: 0.8848 - val_binary_iou: 0.7907 - val_true_positives: 40174352.0000 - val_false_positives: 7346762.0000 - val_true_negatives: 53591184.0000 - val_false_negatives: 4859408.0000 - val_precision: 0.8454 - val_recall: 0.8921\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 171s 429ms/step - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540 - val_loss: 0.0689 - val_accuracy: 0.8901 - val_binary_iou: 0.7975 - val_true_positives: 38453356.0000 - val_false_positives: 4979271.0000 - val_true_negatives: 55869972.0000 - val_false_negatives: 6669114.0000 - val_precision: 0.8854 - val_recall: 0.8522\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 160s 402ms/step - loss: 0.0682 - accuracy: 0.8911 - binary_iou: 0.7976 - true_positives: 112027632.0000 - false_positives: 15746636.0000 - true_negatives: 172694192.0000 - false_negatives: 19052250.0000 - precision: 0.8768 - recall: 0.8547 - val_loss: 0.0703 - val_accuracy: 0.8876 - val_binary_iou: 0.7944 - val_true_positives: 39253120.0000 - val_false_positives: 6203339.0000 - val_true_negatives: 54812624.0000 - val_false_negatives: 5702634.0000 - val_precision: 0.8635 - val_recall: 0.8732\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0678 - accuracy: 0.8924 - binary_iou: 0.7998 - true_positives: 112174480.0000 - false_positives: 15427345.0000 - true_negatives: 172958144.0000 - false_negatives: 18960760.0000 - precision: 0.8791 - recall: 0.8554 - val_loss: 0.0714 - val_accuracy: 0.8860 - val_binary_iou: 0.7922 - val_true_positives: 39661624.0000 - val_false_positives: 6618287.0000 - val_true_negatives: 54230892.0000 - val_false_negatives: 5460903.0000 - val_precision: 0.8570 - val_recall: 0.8790\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0676 - accuracy: 0.8918 - binary_iou: 0.7988 - true_positives: 112268576.0000 - false_positives: 15669733.0000 - true_negatives: 172670096.0000 - false_negatives: 18912436.0000 - precision: 0.8775 - recall: 0.8558 - val_loss: 0.0768 - val_accuracy: 0.8799 - val_binary_iou: 0.7831 - val_true_positives: 40321992.0000 - val_false_positives: 7994599.0000 - val_true_negatives: 52923220.0000 - val_false_negatives: 4731924.0000 - val_precision: 0.8345 - val_recall: 0.8950\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 135s 338ms/step - loss: 0.0672 - accuracy: 0.8930 - binary_iou: 0.8009 - true_positives: 112414688.0000 - false_positives: 15411543.0000 - true_negatives: 172917456.0000 - false_negatives: 18777054.0000 - precision: 0.8794 - recall: 0.8569 - val_loss: 0.1484 - val_accuracy: 0.7818 - val_binary_iou: 0.6113 - val_true_positives: 23371532.0000 - val_false_positives: 1365110.0000 - val_true_negatives: 59475000.0000 - val_false_negatives: 21760066.0000 - val_precision: 0.9448 - val_recall: 0.5179\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0670 - accuracy: 0.8930 - binary_iou: 0.8007 - true_positives: 112071688.0000 - false_positives: 15228398.0000 - true_negatives: 173257568.0000 - false_negatives: 18963102.0000 - precision: 0.8804 - recall: 0.8553 - val_loss: 0.0730 - val_accuracy: 0.8837 - val_binary_iou: 0.7859 - val_true_positives: 37128412.0000 - val_false_positives: 4391111.0000 - val_true_negatives: 56520536.0000 - val_false_negatives: 7931644.0000 - val_precision: 0.8942 - val_recall: 0.8240\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 427ms/step - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554 - val_loss: 0.0678 - val_accuracy: 0.8915 - val_binary_iou: 0.7994 - val_true_positives: 38122228.0000 - val_false_positives: 4515762.0000 - val_true_negatives: 56352220.0000 - val_false_negatives: 6981488.0000 - val_precision: 0.8941 - val_recall: 0.8452\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 133s 333ms/step - loss: 0.0669 - accuracy: 0.8936 - binary_iou: 0.8018 - true_positives: 112442640.0000 - false_positives: 15260840.0000 - true_negatives: 173075456.0000 - false_negatives: 18741888.0000 - precision: 0.8805 - recall: 0.8571 - val_loss: 0.0707 - val_accuracy: 0.8882 - val_binary_iou: 0.7955 - val_true_positives: 39381688.0000 - val_false_positives: 6069700.0000 - val_true_negatives: 54746240.0000 - val_false_negatives: 5774078.0000 - val_precision: 0.8665 - val_recall: 0.8721\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0668 - accuracy: 0.8932 - binary_iou: 0.8013 - true_positives: 112449040.0000 - false_positives: 15470578.0000 - true_negatives: 172959840.0000 - false_negatives: 18641352.0000 - precision: 0.8791 - recall: 0.8578 - val_loss: 0.0734 - val_accuracy: 0.8809 - val_binary_iou: 0.7799 - val_true_positives: 35980932.0000 - val_false_positives: 3395829.0000 - val_true_negatives: 57365376.0000 - val_false_negatives: 9229588.0000 - val_precision: 0.9138 - val_recall: 0.7959\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8015 - true_positives: 112170456.0000 - false_positives: 15109560.0000 - true_negatives: 173310432.0000 - false_negatives: 18930238.0000 - precision: 0.8813 - recall: 0.8556 - val_loss: 0.0687 - val_accuracy: 0.8896 - val_binary_iou: 0.7965 - val_true_positives: 38277924.0000 - val_false_positives: 4777362.0000 - val_true_negatives: 55992768.0000 - val_false_negatives: 6923645.0000 - val_precision: 0.8890 - val_recall: 0.8468\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0665 - accuracy: 0.8945 - binary_iou: 0.8033 - true_positives: 112567264.0000 - false_positives: 15171494.0000 - true_negatives: 173237200.0000 - false_negatives: 18544780.0000 - precision: 0.8812 - recall: 0.8586 - val_loss: 0.1019 - val_accuracy: 0.8186 - val_binary_iou: 0.6723 - val_true_positives: 27651104.0000 - val_false_positives: 1777387.0000 - val_true_negatives: 59099132.0000 - val_false_negatives: 17444088.0000 - val_precision: 0.9396 - val_recall: 0.6132\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0674 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112299664.0000 - false_positives: 15546087.0000 - true_negatives: 172895488.0000 - false_negatives: 18779640.0000 - precision: 0.8784 - recall: 0.8567 - val_loss: 0.0816 - val_accuracy: 0.8774 - val_binary_iou: 0.7792 - val_true_positives: 40354892.0000 - val_false_positives: 8312571.0000 - val_true_negatives: 52624612.0000 - val_false_negatives: 4679636.0000 - val_precision: 0.8292 - val_recall: 0.8961\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0667 - accuracy: 0.8937 - binary_iou: 0.8020 - true_positives: 112282648.0000 - false_positives: 15109516.0000 - true_negatives: 173280112.0000 - false_negatives: 18848368.0000 - precision: 0.8814 - recall: 0.8563 - val_loss: 0.0783 - val_accuracy: 0.8691 - val_binary_iou: 0.7659 - val_true_positives: 39678192.0000 - val_false_positives: 8383734.0000 - val_true_negatives: 52426100.0000 - val_false_negatives: 5483700.0000 - val_precision: 0.8256 - val_recall: 0.8786\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8018 - true_positives: 112706776.0000 - false_positives: 15555337.0000 - true_negatives: 172791440.0000 - false_negatives: 18467180.0000 - precision: 0.8787 - recall: 0.8592 - val_loss: 0.0741 - val_accuracy: 0.8826 - val_binary_iou: 0.7877 - val_true_positives: 40878036.0000 - val_false_positives: 8097197.0000 - val_true_negatives: 52650636.0000 - val_false_negatives: 4345838.0000 - val_precision: 0.8347 - val_recall: 0.9039\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8952 - binary_iou: 0.8046 - true_positives: 112822448.0000 - false_positives: 15160487.0000 - true_negatives: 173219936.0000 - false_negatives: 18317834.0000 - precision: 0.8815 - recall: 0.8603 - val_loss: 0.0712 - val_accuracy: 0.8861 - val_binary_iou: 0.7889 - val_true_positives: 36594128.0000 - val_false_positives: 3547294.0000 - val_true_negatives: 57302372.0000 - val_false_negatives: 8527889.0000 - val_precision: 0.9116 - val_recall: 0.8110\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0661 - accuracy: 0.8949 - binary_iou: 0.8041 - true_positives: 112634032.0000 - false_positives: 15075881.0000 - true_negatives: 173317312.0000 - false_negatives: 18493656.0000 - precision: 0.8820 - recall: 0.8590 - val_loss: 0.1567 - val_accuracy: 0.7551 - val_binary_iou: 0.5705 - val_true_positives: 20908572.0000 - val_false_positives: 1721498.0000 - val_true_negatives: 59106516.0000 - val_false_negatives: 24235132.0000 - val_precision: 0.9239 - val_recall: 0.4632\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8953 - binary_iou: 0.8046 - true_positives: 112573032.0000 - false_positives: 14919423.0000 - true_negatives: 173497088.0000 - false_negatives: 18531148.0000 - precision: 0.8830 - recall: 0.8587 - val_loss: 0.0721 - val_accuracy: 0.8864 - val_binary_iou: 0.7910 - val_true_positives: 37871184.0000 - val_false_positives: 4839935.0000 - val_true_negatives: 56064496.0000 - val_false_negatives: 7196119.0000 - val_precision: 0.8867 - val_recall: 0.8403\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0654 - accuracy: 0.8963 - binary_iou: 0.8064 - true_positives: 112841192.0000 - false_positives: 14810634.0000 - true_negatives: 173555312.0000 - false_negatives: 18313536.0000 - precision: 0.8840 - recall: 0.8604 - val_loss: 0.0810 - val_accuracy: 0.8655 - val_binary_iou: 0.7549 - val_true_positives: 35077924.0000 - val_false_positives: 4263421.0000 - val_true_negatives: 56635472.0000 - val_false_negatives: 9994884.0000 - val_precision: 0.8916 - val_recall: 0.7783\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0652 - accuracy: 0.8962 - binary_iou: 0.8062 - true_positives: 112972344.0000 - false_positives: 15045884.0000 - true_negatives: 173367568.0000 - false_negatives: 18134990.0000 - precision: 0.8825 - recall: 0.8617 - val_loss: 0.0913 - val_accuracy: 0.8630 - val_binary_iou: 0.7575 - val_true_positives: 40925680.0000 - val_false_positives: 10408766.0000 - val_true_negatives: 50531900.0000 - val_false_negatives: 4105355.0000 - val_precision: 0.7972 - val_recall: 0.9088\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0655 - accuracy: 0.8956 - binary_iou: 0.8053 - true_positives: 112770296.0000 - false_positives: 14935553.0000 - true_negatives: 173408240.0000 - false_negatives: 18406754.0000 - precision: 0.8830 - recall: 0.8597 - val_loss: 0.0681 - val_accuracy: 0.8916 - val_binary_iou: 0.7991 - val_true_positives: 37650052.0000 - val_false_positives: 4016793.0000 - val_true_negatives: 56835504.0000 - val_false_negatives: 7469375.0000 - val_precision: 0.9036 - val_recall: 0.8345\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8965 - binary_iou: 0.8066 - true_positives: 112672744.0000 - false_positives: 14632333.0000 - true_negatives: 173781648.0000 - false_negatives: 18434098.0000 - precision: 0.8851 - recall: 0.8594 - val_loss: 0.0741 - val_accuracy: 0.8843 - val_binary_iou: 0.7891 - val_true_positives: 39229924.0000 - val_false_positives: 6452676.0000 - val_true_negatives: 54484932.0000 - val_false_negatives: 5804178.0000 - val_precision: 0.8587 - val_recall: 0.8711\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0654 - accuracy: 0.8961 - binary_iou: 0.8061 - true_positives: 112790800.0000 - false_positives: 14832199.0000 - true_negatives: 173542400.0000 - false_negatives: 18355386.0000 - precision: 0.8838 - recall: 0.8600 - val_loss: 0.0749 - val_accuracy: 0.8854 - val_binary_iou: 0.7920 - val_true_positives: 40681160.0000 - val_false_positives: 7715254.0000 - val_true_negatives: 53141616.0000 - val_false_negatives: 4433672.0000 - val_precision: 0.8406 - val_recall: 0.9017\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0653 - accuracy: 0.8962 - binary_iou: 0.8061 - true_positives: 112847560.0000 - false_positives: 14876293.0000 - true_negatives: 173496784.0000 - false_negatives: 18300084.0000 - precision: 0.8835 - recall: 0.8605 - val_loss: 0.0764 - val_accuracy: 0.8787 - val_binary_iou: 0.7810 - val_true_positives: 40074776.0000 - val_false_positives: 7857041.0000 - val_true_negatives: 53039168.0000 - val_false_negatives: 5000726.0000 - val_precision: 0.8361 - val_recall: 0.8891\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598 - val_loss: 0.0676 - val_accuracy: 0.8920 - val_binary_iou: 0.8012 - val_true_positives: 39038164.0000 - val_false_positives: 5411304.0000 - val_true_negatives: 55491768.0000 - val_false_negatives: 6030472.0000 - val_precision: 0.8783 - val_recall: 0.8662\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 133s 334ms/step - loss: 0.0649 - accuracy: 0.8968 - binary_iou: 0.8072 - true_positives: 112836920.0000 - false_positives: 14683751.0000 - true_negatives: 173715984.0000 - false_negatives: 18284156.0000 - precision: 0.8849 - recall: 0.8606 - val_loss: 0.0736 - val_accuracy: 0.8828 - val_binary_iou: 0.7850 - val_true_positives: 37599728.0000 - val_false_positives: 4910598.0000 - val_true_negatives: 55953576.0000 - val_false_negatives: 7507811.0000 - val_precision: 0.8845 - val_recall: 0.8336\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0644 - accuracy: 0.8975 - binary_iou: 0.8083 - true_positives: 113073528.0000 - false_positives: 14661790.0000 - true_negatives: 173689344.0000 - false_negatives: 18096160.0000 - precision: 0.8852 - recall: 0.8620 - val_loss: 0.0808 - val_accuracy: 0.8723 - val_binary_iou: 0.7642 - val_true_positives: 34353932.0000 - val_false_positives: 2753126.0000 - val_true_negatives: 58084044.0000 - val_false_negatives: 10780616.0000 - val_precision: 0.9258 - val_recall: 0.7611\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8971 - binary_iou: 0.8076 - true_positives: 112894736.0000 - false_positives: 14678940.0000 - true_negatives: 173739488.0000 - false_negatives: 18207648.0000 - precision: 0.8849 - recall: 0.8611 - val_loss: 0.0691 - val_accuracy: 0.8917 - val_binary_iou: 0.8007 - val_true_positives: 39146796.0000 - val_false_positives: 5586695.0000 - val_true_negatives: 55345212.0000 - val_false_negatives: 5892998.0000 - val_precision: 0.8751 - val_recall: 0.8692\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0648 - accuracy: 0.8970 - binary_iou: 0.8074 - true_positives: 112868432.0000 - false_positives: 14630436.0000 - true_negatives: 173732256.0000 - false_negatives: 18289650.0000 - precision: 0.8853 - recall: 0.8606 - val_loss: 0.0872 - val_accuracy: 0.8663 - val_binary_iou: 0.7620 - val_true_positives: 40245384.0000 - val_false_positives: 9343865.0000 - val_true_negatives: 51557684.0000 - val_false_negatives: 4824793.0000 - val_precision: 0.8116 - val_recall: 0.8929\n",
      "132/132 [==============================] - 45s 317ms/step - loss: 212.9752 - accuracy: 0.8897 - binary_iou: 0.7965 - true_positives: 38099952.0000 - false_positives: 5604668.0000 - true_negatives: 56180072.0000 - false_negatives: 6087014.0000 - precision: 0.8718 - recall: 0.8622\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 185s 442ms/step - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509 - val_loss: 0.1105 - val_accuracy: 0.8061 - val_binary_iou: 0.6605 - val_true_positives: 29558962.0000 - val_false_positives: 5074877.0000 - val_true_negatives: 55861256.0000 - val_false_negatives: 15476612.0000 - val_precision: 0.8535 - val_recall: 0.6563\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0969 - accuracy: 0.8330 - binary_iou: 0.7067 - true_positives: 103866728.0000 - false_positives: 26122214.0000 - true_negatives: 162309504.0000 - false_negatives: 27222196.0000 - precision: 0.7990 - recall: 0.7923 - val_loss: 0.1090 - val_accuracy: 0.7971 - val_binary_iou: 0.6466 - val_true_positives: 28650442.0000 - val_false_positives: 5022378.0000 - val_true_negatives: 55819924.0000 - val_false_negatives: 16478962.0000 - val_precision: 0.8508 - val_recall: 0.6349\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946 - val_loss: 0.1040 - val_accuracy: 0.8304 - val_binary_iou: 0.7052 - val_true_positives: 36088200.0000 - val_false_positives: 8909478.0000 - val_true_negatives: 51910856.0000 - val_false_negatives: 9063180.0000 - val_precision: 0.8020 - val_recall: 0.7993\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036 - val_loss: 0.0947 - val_accuracy: 0.8398 - val_binary_iou: 0.7195 - val_true_positives: 36842232.0000 - val_false_positives: 8677888.0000 - val_true_negatives: 52152584.0000 - val_false_negatives: 8299018.0000 - val_precision: 0.8094 - val_recall: 0.8162\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0914 - accuracy: 0.8468 - binary_iou: 0.7275 - true_positives: 106150000.0000 - false_positives: 23878964.0000 - true_negatives: 164412704.0000 - false_negatives: 25079016.0000 - precision: 0.8164 - recall: 0.8089 - val_loss: 0.1028 - val_accuracy: 0.8082 - val_binary_iou: 0.6639 - val_true_positives: 29808732.0000 - val_false_positives: 5023932.0000 - val_true_negatives: 55838920.0000 - val_false_negatives: 15300131.0000 - val_precision: 0.8558 - val_recall: 0.6608\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109 - val_loss: 0.0844 - val_accuracy: 0.8593 - val_binary_iou: 0.7474 - val_true_positives: 36334244.0000 - val_false_positives: 6082476.0000 - val_true_negatives: 54722900.0000 - val_false_negatives: 8832084.0000 - val_precision: 0.8566 - val_recall: 0.8045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0889 - accuracy: 0.8510 - binary_iou: 0.7339 - true_positives: 106864624.0000 - false_positives: 23327616.0000 - true_negatives: 165044144.0000 - false_negatives: 24284384.0000 - precision: 0.8208 - recall: 0.8148 - val_loss: 0.1001 - val_accuracy: 0.8204 - val_binary_iou: 0.6782 - val_true_positives: 29000756.0000 - val_false_positives: 3039177.0000 - val_true_negatives: 57938184.0000 - val_false_negatives: 15993596.0000 - val_precision: 0.9051 - val_recall: 0.6445\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0877 - accuracy: 0.8533 - binary_iou: 0.7374 - true_positives: 107015776.0000 - false_positives: 22760176.0000 - true_negatives: 165621696.0000 - false_negatives: 24123068.0000 - precision: 0.8246 - recall: 0.8160 - val_loss: 0.0992 - val_accuracy: 0.8232 - val_binary_iou: 0.6827 - val_true_positives: 29234104.0000 - val_false_positives: 2876097.0000 - val_true_negatives: 58006276.0000 - val_false_negatives: 15855237.0000 - val_precision: 0.9104 - val_recall: 0.6484\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0868 - accuracy: 0.8551 - binary_iou: 0.7402 - true_positives: 107298048.0000 - false_positives: 22419816.0000 - true_negatives: 165917520.0000 - false_negatives: 23885356.0000 - precision: 0.8272 - recall: 0.8179 - val_loss: 0.0907 - val_accuracy: 0.8447 - val_binary_iou: 0.7263 - val_true_positives: 36638376.0000 - val_false_positives: 7956607.0000 - val_true_negatives: 52870960.0000 - val_false_negatives: 8505777.0000 - val_precision: 0.8216 - val_recall: 0.8116\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0860 - accuracy: 0.8567 - binary_iou: 0.7427 - true_positives: 107560656.0000 - false_positives: 22263318.0000 - true_negatives: 166169616.0000 - false_negatives: 23527152.0000 - precision: 0.8285 - recall: 0.8205 - val_loss: 0.0871 - val_accuracy: 0.8539 - val_binary_iou: 0.7427 - val_true_positives: 39383768.0000 - val_false_positives: 9782407.0000 - val_true_negatives: 51109704.0000 - val_false_negatives: 5695821.0000 - val_precision: 0.8010 - val_recall: 0.8736\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0840 - accuracy: 0.8601 - binary_iou: 0.7481 - true_positives: 108232024.0000 - false_positives: 21758164.0000 - true_negatives: 166597248.0000 - false_negatives: 22933332.0000 - precision: 0.8326 - recall: 0.8252 - val_loss: 0.0899 - val_accuracy: 0.8479 - val_binary_iou: 0.7261 - val_true_positives: 33317968.0000 - val_false_positives: 4355052.0000 - val_true_negatives: 56538512.0000 - val_false_negatives: 11760183.0000 - val_precision: 0.8844 - val_recall: 0.7391\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262 - val_loss: 0.0843 - val_accuracy: 0.8626 - val_binary_iou: 0.7532 - val_true_positives: 36904740.0000 - val_false_positives: 6333535.0000 - val_true_negatives: 54509848.0000 - val_false_negatives: 8223592.0000 - val_precision: 0.8535 - val_recall: 0.8178\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0827 - accuracy: 0.8639 - binary_iou: 0.7537 - true_positives: 108190992.0000 - false_positives: 20585124.0000 - true_negatives: 167837744.0000 - false_negatives: 22906836.0000 - precision: 0.8401 - recall: 0.8253 - val_loss: 0.0861 - val_accuracy: 0.8567 - val_binary_iou: 0.7439 - val_true_positives: 36617192.0000 - val_false_positives: 6830996.0000 - val_true_negatives: 54164012.0000 - val_false_negatives: 8359509.0000 - val_precision: 0.8428 - val_recall: 0.8141\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304 - val_loss: 0.0832 - val_accuracy: 0.8657 - val_binary_iou: 0.7568 - val_true_positives: 36133160.0000 - val_false_positives: 5289682.0000 - val_true_negatives: 55606572.0000 - val_false_negatives: 8942304.0000 - val_precision: 0.8723 - val_recall: 0.8016\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0805 - accuracy: 0.8679 - binary_iou: 0.7603 - true_positives: 109205312.0000 - false_positives: 20384652.0000 - true_negatives: 168115712.0000 - false_negatives: 21815188.0000 - precision: 0.8427 - recall: 0.8335 - val_loss: 0.0826 - val_accuracy: 0.8640 - val_binary_iou: 0.7537 - val_true_positives: 35741368.0000 - val_false_positives: 5012108.0000 - val_true_negatives: 55818184.0000 - val_false_negatives: 9400030.0000 - val_precision: 0.8770 - val_recall: 0.7918\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0796 - accuracy: 0.8695 - binary_iou: 0.7628 - true_positives: 109519336.0000 - false_positives: 20095204.0000 - true_negatives: 168288400.0000 - false_negatives: 21617852.0000 - precision: 0.8450 - recall: 0.8352 - val_loss: 0.0904 - val_accuracy: 0.8553 - val_binary_iou: 0.7370 - val_true_positives: 33358712.0000 - val_false_positives: 3548969.0000 - val_true_negatives: 57280136.0000 - val_false_negatives: 11783893.0000 - val_precision: 0.9038 - val_recall: 0.7390\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0802 - accuracy: 0.8684 - binary_iou: 0.7611 - true_positives: 109389072.0000 - false_positives: 20335696.0000 - true_negatives: 168089696.0000 - false_negatives: 21706340.0000 - precision: 0.8432 - recall: 0.8344 - val_loss: 0.0819 - val_accuracy: 0.8643 - val_binary_iou: 0.7543 - val_true_positives: 35849168.0000 - val_false_positives: 5100314.0000 - val_true_negatives: 55738372.0000 - val_false_negatives: 9283861.0000 - val_precision: 0.8754 - val_recall: 0.7943\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0787 - accuracy: 0.8711 - binary_iou: 0.7654 - true_positives: 109737320.0000 - false_positives: 19834218.0000 - true_negatives: 168589664.0000 - false_negatives: 21359514.0000 - precision: 0.8469 - recall: 0.8371 - val_loss: 0.0840 - val_accuracy: 0.8606 - val_binary_iou: 0.7474 - val_true_positives: 34968736.0000 - val_false_positives: 4551350.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 10224023.0000 - val_precision: 0.8848 - val_recall: 0.7738\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404 - val_loss: 0.0795 - val_accuracy: 0.8686 - val_binary_iou: 0.7619 - val_true_positives: 36683320.0000 - val_false_positives: 5540348.0000 - val_true_negatives: 55363864.0000 - val_false_negatives: 8384161.0000 - val_precision: 0.8688 - val_recall: 0.8140\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0776 - accuracy: 0.8728 - binary_iou: 0.7680 - true_positives: 109780352.0000 - false_positives: 19325732.0000 - true_negatives: 169090848.0000 - false_negatives: 21323936.0000 - precision: 0.8503 - recall: 0.8374 - val_loss: 0.0809 - val_accuracy: 0.8656 - val_binary_iou: 0.7602 - val_true_positives: 39312376.0000 - val_false_positives: 8557187.0000 - val_true_negatives: 52416080.0000 - val_false_negatives: 5686077.0000 - val_precision: 0.8212 - val_recall: 0.8736\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410 - val_loss: 0.0794 - val_accuracy: 0.8732 - val_binary_iou: 0.7725 - val_true_positives: 40125432.0000 - val_false_positives: 8428567.0000 - val_true_negatives: 52404920.0000 - val_false_negatives: 5012805.0000 - val_precision: 0.8264 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0762 - accuracy: 0.8764 - binary_iou: 0.7739 - true_positives: 110538152.0000 - false_positives: 18913164.0000 - true_negatives: 169494592.0000 - false_negatives: 20574936.0000 - precision: 0.8539 - recall: 0.8431 - val_loss: 0.0951 - val_accuracy: 0.8363 - val_binary_iou: 0.7062 - val_true_positives: 31574824.0000 - val_false_positives: 3741021.0000 - val_true_negatives: 57054612.0000 - val_false_negatives: 13601249.0000 - val_precision: 0.8941 - val_recall: 0.6989\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442 - val_loss: 0.0744 - val_accuracy: 0.8783 - val_binary_iou: 0.7776 - val_true_positives: 37268520.0000 - val_false_positives: 5039199.0000 - val_true_negatives: 55808504.0000 - val_false_negatives: 7855478.0000 - val_precision: 0.8809 - val_recall: 0.8259\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0753 - accuracy: 0.8775 - binary_iou: 0.7757 - true_positives: 110844512.0000 - false_positives: 18808940.0000 - true_negatives: 169537376.0000 - false_negatives: 20330032.0000 - precision: 0.8549 - recall: 0.8450 - val_loss: 0.0757 - val_accuracy: 0.8756 - val_binary_iou: 0.7748 - val_true_positives: 38605216.0000 - val_false_positives: 6663971.0000 - val_true_negatives: 54178532.0000 - val_false_negatives: 6523988.0000 - val_precision: 0.8528 - val_recall: 0.8554\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0744 - accuracy: 0.8792 - binary_iou: 0.7784 - true_positives: 110836560.0000 - false_positives: 18290544.0000 - true_negatives: 170090624.0000 - false_negatives: 20303034.0000 - precision: 0.8584 - recall: 0.8452 - val_loss: 0.0838 - val_accuracy: 0.8686 - val_binary_iou: 0.7643 - val_true_positives: 38808680.0000 - val_false_positives: 7733552.0000 - val_true_negatives: 53238424.0000 - val_false_negatives: 6191043.0000 - val_precision: 0.8338 - val_recall: 0.8624\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455 - val_loss: 0.0743 - val_accuracy: 0.8803 - val_binary_iou: 0.7815 - val_true_positives: 37964788.0000 - val_false_positives: 5535672.0000 - val_true_negatives: 55320728.0000 - val_false_negatives: 7150529.0000 - val_precision: 0.8727 - val_recall: 0.8415\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8807 - binary_iou: 0.7808 - true_positives: 110972968.0000 - false_positives: 17974036.0000 - true_negatives: 170442016.0000 - false_negatives: 20131872.0000 - precision: 0.8606 - recall: 0.8464 - val_loss: 0.0780 - val_accuracy: 0.8706 - val_binary_iou: 0.7684 - val_true_positives: 39906784.0000 - val_false_positives: 8499998.0000 - val_true_negatives: 52356132.0000 - val_false_negatives: 5208790.0000 - val_precision: 0.8244 - val_recall: 0.8845\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0728 - accuracy: 0.8829 - binary_iou: 0.7843 - true_positives: 111373168.0000 - false_positives: 17715180.0000 - true_negatives: 170722176.0000 - false_negatives: 19710296.0000 - precision: 0.8628 - recall: 0.8496 - val_loss: 0.0770 - val_accuracy: 0.8757 - val_binary_iou: 0.7717 - val_true_positives: 35798568.0000 - val_false_positives: 3818787.0000 - val_true_negatives: 57002196.0000 - val_false_negatives: 9352164.0000 - val_precision: 0.9036 - val_recall: 0.7929\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0726 - accuracy: 0.8827 - binary_iou: 0.7841 - true_positives: 111452024.0000 - false_positives: 17798892.0000 - true_negatives: 170586352.0000 - false_negatives: 19683584.0000 - precision: 0.8623 - recall: 0.8499 - val_loss: 0.0810 - val_accuracy: 0.8639 - val_binary_iou: 0.7540 - val_true_positives: 36116544.0000 - val_false_positives: 5372076.0000 - val_true_negatives: 55429736.0000 - val_false_negatives: 9053340.0000 - val_precision: 0.8705 - val_recall: 0.7996\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505 - val_loss: 0.0704 - val_accuracy: 0.8863 - val_binary_iou: 0.7915 - val_true_positives: 38513900.0000 - val_false_positives: 5352287.0000 - val_true_negatives: 55406376.0000 - val_false_negatives: 6699139.0000 - val_precision: 0.8780 - val_recall: 0.8518\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0720 - accuracy: 0.8833 - binary_iou: 0.7852 - true_positives: 111675440.0000 - false_positives: 17808288.0000 - true_negatives: 170566208.0000 - false_negatives: 19470846.0000 - precision: 0.8625 - recall: 0.8515 - val_loss: 0.0821 - val_accuracy: 0.8666 - val_binary_iou: 0.7624 - val_true_positives: 40110328.0000 - val_false_positives: 9223599.0000 - val_true_negatives: 51725288.0000 - val_false_negatives: 4912495.0000 - val_precision: 0.8130 - val_recall: 0.8909\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0706 - accuracy: 0.8862 - binary_iou: 0.7899 - true_positives: 111930336.0000 - false_positives: 17126412.0000 - true_negatives: 171239056.0000 - false_negatives: 19225072.0000 - precision: 0.8673 - recall: 0.8534 - val_loss: 0.0739 - val_accuracy: 0.8792 - val_binary_iou: 0.7784 - val_true_positives: 36755232.0000 - val_false_positives: 4481793.0000 - val_true_negatives: 56420288.0000 - val_false_negatives: 8314384.0000 - val_precision: 0.8913 - val_recall: 0.8155\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0708 - accuracy: 0.8861 - binary_iou: 0.7896 - true_positives: 111675448.0000 - false_positives: 17012134.0000 - true_negatives: 171463120.0000 - false_negatives: 19370032.0000 - precision: 0.8678 - recall: 0.8522 - val_loss: 0.0725 - val_accuracy: 0.8842 - val_binary_iou: 0.7874 - val_true_positives: 37718920.0000 - val_false_positives: 4882348.0000 - val_true_negatives: 55984972.0000 - val_false_negatives: 7385472.0000 - val_precision: 0.8854 - val_recall: 0.8363\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0706 - accuracy: 0.8864 - binary_iou: 0.7901 - true_positives: 112083648.0000 - false_positives: 17320000.0000 - true_negatives: 171126784.0000 - false_negatives: 18990262.0000 - precision: 0.8662 - recall: 0.8551 - val_loss: 0.0778 - val_accuracy: 0.8782 - val_binary_iou: 0.7759 - val_true_positives: 36081004.0000 - val_false_positives: 3847325.0000 - val_true_negatives: 56984628.0000 - val_false_negatives: 9058767.0000 - val_precision: 0.9036 - val_recall: 0.7993\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0708 - accuracy: 0.8855 - binary_iou: 0.7886 - true_positives: 111719080.0000 - false_positives: 17155256.0000 - true_negatives: 171213584.0000 - false_negatives: 19432856.0000 - precision: 0.8669 - recall: 0.8518 - val_loss: 0.0713 - val_accuracy: 0.8854 - val_binary_iou: 0.7898 - val_true_positives: 38198888.0000 - val_false_positives: 5231896.0000 - val_true_negatives: 55629572.0000 - val_false_negatives: 6911343.0000 - val_precision: 0.8795 - val_recall: 0.8468\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 437ms/step - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573 - val_loss: 0.0690 - val_accuracy: 0.8875 - val_binary_iou: 0.7944 - val_true_positives: 39463176.0000 - val_false_positives: 6336379.0000 - val_true_negatives: 54590884.0000 - val_false_negatives: 5581280.0000 - val_precision: 0.8616 - val_recall: 0.8761\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0696 - accuracy: 0.8883 - binary_iou: 0.7932 - true_positives: 112009744.0000 - false_positives: 16654082.0000 - true_negatives: 171826960.0000 - false_negatives: 19029884.0000 - precision: 0.8706 - recall: 0.8548 - val_loss: 0.0782 - val_accuracy: 0.8673 - val_binary_iou: 0.7644 - val_true_positives: 41361104.0000 - val_false_positives: 10324735.0000 - val_true_negatives: 50551800.0000 - val_false_negatives: 3734080.0000 - val_precision: 0.8002 - val_recall: 0.9172\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569 - val_loss: 0.0699 - val_accuracy: 0.8879 - val_binary_iou: 0.7946 - val_true_positives: 38986240.0000 - val_false_positives: 5839663.0000 - val_true_negatives: 55106392.0000 - val_false_negatives: 6039420.0000 - val_precision: 0.8697 - val_recall: 0.8659\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0682 - accuracy: 0.8907 - binary_iou: 0.7971 - true_positives: 112353240.0000 - false_positives: 16102053.0000 - true_negatives: 172235680.0000 - false_negatives: 18829746.0000 - precision: 0.8746 - recall: 0.8565 - val_loss: 0.0704 - val_accuracy: 0.8881 - val_binary_iou: 0.7939 - val_true_positives: 38109872.0000 - val_false_positives: 4901732.0000 - val_true_negatives: 55998932.0000 - val_false_negatives: 6961182.0000 - val_precision: 0.8860 - val_recall: 0.8456\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568 - val_loss: 0.0682 - val_accuracy: 0.8908 - val_binary_iou: 0.7980 - val_true_positives: 37943940.0000 - val_false_positives: 4332921.0000 - val_true_negatives: 56451604.0000 - val_false_negatives: 7243249.0000 - val_precision: 0.8975 - val_recall: 0.8397\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0678 - accuracy: 0.8911 - binary_iou: 0.7979 - true_positives: 112549024.0000 - false_positives: 16229167.0000 - true_negatives: 172190704.0000 - false_negatives: 18551880.0000 - precision: 0.8740 - recall: 0.8585 - val_loss: 0.0777 - val_accuracy: 0.8769 - val_binary_iou: 0.7724 - val_true_positives: 34971264.0000 - val_false_positives: 2822913.0000 - val_true_negatives: 57959224.0000 - val_false_negatives: 10218323.0000 - val_precision: 0.9253 - val_recall: 0.7739\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557 - val_loss: 0.0680 - val_accuracy: 0.8908 - val_binary_iou: 0.7986 - val_true_positives: 38459688.0000 - val_false_positives: 4965429.0000 - val_true_negatives: 55937692.0000 - val_false_negatives: 6608893.0000 - val_precision: 0.8857 - val_recall: 0.8534\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0672 - accuracy: 0.8924 - binary_iou: 0.8000 - true_positives: 112625344.0000 - false_positives: 15909708.0000 - true_negatives: 172527040.0000 - false_negatives: 18458692.0000 - precision: 0.8762 - recall: 0.8592 - val_loss: 0.0681 - val_accuracy: 0.8911 - val_binary_iou: 0.7985 - val_true_positives: 37945288.0000 - val_false_positives: 4341430.0000 - val_true_negatives: 56481624.0000 - val_false_negatives: 7203356.0000 - val_precision: 0.8973 - val_recall: 0.8405\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0670 - accuracy: 0.8926 - binary_iou: 0.8004 - true_positives: 112697608.0000 - false_positives: 15912619.0000 - true_negatives: 172519168.0000 - false_negatives: 18391396.0000 - precision: 0.8763 - recall: 0.8597 - val_loss: 0.0695 - val_accuracy: 0.8885 - val_binary_iou: 0.7942 - val_true_positives: 37790920.0000 - val_false_positives: 4531809.0000 - val_true_negatives: 56360128.0000 - val_false_negatives: 7288845.0000 - val_precision: 0.8929 - val_recall: 0.8383\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0677 - accuracy: 0.8915 - binary_iou: 0.7986 - true_positives: 112710072.0000 - false_positives: 16261744.0000 - true_negatives: 172151872.0000 - false_negatives: 18397136.0000 - precision: 0.8739 - recall: 0.8597 - val_loss: 0.0678 - val_accuracy: 0.8902 - val_binary_iou: 0.7985 - val_true_positives: 39367096.0000 - val_false_positives: 5935776.0000 - val_true_negatives: 54966212.0000 - val_false_negatives: 5702605.0000 - val_precision: 0.8690 - val_recall: 0.8735\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 438ms/step - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633 - val_loss: 0.0660 - val_accuracy: 0.8946 - val_binary_iou: 0.8052 - val_true_positives: 39001808.0000 - val_false_positives: 4980377.0000 - val_true_negatives: 55796588.0000 - val_false_negatives: 6192927.0000 - val_precision: 0.8868 - val_recall: 0.8630\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0664 - accuracy: 0.8936 - binary_iou: 0.8020 - true_positives: 112788272.0000 - false_positives: 15639641.0000 - true_negatives: 172750048.0000 - false_negatives: 18342840.0000 - precision: 0.8782 - recall: 0.8601 - val_loss: 0.0699 - val_accuracy: 0.8875 - val_binary_iou: 0.7919 - val_true_positives: 37142420.0000 - val_false_positives: 4069980.0000 - val_true_negatives: 56904784.0000 - val_false_negatives: 7854534.0000 - val_precision: 0.9012 - val_recall: 0.8254\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0655 - accuracy: 0.8950 - binary_iou: 0.8044 - true_positives: 113115328.0000 - false_positives: 15486498.0000 - true_negatives: 172855152.0000 - false_negatives: 18063804.0000 - precision: 0.8796 - recall: 0.8623 - val_loss: 0.0692 - val_accuracy: 0.8888 - val_binary_iou: 0.7959 - val_true_positives: 38962320.0000 - val_false_positives: 5677038.0000 - val_true_negatives: 55221624.0000 - val_false_negatives: 6110758.0000 - val_precision: 0.8728 - val_recall: 0.8644\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0651 - accuracy: 0.8960 - binary_iou: 0.8059 - true_positives: 113075528.0000 - false_positives: 15203770.0000 - true_negatives: 173212272.0000 - false_negatives: 18029176.0000 - precision: 0.8815 - recall: 0.8625 - val_loss: 0.0729 - val_accuracy: 0.8840 - val_binary_iou: 0.7863 - val_true_positives: 37080092.0000 - val_false_positives: 4269862.0000 - val_true_negatives: 56597916.0000 - val_false_negatives: 8023830.0000 - val_precision: 0.8967 - val_recall: 0.8221\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0648 - accuracy: 0.8961 - binary_iou: 0.8062 - true_positives: 113327736.0000 - false_positives: 15474886.0000 - true_negatives: 172995104.0000 - false_negatives: 17722972.0000 - precision: 0.8799 - recall: 0.8648 - val_loss: 0.0675 - val_accuracy: 0.8916 - val_binary_iou: 0.7997 - val_true_positives: 38295708.0000 - val_false_positives: 4763659.0000 - val_true_negatives: 56185512.0000 - val_false_negatives: 6726823.0000 - val_precision: 0.8894 - val_recall: 0.8506\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0644 - accuracy: 0.8971 - binary_iou: 0.8078 - true_positives: 113363456.0000 - false_positives: 15155710.0000 - true_negatives: 173270416.0000 - false_negatives: 17731144.0000 - precision: 0.8821 - recall: 0.8647 - val_loss: 0.0699 - val_accuracy: 0.8883 - val_binary_iou: 0.7926 - val_true_positives: 36737004.0000 - val_false_positives: 3459131.0000 - val_true_negatives: 57393536.0000 - val_false_negatives: 8382044.0000 - val_precision: 0.9139 - val_recall: 0.8142\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0649 - accuracy: 0.8960 - binary_iou: 0.8061 - true_positives: 113351536.0000 - false_positives: 15406054.0000 - true_negatives: 172946240.0000 - false_negatives: 17816920.0000 - precision: 0.8803 - recall: 0.8642 - val_loss: 0.0693 - val_accuracy: 0.8881 - val_binary_iou: 0.7931 - val_true_positives: 37406232.0000 - val_false_positives: 4189810.0000 - val_true_negatives: 56703164.0000 - val_false_negatives: 7672504.0000 - val_precision: 0.8993 - val_recall: 0.8298\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 439ms/step - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635 - val_loss: 0.0644 - val_accuracy: 0.8982 - val_binary_iou: 0.8115 - val_true_positives: 39367752.0000 - val_false_positives: 4995223.0000 - val_true_negatives: 55818860.0000 - val_false_negatives: 5789865.0000 - val_precision: 0.8874 - val_recall: 0.8718\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0637 - accuracy: 0.8982 - binary_iou: 0.8098 - true_positives: 113737680.0000 - false_positives: 15229448.0000 - true_negatives: 173259152.0000 - false_negatives: 17294578.0000 - precision: 0.8819 - recall: 0.8680 - val_loss: 0.0701 - val_accuracy: 0.8890 - val_binary_iou: 0.7959 - val_true_positives: 38609764.0000 - val_false_positives: 5199589.0000 - val_true_negatives: 55594380.0000 - val_false_negatives: 6567994.0000 - val_precision: 0.8813 - val_recall: 0.8546\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0643 - accuracy: 0.8975 - binary_iou: 0.8085 - true_positives: 113463744.0000 - false_positives: 15104503.0000 - true_negatives: 173302384.0000 - false_negatives: 17650162.0000 - precision: 0.8825 - recall: 0.8654 - val_loss: 0.0674 - val_accuracy: 0.8904 - val_binary_iou: 0.7991 - val_true_positives: 39483080.0000 - val_false_positives: 5960064.0000 - val_true_negatives: 54877108.0000 - val_false_negatives: 5651467.0000 - val_precision: 0.8688 - val_recall: 0.8748\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0637 - accuracy: 0.8983 - binary_iou: 0.8098 - true_positives: 113509408.0000 - false_positives: 14836776.0000 - true_negatives: 173506304.0000 - false_negatives: 17668256.0000 - precision: 0.8844 - recall: 0.8653 - val_loss: 0.0679 - val_accuracy: 0.8912 - val_binary_iou: 0.7994 - val_true_positives: 38486376.0000 - val_false_positives: 4910151.0000 - val_true_negatives: 55960840.0000 - val_false_negatives: 6614339.0000 - val_precision: 0.8869 - val_recall: 0.8533\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0631 - accuracy: 0.8992 - binary_iou: 0.8113 - true_positives: 113698048.0000 - false_positives: 14690406.0000 - true_negatives: 173600240.0000 - false_negatives: 17532068.0000 - precision: 0.8856 - recall: 0.8664 - val_loss: 0.0652 - val_accuracy: 0.8966 - val_binary_iou: 0.8095 - val_true_positives: 40043744.0000 - val_false_positives: 5826681.0000 - val_true_negatives: 54969080.0000 - val_false_negatives: 5132186.0000 - val_precision: 0.8730 - val_recall: 0.8864\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0637 - accuracy: 0.8980 - binary_iou: 0.8094 - true_positives: 113588616.0000 - false_positives: 14980239.0000 - true_negatives: 173351664.0000 - false_negatives: 17600292.0000 - precision: 0.8835 - recall: 0.8658 - val_loss: 0.0656 - val_accuracy: 0.8946 - val_binary_iou: 0.8057 - val_true_positives: 39386224.0000 - val_false_positives: 5345324.0000 - val_true_negatives: 55416720.0000 - val_false_negatives: 5823438.0000 - val_precision: 0.8805 - val_recall: 0.8712\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0632 - accuracy: 0.8994 - binary_iou: 0.8117 - true_positives: 113913360.0000 - false_positives: 14901580.0000 - true_negatives: 173453984.0000 - false_negatives: 17251912.0000 - precision: 0.8843 - recall: 0.8685 - val_loss: 0.0677 - val_accuracy: 0.8909 - val_binary_iou: 0.7967 - val_true_positives: 36674312.0000 - val_false_positives: 3143865.0000 - val_true_negatives: 57733296.0000 - val_false_negatives: 8420255.0000 - val_precision: 0.9210 - val_recall: 0.8133\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0628 - accuracy: 0.8998 - binary_iou: 0.8124 - true_positives: 113707192.0000 - false_positives: 14696928.0000 - true_negatives: 173804480.0000 - false_negatives: 17312232.0000 - precision: 0.8855 - recall: 0.8679 - val_loss: 0.0644 - val_accuracy: 0.8966 - val_binary_iou: 0.8081 - val_true_positives: 38568048.0000 - val_false_positives: 4499647.0000 - val_true_negatives: 56449208.0000 - val_false_negatives: 6454799.0000 - val_precision: 0.8955 - val_recall: 0.8566\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0629 - accuracy: 0.8991 - binary_iou: 0.8111 - true_positives: 113587144.0000 - false_positives: 14703208.0000 - true_negatives: 173683136.0000 - false_negatives: 17547360.0000 - precision: 0.8854 - recall: 0.8662 - val_loss: 0.0652 - val_accuracy: 0.8961 - val_binary_iou: 0.8068 - val_true_positives: 38103600.0000 - val_false_positives: 3996850.0000 - val_true_negatives: 56860540.0000 - val_false_negatives: 7010724.0000 - val_precision: 0.9051 - val_recall: 0.8446\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9011 - binary_iou: 0.8147 - true_positives: 114228344.0000 - false_positives: 14679725.0000 - true_negatives: 173688992.0000 - false_negatives: 16923826.0000 - precision: 0.8861 - recall: 0.8710 - val_loss: 0.0670 - val_accuracy: 0.8930 - val_binary_iou: 0.8033 - val_true_positives: 39714736.0000 - val_false_positives: 5934338.0000 - val_true_negatives: 54915616.0000 - val_false_negatives: 5407036.0000 - val_precision: 0.8700 - val_recall: 0.8802\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0620 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114160192.0000 - false_positives: 14541802.0000 - true_negatives: 173797200.0000 - false_negatives: 17021584.0000 - precision: 0.8870 - recall: 0.8702 - val_loss: 0.0660 - val_accuracy: 0.8971 - val_binary_iou: 0.8080 - val_true_positives: 37770996.0000 - val_false_positives: 3567448.0000 - val_true_negatives: 57291268.0000 - val_false_negatives: 7341999.0000 - val_precision: 0.9137 - val_recall: 0.8373\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0617 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114073448.0000 - false_positives: 14479113.0000 - true_negatives: 173890848.0000 - false_negatives: 17077416.0000 - precision: 0.8874 - recall: 0.8698 - val_loss: 0.0689 - val_accuracy: 0.8869 - val_binary_iou: 0.7917 - val_true_positives: 37728168.0000 - val_false_positives: 4620711.0000 - val_true_negatives: 56262276.0000 - val_false_negatives: 7360528.0000 - val_precision: 0.8909 - val_recall: 0.8368\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9012 - binary_iou: 0.8148 - true_positives: 114021800.0000 - false_positives: 14454801.0000 - true_negatives: 173942048.0000 - false_negatives: 17102218.0000 - precision: 0.8875 - recall: 0.8696 - val_loss: 0.0649 - val_accuracy: 0.8959 - val_binary_iou: 0.8076 - val_true_positives: 39236980.0000 - val_false_positives: 5234554.0000 - val_true_negatives: 55702736.0000 - val_false_negatives: 5797450.0000 - val_precision: 0.8823 - val_recall: 0.8713\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0616 - accuracy: 0.9018 - binary_iou: 0.8158 - true_positives: 114294520.0000 - false_positives: 14557606.0000 - true_negatives: 173837216.0000 - false_negatives: 16831460.0000 - precision: 0.8870 - recall: 0.8716 - val_loss: 0.0668 - val_accuracy: 0.8935 - val_binary_iou: 0.8021 - val_true_positives: 37644852.0000 - val_false_positives: 3729698.0000 - val_true_negatives: 57043988.0000 - val_false_negatives: 7553180.0000 - val_precision: 0.9099 - val_recall: 0.8329\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0610 - accuracy: 0.9025 - binary_iou: 0.8171 - true_positives: 114541624.0000 - false_positives: 14579440.0000 - true_negatives: 173826448.0000 - false_negatives: 16573294.0000 - precision: 0.8871 - recall: 0.8736 - val_loss: 0.0697 - val_accuracy: 0.8909 - val_binary_iou: 0.8004 - val_true_positives: 40092472.0000 - val_false_positives: 6589798.0000 - val_true_negatives: 54318728.0000 - val_false_negatives: 4970714.0000 - val_precision: 0.8588 - val_recall: 0.8897\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 436ms/step - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715 - val_loss: 0.0628 - val_accuracy: 0.8995 - val_binary_iou: 0.8142 - val_true_positives: 40126964.0000 - val_false_positives: 5757267.0000 - val_true_negatives: 55192272.0000 - val_false_negatives: 4895184.0000 - val_precision: 0.8745 - val_recall: 0.8913\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0604 - accuracy: 0.9035 - binary_iou: 0.8187 - true_positives: 114372352.0000 - false_positives: 14042377.0000 - true_negatives: 174325200.0000 - false_negatives: 16780868.0000 - precision: 0.8906 - recall: 0.8721 - val_loss: 0.0720 - val_accuracy: 0.8868 - val_binary_iou: 0.7945 - val_true_positives: 40941160.0000 - val_false_positives: 7836965.0000 - val_true_negatives: 53037104.0000 - val_false_negatives: 4156491.0000 - val_precision: 0.8393 - val_recall: 0.9078\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0598 - accuracy: 0.9050 - binary_iou: 0.8213 - true_positives: 114764616.0000 - false_positives: 13977922.0000 - true_negatives: 174412896.0000 - false_negatives: 16365363.0000 - precision: 0.8914 - recall: 0.8752 - val_loss: 0.0632 - val_accuracy: 0.8991 - val_binary_iou: 0.8121 - val_true_positives: 38543120.0000 - val_false_positives: 4116308.0000 - val_true_negatives: 56735084.0000 - val_false_negatives: 6577184.0000 - val_precision: 0.9035 - val_recall: 0.8542\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0602 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114492112.0000 - false_positives: 14097260.0000 - true_negatives: 174293072.0000 - false_negatives: 16638253.0000 - precision: 0.8904 - recall: 0.8731 - val_loss: 0.0649 - val_accuracy: 0.8957 - val_binary_iou: 0.8085 - val_true_positives: 40805296.0000 - val_false_positives: 6699145.0000 - val_true_negatives: 54108424.0000 - val_false_negatives: 4358863.0000 - val_precision: 0.8590 - val_recall: 0.9035\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0605 - accuracy: 0.9037 - binary_iou: 0.8190 - true_positives: 114271792.0000 - false_positives: 13944031.0000 - true_negatives: 174493456.0000 - false_negatives: 16811372.0000 - precision: 0.8912 - recall: 0.8718 - val_loss: 0.0673 - val_accuracy: 0.8897 - val_binary_iou: 0.7995 - val_true_positives: 41579912.0000 - val_false_positives: 8194420.0000 - val_true_negatives: 52699744.0000 - val_false_negatives: 3497623.0000 - val_precision: 0.8354 - val_recall: 0.9224\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0606 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114383448.0000 - false_positives: 13910560.0000 - true_negatives: 174400160.0000 - false_negatives: 16826680.0000 - precision: 0.8916 - recall: 0.8718 - val_loss: 0.0766 - val_accuracy: 0.8862 - val_binary_iou: 0.7928 - val_true_positives: 40028572.0000 - val_false_positives: 7006960.0000 - val_true_negatives: 53881560.0000 - val_false_negatives: 5054641.0000 - val_precision: 0.8510 - val_recall: 0.8879\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739 - val_loss: 0.0630 - val_accuracy: 0.9009 - val_binary_iou: 0.8159 - val_true_positives: 39473896.0000 - val_false_positives: 4852153.0000 - val_true_negatives: 55992092.0000 - val_false_negatives: 5653550.0000 - val_precision: 0.8905 - val_recall: 0.8747\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0598 - accuracy: 0.9053 - binary_iou: 0.8217 - true_positives: 114655032.0000 - false_positives: 13736962.0000 - true_negatives: 174595376.0000 - false_negatives: 16533304.0000 - precision: 0.8930 - recall: 0.8740 - val_loss: 0.0671 - val_accuracy: 0.8912 - val_binary_iou: 0.7983 - val_true_positives: 37558328.0000 - val_false_positives: 3884693.0000 - val_true_negatives: 56883664.0000 - val_false_negatives: 7645055.0000 - val_precision: 0.9063 - val_recall: 0.8309\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750 - val_loss: 0.0613 - val_accuracy: 0.9038 - val_binary_iou: 0.8209 - val_true_positives: 39589588.0000 - val_false_positives: 4649140.0000 - val_true_negatives: 56191696.0000 - val_false_negatives: 5541295.0000 - val_precision: 0.8949 - val_recall: 0.8772\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9066 - binary_iou: 0.8240 - true_positives: 114924592.0000 - false_positives: 13616651.0000 - true_negatives: 174744976.0000 - false_negatives: 16234598.0000 - precision: 0.8941 - recall: 0.8762 - val_loss: 0.0657 - val_accuracy: 0.8950 - val_binary_iou: 0.8070 - val_true_positives: 40115272.0000 - val_false_positives: 6156170.0000 - val_true_negatives: 54733744.0000 - val_false_negatives: 4966526.0000 - val_precision: 0.8670 - val_recall: 0.8898\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0590 - accuracy: 0.9069 - binary_iou: 0.8244 - true_positives: 114822896.0000 - false_positives: 13371130.0000 - true_negatives: 174937648.0000 - false_negatives: 16389186.0000 - precision: 0.8957 - recall: 0.8751 - val_loss: 0.0643 - val_accuracy: 0.8999 - val_binary_iou: 0.8143 - val_true_positives: 39385200.0000 - val_false_positives: 4859034.0000 - val_true_negatives: 55981228.0000 - val_false_negatives: 5746234.0000 - val_precision: 0.8902 - val_recall: 0.8727\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0592 - accuracy: 0.9064 - binary_iou: 0.8238 - true_positives: 115060424.0000 - false_positives: 13745673.0000 - true_negatives: 174567392.0000 - false_negatives: 16147346.0000 - precision: 0.8933 - recall: 0.8769 - val_loss: 0.0611 - val_accuracy: 0.9035 - val_binary_iou: 0.8204 - val_true_positives: 39653136.0000 - val_false_positives: 4728918.0000 - val_true_negatives: 56094144.0000 - val_false_negatives: 5495510.0000 - val_precision: 0.8934 - val_recall: 0.8783\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9059 - binary_iou: 0.8228 - true_positives: 114785464.0000 - false_positives: 13761449.0000 - true_negatives: 174670400.0000 - false_negatives: 16303439.0000 - precision: 0.8929 - recall: 0.8756 - val_loss: 0.0693 - val_accuracy: 0.8904 - val_binary_iou: 0.7999 - val_true_positives: 40398372.0000 - val_false_positives: 6853430.0000 - val_true_negatives: 53963436.0000 - val_false_negatives: 4756454.0000 - val_precision: 0.8550 - val_recall: 0.8947\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0584 - accuracy: 0.9071 - binary_iou: 0.8249 - true_positives: 115098648.0000 - false_positives: 13609404.0000 - true_negatives: 174737072.0000 - false_negatives: 16075616.0000 - precision: 0.8943 - recall: 0.8774 - val_loss: 0.0620 - val_accuracy: 0.9023 - val_binary_iou: 0.8191 - val_true_positives: 40398948.0000 - val_false_positives: 5691739.0000 - val_true_negatives: 55220200.0000 - val_false_negatives: 4660829.0000 - val_precision: 0.8765 - val_recall: 0.8966\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0580 - accuracy: 0.9078 - binary_iou: 0.8260 - true_positives: 115041896.0000 - false_positives: 13368177.0000 - true_negatives: 175011792.0000 - false_negatives: 16098864.0000 - precision: 0.8959 - recall: 0.8772 - val_loss: 0.0618 - val_accuracy: 0.9024 - val_binary_iou: 0.8176 - val_true_positives: 38695004.0000 - val_false_positives: 3913730.0000 - val_true_negatives: 56928672.0000 - val_false_negatives: 6434295.0000 - val_precision: 0.9081 - val_recall: 0.8574\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0586 - accuracy: 0.9073 - binary_iou: 0.8253 - true_positives: 115108880.0000 - false_positives: 13592248.0000 - true_negatives: 174804848.0000 - false_negatives: 16014808.0000 - precision: 0.8944 - recall: 0.8779 - val_loss: 0.0632 - val_accuracy: 0.9009 - val_binary_iou: 0.8162 - val_true_positives: 39746444.0000 - val_false_positives: 5064269.0000 - val_true_negatives: 55720692.0000 - val_false_negatives: 5440308.0000 - val_precision: 0.8870 - val_recall: 0.8796\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783 - val_loss: 0.0609 - val_accuracy: 0.9045 - val_binary_iou: 0.8220 - val_true_positives: 39622044.0000 - val_false_positives: 4580523.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 5541544.0000 - val_precision: 0.8964 - val_recall: 0.8773\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0579 - accuracy: 0.9080 - binary_iou: 0.8265 - true_positives: 115247800.0000 - false_positives: 13446067.0000 - true_negatives: 174880816.0000 - false_negatives: 15946018.0000 - precision: 0.8955 - recall: 0.8785 - val_loss: 0.0743 - val_accuracy: 0.8851 - val_binary_iou: 0.7913 - val_true_positives: 40276164.0000 - val_false_positives: 7452888.0000 - val_true_negatives: 53520128.0000 - val_false_negatives: 4722535.0000 - val_precision: 0.8439 - val_recall: 0.8951\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0573 - accuracy: 0.9089 - binary_iou: 0.8280 - true_positives: 115350232.0000 - false_positives: 13306295.0000 - true_negatives: 175061568.0000 - false_negatives: 15802560.0000 - precision: 0.8966 - recall: 0.8795 - val_loss: 0.0687 - val_accuracy: 0.8928 - val_binary_iou: 0.8045 - val_true_positives: 41609304.0000 - val_false_positives: 7912378.0000 - val_true_negatives: 52998040.0000 - val_false_negatives: 3452000.0000 - val_precision: 0.8402 - val_recall: 0.9234\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0570 - accuracy: 0.9097 - binary_iou: 0.8295 - true_positives: 115566680.0000 - false_positives: 13204775.0000 - true_negatives: 175116896.0000 - false_negatives: 15632293.0000 - precision: 0.8975 - recall: 0.8809 - val_loss: 0.0618 - val_accuracy: 0.9033 - val_binary_iou: 0.8206 - val_true_positives: 40212672.0000 - val_false_positives: 5331110.0000 - val_true_negatives: 55514868.0000 - val_false_negatives: 4913069.0000 - val_precision: 0.8829 - val_recall: 0.8911\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0574 - accuracy: 0.9091 - binary_iou: 0.8283 - true_positives: 115335368.0000 - false_positives: 13241246.0000 - true_negatives: 175149360.0000 - false_negatives: 15794777.0000 - precision: 0.8970 - recall: 0.8795 - val_loss: 0.0619 - val_accuracy: 0.9025 - val_binary_iou: 0.8185 - val_true_positives: 39427960.0000 - val_false_positives: 4689384.0000 - val_true_negatives: 56207648.0000 - val_false_negatives: 5646732.0000 - val_precision: 0.8937 - val_recall: 0.8747\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0572 - accuracy: 0.9092 - binary_iou: 0.8284 - true_positives: 115450496.0000 - false_positives: 13292661.0000 - true_negatives: 175043360.0000 - false_negatives: 15734289.0000 - precision: 0.8968 - recall: 0.8801 - val_loss: 0.0653 - val_accuracy: 0.8978 - val_binary_iou: 0.8097 - val_true_positives: 38248656.0000 - val_false_positives: 3970812.0000 - val_true_negatives: 56891840.0000 - val_false_negatives: 6860412.0000 - val_precision: 0.9059 - val_recall: 0.8479\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0576 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115059888.0000 - false_positives: 13279338.0000 - true_negatives: 175221456.0000 - false_negatives: 15960160.0000 - precision: 0.8965 - recall: 0.8782 - val_loss: 0.0621 - val_accuracy: 0.9005 - val_binary_iou: 0.8159 - val_true_positives: 40226056.0000 - val_false_positives: 5739225.0000 - val_true_negatives: 55198836.0000 - val_false_negatives: 4807608.0000 - val_precision: 0.8751 - val_recall: 0.8932\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0567 - accuracy: 0.9100 - binary_iou: 0.8299 - true_positives: 115410632.0000 - false_positives: 13091224.0000 - true_negatives: 175366784.0000 - false_negatives: 15652111.0000 - precision: 0.8981 - recall: 0.8806 - val_loss: 0.0648 - val_accuracy: 0.8976 - val_binary_iou: 0.8096 - val_true_positives: 38385240.0000 - val_false_positives: 4143129.0000 - val_true_negatives: 56738792.0000 - val_false_negatives: 6704553.0000 - val_precision: 0.9026 - val_recall: 0.8513\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0569 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115559664.0000 - false_positives: 13187510.0000 - true_negatives: 175197328.0000 - false_negatives: 15576244.0000 - precision: 0.8976 - recall: 0.8812 - val_loss: 0.0616 - val_accuracy: 0.9021 - val_binary_iou: 0.8190 - val_true_positives: 40675596.0000 - val_false_positives: 5981493.0000 - val_true_negatives: 54921920.0000 - val_false_negatives: 4392702.0000 - val_precision: 0.8718 - val_recall: 0.9025\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817 - val_loss: 0.0604 - val_accuracy: 0.9043 - val_binary_iou: 0.8220 - val_true_positives: 40136756.0000 - val_false_positives: 5091398.0000 - val_true_negatives: 55688312.0000 - val_false_negatives: 5055239.0000 - val_precision: 0.8874 - val_recall: 0.8881\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0565 - accuracy: 0.9104 - binary_iou: 0.8305 - true_positives: 115524848.0000 - false_positives: 13007364.0000 - true_negatives: 175357504.0000 - false_negatives: 15631114.0000 - precision: 0.8988 - recall: 0.8808 - val_loss: 0.0637 - val_accuracy: 0.8973 - val_binary_iou: 0.8116 - val_true_positives: 41283940.0000 - val_false_positives: 7066725.0000 - val_true_negatives: 53805696.0000 - val_false_negatives: 3815342.0000 - val_precision: 0.8538 - val_recall: 0.9154\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0566 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115418920.0000 - false_positives: 13103144.0000 - true_negatives: 175337664.0000 - false_negatives: 15661151.0000 - precision: 0.8980 - recall: 0.8805 - val_loss: 0.0685 - val_accuracy: 0.8931 - val_binary_iou: 0.8000 - val_true_positives: 36465344.0000 - val_false_positives: 2706221.0000 - val_true_negatives: 58180776.0000 - val_false_negatives: 8619357.0000 - val_precision: 0.9309 - val_recall: 0.8088\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830 - val_loss: 0.0591 - val_accuracy: 0.9071 - val_binary_iou: 0.8267 - val_true_positives: 40077468.0000 - val_false_positives: 4810660.0000 - val_true_negatives: 56051568.0000 - val_false_negatives: 5032024.0000 - val_precision: 0.8928 - val_recall: 0.8884\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0561 - accuracy: 0.9108 - binary_iou: 0.8312 - true_positives: 115485504.0000 - false_positives: 12872387.0000 - true_negatives: 175535872.0000 - false_negatives: 15627070.0000 - precision: 0.8997 - recall: 0.8808 - val_loss: 0.0686 - val_accuracy: 0.8930 - val_binary_iou: 0.8049 - val_true_positives: 41539792.0000 - val_false_positives: 7744004.0000 - val_true_negatives: 53097324.0000 - val_false_negatives: 3590584.0000 - val_precision: 0.8429 - val_recall: 0.9204\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0560 - accuracy: 0.9111 - binary_iou: 0.8318 - true_positives: 115753184.0000 - false_positives: 13009851.0000 - true_negatives: 175361808.0000 - false_negatives: 15395915.0000 - precision: 0.8990 - recall: 0.8826 - val_loss: 0.0621 - val_accuracy: 0.9018 - val_binary_iou: 0.8154 - val_true_positives: 37469948.0000 - val_false_positives: 2734699.0000 - val_true_negatives: 58100136.0000 - val_false_negatives: 7666928.0000 - val_precision: 0.9320 - val_recall: 0.8301\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0557 - accuracy: 0.9119 - binary_iou: 0.8331 - true_positives: 115764048.0000 - false_positives: 12780396.0000 - true_negatives: 175605136.0000 - false_negatives: 15371262.0000 - precision: 0.9006 - recall: 0.8828 - val_loss: 0.0607 - val_accuracy: 0.9049 - val_binary_iou: 0.8227 - val_true_positives: 39667376.0000 - val_false_positives: 4631294.0000 - val_true_negatives: 56222816.0000 - val_false_negatives: 5450231.0000 - val_precision: 0.8955 - val_recall: 0.8792\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0556 - accuracy: 0.9117 - binary_iou: 0.8328 - true_positives: 115600880.0000 - false_positives: 12729907.0000 - true_negatives: 175719568.0000 - false_negatives: 15470327.0000 - precision: 0.9008 - recall: 0.8820 - val_loss: 0.0629 - val_accuracy: 0.8997 - val_binary_iou: 0.8149 - val_true_positives: 40599992.0000 - val_false_positives: 6119560.0000 - val_true_negatives: 54737740.0000 - val_false_negatives: 4514413.0000 - val_precision: 0.8690 - val_recall: 0.8999\n",
      "132/132 [==============================] - 20s 121ms/step - loss: 224.4008 - accuracy: 0.9036 - binary_iou: 0.8199 - true_positives: 38915348.0000 - false_positives: 4943305.0000 - true_negatives: 56841440.0000 - false_negatives: 5271624.0000 - precision: 0.8873 - recall: 0.8807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Durch RegEx kann aus den Layernamen der Index der Convolutional-Layer entnommen werden und diese dann nacheinander eingefroren werden\n",
    "\n",
    "conv_layers = [4, 7, 11, 15, 18, 22, 26, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 64, 68, 72, 75, 79, 83, 86, 90, 94, 95, 98, 102, 106, 110, 114, 118,\n",
    " 121, 125, 129, 132, 136, 140, 141, 144, 148, 152, 156, 160, 164, 167, 171, 175, 176, 179, 183, 190]\n",
    "\n",
    "import gc\n",
    "\n",
    "for number in conv_layers:      \n",
    "\n",
    "    training_split = 0.6\n",
    "\n",
    "    pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "    conf = {\n",
    "        'AVG': 'BN',\n",
    "        'RNDM': 'BN',\n",
    "        'EXTRA_CONV': 'CONV',\n",
    "        'RGB_SPLIT': 'SPLIT'\n",
    "        } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "    lr = 0.001 # Learning rate\n",
    "\n",
    "    rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "    ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "    l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "    l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "    #freeze = True # Trainierbarkeit des Encoders\n",
    "    freeze_from = 'input' # Ab diesem layer wird eingefroren, EXKLUSIVE (wird überschrieben bei SPLIT-Variante)!\n",
    "    train_encoder_layers = number # Anzahl an Layern (int) im Encoder, die trainiert werden. Rückwärts gezählt ab Bottleneck\n",
    "    #freeze_what = 'No1ConvBN' # Beschreibung ob 1. Layer eingefroren oder nicht\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    patch_size = 224 # Maße des inputs\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "\n",
    "    unet = load_model(conf[pretrained_weights])\n",
    "    set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "    set_weight_decay(unet, l1= l1, l2= l2)\n",
    "    set_pretrained_weights(unet, pretrained_weights)\n",
    "    set_encoder_frozen(unet, pretrained_weights, freeze_from= freeze_from, train_encoder_layers= train_encoder_layers)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "\n",
    "    loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "    model_name = f'FT_test_AVG_no_of_frozen_layers_{number}'\n",
    "\n",
    "    checkpoint_path = f'../saved_model_FT_test/{model_name}_e{str(epochs)}'\n",
    "    logger_path = f'../saved_history_FT_test/{model_name}_e{str(epochs)}.log'\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path)\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "\n",
    "\n",
    "    train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/masks'\n",
    "    )\n",
    "\n",
    "    val_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = True,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/masks'\n",
    "    )\n",
    "\n",
    "    test_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = False,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/masks'\n",
    "    )\n",
    "\n",
    "    model_history = unet.fit(train_data_generator, validation_data=val_data_generator, callbacks= [checkpoint_callback, history_logger], epochs=epochs)\n",
    "\n",
    "\n",
    "    # laden des besten models\n",
    "    unet = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "    # Evaluieren & Ergebnisse in Tabelle\n",
    "    eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "    with open('../results/FT_test_eval_output.csv', 'a') as f_object:\n",
    "        row = []\n",
    "        \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)\n",
    "\n",
    "        writer_object = csv.writer(f_object)\n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "    del unet\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob trainable oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfigurationen, Laden & Kompilieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BN',\n",
    "    'RNDM': 'BN',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0.2 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 480\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "early_stop = True\n",
    "\n",
    "model_name = f'Final_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}_e{total_epochs}'\n",
    "\n",
    "# Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren der Data Generator & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.7853 - binary_iou: 0.6445 - true_positives: 110871992.0000 - false_positives: 48519908.0000 - true_negatives: 140056592.0000 - false_negatives: 20072296.0000 - precision: 0.6956 - recall: 0.8467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 95s 459ms/step - loss: 0.2551 - accuracy: 0.7853 - binary_iou: 0.6445 - true_positives: 110871992.0000 - false_positives: 48519908.0000 - true_negatives: 140056592.0000 - false_negatives: 20072296.0000 - precision: 0.6956 - recall: 0.8467 - val_loss: 0.2483 - val_accuracy: 0.7593 - val_binary_iou: 0.6119 - val_true_positives: 41036992.0000 - val_false_positives: 21511792.0000 - val_true_negatives: 39424340.0000 - val_false_negatives: 3998570.0000 - val_precision: 0.6561 - val_recall: 0.9112\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.8449 - binary_iou: 0.7270 - true_positives: 111473824.0000 - false_positives: 29961636.0000 - true_negatives: 158483200.0000 - false_negatives: 19602096.0000 - precision: 0.7882 - recall: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 102s 514ms/step - loss: 0.1849 - accuracy: 0.8449 - binary_iou: 0.7270 - true_positives: 111473824.0000 - false_positives: 29961636.0000 - true_negatives: 158483200.0000 - false_negatives: 19602096.0000 - precision: 0.7882 - recall: 0.8505 - val_loss: 0.1941 - val_accuracy: 0.8259 - val_binary_iou: 0.7017 - val_true_positives: 38923104.0000 - val_false_positives: 12282605.0000 - val_true_negatives: 48601448.0000 - val_false_negatives: 6164544.0000 - val_precision: 0.7601 - val_recall: 0.8633\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - 76s 378ms/step - loss: 0.1717 - accuracy: 0.8573 - binary_iou: 0.7454 - true_positives: 111879208.0000 - false_positives: 26470124.0000 - true_negatives: 162034192.0000 - false_negatives: 19137280.0000 - precision: 0.8087 - recall: 0.8539 - val_loss: 0.2053 - val_accuracy: 0.7984 - val_binary_iou: 0.6644 - val_true_positives: 41943008.0000 - val_false_positives: 18361716.0000 - val_true_negatives: 42665816.0000 - val_false_negatives: 3001159.0000 - val_precision: 0.6955 - val_recall: 0.9332\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.1610 - accuracy: 0.8667 - binary_iou: 0.7599 - true_positives: 112964112.0000 - false_positives: 24476844.0000 - true_negatives: 163953584.0000 - false_negatives: 18126196.0000 - precision: 0.8219 - recall: 0.8617 - val_loss: 0.2360 - val_accuracy: 0.7721 - val_binary_iou: 0.6287 - val_true_positives: 39499256.0000 - val_false_positives: 18446650.0000 - val_true_negatives: 42325672.0000 - val_false_negatives: 5700130.0000 - val_precision: 0.6817 - val_recall: 0.8739\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.8694 - binary_iou: 0.7642 - true_positives: 112891960.0000 - false_positives: 23488452.0000 - true_negatives: 164913872.0000 - false_negatives: 18226568.0000 - precision: 0.8278 - recall: 0.8610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1578 - accuracy: 0.8694 - binary_iou: 0.7642 - true_positives: 112891960.0000 - false_positives: 23488452.0000 - true_negatives: 164913872.0000 - false_negatives: 18226568.0000 - precision: 0.8278 - recall: 0.8610 - val_loss: 0.1716 - val_accuracy: 0.8398 - val_binary_iou: 0.7231 - val_true_positives: 41407768.0000 - val_false_positives: 13370449.0000 - val_true_negatives: 47586208.0000 - val_false_negatives: 3607286.0000 - val_precision: 0.7559 - val_recall: 0.9199\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.8737 - binary_iou: 0.7709 - true_positives: 113559080.0000 - false_positives: 22782696.0000 - true_negatives: 165597696.0000 - false_negatives: 17581320.0000 - precision: 0.8329 - recall: 0.8659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 455ms/step - loss: 0.1527 - accuracy: 0.8737 - binary_iou: 0.7709 - true_positives: 113559080.0000 - false_positives: 22782696.0000 - true_negatives: 165597696.0000 - false_negatives: 17581320.0000 - precision: 0.8329 - recall: 0.8659 - val_loss: 0.1632 - val_accuracy: 0.8480 - val_binary_iou: 0.7355 - val_true_positives: 41869756.0000 - val_false_positives: 12802186.0000 - val_true_negatives: 47998320.0000 - val_false_negatives: 3301457.0000 - val_precision: 0.7658 - val_recall: 0.9269\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - 76s 378ms/step - loss: 0.1477 - accuracy: 0.8779 - binary_iou: 0.7776 - true_positives: 113999072.0000 - false_positives: 21954576.0000 - true_negatives: 166507776.0000 - false_negatives: 17059336.0000 - precision: 0.8385 - recall: 0.8698 - val_loss: 0.2138 - val_accuracy: 0.7814 - val_binary_iou: 0.6409 - val_true_positives: 43204196.0000 - val_false_positives: 21326196.0000 - val_true_negatives: 39597752.0000 - val_false_negatives: 1843560.0000 - val_precision: 0.6695 - val_recall: 0.9591\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.1414 - accuracy: 0.8837 - binary_iou: 0.7869 - true_positives: 114552008.0000 - false_positives: 20568270.0000 - true_negatives: 167807872.0000 - false_negatives: 16592652.0000 - precision: 0.8478 - recall: 0.8735 - val_loss: 0.1846 - val_accuracy: 0.8205 - val_binary_iou: 0.6956 - val_true_positives: 42490680.0000 - val_false_positives: 16336055.0000 - val_true_negatives: 44462772.0000 - val_false_negatives: 2682198.0000 - val_precision: 0.7223 - val_recall: 0.9406\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.1369 - accuracy: 0.8875 - binary_iou: 0.7930 - true_positives: 114919408.0000 - false_positives: 19676536.0000 - true_negatives: 168657184.0000 - false_negatives: 16267555.0000 - precision: 0.8538 - recall: 0.8760 - val_loss: 0.1638 - val_accuracy: 0.8476 - val_binary_iou: 0.7348 - val_true_positives: 41801292.0000 - val_false_positives: 12911122.0000 - val_true_negatives: 48015964.0000 - val_false_negatives: 3243325.0000 - val_precision: 0.7640 - val_recall: 0.9280\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.1334 - accuracy: 0.8905 - binary_iou: 0.7979 - true_positives: 115116136.0000 - false_positives: 18976312.0000 - true_negatives: 169427136.0000 - false_negatives: 16001172.0000 - precision: 0.8585 - recall: 0.8780 - val_loss: 0.1640 - val_accuracy: 0.8467 - val_binary_iou: 0.7335 - val_true_positives: 41912196.0000 - val_false_positives: 13094309.0000 - val_true_negatives: 47811680.0000 - val_false_negatives: 3153512.0000 - val_precision: 0.7619 - val_recall: 0.9300\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.1301 - accuracy: 0.8934 - binary_iou: 0.8026 - true_positives: 115471712.0000 - false_positives: 18388956.0000 - true_negatives: 169983472.0000 - false_negatives: 15676596.0000 - precision: 0.8626 - recall: 0.8805 - val_loss: 0.1743 - val_accuracy: 0.8393 - val_binary_iou: 0.7222 - val_true_positives: 41079804.0000 - val_false_positives: 13061697.0000 - val_true_negatives: 47861644.0000 - val_false_negatives: 3968568.0000 - val_precision: 0.7587 - val_recall: 0.9119\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.1282 - accuracy: 0.8946 - binary_iou: 0.8046 - true_positives: 115749528.0000 - false_positives: 18374564.0000 - true_negatives: 170086752.0000 - false_negatives: 15309880.0000 - precision: 0.8630 - recall: 0.8832 - val_loss: 0.1732 - val_accuracy: 0.8369 - val_binary_iou: 0.7191 - val_true_positives: 41845000.0000 - val_false_positives: 13967900.0000 - val_true_negatives: 46843472.0000 - val_false_negatives: 3315343.0000 - val_precision: 0.7497 - val_recall: 0.9266\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.8963 - binary_iou: 0.8075 - true_positives: 115954168.0000 - false_positives: 18038428.0000 - true_negatives: 170433296.0000 - false_negatives: 15094804.0000 - precision: 0.8654 - recall: 0.8848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1265 - accuracy: 0.8963 - binary_iou: 0.8075 - true_positives: 115954168.0000 - false_positives: 18038428.0000 - true_negatives: 170433296.0000 - false_negatives: 15094804.0000 - precision: 0.8654 - recall: 0.8848 - val_loss: 0.1504 - val_accuracy: 0.8649 - val_binary_iou: 0.7605 - val_true_positives: 41183236.0000 - val_false_positives: 10423189.0000 - val_true_negatives: 50471704.0000 - val_false_negatives: 3893591.0000 - val_precision: 0.7980 - val_recall: 0.9136\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.8996 - binary_iou: 0.8130 - true_positives: 116389784.0000 - false_positives: 17332494.0000 - true_negatives: 171054000.0000 - false_negatives: 14744513.0000 - precision: 0.8704 - recall: 0.8876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1229 - accuracy: 0.8996 - binary_iou: 0.8130 - true_positives: 116389784.0000 - false_positives: 17332494.0000 - true_negatives: 171054000.0000 - false_negatives: 14744513.0000 - precision: 0.8704 - recall: 0.8876 - val_loss: 0.1483 - val_accuracy: 0.8649 - val_binary_iou: 0.7608 - val_true_positives: 41733008.0000 - val_false_positives: 10950870.0000 - val_true_negatives: 49917688.0000 - val_false_negatives: 3370133.0000 - val_precision: 0.7921 - val_recall: 0.9253\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - 76s 378ms/step - loss: 0.1195 - accuracy: 0.9024 - binary_iou: 0.8175 - true_positives: 116469800.0000 - false_positives: 16559216.0000 - true_negatives: 171850096.0000 - false_negatives: 14641642.0000 - precision: 0.8755 - recall: 0.8883 - val_loss: 0.1878 - val_accuracy: 0.8170 - val_binary_iou: 0.6905 - val_true_positives: 42440360.0000 - val_false_positives: 16756497.0000 - val_true_negatives: 44133940.0000 - val_false_negatives: 2640933.0000 - val_precision: 0.7169 - val_recall: 0.9414\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.1186 - accuracy: 0.9028 - binary_iou: 0.8184 - true_positives: 116686968.0000 - false_positives: 16600964.0000 - true_negatives: 171787456.0000 - false_negatives: 14445490.0000 - precision: 0.8755 - recall: 0.8898 - val_loss: 0.1696 - val_accuracy: 0.8366 - val_binary_iou: 0.7190 - val_true_positives: 42879460.0000 - val_false_positives: 15129234.0000 - val_true_negatives: 45778404.0000 - val_false_negatives: 2184628.0000 - val_precision: 0.7392 - val_recall: 0.9515\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.1166 - accuracy: 0.9047 - binary_iou: 0.8214 - true_positives: 116769136.0000 - false_positives: 16130092.0000 - true_negatives: 172285888.0000 - false_negatives: 14335714.0000 - precision: 0.8786 - recall: 0.8907 - val_loss: 0.1520 - val_accuracy: 0.8593 - val_binary_iou: 0.7525 - val_true_positives: 42091744.0000 - val_false_positives: 11913586.0000 - val_true_negatives: 48970528.0000 - val_false_negatives: 2995853.0000 - val_precision: 0.7794 - val_recall: 0.9336\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.1131 - accuracy: 0.9078 - binary_iou: 0.8268 - true_positives: 117174624.0000 - false_positives: 15467443.0000 - true_negatives: 172896848.0000 - false_negatives: 13981847.0000 - precision: 0.8834 - recall: 0.8934 - val_loss: 0.1835 - val_accuracy: 0.8203 - val_binary_iou: 0.6954 - val_true_positives: 43009368.0000 - val_false_positives: 16866072.0000 - val_true_negatives: 43921556.0000 - val_false_negatives: 2174713.0000 - val_precision: 0.7183 - val_recall: 0.9519\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9093 - binary_iou: 0.8294 - true_positives: 117615800.0000 - false_positives: 15446000.0000 - true_negatives: 172926528.0000 - false_negatives: 13532505.0000 - precision: 0.8839 - recall: 0.8968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 452ms/step - loss: 0.1111 - accuracy: 0.9093 - binary_iou: 0.8294 - true_positives: 117615800.0000 - false_positives: 15446000.0000 - true_negatives: 172926528.0000 - false_negatives: 13532505.0000 - precision: 0.8839 - recall: 0.8968 - val_loss: 0.1452 - val_accuracy: 0.8680 - val_binary_iou: 0.7657 - val_true_positives: 41801352.0000 - val_false_positives: 10620468.0000 - val_true_negatives: 50184780.0000 - val_false_negatives: 3365110.0000 - val_precision: 0.7974 - val_recall: 0.9255\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - 76s 378ms/step - loss: 0.1094 - accuracy: 0.9107 - binary_iou: 0.8316 - true_positives: 117403048.0000 - false_positives: 14844650.0000 - true_negatives: 173568480.0000 - false_negatives: 13704499.0000 - precision: 0.8878 - recall: 0.8955 - val_loss: 0.1613 - val_accuracy: 0.8504 - val_binary_iou: 0.7390 - val_true_positives: 41829620.0000 - val_false_positives: 12571344.0000 - val_true_negatives: 48288120.0000 - val_false_negatives: 3282642.0000 - val_precision: 0.7689 - val_recall: 0.9272\n",
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 2 trainable: True\n",
      "170 conv5_block1_3_conv trainable weights: 2 trainable: True\n",
      "171 conv5_block1_out trainable weights: 0 trainable: True\n",
      "172 conv5_block2_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: True\n",
      "174 conv5_block2_1_conv trainable weights: 1 trainable: True\n",
      "175 conv5_block2_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: True\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: True\n",
      "178 conv5_block2_2_conv trainable weights: 1 trainable: True\n",
      "179 conv5_block2_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: True\n",
      "181 conv5_block2_3_conv trainable weights: 2 trainable: True\n",
      "182 conv5_block2_out trainable weights: 0 trainable: True\n",
      "183 conv5_block3_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: True\n",
      "185 conv5_block3_1_conv trainable weights: 1 trainable: True\n",
      "186 conv5_block3_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: True\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: True\n",
      "189 conv5_block3_2_conv trainable weights: 1 trainable: True\n",
      "190 conv5_block3_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: True\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2  trainable:  True  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 21/500\n",
      "199/199 [==============================] - 82s 393ms/step - loss: 0.1161 - accuracy: 0.9053 - binary_iou: 0.8226 - true_positives: 117032864.0000 - false_positives: 16141195.0000 - true_negatives: 172231616.0000 - false_negatives: 14115061.0000 - precision: 0.8788 - recall: 0.8924 - val_loss: 0.1480 - val_accuracy: 0.8628 - val_binary_iou: 0.7579 - val_true_positives: 42387940.0000 - val_false_positives: 11764651.0000 - val_true_negatives: 49042304.0000 - val_false_negatives: 2776828.0000 - val_precision: 0.7827 - val_recall: 0.9385\n",
      "Epoch 22/500\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.1017 - accuracy: 0.9173 - binary_iou: 0.8430 - true_positives: 118167176.0000 - false_positives: 13531930.0000 - true_negatives: 174920768.0000 - false_negatives: 12900867.0000 - precision: 0.8973 - recall: 0.9016 - val_loss: 0.1467 - val_accuracy: 0.8653 - val_binary_iou: 0.7617 - val_true_positives: 42187328.0000 - val_false_positives: 11279802.0000 - val_true_negatives: 49509140.0000 - val_false_negatives: 2995458.0000 - val_precision: 0.7890 - val_recall: 0.9337\n",
      "Epoch 23/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9212 - binary_iou: 0.8500 - true_positives: 119076032.0000 - false_positives: 13096166.0000 - true_negatives: 175275888.0000 - false_negatives: 12072720.0000 - precision: 0.9009 - recall: 0.9079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0969 - accuracy: 0.9212 - binary_iou: 0.8500 - true_positives: 119076032.0000 - false_positives: 13096166.0000 - true_negatives: 175275888.0000 - false_negatives: 12072720.0000 - precision: 0.9009 - recall: 0.9079 - val_loss: 0.1421 - val_accuracy: 0.8694 - val_binary_iou: 0.7680 - val_true_positives: 42360256.0000 - val_false_positives: 11058064.0000 - val_true_negatives: 49766920.0000 - val_false_negatives: 2786484.0000 - val_precision: 0.7930 - val_recall: 0.9383\n",
      "Epoch 24/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9256 - binary_iou: 0.8576 - true_positives: 119439400.0000 - false_positives: 12163717.0000 - true_negatives: 176306800.0000 - false_negatives: 11610785.0000 - precision: 0.9076 - recall: 0.9114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 460ms/step - loss: 0.0919 - accuracy: 0.9256 - binary_iou: 0.8576 - true_positives: 119439400.0000 - false_positives: 12163717.0000 - true_negatives: 176306800.0000 - false_negatives: 11610785.0000 - precision: 0.9076 - recall: 0.9114 - val_loss: 0.1427 - val_accuracy: 0.8705 - val_binary_iou: 0.7696 - val_true_positives: 41945108.0000 - val_false_positives: 10509026.0000 - val_true_negatives: 50308180.0000 - val_false_negatives: 3209401.0000 - val_precision: 0.7997 - val_recall: 0.9289\n",
      "Epoch 25/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0881 - accuracy: 0.9287 - binary_iou: 0.8632 - true_positives: 119983136.0000 - false_positives: 11723242.0000 - true_negatives: 176765888.0000 - false_negatives: 11048540.0000 - precision: 0.9110 - recall: 0.9157 - val_loss: 0.1484 - val_accuracy: 0.8616 - val_binary_iou: 0.7563 - val_true_positives: 42900796.0000 - val_false_positives: 12391311.0000 - val_true_negatives: 48399912.0000 - val_false_negatives: 2279701.0000 - val_precision: 0.7759 - val_recall: 0.9495\n",
      "Epoch 26/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0857 - accuracy: 0.9308 - binary_iou: 0.8668 - true_positives: 120276784.0000 - false_positives: 11257390.0000 - true_negatives: 177119456.0000 - false_negatives: 10867131.0000 - precision: 0.9144 - recall: 0.9171 - val_loss: 0.1429 - val_accuracy: 0.8677 - val_binary_iou: 0.7656 - val_true_positives: 42564908.0000 - val_false_positives: 11544135.0000 - val_true_negatives: 49389856.0000 - val_false_negatives: 2472811.0000 - val_precision: 0.7867 - val_recall: 0.9451\n",
      "Epoch 27/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9333 - binary_iou: 0.8714 - true_positives: 120631880.0000 - false_positives: 10830180.0000 - true_negatives: 177584640.0000 - false_negatives: 10474104.0000 - precision: 0.9176 - recall: 0.9201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 465ms/step - loss: 0.0826 - accuracy: 0.9333 - binary_iou: 0.8714 - true_positives: 120631880.0000 - false_positives: 10830180.0000 - true_negatives: 177584640.0000 - false_negatives: 10474104.0000 - precision: 0.9176 - recall: 0.9201 - val_loss: 0.1387 - val_accuracy: 0.8737 - val_binary_iou: 0.7746 - val_true_positives: 42243348.0000 - val_false_positives: 10507282.0000 - val_true_negatives: 50341324.0000 - val_false_negatives: 2879754.0000 - val_precision: 0.8008 - val_recall: 0.9362\n",
      "Epoch 28/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9363 - binary_iou: 0.8767 - true_positives: 121017792.0000 - false_positives: 10226993.0000 - true_negatives: 178145136.0000 - false_negatives: 10130853.0000 - precision: 0.9221 - recall: 0.9228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0787 - accuracy: 0.9363 - binary_iou: 0.8767 - true_positives: 121017792.0000 - false_positives: 10226993.0000 - true_negatives: 178145136.0000 - false_negatives: 10130853.0000 - precision: 0.9221 - recall: 0.9228 - val_loss: 0.1396 - val_accuracy: 0.8738 - val_binary_iou: 0.7749 - val_true_positives: 42211680.0000 - val_false_positives: 10547946.0000 - val_true_negatives: 50391280.0000 - val_false_negatives: 2820811.0000 - val_precision: 0.8001 - val_recall: 0.9374\n",
      "Epoch 29/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9378 - binary_iou: 0.8795 - true_positives: 121162856.0000 - false_positives: 9903596.0000 - true_negatives: 178498560.0000 - false_negatives: 9955833.0000 - precision: 0.9244 - recall: 0.9241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0769 - accuracy: 0.9378 - binary_iou: 0.8795 - true_positives: 121162856.0000 - false_positives: 9903596.0000 - true_negatives: 178498560.0000 - false_negatives: 9955833.0000 - precision: 0.9244 - recall: 0.9241 - val_loss: 0.1347 - val_accuracy: 0.8791 - val_binary_iou: 0.7829 - val_true_positives: 41843704.0000 - val_false_positives: 9498717.0000 - val_true_negatives: 51318104.0000 - val_false_negatives: 3311182.0000 - val_precision: 0.8150 - val_recall: 0.9267\n",
      "Epoch 30/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0749 - accuracy: 0.9395 - binary_iou: 0.8826 - true_positives: 121475528.0000 - false_positives: 9681173.0000 - true_negatives: 178730016.0000 - false_negatives: 9634020.0000 - precision: 0.9262 - recall: 0.9265 - val_loss: 0.1352 - val_accuracy: 0.8774 - val_binary_iou: 0.7804 - val_true_positives: 42158808.0000 - val_false_positives: 10031138.0000 - val_true_negatives: 50820196.0000 - val_false_negatives: 2961580.0000 - val_precision: 0.8078 - val_recall: 0.9344\n",
      "Epoch 31/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0727 - accuracy: 0.9414 - binary_iou: 0.8861 - true_positives: 121802504.0000 - false_positives: 9350534.0000 - true_negatives: 179006464.0000 - false_negatives: 9361237.0000 - precision: 0.9287 - recall: 0.9286 - val_loss: 0.1366 - val_accuracy: 0.8757 - val_binary_iou: 0.7779 - val_true_positives: 42207028.0000 - val_false_positives: 10276976.0000 - val_true_negatives: 50597504.0000 - val_false_negatives: 2890206.0000 - val_precision: 0.8042 - val_recall: 0.9359\n",
      "Epoch 32/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9421 - binary_iou: 0.8873 - true_positives: 121872880.0000 - false_positives: 9215358.0000 - true_negatives: 179144720.0000 - false_negatives: 9287776.0000 - precision: 0.9297 - recall: 0.9292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0718 - accuracy: 0.9421 - binary_iou: 0.8873 - true_positives: 121872880.0000 - false_positives: 9215358.0000 - true_negatives: 179144720.0000 - false_negatives: 9287776.0000 - precision: 0.9297 - recall: 0.9292 - val_loss: 0.1315 - val_accuracy: 0.8806 - val_binary_iou: 0.7854 - val_true_positives: 42171440.0000 - val_false_positives: 9696925.0000 - val_true_negatives: 51144520.0000 - val_false_negatives: 2958841.0000 - val_precision: 0.8130 - val_recall: 0.9344\n",
      "Epoch 33/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9426 - binary_iou: 0.8882 - true_positives: 121957824.0000 - false_positives: 9185886.0000 - true_negatives: 179225760.0000 - false_negatives: 9151249.0000 - precision: 0.9300 - recall: 0.9302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0710 - accuracy: 0.9426 - binary_iou: 0.8882 - true_positives: 121957824.0000 - false_positives: 9185886.0000 - true_negatives: 179225760.0000 - false_negatives: 9151249.0000 - precision: 0.9300 - recall: 0.9302 - val_loss: 0.1280 - val_accuracy: 0.8856 - val_binary_iou: 0.7932 - val_true_positives: 41982616.0000 - val_false_positives: 8991260.0000 - val_true_negatives: 51860828.0000 - val_false_negatives: 3137012.0000 - val_precision: 0.8236 - val_recall: 0.9305\n",
      "Epoch 34/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0691 - accuracy: 0.9445 - binary_iou: 0.8916 - true_positives: 122055216.0000 - false_positives: 8717616.0000 - true_negatives: 179726848.0000 - false_negatives: 9021055.0000 - precision: 0.9333 - recall: 0.9312 - val_loss: 0.1315 - val_accuracy: 0.8824 - val_binary_iou: 0.7882 - val_true_positives: 42040444.0000 - val_false_positives: 9452446.0000 - val_true_negatives: 51471864.0000 - val_false_negatives: 3006957.0000 - val_precision: 0.8164 - val_recall: 0.9332\n",
      "Epoch 35/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0673 - accuracy: 0.9456 - binary_iou: 0.8938 - true_positives: 122449288.0000 - false_positives: 8626454.0000 - true_negatives: 179701072.0000 - false_negatives: 8743997.0000 - precision: 0.9342 - recall: 0.9334 - val_loss: 0.1303 - val_accuracy: 0.8836 - val_binary_iou: 0.7901 - val_true_positives: 42099440.0000 - val_false_positives: 9352064.0000 - val_true_negatives: 51535944.0000 - val_false_negatives: 2984264.0000 - val_precision: 0.8182 - val_recall: 0.9338\n",
      "Epoch 36/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0657 - accuracy: 0.9468 - binary_iou: 0.8959 - true_positives: 122491432.0000 - false_positives: 8420950.0000 - true_negatives: 180024384.0000 - false_negatives: 8583938.0000 - precision: 0.9357 - recall: 0.9345 - val_loss: 0.1355 - val_accuracy: 0.8765 - val_binary_iou: 0.7791 - val_true_positives: 42398184.0000 - val_false_positives: 10424447.0000 - val_true_negatives: 50480976.0000 - val_false_negatives: 2668113.0000 - val_precision: 0.8027 - val_recall: 0.9408\n",
      "Epoch 37/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9475 - binary_iou: 0.8972 - true_positives: 122647024.0000 - false_positives: 8346757.0000 - true_negatives: 180094768.0000 - false_negatives: 8432264.0000 - precision: 0.9363 - recall: 0.9357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0651 - accuracy: 0.9475 - binary_iou: 0.8972 - true_positives: 122647024.0000 - false_positives: 8346757.0000 - true_negatives: 180094768.0000 - false_negatives: 8432264.0000 - precision: 0.9363 - recall: 0.9357 - val_loss: 0.1257 - val_accuracy: 0.8879 - val_binary_iou: 0.7968 - val_true_positives: 41770448.0000 - val_false_positives: 8555145.0000 - val_true_negatives: 52325856.0000 - val_false_negatives: 3320267.0000 - val_precision: 0.8300 - val_recall: 0.9264\n",
      "Epoch 38/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0636 - accuracy: 0.9485 - binary_iou: 0.8990 - true_positives: 122792992.0000 - false_positives: 8106492.0000 - true_negatives: 180257984.0000 - false_negatives: 8363210.0000 - precision: 0.9381 - recall: 0.9362 - val_loss: 0.1295 - val_accuracy: 0.8833 - val_binary_iou: 0.7896 - val_true_positives: 42067272.0000 - val_false_positives: 9267178.0000 - val_true_negatives: 51532980.0000 - val_false_negatives: 3104279.0000 - val_precision: 0.8195 - val_recall: 0.9313\n",
      "Epoch 39/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0624 - accuracy: 0.9496 - binary_iou: 0.9011 - true_positives: 122819128.0000 - false_positives: 7835624.0000 - true_negatives: 180594016.0000 - false_negatives: 8271983.0000 - precision: 0.9400 - recall: 0.9369 - val_loss: 0.1326 - val_accuracy: 0.8804 - val_binary_iou: 0.7851 - val_true_positives: 42055880.0000 - val_false_positives: 9655177.0000 - val_true_negatives: 51245440.0000 - val_false_negatives: 3015210.0000 - val_precision: 0.8133 - val_recall: 0.9331\n",
      "Epoch 40/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0621 - accuracy: 0.9500 - binary_iou: 0.9019 - true_positives: 122957888.0000 - false_positives: 7867755.0000 - true_negatives: 180600640.0000 - false_negatives: 8094499.0000 - precision: 0.9399 - recall: 0.9382 - val_loss: 0.1275 - val_accuracy: 0.8861 - val_binary_iou: 0.7940 - val_true_positives: 41904552.0000 - val_false_positives: 8877881.0000 - val_true_negatives: 51995892.0000 - val_false_negatives: 3193386.0000 - val_precision: 0.8252 - val_recall: 0.9292\n",
      "Epoch 41/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0608 - accuracy: 0.9509 - binary_iou: 0.9036 - true_positives: 123265856.0000 - false_positives: 7821314.0000 - true_negatives: 180574016.0000 - false_negatives: 7859492.0000 - precision: 0.9403 - recall: 0.9401 - val_loss: 0.1300 - val_accuracy: 0.8826 - val_binary_iou: 0.7886 - val_true_positives: 42101456.0000 - val_false_positives: 9388780.0000 - val_true_negatives: 51430716.0000 - val_false_negatives: 3050776.0000 - val_precision: 0.8177 - val_recall: 0.9324\n",
      "Epoch 42/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9519 - binary_iou: 0.9054 - true_positives: 123317856.0000 - false_positives: 7570347.0000 - true_negatives: 180830400.0000 - false_negatives: 7802196.0000 - precision: 0.9422 - recall: 0.9405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 465ms/step - loss: 0.0595 - accuracy: 0.9519 - binary_iou: 0.9054 - true_positives: 123317856.0000 - false_positives: 7570347.0000 - true_negatives: 180830400.0000 - false_negatives: 7802196.0000 - precision: 0.9422 - recall: 0.9405 - val_loss: 0.1246 - val_accuracy: 0.8895 - val_binary_iou: 0.7993 - val_true_positives: 41853944.0000 - val_false_positives: 8425754.0000 - val_true_negatives: 52403844.0000 - val_false_negatives: 3288166.0000 - val_precision: 0.8324 - val_recall: 0.9272\n",
      "Epoch 43/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0596 - accuracy: 0.9520 - binary_iou: 0.9056 - true_positives: 123339184.0000 - false_positives: 7609472.0000 - true_negatives: 180840272.0000 - false_negatives: 7731827.0000 - precision: 0.9419 - recall: 0.9410 - val_loss: 0.1288 - val_accuracy: 0.8849 - val_binary_iou: 0.7921 - val_true_positives: 41775532.0000 - val_false_positives: 8895232.0000 - val_true_negatives: 52003540.0000 - val_false_negatives: 3297408.0000 - val_precision: 0.8245 - val_recall: 0.9268\n",
      "Epoch 44/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0581 - accuracy: 0.9531 - binary_iou: 0.9076 - true_positives: 123409824.0000 - false_positives: 7363923.0000 - true_negatives: 181120576.0000 - false_negatives: 7626432.0000 - precision: 0.9437 - recall: 0.9418 - val_loss: 0.1261 - val_accuracy: 0.8865 - val_binary_iou: 0.7947 - val_true_positives: 42115228.0000 - val_false_positives: 8988935.0000 - val_true_negatives: 51825700.0000 - val_false_negatives: 3041835.0000 - val_precision: 0.8241 - val_recall: 0.9326\n",
      "Epoch 45/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0575 - accuracy: 0.9536 - binary_iou: 0.9086 - true_positives: 123691192.0000 - false_positives: 7367136.0000 - true_negatives: 181005200.0000 - false_negatives: 7457195.0000 - precision: 0.9438 - recall: 0.9431 - val_loss: 0.1257 - val_accuracy: 0.8881 - val_binary_iou: 0.7971 - val_true_positives: 41812896.0000 - val_false_positives: 8528524.0000 - val_true_negatives: 52301484.0000 - val_false_negatives: 3328794.0000 - val_precision: 0.8306 - val_recall: 0.9263\n",
      "Epoch 46/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9543 - binary_iou: 0.9100 - true_positives: 123814984.0000 - false_positives: 7299923.0000 - true_negatives: 181115488.0000 - false_negatives: 7290334.0000 - precision: 0.9443 - recall: 0.9444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0565 - accuracy: 0.9543 - binary_iou: 0.9100 - true_positives: 123814984.0000 - false_positives: 7299923.0000 - true_negatives: 181115488.0000 - false_negatives: 7290334.0000 - precision: 0.9443 - recall: 0.9444 - val_loss: 0.1242 - val_accuracy: 0.8897 - val_binary_iou: 0.7996 - val_true_positives: 41746424.0000 - val_false_positives: 8377013.0000 - val_true_negatives: 52532720.0000 - val_false_negatives: 3315544.0000 - val_precision: 0.8329 - val_recall: 0.9264\n",
      "Epoch 47/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0562 - accuracy: 0.9548 - binary_iou: 0.9109 - true_positives: 123730608.0000 - false_positives: 7161344.0000 - true_negatives: 181348656.0000 - false_negatives: 7280239.0000 - precision: 0.9453 - recall: 0.9444 - val_loss: 0.1309 - val_accuracy: 0.8816 - val_binary_iou: 0.7871 - val_true_positives: 42277252.0000 - val_false_positives: 9728853.0000 - val_true_negatives: 51148032.0000 - val_false_negatives: 2817566.0000 - val_precision: 0.8129 - val_recall: 0.9375\n",
      "Epoch 48/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0557 - accuracy: 0.9551 - binary_iou: 0.9114 - true_positives: 123894432.0000 - false_positives: 7127705.0000 - true_negatives: 181273088.0000 - false_negatives: 7225512.0000 - precision: 0.9456 - recall: 0.9449 - val_loss: 0.1340 - val_accuracy: 0.8781 - val_binary_iou: 0.7815 - val_true_positives: 42110152.0000 - val_false_positives: 9957786.0000 - val_true_negatives: 50943680.0000 - val_false_negatives: 2960089.0000 - val_precision: 0.8088 - val_recall: 0.9343\n",
      "Epoch 49/500\n",
      "199/199 [==============================] - 78s 393ms/step - loss: 0.0547 - accuracy: 0.9559 - binary_iou: 0.9130 - true_positives: 124048768.0000 - false_positives: 7004540.0000 - true_negatives: 181383936.0000 - false_negatives: 7083510.0000 - precision: 0.9466 - recall: 0.9460 - val_loss: 0.1281 - val_accuracy: 0.8855 - val_binary_iou: 0.7929 - val_true_positives: 41827468.0000 - val_false_positives: 8855179.0000 - val_true_negatives: 52007936.0000 - val_false_negatives: 3281119.0000 - val_precision: 0.8253 - val_recall: 0.9273\n",
      "Epoch 50/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9564 - binary_iou: 0.9139 - true_positives: 124150240.0000 - false_positives: 6944990.0000 - true_negatives: 181434720.0000 - false_negatives: 6990905.0000 - precision: 0.9470 - recall: 0.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0540 - accuracy: 0.9564 - binary_iou: 0.9139 - true_positives: 124150240.0000 - false_positives: 6944990.0000 - true_negatives: 181434720.0000 - false_negatives: 6990905.0000 - precision: 0.9470 - recall: 0.9467 - val_loss: 0.1222 - val_accuracy: 0.8919 - val_binary_iou: 0.8031 - val_true_positives: 41661540.0000 - val_false_positives: 8041315.0000 - val_true_negatives: 52855652.0000 - val_false_negatives: 3413214.0000 - val_precision: 0.8382 - val_recall: 0.9243\n",
      "Epoch 51/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0534 - accuracy: 0.9569 - binary_iou: 0.9148 - true_positives: 124208896.0000 - false_positives: 6821918.0000 - true_negatives: 181525280.0000 - false_negatives: 6964568.0000 - precision: 0.9479 - recall: 0.9469 - val_loss: 0.1223 - val_accuracy: 0.8915 - val_binary_iou: 0.8024 - val_true_positives: 41753120.0000 - val_false_positives: 8129378.0000 - val_true_negatives: 52715552.0000 - val_false_negatives: 3373643.0000 - val_precision: 0.8370 - val_recall: 0.9252\n",
      "Epoch 52/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0529 - accuracy: 0.9573 - binary_iou: 0.9155 - true_positives: 124242392.0000 - false_positives: 6796562.0000 - true_negatives: 181623104.0000 - false_negatives: 6858741.0000 - precision: 0.9481 - recall: 0.9477 - val_loss: 0.1269 - val_accuracy: 0.8871 - val_binary_iou: 0.7955 - val_true_positives: 41912720.0000 - val_false_positives: 8807294.0000 - val_true_negatives: 52090096.0000 - val_false_negatives: 3161605.0000 - val_precision: 0.8264 - val_recall: 0.9299\n",
      "Epoch 53/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0527 - accuracy: 0.9576 - binary_iou: 0.9161 - true_positives: 124339128.0000 - false_positives: 6753952.0000 - true_negatives: 181618928.0000 - false_negatives: 6808885.0000 - precision: 0.9485 - recall: 0.9481 - val_loss: 0.1232 - val_accuracy: 0.8902 - val_binary_iou: 0.8005 - val_true_positives: 41812236.0000 - val_false_positives: 8362718.0000 - val_true_negatives: 52524824.0000 - val_false_negatives: 3271953.0000 - val_precision: 0.8333 - val_recall: 0.9274\n",
      "Epoch 54/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9586 - binary_iou: 0.9181 - true_positives: 124474576.0000 - false_positives: 6551928.0000 - true_negatives: 181825328.0000 - false_negatives: 6668850.0000 - precision: 0.9500 - recall: 0.9491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0512 - accuracy: 0.9586 - binary_iou: 0.9181 - true_positives: 124474576.0000 - false_positives: 6551928.0000 - true_negatives: 181825328.0000 - false_negatives: 6668850.0000 - precision: 0.9500 - recall: 0.9491 - val_loss: 0.1219 - val_accuracy: 0.8933 - val_binary_iou: 0.8052 - val_true_positives: 41421368.0000 - val_false_positives: 7566449.0000 - val_true_negatives: 53242968.0000 - val_false_negatives: 3740926.0000 - val_precision: 0.8455 - val_recall: 0.9172\n",
      "Epoch 55/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0509 - accuracy: 0.9590 - binary_iou: 0.9188 - true_positives: 124498568.0000 - false_positives: 6482730.0000 - true_negatives: 181924256.0000 - false_negatives: 6615185.0000 - precision: 0.9505 - recall: 0.9495 - val_loss: 0.1262 - val_accuracy: 0.8871 - val_binary_iou: 0.7957 - val_true_positives: 42056816.0000 - val_false_positives: 8884642.0000 - val_true_negatives: 51952576.0000 - val_false_negatives: 3077687.0000 - val_precision: 0.8256 - val_recall: 0.9318\n",
      "Epoch 56/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9591 - binary_iou: 0.9190 - true_positives: 124608576.0000 - false_positives: 6522735.0000 - true_negatives: 181834432.0000 - false_negatives: 6555060.0000 - precision: 0.9503 - recall: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0508 - accuracy: 0.9591 - binary_iou: 0.9190 - true_positives: 124608576.0000 - false_positives: 6522735.0000 - true_negatives: 181834432.0000 - false_negatives: 6555060.0000 - precision: 0.9503 - recall: 0.9500 - val_loss: 0.1206 - val_accuracy: 0.8936 - val_binary_iou: 0.8058 - val_true_positives: 41610432.0000 - val_false_positives: 7841196.0000 - val_true_negatives: 53084456.0000 - val_false_negatives: 3435620.0000 - val_precision: 0.8414 - val_recall: 0.9237\n",
      "Epoch 57/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0501 - accuracy: 0.9595 - binary_iou: 0.9198 - true_positives: 124652152.0000 - false_positives: 6494837.0000 - true_negatives: 181933584.0000 - false_negatives: 6440269.0000 - precision: 0.9505 - recall: 0.9509 - val_loss: 0.1215 - val_accuracy: 0.8934 - val_binary_iou: 0.8055 - val_true_positives: 41684836.0000 - val_false_positives: 7899357.0000 - val_true_negatives: 52988456.0000 - val_false_negatives: 3399062.0000 - val_precision: 0.8407 - val_recall: 0.9246\n",
      "Epoch 58/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0497 - accuracy: 0.9599 - binary_iou: 0.9205 - true_positives: 124685232.0000 - false_positives: 6388964.0000 - true_negatives: 182021184.0000 - false_negatives: 6425340.0000 - precision: 0.9513 - recall: 0.9510 - val_loss: 0.1253 - val_accuracy: 0.8880 - val_binary_iou: 0.7970 - val_true_positives: 41902152.0000 - val_false_positives: 8619049.0000 - val_true_negatives: 52197204.0000 - val_false_negatives: 3253293.0000 - val_precision: 0.8294 - val_recall: 0.9280\n",
      "Epoch 59/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0485 - accuracy: 0.9607 - binary_iou: 0.9221 - true_positives: 124843768.0000 - false_positives: 6237962.0000 - true_negatives: 182133872.0000 - false_negatives: 6305220.0000 - precision: 0.9524 - recall: 0.9519 - val_loss: 0.1215 - val_accuracy: 0.8927 - val_binary_iou: 0.8046 - val_true_positives: 41811372.0000 - val_false_positives: 8136709.0000 - val_true_negatives: 52794552.0000 - val_false_negatives: 3229087.0000 - val_precision: 0.8371 - val_recall: 0.9283\n",
      "Epoch 60/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0489 - accuracy: 0.9604 - binary_iou: 0.9215 - true_positives: 124729952.0000 - false_positives: 6309748.0000 - true_negatives: 182136304.0000 - false_negatives: 6344792.0000 - precision: 0.9518 - recall: 0.9516 - val_loss: 0.1248 - val_accuracy: 0.8892 - val_binary_iou: 0.7989 - val_true_positives: 41824496.0000 - val_false_positives: 8407685.0000 - val_true_negatives: 52405208.0000 - val_false_negatives: 3334311.0000 - val_precision: 0.8326 - val_recall: 0.9262\n",
      "Epoch 61/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0486 - accuracy: 0.9607 - binary_iou: 0.9220 - true_positives: 124820352.0000 - false_positives: 6267639.0000 - true_negatives: 182133680.0000 - false_negatives: 6299037.0000 - precision: 0.9522 - recall: 0.9520 - val_loss: 0.1308 - val_accuracy: 0.8832 - val_binary_iou: 0.7894 - val_true_positives: 41925036.0000 - val_false_positives: 9244025.0000 - val_true_negatives: 51668404.0000 - val_false_negatives: 3134259.0000 - val_precision: 0.8193 - val_recall: 0.9304\n",
      "Epoch 62/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0479 - accuracy: 0.9613 - binary_iou: 0.9232 - true_positives: 124945712.0000 - false_positives: 6129869.0000 - true_negatives: 182212112.0000 - false_negatives: 6233134.0000 - precision: 0.9532 - recall: 0.9525 - val_loss: 0.1240 - val_accuracy: 0.8896 - val_binary_iou: 0.7996 - val_true_positives: 42051700.0000 - val_false_positives: 8637970.0000 - val_true_negatives: 52218488.0000 - val_false_negatives: 3063563.0000 - val_precision: 0.8296 - val_recall: 0.9321\n",
      "Epoch 63/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0467 - accuracy: 0.9622 - binary_iou: 0.9249 - true_positives: 125052880.0000 - false_positives: 5985558.0000 - true_negatives: 182395552.0000 - false_negatives: 6086801.0000 - precision: 0.9543 - recall: 0.9536 - val_loss: 0.1207 - val_accuracy: 0.8929 - val_binary_iou: 0.8049 - val_true_positives: 41907064.0000 - val_false_positives: 8148010.0000 - val_true_negatives: 52720216.0000 - val_false_negatives: 3196420.0000 - val_precision: 0.8372 - val_recall: 0.9291\n",
      "Epoch 64/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0464 - accuracy: 0.9625 - binary_iou: 0.9256 - true_positives: 125132352.0000 - false_positives: 5924953.0000 - true_negatives: 182418400.0000 - false_negatives: 6045100.0000 - precision: 0.9548 - recall: 0.9539 - val_loss: 0.1256 - val_accuracy: 0.8874 - val_binary_iou: 0.7961 - val_true_positives: 42023624.0000 - val_false_positives: 8831275.0000 - val_true_negatives: 52012144.0000 - val_false_negatives: 3104671.0000 - val_precision: 0.8263 - val_recall: 0.9312\n",
      "Epoch 65/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9627 - binary_iou: 0.9258 - true_positives: 125165728.0000 - false_positives: 5918677.0000 - true_negatives: 182429616.0000 - false_negatives: 6006826.0000 - precision: 0.9548 - recall: 0.9542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0461 - accuracy: 0.9627 - binary_iou: 0.9258 - true_positives: 125165728.0000 - false_positives: 5918677.0000 - true_negatives: 182429616.0000 - false_negatives: 6006826.0000 - precision: 0.9548 - recall: 0.9542 - val_loss: 0.1189 - val_accuracy: 0.8952 - val_binary_iou: 0.8083 - val_true_positives: 41606648.0000 - val_false_positives: 7649727.0000 - val_true_negatives: 53254560.0000 - val_false_negatives: 3460792.0000 - val_precision: 0.8447 - val_recall: 0.9232\n",
      "Epoch 66/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0461 - accuracy: 0.9628 - binary_iou: 0.9260 - true_positives: 125186976.0000 - false_positives: 5937238.0000 - true_negatives: 182435856.0000 - false_negatives: 5960641.0000 - precision: 0.9547 - recall: 0.9546 - val_loss: 0.1210 - val_accuracy: 0.8928 - val_binary_iou: 0.8047 - val_true_positives: 41757320.0000 - val_false_positives: 7913466.0000 - val_true_negatives: 52858680.0000 - val_false_negatives: 3442239.0000 - val_precision: 0.8407 - val_recall: 0.9238\n",
      "Epoch 67/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0456 - accuracy: 0.9631 - binary_iou: 0.9267 - true_positives: 125294720.0000 - false_positives: 5874910.0000 - true_negatives: 182443072.0000 - false_negatives: 5908088.0000 - precision: 0.9552 - recall: 0.9550 - val_loss: 0.1206 - val_accuracy: 0.8929 - val_binary_iou: 0.8048 - val_true_positives: 41945632.0000 - val_false_positives: 8205150.0000 - val_true_negatives: 52673356.0000 - val_false_negatives: 3147574.0000 - val_precision: 0.8364 - val_recall: 0.9302\n",
      "Epoch 68/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9634 - binary_iou: 0.9273 - true_positives: 125223144.0000 - false_positives: 5742927.0000 - true_negatives: 182616768.0000 - false_negatives: 5937899.0000 - precision: 0.9561 - recall: 0.9547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0453 - accuracy: 0.9634 - binary_iou: 0.9273 - true_positives: 125223144.0000 - false_positives: 5742927.0000 - true_negatives: 182616768.0000 - false_negatives: 5937899.0000 - precision: 0.9561 - recall: 0.9547 - val_loss: 0.1167 - val_accuracy: 0.8980 - val_binary_iou: 0.8129 - val_true_positives: 41582416.0000 - val_false_positives: 7262783.0000 - val_true_negatives: 53578216.0000 - val_false_negatives: 3548295.0000 - val_precision: 0.8513 - val_recall: 0.9214\n",
      "Epoch 69/500\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0451 - accuracy: 0.9634 - binary_iou: 0.9272 - true_positives: 125288264.0000 - false_positives: 5847377.0000 - true_negatives: 182536752.0000 - false_negatives: 5848343.0000 - precision: 0.9554 - recall: 0.9554 - val_loss: 0.1232 - val_accuracy: 0.8900 - val_binary_iou: 0.8003 - val_true_positives: 42052168.0000 - val_false_positives: 8613090.0000 - val_true_negatives: 52260068.0000 - val_false_negatives: 3046394.0000 - val_precision: 0.8300 - val_recall: 0.9325\n",
      "Epoch 70/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0450 - accuracy: 0.9637 - binary_iou: 0.9277 - true_positives: 125207664.0000 - false_positives: 5776400.0000 - true_negatives: 182711536.0000 - false_negatives: 5825133.0000 - precision: 0.9559 - recall: 0.9555 - val_loss: 0.1216 - val_accuracy: 0.8912 - val_binary_iou: 0.8022 - val_true_positives: 42039144.0000 - val_false_positives: 8377021.0000 - val_true_negatives: 52401928.0000 - val_false_negatives: 3153628.0000 - val_precision: 0.8338 - val_recall: 0.9302\n",
      "Epoch 71/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0440 - accuracy: 0.9644 - binary_iou: 0.9292 - true_positives: 125461672.0000 - false_positives: 5680315.0000 - true_negatives: 182693840.0000 - false_negatives: 5684932.0000 - precision: 0.9567 - recall: 0.9567 - val_loss: 0.1268 - val_accuracy: 0.8860 - val_binary_iou: 0.7939 - val_true_positives: 42120440.0000 - val_false_positives: 9141168.0000 - val_true_negatives: 51766000.0000 - val_false_negatives: 2944097.0000 - val_precision: 0.8217 - val_recall: 0.9347\n",
      "Epoch 72/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0439 - accuracy: 0.9644 - binary_iou: 0.9292 - true_positives: 125397072.0000 - false_positives: 5683022.0000 - true_negatives: 182762304.0000 - false_negatives: 5678375.0000 - precision: 0.9566 - recall: 0.9567 - val_loss: 0.1246 - val_accuracy: 0.8885 - val_binary_iou: 0.7979 - val_true_positives: 42004496.0000 - val_false_positives: 8601797.0000 - val_true_negatives: 52154352.0000 - val_false_negatives: 3211056.0000 - val_precision: 0.8300 - val_recall: 0.9290\n",
      "Epoch 73/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0435 - accuracy: 0.9648 - binary_iou: 0.9299 - true_positives: 125438352.0000 - false_positives: 5537698.0000 - true_negatives: 182834544.0000 - false_negatives: 5710256.0000 - precision: 0.9577 - recall: 0.9565 - val_loss: 0.1182 - val_accuracy: 0.8953 - val_binary_iou: 0.8088 - val_true_positives: 41908288.0000 - val_false_positives: 7893304.0000 - val_true_negatives: 52970564.0000 - val_false_negatives: 3199555.0000 - val_precision: 0.8415 - val_recall: 0.9291\n",
      "Epoch 74/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0435 - accuracy: 0.9650 - binary_iou: 0.9304 - true_positives: 125498280.0000 - false_positives: 5531368.0000 - true_negatives: 182852912.0000 - false_negatives: 5638100.0000 - precision: 0.9578 - recall: 0.9570 - val_loss: 0.1230 - val_accuracy: 0.8910 - val_binary_iou: 0.8019 - val_true_positives: 41984324.0000 - val_false_positives: 8465641.0000 - val_true_negatives: 52437412.0000 - val_false_negatives: 3084328.0000 - val_precision: 0.8322 - val_recall: 0.9316\n",
      "Epoch 75/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0430 - accuracy: 0.9653 - binary_iou: 0.9309 - true_positives: 125682424.0000 - false_positives: 5539541.0000 - true_negatives: 182757072.0000 - false_negatives: 5541738.0000 - precision: 0.9578 - recall: 0.9578 - val_loss: 0.1204 - val_accuracy: 0.8937 - val_binary_iou: 0.8061 - val_true_positives: 41774060.0000 - val_false_positives: 7934615.0000 - val_true_negatives: 52934636.0000 - val_false_negatives: 3328391.0000 - val_precision: 0.8404 - val_recall: 0.9262\n",
      "Epoch 76/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0422 - accuracy: 0.9658 - binary_iou: 0.9319 - true_positives: 125737072.0000 - false_positives: 5460914.0000 - true_negatives: 182865552.0000 - false_negatives: 5457208.0000 - precision: 0.9584 - recall: 0.9584 - val_loss: 0.1196 - val_accuracy: 0.8938 - val_binary_iou: 0.8063 - val_true_positives: 41870952.0000 - val_false_positives: 8040349.0000 - val_true_negatives: 52844488.0000 - val_false_negatives: 3215915.0000 - val_precision: 0.8389 - val_recall: 0.9287\n",
      "Epoch 77/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0420 - accuracy: 0.9660 - binary_iou: 0.9323 - true_positives: 125683400.0000 - false_positives: 5385466.0000 - true_negatives: 182987344.0000 - false_negatives: 5464519.0000 - precision: 0.9589 - recall: 0.9583 - val_loss: 0.1222 - val_accuracy: 0.8908 - val_binary_iou: 0.8016 - val_true_positives: 42110328.0000 - val_false_positives: 8591626.0000 - val_true_negatives: 52289048.0000 - val_false_negatives: 2980710.0000 - val_precision: 0.8305 - val_recall: 0.9339\n",
      "Epoch 78/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0419 - accuracy: 0.9662 - binary_iou: 0.9325 - true_positives: 125718264.0000 - false_positives: 5405481.0000 - true_negatives: 182990400.0000 - false_negatives: 5406699.0000 - precision: 0.9588 - recall: 0.9588 - val_loss: 0.1207 - val_accuracy: 0.8927 - val_binary_iou: 0.8046 - val_true_positives: 41974688.0000 - val_false_positives: 8197211.0000 - val_true_negatives: 52624980.0000 - val_false_negatives: 3174840.0000 - val_precision: 0.8366 - val_recall: 0.9297\n",
      "Epoch 79/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0418 - accuracy: 0.9663 - binary_iou: 0.9327 - true_positives: 125710144.0000 - false_positives: 5353292.0000 - true_negatives: 183038640.0000 - false_negatives: 5418668.0000 - precision: 0.9592 - recall: 0.9587 - val_loss: 0.1238 - val_accuracy: 0.8892 - val_binary_iou: 0.7991 - val_true_positives: 42060008.0000 - val_false_positives: 8761004.0000 - val_true_negatives: 52174988.0000 - val_false_negatives: 2975719.0000 - val_precision: 0.8276 - val_recall: 0.9339\n",
      "Epoch 80/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0410 - accuracy: 0.9668 - binary_iou: 0.9337 - true_positives: 125728432.0000 - false_positives: 5276412.0000 - true_negatives: 183181232.0000 - false_negatives: 5334726.0000 - precision: 0.9597 - recall: 0.9593 - val_loss: 0.1193 - val_accuracy: 0.8940 - val_binary_iou: 0.8067 - val_true_positives: 41943540.0000 - val_false_positives: 8095513.0000 - val_true_negatives: 52796336.0000 - val_false_negatives: 3136327.0000 - val_precision: 0.8382 - val_recall: 0.9304\n",
      "Epoch 81/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0410 - accuracy: 0.9669 - binary_iou: 0.9339 - true_positives: 125847384.0000 - false_positives: 5308735.0000 - true_negatives: 183092592.0000 - false_negatives: 5272086.0000 - precision: 0.9595 - recall: 0.9598 - val_loss: 0.1193 - val_accuracy: 0.8945 - val_binary_iou: 0.8074 - val_true_positives: 41819408.0000 - val_false_positives: 7933543.0000 - val_true_negatives: 52974004.0000 - val_false_negatives: 3244751.0000 - val_precision: 0.8405 - val_recall: 0.9280\n",
      "Epoch 82/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0411 - accuracy: 0.9669 - binary_iou: 0.9339 - true_positives: 125817064.0000 - false_positives: 5270892.0000 - true_negatives: 183118928.0000 - false_negatives: 5313910.0000 - precision: 0.9598 - recall: 0.9595 - val_loss: 0.1271 - val_accuracy: 0.8856 - val_binary_iou: 0.7933 - val_true_positives: 42083560.0000 - val_false_positives: 9094966.0000 - val_true_negatives: 51764212.0000 - val_false_negatives: 3028986.0000 - val_precision: 0.8223 - val_recall: 0.9329\n",
      "Epoch 83/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0405 - accuracy: 0.9672 - binary_iou: 0.9346 - true_positives: 125881424.0000 - false_positives: 5209532.0000 - true_negatives: 183172624.0000 - false_negatives: 5257258.0000 - precision: 0.9603 - recall: 0.9599 - val_loss: 0.1221 - val_accuracy: 0.8927 - val_binary_iou: 0.8045 - val_true_positives: 41789268.0000 - val_false_positives: 7953678.0000 - val_true_negatives: 52814768.0000 - val_false_negatives: 3414001.0000 - val_precision: 0.8401 - val_recall: 0.9245\n",
      "Epoch 84/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0404 - accuracy: 0.9673 - binary_iou: 0.9348 - true_positives: 125919088.0000 - false_positives: 5172602.0000 - true_negatives: 183165072.0000 - false_negatives: 5263927.0000 - precision: 0.9605 - recall: 0.9599 - val_loss: 0.1196 - val_accuracy: 0.8949 - val_binary_iou: 0.8080 - val_true_positives: 41697680.0000 - val_false_positives: 7673459.0000 - val_true_negatives: 53138856.0000 - val_false_negatives: 3461713.0000 - val_precision: 0.8446 - val_recall: 0.9233\n",
      "Epoch 85/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0401 - accuracy: 0.9676 - binary_iou: 0.9353 - true_positives: 125964112.0000 - false_positives: 5163825.0000 - true_negatives: 183206352.0000 - false_negatives: 5186538.0000 - precision: 0.9606 - recall: 0.9605 - val_loss: 0.1279 - val_accuracy: 0.8852 - val_binary_iou: 0.7927 - val_true_positives: 42047784.0000 - val_false_positives: 9206003.0000 - val_true_negatives: 51759000.0000 - val_false_negatives: 2958933.0000 - val_precision: 0.8204 - val_recall: 0.9343\n",
      "Epoch 86/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0399 - accuracy: 0.9679 - binary_iou: 0.9358 - true_positives: 125996384.0000 - false_positives: 5113787.0000 - true_negatives: 183259152.0000 - false_negatives: 5151400.0000 - precision: 0.9610 - recall: 0.9607 - val_loss: 0.1209 - val_accuracy: 0.8930 - val_binary_iou: 0.8050 - val_true_positives: 42003260.0000 - val_false_positives: 8147311.0000 - val_true_negatives: 52625424.0000 - val_false_negatives: 3195730.0000 - val_precision: 0.8375 - val_recall: 0.9293\n",
      "Epoch 87/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0392 - accuracy: 0.9682 - binary_iou: 0.9365 - true_positives: 126113680.0000 - false_positives: 5119376.0000 - true_negatives: 183253632.0000 - false_negatives: 5034145.0000 - precision: 0.9610 - recall: 0.9616 - val_loss: 0.1186 - val_accuracy: 0.8949 - val_binary_iou: 0.8081 - val_true_positives: 41740448.0000 - val_false_positives: 7715908.0000 - val_true_negatives: 53098728.0000 - val_false_negatives: 3416629.0000 - val_precision: 0.8440 - val_recall: 0.9243\n",
      "Epoch 88/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0390 - accuracy: 0.9684 - binary_iou: 0.9368 - true_positives: 126170216.0000 - false_positives: 5091903.0000 - true_negatives: 183250400.0000 - false_negatives: 5008110.0000 - precision: 0.9612 - recall: 0.9618 - val_loss: 0.1181 - val_accuracy: 0.8964 - val_binary_iou: 0.8103 - val_true_positives: 41536916.0000 - val_false_positives: 7482807.0000 - val_true_negatives: 53455616.0000 - val_false_negatives: 3496366.0000 - val_precision: 0.8474 - val_recall: 0.9224\n",
      "Epoch 89/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0390 - accuracy: 0.9685 - binary_iou: 0.9370 - true_positives: 126080368.0000 - false_positives: 5013831.0000 - true_negatives: 183379328.0000 - false_negatives: 5047230.0000 - precision: 0.9618 - recall: 0.9615 - val_loss: 0.1218 - val_accuracy: 0.8915 - val_binary_iou: 0.8026 - val_true_positives: 41944792.0000 - val_false_positives: 8291541.0000 - val_true_negatives: 52527464.0000 - val_false_negatives: 3207907.0000 - val_precision: 0.8349 - val_recall: 0.9290\n",
      "Epoch 90/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0384 - accuracy: 0.9690 - binary_iou: 0.9380 - true_positives: 126211160.0000 - false_positives: 4913976.0000 - true_negatives: 183404976.0000 - false_negatives: 4990677.0000 - precision: 0.9625 - recall: 0.9620 - val_loss: 0.1220 - val_accuracy: 0.8920 - val_binary_iou: 0.8033 - val_true_positives: 41773080.0000 - val_false_positives: 8104845.0000 - val_true_negatives: 52752108.0000 - val_false_negatives: 3341668.0000 - val_precision: 0.8375 - val_recall: 0.9259\n",
      "Epoch 91/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0383 - accuracy: 0.9690 - binary_iou: 0.9380 - true_positives: 126208488.0000 - false_positives: 4990331.0000 - true_negatives: 183414960.0000 - false_negatives: 4907018.0000 - precision: 0.9620 - recall: 0.9626 - val_loss: 0.1228 - val_accuracy: 0.8909 - val_binary_iou: 0.8017 - val_true_positives: 41900828.0000 - val_false_positives: 8394955.0000 - val_true_negatives: 52512824.0000 - val_false_negatives: 3163111.0000 - val_precision: 0.8331 - val_recall: 0.9298\n",
      "Epoch 92/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0385 - accuracy: 0.9689 - binary_iou: 0.9378 - true_positives: 126100816.0000 - false_positives: 4921097.0000 - true_negatives: 183486720.0000 - false_negatives: 5012126.0000 - precision: 0.9624 - recall: 0.9618 - val_loss: 0.1231 - val_accuracy: 0.8907 - val_binary_iou: 0.8013 - val_true_positives: 41874536.0000 - val_false_positives: 8330434.0000 - val_true_negatives: 52516312.0000 - val_false_negatives: 3250430.0000 - val_precision: 0.8341 - val_recall: 0.9280\n",
      "Epoch 93/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0379 - accuracy: 0.9692 - binary_iou: 0.9384 - true_positives: 126202600.0000 - false_positives: 4930683.0000 - true_negatives: 183480128.0000 - false_negatives: 4907438.0000 - precision: 0.9624 - recall: 0.9626 - val_loss: 0.1192 - val_accuracy: 0.8942 - val_binary_iou: 0.8070 - val_true_positives: 41993572.0000 - val_false_positives: 8101824.0000 - val_true_negatives: 52764444.0000 - val_false_negatives: 3111882.0000 - val_precision: 0.8383 - val_recall: 0.9310\n",
      "Epoch 94/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0378 - accuracy: 0.9694 - binary_iou: 0.9388 - true_positives: 126235048.0000 - false_positives: 4822091.0000 - true_negatives: 183519296.0000 - false_negatives: 4944243.0000 - precision: 0.9632 - recall: 0.9623 - val_loss: 0.1177 - val_accuracy: 0.8964 - val_binary_iou: 0.8105 - val_true_positives: 41868816.0000 - val_false_positives: 7710398.0000 - val_true_negatives: 53121316.0000 - val_false_negatives: 3271175.0000 - val_precision: 0.8445 - val_recall: 0.9275\n",
      "Epoch 95/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0378 - accuracy: 0.9694 - binary_iou: 0.9388 - true_positives: 126283016.0000 - false_positives: 4864026.0000 - true_negatives: 183470368.0000 - false_negatives: 4903352.0000 - precision: 0.9629 - recall: 0.9626 - val_loss: 0.1188 - val_accuracy: 0.8960 - val_binary_iou: 0.8096 - val_true_positives: 41528936.0000 - val_false_positives: 7458264.0000 - val_true_negatives: 53419964.0000 - val_false_negatives: 3564548.0000 - val_precision: 0.8478 - val_recall: 0.9210\n",
      "Epoch 96/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0371 - accuracy: 0.9700 - binary_iou: 0.9399 - true_positives: 126291968.0000 - false_positives: 4777623.0000 - true_negatives: 183637728.0000 - false_negatives: 4813415.0000 - precision: 0.9635 - recall: 0.9633 - val_loss: 0.1226 - val_accuracy: 0.8911 - val_binary_iou: 0.8019 - val_true_positives: 41972164.0000 - val_false_positives: 8399711.0000 - val_true_negatives: 52454088.0000 - val_false_negatives: 3145756.0000 - val_precision: 0.8332 - val_recall: 0.9303\n",
      "Epoch 97/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0372 - accuracy: 0.9700 - binary_iou: 0.9400 - true_positives: 126405968.0000 - false_positives: 4778338.0000 - true_negatives: 183539232.0000 - false_negatives: 4797295.0000 - precision: 0.9636 - recall: 0.9634 - val_loss: 0.1198 - val_accuracy: 0.8942 - val_binary_iou: 0.8069 - val_true_positives: 41838944.0000 - val_false_positives: 8006038.0000 - val_true_negatives: 52921996.0000 - val_false_negatives: 3204723.0000 - val_precision: 0.8394 - val_recall: 0.9289\n",
      "Epoch 98/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0366 - accuracy: 0.9705 - binary_iou: 0.9408 - true_positives: 126355304.0000 - false_positives: 4743102.0000 - true_negatives: 183724224.0000 - false_negatives: 4698073.0000 - precision: 0.9638 - recall: 0.9642 - val_loss: 0.1221 - val_accuracy: 0.8925 - val_binary_iou: 0.8041 - val_true_positives: 41737176.0000 - val_false_positives: 8111002.0000 - val_true_negatives: 52841064.0000 - val_false_negatives: 3282478.0000 - val_precision: 0.8373 - val_recall: 0.9271\n",
      "Epoch 99/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0364 - accuracy: 0.9707 - binary_iou: 0.9413 - true_positives: 126461072.0000 - false_positives: 4682576.0000 - true_negatives: 183699200.0000 - false_negatives: 4677934.0000 - precision: 0.9643 - recall: 0.9643 - val_loss: 0.1202 - val_accuracy: 0.8940 - val_binary_iou: 0.8066 - val_true_positives: 42002588.0000 - val_false_positives: 8082824.0000 - val_true_negatives: 52731712.0000 - val_false_negatives: 3154588.0000 - val_precision: 0.8386 - val_recall: 0.9301\n",
      "Epoch 100/500\n",
      "199/199 [==============================] - 79s 396ms/step - loss: 0.0360 - accuracy: 0.9709 - binary_iou: 0.9417 - true_positives: 126500048.0000 - false_positives: 4661270.0000 - true_negatives: 183718912.0000 - false_negatives: 4640603.0000 - precision: 0.9645 - recall: 0.9646 - val_loss: 0.1205 - val_accuracy: 0.8932 - val_binary_iou: 0.8054 - val_true_positives: 41905472.0000 - val_false_positives: 8205398.0000 - val_true_negatives: 52751560.0000 - val_false_negatives: 3109300.0000 - val_precision: 0.8363 - val_recall: 0.9309\n",
      "Epoch 101/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9709 - binary_iou: 0.9417 - true_positives: 126416704.0000 - false_positives: 4642693.0000 - true_negatives: 183807520.0000 - false_negatives: 4653846.0000 - precision: 0.9646 - recall: 0.9645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 464ms/step - loss: 0.0361 - accuracy: 0.9709 - binary_iou: 0.9417 - true_positives: 126416704.0000 - false_positives: 4642693.0000 - true_negatives: 183807520.0000 - false_negatives: 4653846.0000 - precision: 0.9646 - recall: 0.9645 - val_loss: 0.1160 - val_accuracy: 0.8984 - val_binary_iou: 0.8136 - val_true_positives: 41761152.0000 - val_false_positives: 7393230.0000 - val_true_negatives: 53440360.0000 - val_false_negatives: 3376976.0000 - val_precision: 0.8496 - val_recall: 0.9252\n",
      "Epoch 102/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0359 - accuracy: 0.9709 - binary_iou: 0.9417 - true_positives: 126443848.0000 - false_positives: 4594982.0000 - true_negatives: 183791472.0000 - false_negatives: 4690577.0000 - precision: 0.9649 - recall: 0.9642 - val_loss: 0.1177 - val_accuracy: 0.8967 - val_binary_iou: 0.8109 - val_true_positives: 41646856.0000 - val_false_positives: 7469505.0000 - val_true_negatives: 53380204.0000 - val_false_negatives: 3475159.0000 - val_precision: 0.8479 - val_recall: 0.9230\n",
      "Epoch 103/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0361 - accuracy: 0.9708 - binary_iou: 0.9416 - true_positives: 126507560.0000 - false_positives: 4682388.0000 - true_negatives: 183696624.0000 - false_negatives: 4634159.0000 - precision: 0.9643 - recall: 0.9647 - val_loss: 0.1188 - val_accuracy: 0.8949 - val_binary_iou: 0.8080 - val_true_positives: 41848192.0000 - val_false_positives: 7889020.0000 - val_true_negatives: 52981592.0000 - val_false_negatives: 3252900.0000 - val_precision: 0.8414 - val_recall: 0.9279\n",
      "Epoch 104/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0355 - accuracy: 0.9713 - binary_iou: 0.9425 - true_positives: 126588472.0000 - false_positives: 4563958.0000 - true_negatives: 183762832.0000 - false_negatives: 4605466.0000 - precision: 0.9652 - recall: 0.9649 - val_loss: 0.1202 - val_accuracy: 0.8953 - val_binary_iou: 0.8086 - val_true_positives: 41652776.0000 - val_false_positives: 7720507.0000 - val_true_negatives: 53228112.0000 - val_false_negatives: 3370321.0000 - val_precision: 0.8436 - val_recall: 0.9251\n",
      "Epoch 105/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0351 - accuracy: 0.9716 - binary_iou: 0.9430 - true_positives: 126622976.0000 - false_positives: 4534560.0000 - true_negatives: 183824128.0000 - false_negatives: 4539174.0000 - precision: 0.9654 - recall: 0.9654 - val_loss: 0.1180 - val_accuracy: 0.8961 - val_binary_iou: 0.8100 - val_true_positives: 41762732.0000 - val_false_positives: 7680780.0000 - val_true_negatives: 53199880.0000 - val_false_negatives: 3328323.0000 - val_precision: 0.8447 - val_recall: 0.9262\n",
      "Epoch 106/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0349 - accuracy: 0.9718 - binary_iou: 0.9434 - true_positives: 126654320.0000 - false_positives: 4516012.0000 - true_negatives: 183855696.0000 - false_negatives: 4494724.0000 - precision: 0.9656 - recall: 0.9657 - val_loss: 0.1154 - val_accuracy: 0.8983 - val_binary_iou: 0.8135 - val_true_positives: 41792332.0000 - val_false_positives: 7477065.0000 - val_true_negatives: 53397848.0000 - val_false_negatives: 3304465.0000 - val_precision: 0.8482 - val_recall: 0.9267\n",
      "Epoch 107/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0351 - accuracy: 0.9717 - binary_iou: 0.9432 - true_positives: 126571688.0000 - false_positives: 4529311.0000 - true_negatives: 183906496.0000 - false_negatives: 4513264.0000 - precision: 0.9655 - recall: 0.9656 - val_loss: 0.1166 - val_accuracy: 0.8978 - val_binary_iou: 0.8126 - val_true_positives: 41632944.0000 - val_false_positives: 7366389.0000 - val_true_negatives: 53509872.0000 - val_false_negatives: 3462520.0000 - val_precision: 0.8497 - val_recall: 0.9232\n",
      "Epoch 108/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0350 - accuracy: 0.9717 - binary_iou: 0.9432 - true_positives: 126652696.0000 - false_positives: 4554831.0000 - true_negatives: 183827360.0000 - false_negatives: 4485899.0000 - precision: 0.9653 - recall: 0.9658 - val_loss: 0.1185 - val_accuracy: 0.8959 - val_binary_iou: 0.8096 - val_true_positives: 41764976.0000 - val_false_positives: 7736519.0000 - val_true_negatives: 53170692.0000 - val_false_negatives: 3299528.0000 - val_precision: 0.8437 - val_recall: 0.9268\n",
      "Epoch 109/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9721 - binary_iou: 0.9439 - true_positives: 126616608.0000 - false_positives: 4454262.0000 - true_negatives: 183973776.0000 - false_negatives: 4476119.0000 - precision: 0.9660 - recall: 0.9659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 466ms/step - loss: 0.0345 - accuracy: 0.9721 - binary_iou: 0.9439 - true_positives: 126616608.0000 - false_positives: 4454262.0000 - true_negatives: 183973776.0000 - false_negatives: 4476119.0000 - precision: 0.9660 - recall: 0.9659 - val_loss: 0.1149 - val_accuracy: 0.8991 - val_binary_iou: 0.8148 - val_true_positives: 41821744.0000 - val_false_positives: 7421501.0000 - val_true_negatives: 53455500.0000 - val_false_negatives: 3272955.0000 - val_precision: 0.8493 - val_recall: 0.9274\n",
      "Epoch 110/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0344 - accuracy: 0.9721 - binary_iou: 0.9440 - true_positives: 126667760.0000 - false_positives: 4461167.0000 - true_negatives: 183929184.0000 - false_negatives: 4462564.0000 - precision: 0.9660 - recall: 0.9660 - val_loss: 0.1184 - val_accuracy: 0.8961 - val_binary_iou: 0.8100 - val_true_positives: 41743144.0000 - val_false_positives: 7603659.0000 - val_true_negatives: 53221572.0000 - val_false_negatives: 3403341.0000 - val_precision: 0.8459 - val_recall: 0.9246\n",
      "Epoch 111/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0345 - accuracy: 0.9721 - binary_iou: 0.9441 - true_positives: 126690576.0000 - false_positives: 4438761.0000 - true_negatives: 183921776.0000 - false_negatives: 4469647.0000 - precision: 0.9661 - recall: 0.9659 - val_loss: 0.1174 - val_accuracy: 0.8967 - val_binary_iou: 0.8109 - val_true_positives: 41896008.0000 - val_false_positives: 7800030.0000 - val_true_negatives: 53124664.0000 - val_false_negatives: 3151005.0000 - val_precision: 0.8430 - val_recall: 0.9301\n",
      "Epoch 112/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0338 - accuracy: 0.9726 - binary_iou: 0.9451 - true_positives: 126742656.0000 - false_positives: 4376627.0000 - true_negatives: 184038288.0000 - false_negatives: 4363207.0000 - precision: 0.9666 - recall: 0.9667 - val_loss: 0.1167 - val_accuracy: 0.8970 - val_binary_iou: 0.8115 - val_true_positives: 41749684.0000 - val_false_positives: 7596579.0000 - val_true_negatives: 53311616.0000 - val_false_negatives: 3313814.0000 - val_precision: 0.8461 - val_recall: 0.9265\n",
      "Epoch 113/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0334 - accuracy: 0.9730 - binary_iou: 0.9458 - true_positives: 126876624.0000 - false_positives: 4295073.0000 - true_negatives: 184020624.0000 - false_negatives: 4328405.0000 - precision: 0.9673 - recall: 0.9670 - val_loss: 0.1193 - val_accuracy: 0.8950 - val_binary_iou: 0.8082 - val_true_positives: 41911488.0000 - val_false_positives: 7937687.0000 - val_true_negatives: 52932796.0000 - val_false_negatives: 3189739.0000 - val_precision: 0.8408 - val_recall: 0.9293\n",
      "Epoch 114/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9728 - binary_iou: 0.9455 - true_positives: 126803888.0000 - false_positives: 4374298.0000 - true_negatives: 184038096.0000 - false_negatives: 4304532.0000 - precision: 0.9667 - recall: 0.9672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0337 - accuracy: 0.9728 - binary_iou: 0.9455 - true_positives: 126803888.0000 - false_positives: 4374298.0000 - true_negatives: 184038096.0000 - false_negatives: 4304532.0000 - precision: 0.9667 - recall: 0.9672 - val_loss: 0.1136 - val_accuracy: 0.9003 - val_binary_iou: 0.8169 - val_true_positives: 41879232.0000 - val_false_positives: 7196902.0000 - val_true_negatives: 53529696.0000 - val_false_negatives: 3365884.0000 - val_precision: 0.8534 - val_recall: 0.9256\n",
      "Epoch 115/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0338 - accuracy: 0.9726 - binary_iou: 0.9451 - true_positives: 126741312.0000 - false_positives: 4361245.0000 - true_negatives: 184040000.0000 - false_negatives: 4378171.0000 - precision: 0.9667 - recall: 0.9666 - val_loss: 0.1198 - val_accuracy: 0.8939 - val_binary_iou: 0.8066 - val_true_positives: 41961640.0000 - val_false_positives: 8082997.0000 - val_true_negatives: 52771040.0000 - val_false_negatives: 3156031.0000 - val_precision: 0.8385 - val_recall: 0.9300\n",
      "Epoch 116/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0331 - accuracy: 0.9732 - binary_iou: 0.9461 - true_positives: 126806112.0000 - false_positives: 4282878.0000 - true_negatives: 184137760.0000 - false_negatives: 4293997.0000 - precision: 0.9673 - recall: 0.9672 - val_loss: 0.1151 - val_accuracy: 0.8988 - val_binary_iou: 0.8145 - val_true_positives: 41884664.0000 - val_false_positives: 7475793.0000 - val_true_negatives: 53366624.0000 - val_false_negatives: 3244636.0000 - val_precision: 0.8485 - val_recall: 0.9281\n",
      "Epoch 117/500\n",
      "199/199 [==============================] - 78s 394ms/step - loss: 0.0332 - accuracy: 0.9731 - binary_iou: 0.9460 - true_positives: 126758832.0000 - false_positives: 4253271.0000 - true_negatives: 184173920.0000 - false_negatives: 4334742.0000 - precision: 0.9675 - recall: 0.9669 - val_loss: 0.1158 - val_accuracy: 0.8981 - val_binary_iou: 0.8132 - val_true_positives: 41728260.0000 - val_false_positives: 7410664.0000 - val_true_negatives: 53449736.0000 - val_false_negatives: 3383073.0000 - val_precision: 0.8492 - val_recall: 0.9250\n",
      "Epoch 118/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0325 - accuracy: 0.9736 - binary_iou: 0.9470 - true_positives: 126919688.0000 - false_positives: 4237619.0000 - true_negatives: 184174272.0000 - false_negatives: 4189219.0000 - precision: 0.9677 - recall: 0.9680 - val_loss: 0.1199 - val_accuracy: 0.8937 - val_binary_iou: 0.8062 - val_true_positives: 41965100.0000 - val_false_positives: 8138678.0000 - val_true_negatives: 52742112.0000 - val_false_negatives: 3125824.0000 - val_precision: 0.8376 - val_recall: 0.9307\n",
      "Epoch 119/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0327 - accuracy: 0.9736 - binary_iou: 0.9469 - true_positives: 126902736.0000 - false_positives: 4232709.0000 - true_negatives: 184178784.0000 - false_negatives: 4206567.0000 - precision: 0.9677 - recall: 0.9679 - val_loss: 0.1180 - val_accuracy: 0.8945 - val_binary_iou: 0.8076 - val_true_positives: 42102264.0000 - val_false_positives: 8088092.0000 - val_true_negatives: 52690964.0000 - val_false_negatives: 3090387.0000 - val_precision: 0.8389 - val_recall: 0.9316\n",
      "Epoch 120/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0327 - accuracy: 0.9736 - binary_iou: 0.9469 - true_positives: 126972272.0000 - false_positives: 4208377.0000 - true_negatives: 184111344.0000 - false_negatives: 4228682.0000 - precision: 0.9679 - recall: 0.9678 - val_loss: 0.1190 - val_accuracy: 0.8939 - val_binary_iou: 0.8066 - val_true_positives: 42076068.0000 - val_false_positives: 8222997.0000 - val_true_negatives: 52650740.0000 - val_false_negatives: 3021918.0000 - val_precision: 0.8365 - val_recall: 0.9330\n",
      "Epoch 121/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0326 - accuracy: 0.9736 - binary_iou: 0.9470 - true_positives: 126882704.0000 - false_positives: 4167369.0000 - true_negatives: 184205472.0000 - false_negatives: 4265138.0000 - precision: 0.9682 - recall: 0.9675 - val_loss: 0.1214 - val_accuracy: 0.8919 - val_binary_iou: 0.8033 - val_true_positives: 42069492.0000 - val_false_positives: 8509113.0000 - val_true_negatives: 52445712.0000 - val_false_negatives: 2947399.0000 - val_precision: 0.8318 - val_recall: 0.9345\n",
      "Epoch 122/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0323 - accuracy: 0.9738 - binary_iou: 0.9474 - true_positives: 126936048.0000 - false_positives: 4193704.0000 - true_negatives: 184223168.0000 - false_negatives: 4167780.0000 - precision: 0.9680 - recall: 0.9682 - val_loss: 0.1180 - val_accuracy: 0.8965 - val_binary_iou: 0.8106 - val_true_positives: 41703540.0000 - val_false_positives: 7661682.0000 - val_true_negatives: 53301592.0000 - val_false_negatives: 3304907.0000 - val_precision: 0.8448 - val_recall: 0.9266\n",
      "Epoch 123/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0319 - accuracy: 0.9742 - binary_iou: 0.9481 - true_positives: 126980104.0000 - false_positives: 4155874.0000 - true_negatives: 184292672.0000 - false_negatives: 4092050.0000 - precision: 0.9683 - recall: 0.9688 - val_loss: 0.1158 - val_accuracy: 0.8979 - val_binary_iou: 0.8129 - val_true_positives: 41775940.0000 - val_false_positives: 7569567.0000 - val_true_negatives: 53378372.0000 - val_false_negatives: 3247827.0000 - val_precision: 0.8466 - val_recall: 0.9279\n",
      "Epoch 124/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0318 - accuracy: 0.9743 - binary_iou: 0.9483 - true_positives: 126987568.0000 - false_positives: 4104942.0000 - true_negatives: 184326224.0000 - false_negatives: 4101970.0000 - precision: 0.9687 - recall: 0.9687 - val_loss: 0.1171 - val_accuracy: 0.8967 - val_binary_iou: 0.8110 - val_true_positives: 41926632.0000 - val_false_positives: 7827111.0000 - val_true_negatives: 53095288.0000 - val_false_negatives: 3122676.0000 - val_precision: 0.8427 - val_recall: 0.9307\n",
      "Epoch 125/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0316 - accuracy: 0.9745 - binary_iou: 0.9486 - true_positives: 126957896.0000 - false_positives: 4097389.0000 - true_negatives: 184400432.0000 - false_negatives: 4065134.0000 - precision: 0.9687 - recall: 0.9690 - val_loss: 0.1195 - val_accuracy: 0.8936 - val_binary_iou: 0.8061 - val_true_positives: 41989888.0000 - val_false_positives: 8155885.0000 - val_true_negatives: 52709152.0000 - val_false_negatives: 3116790.0000 - val_precision: 0.8374 - val_recall: 0.9309\n",
      "Epoch 126/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9747 - binary_iou: 0.9491 - true_positives: 127147312.0000 - false_positives: 4026821.0000 - true_negatives: 184290688.0000 - false_negatives: 4055980.0000 - precision: 0.9693 - recall: 0.9691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0313 - accuracy: 0.9747 - binary_iou: 0.9491 - true_positives: 127147312.0000 - false_positives: 4026821.0000 - true_negatives: 184290688.0000 - false_negatives: 4055980.0000 - precision: 0.9693 - recall: 0.9691 - val_loss: 0.1129 - val_accuracy: 0.9007 - val_binary_iou: 0.8173 - val_true_positives: 41628784.0000 - val_false_positives: 7063200.0000 - val_true_negatives: 53818056.0000 - val_false_negatives: 3461686.0000 - val_precision: 0.8549 - val_recall: 0.9232\n",
      "Epoch 127/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0313 - accuracy: 0.9746 - binary_iou: 0.9489 - true_positives: 127110568.0000 - false_positives: 4094394.0000 - true_negatives: 184299488.0000 - false_negatives: 4016331.0000 - precision: 0.9688 - recall: 0.9694 - val_loss: 0.1175 - val_accuracy: 0.8972 - val_binary_iou: 0.8117 - val_true_positives: 41598996.0000 - val_false_positives: 7435812.0000 - val_true_negatives: 53481220.0000 - val_false_negatives: 3455691.0000 - val_precision: 0.8484 - val_recall: 0.9233\n",
      "Epoch 128/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0312 - accuracy: 0.9747 - binary_iou: 0.9491 - true_positives: 127153456.0000 - false_positives: 4050210.0000 - true_negatives: 184290672.0000 - false_negatives: 4026438.0000 - precision: 0.9691 - recall: 0.9693 - val_loss: 0.1158 - val_accuracy: 0.8979 - val_binary_iou: 0.8129 - val_true_positives: 41787764.0000 - val_false_positives: 7510815.0000 - val_true_negatives: 53364204.0000 - val_false_negatives: 3308903.0000 - val_precision: 0.8476 - val_recall: 0.9266\n",
      "Epoch 129/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0310 - accuracy: 0.9750 - binary_iou: 0.9496 - true_positives: 127067848.0000 - false_positives: 3991251.0000 - true_negatives: 184454448.0000 - false_negatives: 4007390.0000 - precision: 0.9695 - recall: 0.9694 - val_loss: 0.1165 - val_accuracy: 0.8981 - val_binary_iou: 0.8132 - val_true_positives: 41844896.0000 - val_false_positives: 7525394.0000 - val_true_negatives: 53326344.0000 - val_false_negatives: 3275083.0000 - val_precision: 0.8476 - val_recall: 0.9274\n",
      "Epoch 130/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0308 - accuracy: 0.9751 - binary_iou: 0.9499 - true_positives: 127100608.0000 - false_positives: 3980929.0000 - true_negatives: 184464256.0000 - false_negatives: 3974969.0000 - precision: 0.9696 - recall: 0.9697 - val_loss: 0.1166 - val_accuracy: 0.8977 - val_binary_iou: 0.8126 - val_true_positives: 41896664.0000 - val_false_positives: 7565467.0000 - val_true_negatives: 53233892.0000 - val_false_negatives: 3275672.0000 - val_precision: 0.8470 - val_recall: 0.9275\n",
      "Epoch 131/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0311 - accuracy: 0.9748 - binary_iou: 0.9493 - true_positives: 127098248.0000 - false_positives: 4030138.0000 - true_negatives: 184373024.0000 - false_negatives: 4019299.0000 - precision: 0.9693 - recall: 0.9693 - val_loss: 0.1186 - val_accuracy: 0.8961 - val_binary_iou: 0.8100 - val_true_positives: 41893720.0000 - val_false_positives: 7778982.0000 - val_true_negatives: 53065320.0000 - val_false_negatives: 3233695.0000 - val_precision: 0.8434 - val_recall: 0.9283\n",
      "Epoch 132/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0307 - accuracy: 0.9752 - binary_iou: 0.9501 - true_positives: 127123272.0000 - false_positives: 3995799.0000 - true_negatives: 184473536.0000 - false_negatives: 3928118.0000 - precision: 0.9695 - recall: 0.9700 - val_loss: 0.1186 - val_accuracy: 0.8950 - val_binary_iou: 0.8083 - val_true_positives: 41916036.0000 - val_false_positives: 7967486.0000 - val_true_negatives: 52931488.0000 - val_false_negatives: 3156707.0000 - val_precision: 0.8403 - val_recall: 0.9300\n",
      "Epoch 133/500\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0304 - accuracy: 0.9753 - binary_iou: 0.9503 - true_positives: 127213104.0000 - false_positives: 3931628.0000 - true_negatives: 184420624.0000 - false_negatives: 3955391.0000 - precision: 0.9700 - recall: 0.9698 - val_loss: 0.1169 - val_accuracy: 0.8973 - val_binary_iou: 0.8120 - val_true_positives: 41864584.0000 - val_false_positives: 7589232.0000 - val_true_negatives: 53225464.0000 - val_false_negatives: 3292423.0000 - val_precision: 0.8465 - val_recall: 0.9271\n",
      "Epoch 134/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0304 - accuracy: 0.9753 - binary_iou: 0.9504 - true_positives: 127207008.0000 - false_positives: 3967033.0000 - true_negatives: 184434688.0000 - false_negatives: 3911987.0000 - precision: 0.9698 - recall: 0.9702 - val_loss: 0.1173 - val_accuracy: 0.8972 - val_binary_iou: 0.8118 - val_true_positives: 41778928.0000 - val_false_positives: 7566781.0000 - val_true_negatives: 53302296.0000 - val_false_negatives: 3323707.0000 - val_precision: 0.8467 - val_recall: 0.9263\n",
      "Epoch 135/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0301 - accuracy: 0.9756 - binary_iou: 0.9509 - true_positives: 127210696.0000 - false_positives: 3894953.0000 - true_negatives: 184523472.0000 - false_negatives: 3891632.0000 - precision: 0.9703 - recall: 0.9703 - val_loss: 0.1190 - val_accuracy: 0.8957 - val_binary_iou: 0.8093 - val_true_positives: 41904880.0000 - val_false_positives: 7978330.0000 - val_true_negatives: 53008856.0000 - val_false_negatives: 3079635.0000 - val_precision: 0.8401 - val_recall: 0.9315\n",
      "Epoch 136/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0304 - accuracy: 0.9755 - binary_iou: 0.9507 - true_positives: 127266352.0000 - false_positives: 3911997.0000 - true_negatives: 184426896.0000 - false_negatives: 3915541.0000 - precision: 0.9702 - recall: 0.9702 - val_loss: 0.1160 - val_accuracy: 0.8979 - val_binary_iou: 0.8129 - val_true_positives: 41771992.0000 - val_false_positives: 7590663.0000 - val_true_negatives: 53384256.0000 - val_false_negatives: 3224788.0000 - val_precision: 0.8462 - val_recall: 0.9283\n",
      "Epoch 137/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0303 - accuracy: 0.9755 - binary_iou: 0.9507 - true_positives: 127219504.0000 - false_positives: 3910366.0000 - true_negatives: 184482240.0000 - false_negatives: 3908625.0000 - precision: 0.9702 - recall: 0.9702 - val_loss: 0.1194 - val_accuracy: 0.8942 - val_binary_iou: 0.8071 - val_true_positives: 42002500.0000 - val_false_positives: 8011759.0000 - val_true_negatives: 52761152.0000 - val_false_negatives: 3196292.0000 - val_precision: 0.8398 - val_recall: 0.9293\n",
      "Epoch 138/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0297 - accuracy: 0.9760 - binary_iou: 0.9516 - true_positives: 127278640.0000 - false_positives: 3840251.0000 - true_negatives: 184566672.0000 - false_negatives: 3835326.0000 - precision: 0.9707 - recall: 0.9707 - val_loss: 0.1158 - val_accuracy: 0.8977 - val_binary_iou: 0.8126 - val_true_positives: 41929824.0000 - val_false_positives: 7747179.0000 - val_true_negatives: 53199068.0000 - val_false_negatives: 3095653.0000 - val_precision: 0.8440 - val_recall: 0.9312\n",
      "Epoch 139/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0298 - accuracy: 0.9759 - binary_iou: 0.9514 - true_positives: 127259728.0000 - false_positives: 3853114.0000 - true_negatives: 184560576.0000 - false_negatives: 3847313.0000 - precision: 0.9706 - recall: 0.9707 - val_loss: 0.1147 - val_accuracy: 0.8992 - val_binary_iou: 0.8150 - val_true_positives: 41674932.0000 - val_false_positives: 7226433.0000 - val_true_negatives: 53618844.0000 - val_false_negatives: 3451489.0000 - val_precision: 0.8522 - val_recall: 0.9235\n",
      "Epoch 140/500\n",
      "199/199 [==============================] - 78s 393ms/step - loss: 0.0297 - accuracy: 0.9760 - binary_iou: 0.9516 - true_positives: 127316496.0000 - false_positives: 3835342.0000 - true_negatives: 184532192.0000 - false_negatives: 3836681.0000 - precision: 0.9708 - recall: 0.9707 - val_loss: 0.1162 - val_accuracy: 0.8983 - val_binary_iou: 0.8135 - val_true_positives: 41760156.0000 - val_false_positives: 7389321.0000 - val_true_negatives: 53434532.0000 - val_false_negatives: 3387711.0000 - val_precision: 0.8497 - val_recall: 0.9250\n",
      "Epoch 141/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0297 - accuracy: 0.9760 - binary_iou: 0.9516 - true_positives: 127253408.0000 - false_positives: 3856856.0000 - true_negatives: 184598032.0000 - false_negatives: 3812469.0000 - precision: 0.9706 - recall: 0.9709 - val_loss: 0.1169 - val_accuracy: 0.8972 - val_binary_iou: 0.8118 - val_true_positives: 41934032.0000 - val_false_positives: 7679167.0000 - val_true_negatives: 53142328.0000 - val_false_negatives: 3216193.0000 - val_precision: 0.8452 - val_recall: 0.9288\n",
      "Epoch 142/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0296 - accuracy: 0.9761 - binary_iou: 0.9518 - true_positives: 127314480.0000 - false_positives: 3819627.0000 - true_negatives: 184564480.0000 - false_negatives: 3822209.0000 - precision: 0.9709 - recall: 0.9709 - val_loss: 0.1178 - val_accuracy: 0.8979 - val_binary_iou: 0.8129 - val_true_positives: 41851368.0000 - val_false_positives: 7612329.0000 - val_true_negatives: 53298848.0000 - val_false_negatives: 3209155.0000 - val_precision: 0.8461 - val_recall: 0.9288\n",
      "Epoch 143/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0293 - accuracy: 0.9764 - binary_iou: 0.9524 - true_positives: 127347544.0000 - false_positives: 3785460.0000 - true_negatives: 184628640.0000 - false_negatives: 3759053.0000 - precision: 0.9711 - recall: 0.9713 - val_loss: 0.1153 - val_accuracy: 0.8994 - val_binary_iou: 0.8152 - val_true_positives: 41502208.0000 - val_false_positives: 7138846.0000 - val_true_negatives: 53811688.0000 - val_false_negatives: 3518977.0000 - val_precision: 0.8532 - val_recall: 0.9218\n",
      "Epoch 144/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0295 - accuracy: 0.9762 - binary_iou: 0.9520 - true_positives: 127257616.0000 - false_positives: 3786293.0000 - true_negatives: 184655984.0000 - false_negatives: 3820836.0000 - precision: 0.9711 - recall: 0.9709 - val_loss: 0.1154 - val_accuracy: 0.8981 - val_binary_iou: 0.8133 - val_true_positives: 41939240.0000 - val_false_positives: 7632881.0000 - val_true_negatives: 53236936.0000 - val_false_negatives: 3162647.0000 - val_precision: 0.8460 - val_recall: 0.9299\n",
      "Epoch 145/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127343184.0000 - false_positives: 3742298.0000 - true_negatives: 184691776.0000 - false_negatives: 3743524.0000 - precision: 0.9715 - recall: 0.9714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 464ms/step - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127343184.0000 - false_positives: 3742298.0000 - true_negatives: 184691776.0000 - false_negatives: 3743524.0000 - precision: 0.9715 - recall: 0.9714 - val_loss: 0.1123 - val_accuracy: 0.9028 - val_binary_iou: 0.8206 - val_true_positives: 41366368.0000 - val_false_positives: 6532016.0000 - val_true_negatives: 54307200.0000 - val_false_negatives: 3766127.0000 - val_precision: 0.8636 - val_recall: 0.9166\n",
      "Epoch 146/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127439856.0000 - false_positives: 3740859.0000 - true_negatives: 184601120.0000 - false_negatives: 3738908.0000 - precision: 0.9715 - recall: 0.9715 - val_loss: 0.1140 - val_accuracy: 0.8996 - val_binary_iou: 0.8156 - val_true_positives: 41815956.0000 - val_false_positives: 7384221.0000 - val_true_negatives: 53514864.0000 - val_false_negatives: 3256670.0000 - val_precision: 0.8499 - val_recall: 0.9277\n",
      "Epoch 147/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0286 - accuracy: 0.9769 - binary_iou: 0.9533 - true_positives: 127423424.0000 - false_positives: 3710860.0000 - true_negatives: 184706128.0000 - false_negatives: 3680344.0000 - precision: 0.9717 - recall: 0.9719 - val_loss: 0.1167 - val_accuracy: 0.8968 - val_binary_iou: 0.8112 - val_true_positives: 41903372.0000 - val_false_positives: 7749947.0000 - val_true_negatives: 53131208.0000 - val_false_negatives: 3187177.0000 - val_precision: 0.8439 - val_recall: 0.9293\n",
      "Epoch 148/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0286 - accuracy: 0.9769 - binary_iou: 0.9534 - true_positives: 127393024.0000 - false_positives: 3685970.0000 - true_negatives: 184740640.0000 - false_negatives: 3701165.0000 - precision: 0.9719 - recall: 0.9718 - val_loss: 0.1172 - val_accuracy: 0.8969 - val_binary_iou: 0.8114 - val_true_positives: 41869808.0000 - val_false_positives: 7628718.0000 - val_true_negatives: 53180820.0000 - val_false_negatives: 3292369.0000 - val_precision: 0.8459 - val_recall: 0.9271\n",
      "Epoch 149/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0283 - accuracy: 0.9771 - binary_iou: 0.9538 - true_positives: 127395952.0000 - false_positives: 3639831.0000 - true_negatives: 184812400.0000 - false_negatives: 3672598.0000 - precision: 0.9722 - recall: 0.9720 - val_loss: 0.1145 - val_accuracy: 0.8995 - val_binary_iou: 0.8154 - val_true_positives: 41704132.0000 - val_false_positives: 7162931.0000 - val_true_negatives: 53613132.0000 - val_false_negatives: 3491529.0000 - val_precision: 0.8534 - val_recall: 0.9227\n",
      "Epoch 150/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0282 - accuracy: 0.9772 - binary_iou: 0.9540 - true_positives: 127536904.0000 - false_positives: 3670784.0000 - true_negatives: 184703952.0000 - false_negatives: 3609075.0000 - precision: 0.9720 - recall: 0.9725 - val_loss: 0.1153 - val_accuracy: 0.8986 - val_binary_iou: 0.8141 - val_true_positives: 41831900.0000 - val_false_positives: 7511787.0000 - val_true_negatives: 53394920.0000 - val_false_negatives: 3233102.0000 - val_precision: 0.8478 - val_recall: 0.9283\n",
      "Epoch 151/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0279 - accuracy: 0.9774 - binary_iou: 0.9544 - true_positives: 127548552.0000 - false_positives: 3606955.0000 - true_negatives: 184755376.0000 - false_negatives: 3609857.0000 - precision: 0.9725 - recall: 0.9725 - val_loss: 0.1168 - val_accuracy: 0.8966 - val_binary_iou: 0.8108 - val_true_positives: 41985852.0000 - val_false_positives: 7923577.0000 - val_true_negatives: 53024092.0000 - val_false_negatives: 3038199.0000 - val_precision: 0.8412 - val_recall: 0.9325\n",
      "Epoch 152/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0280 - accuracy: 0.9773 - binary_iou: 0.9543 - true_positives: 127449320.0000 - false_positives: 3616615.0000 - true_negatives: 184829344.0000 - false_negatives: 3625542.0000 - precision: 0.9724 - recall: 0.9723 - val_loss: 0.1172 - val_accuracy: 0.8972 - val_binary_iou: 0.8117 - val_true_positives: 41675600.0000 - val_false_positives: 7469060.0000 - val_true_negatives: 53405924.0000 - val_false_negatives: 3421141.0000 - val_precision: 0.8480 - val_recall: 0.9241\n",
      "Epoch 153/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0281 - accuracy: 0.9773 - binary_iou: 0.9541 - true_positives: 127453960.0000 - false_positives: 3628461.0000 - true_negatives: 184798688.0000 - false_negatives: 3639657.0000 - precision: 0.9723 - recall: 0.9722 - val_loss: 0.1184 - val_accuracy: 0.8947 - val_binary_iou: 0.8079 - val_true_positives: 42149220.0000 - val_false_positives: 8093468.0000 - val_true_negatives: 52659704.0000 - val_false_negatives: 3069309.0000 - val_precision: 0.8389 - val_recall: 0.9321\n",
      "Epoch 154/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0283 - accuracy: 0.9771 - binary_iou: 0.9539 - true_positives: 127481952.0000 - false_positives: 3653234.0000 - true_negatives: 184734880.0000 - false_negatives: 3650765.0000 - precision: 0.9721 - recall: 0.9722 - val_loss: 0.1187 - val_accuracy: 0.8958 - val_binary_iou: 0.8094 - val_true_positives: 41743548.0000 - val_false_positives: 7822710.0000 - val_true_negatives: 53182300.0000 - val_false_negatives: 3223157.0000 - val_precision: 0.8422 - val_recall: 0.9283\n",
      "Epoch 155/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9549 - true_positives: 127523960.0000 - false_positives: 3567026.0000 - true_negatives: 184857280.0000 - false_negatives: 3572550.0000 - precision: 0.9728 - recall: 0.9727 - val_loss: 0.1215 - val_accuracy: 0.8923 - val_binary_iou: 0.8039 - val_true_positives: 41952856.0000 - val_false_positives: 8333406.0000 - val_true_negatives: 52606540.0000 - val_false_negatives: 3078914.0000 - val_precision: 0.8343 - val_recall: 0.9316\n",
      "Epoch 156/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0274 - accuracy: 0.9778 - binary_iou: 0.9552 - true_positives: 127624576.0000 - false_positives: 3557554.0000 - true_negatives: 184811424.0000 - false_negatives: 3527230.0000 - precision: 0.9729 - recall: 0.9731 - val_loss: 0.1153 - val_accuracy: 0.8993 - val_binary_iou: 0.8150 - val_true_positives: 41556896.0000 - val_false_positives: 7245607.0000 - val_true_negatives: 53741240.0000 - val_false_negatives: 3427951.0000 - val_precision: 0.8515 - val_recall: 0.9238\n",
      "Epoch 157/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9549 - true_positives: 127504792.0000 - false_positives: 3564189.0000 - true_negatives: 184881856.0000 - false_negatives: 3569902.0000 - precision: 0.9728 - recall: 0.9728 - val_loss: 0.1158 - val_accuracy: 0.8982 - val_binary_iou: 0.8133 - val_true_positives: 41701832.0000 - val_false_positives: 7315422.0000 - val_true_negatives: 53483264.0000 - val_false_negatives: 3471183.0000 - val_precision: 0.8508 - val_recall: 0.9232\n",
      "Epoch 158/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9551 - true_positives: 127589184.0000 - false_positives: 3565914.0000 - true_negatives: 184818160.0000 - false_negatives: 3547479.0000 - precision: 0.9728 - recall: 0.9729 - val_loss: 0.1149 - val_accuracy: 0.8988 - val_binary_iou: 0.8144 - val_true_positives: 41713468.0000 - val_false_positives: 7341477.0000 - val_true_negatives: 53538416.0000 - val_false_negatives: 3378355.0000 - val_precision: 0.8503 - val_recall: 0.9251\n",
      "Epoch 159/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0274 - accuracy: 0.9779 - binary_iou: 0.9554 - true_positives: 127621072.0000 - false_positives: 3544869.0000 - true_negatives: 184848592.0000 - false_negatives: 3506198.0000 - precision: 0.9730 - recall: 0.9733 - val_loss: 0.1145 - val_accuracy: 0.8994 - val_binary_iou: 0.8153 - val_true_positives: 41727264.0000 - val_false_positives: 7226901.0000 - val_true_negatives: 53582292.0000 - val_false_negatives: 3435249.0000 - val_precision: 0.8524 - val_recall: 0.9239\n",
      "Epoch 160/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9550 - true_positives: 127558864.0000 - false_positives: 3566911.0000 - true_negatives: 184836352.0000 - false_negatives: 3558675.0000 - precision: 0.9728 - recall: 0.9729 - val_loss: 0.1177 - val_accuracy: 0.8959 - val_binary_iou: 0.8097 - val_true_positives: 41927952.0000 - val_false_positives: 7880412.0000 - val_true_negatives: 53012992.0000 - val_false_negatives: 3150355.0000 - val_precision: 0.8418 - val_recall: 0.9301\n",
      "Epoch 161/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0270 - accuracy: 0.9781 - binary_iou: 0.9558 - true_positives: 127699504.0000 - false_positives: 3543306.0000 - true_negatives: 184829824.0000 - false_negatives: 3448042.0000 - precision: 0.9730 - recall: 0.9737 - val_loss: 0.1139 - val_accuracy: 0.9009 - val_binary_iou: 0.8176 - val_true_positives: 41470796.0000 - val_false_positives: 6903379.0000 - val_true_negatives: 54000604.0000 - val_false_negatives: 3596938.0000 - val_precision: 0.8573 - val_recall: 0.9202\n",
      "Epoch 162/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0273 - accuracy: 0.9779 - binary_iou: 0.9554 - true_positives: 127580160.0000 - false_positives: 3516869.0000 - true_negatives: 184884416.0000 - false_negatives: 3539304.0000 - precision: 0.9732 - recall: 0.9730 - val_loss: 0.1178 - val_accuracy: 0.8959 - val_binary_iou: 0.8096 - val_true_positives: 41917728.0000 - val_false_positives: 7815194.0000 - val_true_negatives: 53017684.0000 - val_false_negatives: 3221097.0000 - val_precision: 0.8429 - val_recall: 0.9286\n",
      "Epoch 163/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0266 - accuracy: 0.9784 - binary_iou: 0.9565 - true_positives: 127784304.0000 - false_positives: 3439523.0000 - true_negatives: 184847536.0000 - false_negatives: 3449345.0000 - precision: 0.9738 - recall: 0.9737 - val_loss: 0.1150 - val_accuracy: 0.8989 - val_binary_iou: 0.8145 - val_true_positives: 41860120.0000 - val_false_positives: 7451642.0000 - val_true_negatives: 53394644.0000 - val_false_negatives: 3265296.0000 - val_precision: 0.8489 - val_recall: 0.9276\n",
      "Epoch 164/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0268 - accuracy: 0.9783 - binary_iou: 0.9562 - true_positives: 127676096.0000 - false_positives: 3476293.0000 - true_negatives: 184910560.0000 - false_negatives: 3457806.0000 - precision: 0.9735 - recall: 0.9736 - val_loss: 0.1153 - val_accuracy: 0.8985 - val_binary_iou: 0.8139 - val_true_positives: 41810812.0000 - val_false_positives: 7448277.0000 - val_true_negatives: 53404248.0000 - val_false_negatives: 3308376.0000 - val_precision: 0.8488 - val_recall: 0.9267\n",
      "Epoch 165/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0267 - accuracy: 0.9784 - binary_iou: 0.9564 - true_positives: 127674752.0000 - false_positives: 3461832.0000 - true_negatives: 184951088.0000 - false_negatives: 3433073.0000 - precision: 0.9736 - recall: 0.9738 - val_loss: 0.1136 - val_accuracy: 0.9002 - val_binary_iou: 0.8166 - val_true_positives: 41885396.0000 - val_false_positives: 7316422.0000 - val_true_negatives: 53506828.0000 - val_false_negatives: 3263068.0000 - val_precision: 0.8513 - val_recall: 0.9277\n",
      "Epoch 166/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0268 - accuracy: 0.9784 - binary_iou: 0.9563 - true_positives: 127571816.0000 - false_positives: 3483282.0000 - true_negatives: 185042144.0000 - false_negatives: 3423499.0000 - precision: 0.9734 - recall: 0.9739 - val_loss: 0.1156 - val_accuracy: 0.8981 - val_binary_iou: 0.8132 - val_true_positives: 41854220.0000 - val_false_positives: 7483356.0000 - val_true_negatives: 53314256.0000 - val_false_negatives: 3319879.0000 - val_precision: 0.8483 - val_recall: 0.9265\n",
      "Epoch 167/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0267 - accuracy: 0.9784 - binary_iou: 0.9564 - true_positives: 127664480.0000 - false_positives: 3452564.0000 - true_negatives: 184956416.0000 - false_negatives: 3447334.0000 - precision: 0.9737 - recall: 0.9737 - val_loss: 0.1155 - val_accuracy: 0.8989 - val_binary_iou: 0.8145 - val_true_positives: 41812260.0000 - val_false_positives: 7444741.0000 - val_true_negatives: 53442856.0000 - val_false_negatives: 3271861.0000 - val_precision: 0.8489 - val_recall: 0.9274\n",
      "Epoch 168/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0264 - accuracy: 0.9787 - binary_iou: 0.9569 - true_positives: 127706152.0000 - false_positives: 3401243.0000 - true_negatives: 185001936.0000 - false_negatives: 3411463.0000 - precision: 0.9741 - recall: 0.9740 - val_loss: 0.1157 - val_accuracy: 0.8986 - val_binary_iou: 0.8141 - val_true_positives: 41862708.0000 - val_false_positives: 7455853.0000 - val_true_negatives: 53365968.0000 - val_false_negatives: 3287179.0000 - val_precision: 0.8488 - val_recall: 0.9272\n",
      "Epoch 169/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0264 - accuracy: 0.9786 - binary_iou: 0.9568 - true_positives: 127801096.0000 - false_positives: 3440638.0000 - true_negatives: 184892784.0000 - false_negatives: 3386205.0000 - precision: 0.9738 - recall: 0.9742 - val_loss: 0.1128 - val_accuracy: 0.9006 - val_binary_iou: 0.8173 - val_true_positives: 41873652.0000 - val_false_positives: 7266176.0000 - val_true_negatives: 53562044.0000 - val_false_negatives: 3269829.0000 - val_precision: 0.8521 - val_recall: 0.9276\n",
      "Epoch 170/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0261 - accuracy: 0.9789 - binary_iou: 0.9573 - true_positives: 127804208.0000 - false_positives: 3397436.0000 - true_negatives: 184963104.0000 - false_negatives: 3356060.0000 - precision: 0.9741 - recall: 0.9744 - val_loss: 0.1165 - val_accuracy: 0.8976 - val_binary_iou: 0.8125 - val_true_positives: 41949008.0000 - val_false_positives: 7692895.0000 - val_true_negatives: 53169728.0000 - val_false_negatives: 3160081.0000 - val_precision: 0.8450 - val_recall: 0.9299\n",
      "Epoch 171/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9788 - binary_iou: 0.9572 - true_positives: 127780976.0000 - false_positives: 3423150.0000 - true_negatives: 184977056.0000 - false_negatives: 3339537.0000 - precision: 0.9739 - recall: 0.9745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 466ms/step - loss: 0.0262 - accuracy: 0.9788 - binary_iou: 0.9572 - true_positives: 127780976.0000 - false_positives: 3423150.0000 - true_negatives: 184977056.0000 - false_negatives: 3339537.0000 - precision: 0.9739 - recall: 0.9745 - val_loss: 0.1116 - val_accuracy: 0.9028 - val_binary_iou: 0.8207 - val_true_positives: 41478016.0000 - val_false_positives: 6674232.0000 - val_true_negatives: 54193136.0000 - val_false_negatives: 3626347.0000 - val_precision: 0.8614 - val_recall: 0.9196\n",
      "Epoch 172/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0266 - accuracy: 0.9785 - binary_iou: 0.9567 - true_positives: 127657312.0000 - false_positives: 3443881.0000 - true_negatives: 185009504.0000 - false_negatives: 3410046.0000 - precision: 0.9737 - recall: 0.9740 - val_loss: 0.1151 - val_accuracy: 0.8989 - val_binary_iou: 0.8144 - val_true_positives: 41698472.0000 - val_false_positives: 7380650.0000 - val_true_negatives: 53554624.0000 - val_false_negatives: 3337979.0000 - val_precision: 0.8496 - val_recall: 0.9259\n",
      "Epoch 173/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0259 - accuracy: 0.9790 - binary_iou: 0.9576 - true_positives: 127785192.0000 - false_positives: 3363443.0000 - true_negatives: 185032864.0000 - false_negatives: 3339287.0000 - precision: 0.9744 - recall: 0.9745 - val_loss: 0.1155 - val_accuracy: 0.8985 - val_binary_iou: 0.8138 - val_true_positives: 41892584.0000 - val_false_positives: 7533666.0000 - val_true_negatives: 53317824.0000 - val_false_negatives: 3227631.0000 - val_precision: 0.8476 - val_recall: 0.9285\n",
      "Epoch 174/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0257 - accuracy: 0.9791 - binary_iou: 0.9578 - true_positives: 127779576.0000 - false_positives: 3338721.0000 - true_negatives: 185075824.0000 - false_negatives: 3326608.0000 - precision: 0.9745 - recall: 0.9746 - val_loss: 0.1143 - val_accuracy: 0.9000 - val_binary_iou: 0.8162 - val_true_positives: 41808920.0000 - val_false_positives: 7250288.0000 - val_true_negatives: 53561060.0000 - val_false_negatives: 3351453.0000 - val_precision: 0.8522 - val_recall: 0.9258\n",
      "Epoch 175/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0255 - accuracy: 0.9793 - binary_iou: 0.9582 - true_positives: 127851104.0000 - false_positives: 3328172.0000 - true_negatives: 185067632.0000 - false_negatives: 3273846.0000 - precision: 0.9746 - recall: 0.9750 - val_loss: 0.1160 - val_accuracy: 0.8984 - val_binary_iou: 0.8136 - val_true_positives: 41720128.0000 - val_false_positives: 7458167.0000 - val_true_negatives: 53479952.0000 - val_false_negatives: 3313474.0000 - val_precision: 0.8483 - val_recall: 0.9264\n",
      "Epoch 176/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0254 - accuracy: 0.9793 - binary_iou: 0.9582 - true_positives: 127747016.0000 - false_positives: 3300648.0000 - true_negatives: 185175536.0000 - false_negatives: 3297530.0000 - precision: 0.9748 - recall: 0.9748 - val_loss: 0.1148 - val_accuracy: 0.8995 - val_binary_iou: 0.8156 - val_true_positives: 41828492.0000 - val_false_positives: 7362378.0000 - val_true_negatives: 53495664.0000 - val_false_negatives: 3285170.0000 - val_precision: 0.8503 - val_recall: 0.9272\n",
      "Epoch 177/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0254 - accuracy: 0.9795 - binary_iou: 0.9585 - true_positives: 127819744.0000 - false_positives: 3283395.0000 - true_negatives: 185140832.0000 - false_negatives: 3276834.0000 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.1161 - val_accuracy: 0.8976 - val_binary_iou: 0.8124 - val_true_positives: 41757856.0000 - val_false_positives: 7575068.0000 - val_true_negatives: 53365640.0000 - val_false_negatives: 3273151.0000 - val_precision: 0.8465 - val_recall: 0.9273\n",
      "Epoch 178/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0253 - accuracy: 0.9796 - binary_iou: 0.9587 - true_positives: 127877528.0000 - false_positives: 3252855.0000 - true_negatives: 185123504.0000 - false_negatives: 3266904.0000 - precision: 0.9752 - recall: 0.9751 - val_loss: 0.1146 - val_accuracy: 0.8999 - val_binary_iou: 0.8161 - val_true_positives: 41797536.0000 - val_false_positives: 7292404.0000 - val_true_negatives: 53562384.0000 - val_false_negatives: 3319396.0000 - val_precision: 0.8514 - val_recall: 0.9264\n",
      "Epoch 179/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0252 - accuracy: 0.9797 - binary_iou: 0.9589 - true_positives: 127854696.0000 - false_positives: 3267569.0000 - true_negatives: 185175984.0000 - false_negatives: 3222573.0000 - precision: 0.9751 - recall: 0.9754 - val_loss: 0.1183 - val_accuracy: 0.8954 - val_binary_iou: 0.8089 - val_true_positives: 41928244.0000 - val_false_positives: 7941854.0000 - val_true_negatives: 52960420.0000 - val_false_negatives: 3141187.0000 - val_precision: 0.8407 - val_recall: 0.9303\n",
      "Epoch 180/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0252 - accuracy: 0.9797 - binary_iou: 0.9589 - true_positives: 127880672.0000 - false_positives: 3266396.0000 - true_negatives: 185139632.0000 - false_negatives: 3234127.0000 - precision: 0.9751 - recall: 0.9753 - val_loss: 0.1193 - val_accuracy: 0.8945 - val_binary_iou: 0.8075 - val_true_positives: 41905244.0000 - val_false_positives: 7998049.0000 - val_true_negatives: 52890488.0000 - val_false_negatives: 3177937.0000 - val_precision: 0.8397 - val_recall: 0.9295\n",
      "Epoch 181/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0248 - accuracy: 0.9799 - binary_iou: 0.9594 - true_positives: 127983744.0000 - false_positives: 3199469.0000 - true_negatives: 185118064.0000 - false_negatives: 3219602.0000 - precision: 0.9756 - recall: 0.9755 - val_loss: 0.1165 - val_accuracy: 0.8971 - val_binary_iou: 0.8116 - val_true_positives: 41863668.0000 - val_false_positives: 7664559.0000 - val_true_negatives: 53204300.0000 - val_false_negatives: 3239179.0000 - val_precision: 0.8452 - val_recall: 0.9282\n",
      "Epoch 182/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0247 - accuracy: 0.9800 - binary_iou: 0.9596 - true_positives: 127924280.0000 - false_positives: 3233466.0000 - true_negatives: 185209552.0000 - false_negatives: 3153493.0000 - precision: 0.9753 - recall: 0.9759 - val_loss: 0.1152 - val_accuracy: 0.8979 - val_binary_iou: 0.8131 - val_true_positives: 42047900.0000 - val_false_positives: 7691092.0000 - val_true_negatives: 53109312.0000 - val_false_negatives: 3123410.0000 - val_precision: 0.8454 - val_recall: 0.9309\n",
      "Epoch 183/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0247 - accuracy: 0.9800 - binary_iou: 0.9596 - true_positives: 127924680.0000 - false_positives: 3196568.0000 - true_negatives: 185221424.0000 - false_negatives: 3178066.0000 - precision: 0.9756 - recall: 0.9758 - val_loss: 0.1131 - val_accuracy: 0.9008 - val_binary_iou: 0.8177 - val_true_positives: 41890368.0000 - val_false_positives: 7234277.0000 - val_true_negatives: 53570632.0000 - val_false_negatives: 3276438.0000 - val_precision: 0.8527 - val_recall: 0.9275\n",
      "Epoch 184/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0247 - accuracy: 0.9800 - binary_iou: 0.9596 - true_positives: 127923648.0000 - false_positives: 3195779.0000 - true_negatives: 185210192.0000 - false_negatives: 3191177.0000 - precision: 0.9756 - recall: 0.9757 - val_loss: 0.1173 - val_accuracy: 0.8970 - val_binary_iou: 0.8114 - val_true_positives: 41711304.0000 - val_false_positives: 7455273.0000 - val_true_negatives: 53350192.0000 - val_false_negatives: 3454952.0000 - val_precision: 0.8484 - val_recall: 0.9235\n",
      "Epoch 185/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0246 - accuracy: 0.9802 - binary_iou: 0.9599 - true_positives: 127995552.0000 - false_positives: 3171405.0000 - true_negatives: 185196416.0000 - false_negatives: 3157394.0000 - precision: 0.9758 - recall: 0.9759 - val_loss: 0.1159 - val_accuracy: 0.8985 - val_binary_iou: 0.8138 - val_true_positives: 41721952.0000 - val_false_positives: 7350595.0000 - val_true_negatives: 53492544.0000 - val_false_negatives: 3406613.0000 - val_precision: 0.8502 - val_recall: 0.9245\n",
      "Epoch 186/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0247 - accuracy: 0.9800 - binary_iou: 0.9595 - true_positives: 127914024.0000 - false_positives: 3218354.0000 - true_negatives: 185216960.0000 - false_negatives: 3171315.0000 - precision: 0.9755 - recall: 0.9758 - val_loss: 0.1121 - val_accuracy: 0.9019 - val_binary_iou: 0.8193 - val_true_positives: 41631108.0000 - val_false_positives: 6938821.0000 - val_true_negatives: 53941672.0000 - val_false_negatives: 3460109.0000 - val_precision: 0.8571 - val_recall: 0.9233\n",
      "Epoch 187/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0245 - accuracy: 0.9802 - binary_iou: 0.9599 - true_positives: 128023296.0000 - false_positives: 3178634.0000 - true_negatives: 185159536.0000 - false_negatives: 3159338.0000 - precision: 0.9758 - recall: 0.9759 - val_loss: 0.1173 - val_accuracy: 0.8961 - val_binary_iou: 0.8101 - val_true_positives: 41908432.0000 - val_false_positives: 7811571.0000 - val_true_negatives: 53056128.0000 - val_false_negatives: 3195578.0000 - val_precision: 0.8429 - val_recall: 0.9292\n",
      "Epoch 188/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9600 - true_positives: 127959872.0000 - false_positives: 3155905.0000 - true_negatives: 185251040.0000 - false_negatives: 3153940.0000 - precision: 0.9759 - recall: 0.9759 - val_loss: 0.1160 - val_accuracy: 0.8985 - val_binary_iou: 0.8140 - val_true_positives: 42021368.0000 - val_false_positives: 7587709.0000 - val_true_negatives: 53193096.0000 - val_false_negatives: 3169551.0000 - val_precision: 0.8471 - val_recall: 0.9299\n",
      "Epoch 189/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0242 - accuracy: 0.9804 - binary_iou: 0.9604 - true_positives: 128018848.0000 - false_positives: 3120299.0000 - true_negatives: 185249232.0000 - false_negatives: 3132364.0000 - precision: 0.9762 - recall: 0.9761 - val_loss: 0.1160 - val_accuracy: 0.8975 - val_binary_iou: 0.8122 - val_true_positives: 41829680.0000 - val_false_positives: 7549137.0000 - val_true_negatives: 53275320.0000 - val_false_negatives: 3317580.0000 - val_precision: 0.8471 - val_recall: 0.9265\n",
      "Epoch 190/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9602 - true_positives: 128036464.0000 - false_positives: 3142199.0000 - true_negatives: 185196576.0000 - false_negatives: 3145511.0000 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.1163 - val_accuracy: 0.8974 - val_binary_iou: 0.8121 - val_true_positives: 41880288.0000 - val_false_positives: 7573228.0000 - val_true_negatives: 53216984.0000 - val_false_negatives: 3301215.0000 - val_precision: 0.8469 - val_recall: 0.9269\n",
      "Epoch 191/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0240 - accuracy: 0.9806 - binary_iou: 0.9608 - true_positives: 128110480.0000 - false_positives: 3104011.0000 - true_negatives: 185223200.0000 - false_negatives: 3083116.0000 - precision: 0.9763 - recall: 0.9765 - val_loss: 0.1171 - val_accuracy: 0.8972 - val_binary_iou: 0.8118 - val_true_positives: 41801668.0000 - val_false_positives: 7577833.0000 - val_true_negatives: 53280448.0000 - val_false_negatives: 3311770.0000 - val_precision: 0.8465 - val_recall: 0.9266\n",
      "Epoch 192/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0239 - accuracy: 0.9807 - binary_iou: 0.9609 - true_positives: 128062896.0000 - false_positives: 3109166.0000 - true_negatives: 185282432.0000 - false_negatives: 3066303.0000 - precision: 0.9763 - recall: 0.9766 - val_loss: 0.1144 - val_accuracy: 0.9003 - val_binary_iou: 0.8168 - val_true_positives: 41739044.0000 - val_false_positives: 7267239.0000 - val_true_negatives: 53669296.0000 - val_false_negatives: 3296135.0000 - val_precision: 0.8517 - val_recall: 0.9268\n",
      "Epoch 193/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0242 - accuracy: 0.9805 - binary_iou: 0.9605 - true_positives: 128003672.0000 - false_positives: 3096934.0000 - true_negatives: 185277440.0000 - false_negatives: 3142678.0000 - precision: 0.9764 - recall: 0.9760 - val_loss: 0.1163 - val_accuracy: 0.8975 - val_binary_iou: 0.8123 - val_true_positives: 41890924.0000 - val_false_positives: 7666011.0000 - val_true_negatives: 53218312.0000 - val_false_negatives: 3196469.0000 - val_precision: 0.8453 - val_recall: 0.9291\n",
      "Epoch 194/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0241 - accuracy: 0.9805 - binary_iou: 0.9605 - true_positives: 128050008.0000 - false_positives: 3105919.0000 - true_negatives: 185231456.0000 - false_negatives: 3133407.0000 - precision: 0.9763 - recall: 0.9761 - val_loss: 0.1129 - val_accuracy: 0.9020 - val_binary_iou: 0.8193 - val_true_positives: 41391948.0000 - val_false_positives: 6738249.0000 - val_true_negatives: 54195232.0000 - val_false_negatives: 3646289.0000 - val_precision: 0.8600 - val_recall: 0.9190\n",
      "Epoch 195/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0242 - accuracy: 0.9805 - binary_iou: 0.9605 - true_positives: 128051032.0000 - false_positives: 3134786.0000 - true_negatives: 185237008.0000 - false_negatives: 3097981.0000 - precision: 0.9761 - recall: 0.9764 - val_loss: 0.1163 - val_accuracy: 0.8978 - val_binary_iou: 0.8126 - val_true_positives: 41711248.0000 - val_false_positives: 7572472.0000 - val_true_negatives: 53427528.0000 - val_false_negatives: 3260475.0000 - val_precision: 0.8463 - val_recall: 0.9275\n",
      "Epoch 196/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0236 - accuracy: 0.9809 - binary_iou: 0.9613 - true_positives: 128082448.0000 - false_positives: 3074396.0000 - true_negatives: 185335872.0000 - false_negatives: 3028003.0000 - precision: 0.9766 - recall: 0.9769 - val_loss: 0.1180 - val_accuracy: 0.8960 - val_binary_iou: 0.8099 - val_true_positives: 41854336.0000 - val_false_positives: 7801563.0000 - val_true_negatives: 53101428.0000 - val_false_negatives: 3214384.0000 - val_precision: 0.8429 - val_recall: 0.9287\n",
      "Epoch 197/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9615 - true_positives: 128102240.0000 - false_positives: 3049400.0000 - true_negatives: 185349760.0000 - false_negatives: 3019395.0000 - precision: 0.9767 - recall: 0.9770 - val_loss: 0.1131 - val_accuracy: 0.9013 - val_binary_iou: 0.8184 - val_true_positives: 41759528.0000 - val_false_positives: 7033493.0000 - val_true_negatives: 53749208.0000 - val_false_negatives: 3429469.0000 - val_precision: 0.8559 - val_recall: 0.9241\n",
      "Epoch 198/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9616 - true_positives: 128115976.0000 - false_positives: 3035713.0000 - true_negatives: 185353376.0000 - false_negatives: 3015694.0000 - precision: 0.9769 - recall: 0.9770 - val_loss: 0.1140 - val_accuracy: 0.8999 - val_binary_iou: 0.8161 - val_true_positives: 41841292.0000 - val_false_positives: 7310805.0000 - val_true_negatives: 53520488.0000 - val_false_negatives: 3299132.0000 - val_precision: 0.8513 - val_recall: 0.9269\n",
      "Epoch 199/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9615 - true_positives: 128122344.0000 - false_positives: 3053393.0000 - true_negatives: 185330048.0000 - false_negatives: 3015002.0000 - precision: 0.9767 - recall: 0.9770 - val_loss: 0.1168 - val_accuracy: 0.8963 - val_binary_iou: 0.8102 - val_true_positives: 41794584.0000 - val_false_positives: 7784795.0000 - val_true_negatives: 53183432.0000 - val_false_negatives: 3208907.0000 - val_precision: 0.8430 - val_recall: 0.9287\n",
      "Epoch 200/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0233 - accuracy: 0.9811 - binary_iou: 0.9618 - true_positives: 128086056.0000 - false_positives: 3043637.0000 - true_negatives: 185407584.0000 - false_negatives: 2983467.0000 - precision: 0.9768 - recall: 0.9772 - val_loss: 0.1154 - val_accuracy: 0.8986 - val_binary_iou: 0.8141 - val_true_positives: 41835692.0000 - val_false_positives: 7424583.0000 - val_true_negatives: 53395344.0000 - val_false_negatives: 3316086.0000 - val_precision: 0.8493 - val_recall: 0.9266\n",
      "Epoch 201/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9615 - true_positives: 128089808.0000 - false_positives: 3032068.0000 - true_negatives: 185360544.0000 - false_negatives: 3038379.0000 - precision: 0.9769 - recall: 0.9768 - val_loss: 0.1150 - val_accuracy: 0.8991 - val_binary_iou: 0.8149 - val_true_positives: 41985112.0000 - val_false_positives: 7431682.0000 - val_true_negatives: 53291844.0000 - val_false_negatives: 3263081.0000 - val_precision: 0.8496 - val_recall: 0.9279\n",
      "Epoch 202/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0231 - accuracy: 0.9813 - binary_iou: 0.9621 - true_positives: 128181744.0000 - false_positives: 3002282.0000 - true_negatives: 185367200.0000 - false_negatives: 2969575.0000 - precision: 0.9771 - recall: 0.9774 - val_loss: 0.1136 - val_accuracy: 0.9003 - val_binary_iou: 0.8167 - val_true_positives: 41790712.0000 - val_false_positives: 7186721.0000 - val_true_negatives: 53610472.0000 - val_false_negatives: 3383803.0000 - val_precision: 0.8533 - val_recall: 0.9251\n",
      "Epoch 203/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0230 - accuracy: 0.9814 - binary_iou: 0.9622 - true_positives: 128204032.0000 - false_positives: 2978449.0000 - true_negatives: 185362352.0000 - false_negatives: 2975927.0000 - precision: 0.9773 - recall: 0.9773 - val_loss: 0.1180 - val_accuracy: 0.8970 - val_binary_iou: 0.8114 - val_true_positives: 41814404.0000 - val_false_positives: 7644382.0000 - val_true_negatives: 53240452.0000 - val_false_negatives: 3272470.0000 - val_precision: 0.8454 - val_recall: 0.9274\n",
      "Epoch 204/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0229 - accuracy: 0.9815 - binary_iou: 0.9625 - true_positives: 128149648.0000 - false_positives: 2985075.0000 - true_negatives: 185451168.0000 - false_negatives: 2934926.0000 - precision: 0.9772 - recall: 0.9776 - val_loss: 0.1198 - val_accuracy: 0.8945 - val_binary_iou: 0.8074 - val_true_positives: 41905944.0000 - val_false_positives: 7955226.0000 - val_true_negatives: 52882096.0000 - val_false_negatives: 3228441.0000 - val_precision: 0.8405 - val_recall: 0.9285\n",
      "Epoch 205/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0231 - accuracy: 0.9814 - binary_iou: 0.9623 - true_positives: 128139072.0000 - false_positives: 2989091.0000 - true_negatives: 185429152.0000 - false_negatives: 2963438.0000 - precision: 0.9772 - recall: 0.9774 - val_loss: 0.1143 - val_accuracy: 0.9006 - val_binary_iou: 0.8173 - val_true_positives: 41775032.0000 - val_false_positives: 7146305.0000 - val_true_negatives: 53662320.0000 - val_false_negatives: 3388060.0000 - val_precision: 0.8539 - val_recall: 0.9250\n",
      "Epoch 206/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0228 - accuracy: 0.9816 - binary_iou: 0.9627 - true_positives: 128207088.0000 - false_positives: 2963970.0000 - true_negatives: 185425952.0000 - false_negatives: 2923758.0000 - precision: 0.9774 - recall: 0.9777 - val_loss: 0.1169 - val_accuracy: 0.8980 - val_binary_iou: 0.8129 - val_true_positives: 41737728.0000 - val_false_positives: 7459769.0000 - val_true_negatives: 53420716.0000 - val_false_negatives: 3353499.0000 - val_precision: 0.8484 - val_recall: 0.9256\n",
      "Epoch 207/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0226 - accuracy: 0.9817 - binary_iou: 0.9628 - true_positives: 128198384.0000 - false_positives: 2955408.0000 - true_negatives: 185464416.0000 - false_negatives: 2902578.0000 - precision: 0.9775 - recall: 0.9779 - val_loss: 0.1140 - val_accuracy: 0.8997 - val_binary_iou: 0.8157 - val_true_positives: 41789200.0000 - val_false_positives: 7282997.0000 - val_true_negatives: 53548900.0000 - val_false_negatives: 3350617.0000 - val_precision: 0.8516 - val_recall: 0.9258\n",
      "Epoch 208/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0228 - accuracy: 0.9816 - binary_iou: 0.9627 - true_positives: 128291336.0000 - false_positives: 2987774.0000 - true_negatives: 185343728.0000 - false_negatives: 2897936.0000 - precision: 0.9772 - recall: 0.9779 - val_loss: 0.1167 - val_accuracy: 0.8971 - val_binary_iou: 0.8117 - val_true_positives: 42040784.0000 - val_false_positives: 7801745.0000 - val_true_negatives: 53023272.0000 - val_false_negatives: 3105909.0000 - val_precision: 0.8435 - val_recall: 0.9312\n",
      "Epoch 209/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9628 - true_positives: 128177888.0000 - false_positives: 2940846.0000 - true_negatives: 185484976.0000 - false_negatives: 2917091.0000 - precision: 0.9776 - recall: 0.9777 - val_loss: 0.1151 - val_accuracy: 0.8991 - val_binary_iou: 0.8149 - val_true_positives: 41888988.0000 - val_false_positives: 7531226.0000 - val_true_negatives: 53392728.0000 - val_false_negatives: 3158768.0000 - val_precision: 0.8476 - val_recall: 0.9299\n",
      "Epoch 210/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0226 - accuracy: 0.9817 - binary_iou: 0.9629 - true_positives: 128203224.0000 - false_positives: 2922962.0000 - true_negatives: 185467120.0000 - false_negatives: 2927567.0000 - precision: 0.9777 - recall: 0.9777 - val_loss: 0.1169 - val_accuracy: 0.8960 - val_binary_iou: 0.8100 - val_true_positives: 42158880.0000 - val_false_positives: 7989299.0000 - val_true_negatives: 52791448.0000 - val_false_negatives: 3032094.0000 - val_precision: 0.8407 - val_recall: 0.9329\n",
      "Epoch 211/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9628 - true_positives: 128263352.0000 - false_positives: 2955893.0000 - true_negatives: 185394320.0000 - false_negatives: 2907142.0000 - precision: 0.9775 - recall: 0.9778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9628 - true_positives: 128263352.0000 - false_positives: 2955893.0000 - true_negatives: 185394320.0000 - false_negatives: 2907142.0000 - precision: 0.9775 - recall: 0.9778 - val_loss: 0.1116 - val_accuracy: 0.9028 - val_binary_iou: 0.8208 - val_true_positives: 41691500.0000 - val_false_positives: 6820514.0000 - val_true_negatives: 53981152.0000 - val_false_negatives: 3478565.0000 - val_precision: 0.8594 - val_recall: 0.9230\n",
      "Epoch 212/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0224 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128254832.0000 - false_positives: 2936046.0000 - true_negatives: 185477984.0000 - false_negatives: 2851861.0000 - precision: 0.9776 - recall: 0.9782 - val_loss: 0.1131 - val_accuracy: 0.9007 - val_binary_iou: 0.8175 - val_true_positives: 41833300.0000 - val_false_positives: 7226069.0000 - val_true_negatives: 53617744.0000 - val_false_negatives: 3294617.0000 - val_precision: 0.8527 - val_recall: 0.9270\n",
      "Epoch 213/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0223 - accuracy: 0.9820 - binary_iou: 0.9635 - true_positives: 128248344.0000 - false_positives: 2881542.0000 - true_negatives: 185527824.0000 - false_negatives: 2863048.0000 - precision: 0.9780 - recall: 0.9782 - val_loss: 0.1127 - val_accuracy: 0.9017 - val_binary_iou: 0.8190 - val_true_positives: 41757256.0000 - val_false_positives: 7068898.0000 - val_true_negatives: 53795828.0000 - val_false_negatives: 3349728.0000 - val_precision: 0.8552 - val_recall: 0.9257\n",
      "Epoch 214/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0220 - accuracy: 0.9821 - binary_iou: 0.9638 - true_positives: 128261984.0000 - false_positives: 2859859.0000 - true_negatives: 185550848.0000 - false_negatives: 2848072.0000 - precision: 0.9782 - recall: 0.9783 - val_loss: 0.1161 - val_accuracy: 0.8979 - val_binary_iou: 0.8130 - val_true_positives: 41912148.0000 - val_false_positives: 7620102.0000 - val_true_negatives: 53244420.0000 - val_false_negatives: 3195026.0000 - val_precision: 0.8462 - val_recall: 0.9292\n",
      "Epoch 215/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0221 - accuracy: 0.9822 - binary_iou: 0.9638 - true_positives: 128281168.0000 - false_positives: 2870830.0000 - true_negatives: 185542864.0000 - false_negatives: 2825836.0000 - precision: 0.9781 - recall: 0.9784 - val_loss: 0.1135 - val_accuracy: 0.9005 - val_binary_iou: 0.8171 - val_true_positives: 41724828.0000 - val_false_positives: 7182009.0000 - val_true_negatives: 53705012.0000 - val_false_negatives: 3359862.0000 - val_precision: 0.8531 - val_recall: 0.9255\n",
      "Epoch 216/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0218 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128238824.0000 - false_positives: 2849901.0000 - true_negatives: 185660720.0000 - false_negatives: 2771307.0000 - precision: 0.9783 - recall: 0.9788 - val_loss: 0.1139 - val_accuracy: 0.9004 - val_binary_iou: 0.8169 - val_true_positives: 41827752.0000 - val_false_positives: 7286566.0000 - val_true_negatives: 53584780.0000 - val_false_negatives: 3272611.0000 - val_precision: 0.8516 - val_recall: 0.9274\n",
      "Epoch 217/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0220 - accuracy: 0.9822 - binary_iou: 0.9639 - true_positives: 128280904.0000 - false_positives: 2840224.0000 - true_negatives: 185557920.0000 - false_negatives: 2841799.0000 - precision: 0.9783 - recall: 0.9783 - val_loss: 0.1140 - val_accuracy: 0.8999 - val_binary_iou: 0.8162 - val_true_positives: 41933156.0000 - val_false_positives: 7372418.0000 - val_true_negatives: 53430156.0000 - val_false_negatives: 3235985.0000 - val_precision: 0.8505 - val_recall: 0.9284\n",
      "Epoch 218/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0217 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128362304.0000 - false_positives: 2835385.0000 - true_negatives: 185533744.0000 - false_negatives: 2789357.0000 - precision: 0.9784 - recall: 0.9787 - val_loss: 0.1121 - val_accuracy: 0.9013 - val_binary_iou: 0.8186 - val_true_positives: 41960072.0000 - val_false_positives: 7268199.0000 - val_true_negatives: 53554332.0000 - val_false_negatives: 3189113.0000 - val_precision: 0.8524 - val_recall: 0.9294\n",
      "Epoch 219/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9823 - binary_iou: 0.9642 - true_positives: 128248240.0000 - false_positives: 2823222.0000 - true_negatives: 185626656.0000 - false_negatives: 2822628.0000 - precision: 0.9785 - recall: 0.9785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 465ms/step - loss: 0.0218 - accuracy: 0.9823 - binary_iou: 0.9642 - true_positives: 128248240.0000 - false_positives: 2823222.0000 - true_negatives: 185626656.0000 - false_negatives: 2822628.0000 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.1116 - val_accuracy: 0.9032 - val_binary_iou: 0.8212 - val_true_positives: 41362016.0000 - val_false_positives: 6503211.0000 - val_true_negatives: 54346500.0000 - val_false_negatives: 3759987.0000 - val_precision: 0.8641 - val_recall: 0.9167\n",
      "Epoch 220/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0221 - accuracy: 0.9822 - binary_iou: 0.9638 - true_positives: 128279968.0000 - false_positives: 2864313.0000 - true_negatives: 185539280.0000 - false_negatives: 2837305.0000 - precision: 0.9782 - recall: 0.9784 - val_loss: 0.1129 - val_accuracy: 0.9008 - val_binary_iou: 0.8177 - val_true_positives: 41842280.0000 - val_false_positives: 7295602.0000 - val_true_negatives: 53618592.0000 - val_false_negatives: 3215240.0000 - val_precision: 0.8515 - val_recall: 0.9286\n",
      "Epoch 221/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0219 - accuracy: 0.9823 - binary_iou: 0.9641 - true_positives: 128331456.0000 - false_positives: 2842559.0000 - true_negatives: 185536480.0000 - false_negatives: 2810165.0000 - precision: 0.9783 - recall: 0.9786 - val_loss: 0.1147 - val_accuracy: 0.8987 - val_binary_iou: 0.8143 - val_true_positives: 42039840.0000 - val_false_positives: 7669176.0000 - val_true_negatives: 53192392.0000 - val_false_negatives: 3070308.0000 - val_precision: 0.8457 - val_recall: 0.9319\n",
      "Epoch 222/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0220 - accuracy: 0.9823 - binary_iou: 0.9641 - true_positives: 128289712.0000 - false_positives: 2823477.0000 - true_negatives: 185581392.0000 - false_negatives: 2826172.0000 - precision: 0.9785 - recall: 0.9784 - val_loss: 0.1146 - val_accuracy: 0.8998 - val_binary_iou: 0.8160 - val_true_positives: 41743968.0000 - val_false_positives: 7259461.0000 - val_true_negatives: 53612040.0000 - val_false_negatives: 3356232.0000 - val_precision: 0.8519 - val_recall: 0.9256\n",
      "Epoch 223/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0222 - accuracy: 0.9820 - binary_iou: 0.9636 - true_positives: 128371136.0000 - false_positives: 2899101.0000 - true_negatives: 185405504.0000 - false_negatives: 2844905.0000 - precision: 0.9779 - recall: 0.9783 - val_loss: 0.1130 - val_accuracy: 0.9004 - val_binary_iou: 0.8170 - val_true_positives: 41832180.0000 - val_false_positives: 7294294.0000 - val_true_negatives: 53589064.0000 - val_false_negatives: 3256169.0000 - val_precision: 0.8515 - val_recall: 0.9278\n",
      "Epoch 224/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0215 - accuracy: 0.9826 - binary_iou: 0.9646 - true_positives: 128458640.0000 - false_positives: 2802148.0000 - true_negatives: 185490400.0000 - false_negatives: 2769613.0000 - precision: 0.9787 - recall: 0.9789 - val_loss: 0.1176 - val_accuracy: 0.8967 - val_binary_iou: 0.8111 - val_true_positives: 42042744.0000 - val_false_positives: 7958827.0000 - val_true_negatives: 52983056.0000 - val_false_negatives: 2987080.0000 - val_precision: 0.8408 - val_recall: 0.9337\n",
      "Epoch 225/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0217 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128322792.0000 - false_positives: 2844006.0000 - true_negatives: 185580544.0000 - false_negatives: 2773478.0000 - precision: 0.9783 - recall: 0.9788 - val_loss: 0.1143 - val_accuracy: 0.8992 - val_binary_iou: 0.8150 - val_true_positives: 41782740.0000 - val_false_positives: 7347461.0000 - val_true_negatives: 53509224.0000 - val_false_negatives: 3332283.0000 - val_precision: 0.8504 - val_recall: 0.9261\n",
      "Epoch 226/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0217 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128285864.0000 - false_positives: 2808489.0000 - true_negatives: 185616080.0000 - false_negatives: 2810259.0000 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.1156 - val_accuracy: 0.8988 - val_binary_iou: 0.8144 - val_true_positives: 41879012.0000 - val_false_positives: 7514736.0000 - val_true_negatives: 53365068.0000 - val_false_negatives: 3212905.0000 - val_precision: 0.8479 - val_recall: 0.9287\n",
      "Epoch 227/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0216 - accuracy: 0.9825 - binary_iou: 0.9645 - true_positives: 128362816.0000 - false_positives: 2811590.0000 - true_negatives: 185571584.0000 - false_negatives: 2774747.0000 - precision: 0.9786 - recall: 0.9788 - val_loss: 0.1140 - val_accuracy: 0.8994 - val_binary_iou: 0.8155 - val_true_positives: 42063576.0000 - val_false_positives: 7511779.0000 - val_true_negatives: 53250628.0000 - val_false_negatives: 3145733.0000 - val_precision: 0.8485 - val_recall: 0.9304\n",
      "Epoch 228/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9827 - binary_iou: 0.9649 - true_positives: 128339832.0000 - false_positives: 2767112.0000 - true_negatives: 185648896.0000 - false_negatives: 2764875.0000 - precision: 0.9789 - recall: 0.9789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 466ms/step - loss: 0.0214 - accuracy: 0.9827 - binary_iou: 0.9649 - true_positives: 128339832.0000 - false_positives: 2767112.0000 - true_negatives: 185648896.0000 - false_negatives: 2764875.0000 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1116 - val_accuracy: 0.9031 - val_binary_iou: 0.8213 - val_true_positives: 41737560.0000 - val_false_positives: 6900010.0000 - val_true_negatives: 53963868.0000 - val_false_negatives: 3370279.0000 - val_precision: 0.8581 - val_recall: 0.9253\n",
      "Epoch 229/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0211 - accuracy: 0.9829 - binary_iou: 0.9653 - true_positives: 128333176.0000 - false_positives: 2750717.0000 - true_negatives: 185728816.0000 - false_negatives: 2708026.0000 - precision: 0.9790 - recall: 0.9793 - val_loss: 0.1127 - val_accuracy: 0.9018 - val_binary_iou: 0.8193 - val_true_positives: 41782176.0000 - val_false_positives: 7068193.0000 - val_true_negatives: 53787708.0000 - val_false_negatives: 3333630.0000 - val_precision: 0.8553 - val_recall: 0.9261\n",
      "Epoch 230/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0213 - accuracy: 0.9828 - binary_iou: 0.9651 - true_positives: 128419888.0000 - false_positives: 2756709.0000 - true_negatives: 185602560.0000 - false_negatives: 2741631.0000 - precision: 0.9790 - recall: 0.9791 - val_loss: 0.1133 - val_accuracy: 0.8998 - val_binary_iou: 0.8161 - val_true_positives: 41977380.0000 - val_false_positives: 7446114.0000 - val_true_negatives: 53375760.0000 - val_false_negatives: 3172457.0000 - val_precision: 0.8493 - val_recall: 0.9297\n",
      "Epoch 231/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9656 - true_positives: 128433296.0000 - false_positives: 2744220.0000 - true_negatives: 185664016.0000 - false_negatives: 2679184.0000 - precision: 0.9791 - recall: 0.9796 - val_loss: 0.1125 - val_accuracy: 0.9009 - val_binary_iou: 0.8178 - val_true_positives: 41800464.0000 - val_false_positives: 7211360.0000 - val_true_negatives: 53671040.0000 - val_false_negatives: 3288845.0000 - val_precision: 0.8529 - val_recall: 0.9271\n",
      "Epoch 232/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9656 - true_positives: 128451136.0000 - false_positives: 2734280.0000 - true_negatives: 185648160.0000 - false_negatives: 2687107.0000 - precision: 0.9792 - recall: 0.9795 - val_loss: 0.1118 - val_accuracy: 0.9024 - val_binary_iou: 0.8203 - val_true_positives: 41750568.0000 - val_false_positives: 6952203.0000 - val_true_negatives: 53881576.0000 - val_false_negatives: 3387356.0000 - val_precision: 0.8573 - val_recall: 0.9250\n",
      "Epoch 233/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0208 - accuracy: 0.9831 - binary_iou: 0.9657 - true_positives: 128438392.0000 - false_positives: 2693219.0000 - true_negatives: 185688688.0000 - false_negatives: 2700352.0000 - precision: 0.9795 - recall: 0.9794 - val_loss: 0.1115 - val_accuracy: 0.9029 - val_binary_iou: 0.8210 - val_true_positives: 41738044.0000 - val_false_positives: 6951517.0000 - val_true_negatives: 53944616.0000 - val_false_negatives: 3337538.0000 - val_precision: 0.8572 - val_recall: 0.9260\n",
      "Epoch 234/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0206 - accuracy: 0.9833 - binary_iou: 0.9660 - true_positives: 128432720.0000 - false_positives: 2679417.0000 - true_negatives: 185744976.0000 - false_negatives: 2663753.0000 - precision: 0.9796 - recall: 0.9797 - val_loss: 0.1141 - val_accuracy: 0.9009 - val_binary_iou: 0.8177 - val_true_positives: 41778400.0000 - val_false_positives: 7260461.0000 - val_true_negatives: 53687680.0000 - val_false_negatives: 3245179.0000 - val_precision: 0.8519 - val_recall: 0.9279\n",
      "Epoch 235/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0207 - accuracy: 0.9832 - binary_iou: 0.9660 - true_positives: 128402704.0000 - false_positives: 2684961.0000 - true_negatives: 185763504.0000 - false_negatives: 2669576.0000 - precision: 0.9795 - recall: 0.9796 - val_loss: 0.1138 - val_accuracy: 0.9000 - val_binary_iou: 0.8163 - val_true_positives: 41754764.0000 - val_false_positives: 7229954.0000 - val_true_negatives: 53622128.0000 - val_false_negatives: 3364879.0000 - val_precision: 0.8524 - val_recall: 0.9254\n",
      "Epoch 236/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0209 - accuracy: 0.9831 - binary_iou: 0.9657 - true_positives: 128479216.0000 - false_positives: 2730941.0000 - true_negatives: 185633632.0000 - false_negatives: 2676995.0000 - precision: 0.9792 - recall: 0.9796 - val_loss: 0.1163 - val_accuracy: 0.8974 - val_binary_iou: 0.8122 - val_true_positives: 41941688.0000 - val_false_positives: 7735460.0000 - val_true_negatives: 53160080.0000 - val_false_negatives: 3134463.0000 - val_precision: 0.8443 - val_recall: 0.9305\n",
      "Epoch 237/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0208 - accuracy: 0.9832 - binary_iou: 0.9658 - true_positives: 128438728.0000 - false_positives: 2689260.0000 - true_negatives: 185700848.0000 - false_negatives: 2691882.0000 - precision: 0.9795 - recall: 0.9795 - val_loss: 0.1145 - val_accuracy: 0.8994 - val_binary_iou: 0.8155 - val_true_positives: 41927276.0000 - val_false_positives: 7489171.0000 - val_true_negatives: 53388200.0000 - val_false_negatives: 3167065.0000 - val_precision: 0.8484 - val_recall: 0.9298\n",
      "Epoch 238/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0207 - accuracy: 0.9833 - binary_iou: 0.9660 - true_positives: 128431360.0000 - false_positives: 2679511.0000 - true_negatives: 185739920.0000 - false_negatives: 2669991.0000 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.1139 - val_accuracy: 0.9002 - val_binary_iou: 0.8167 - val_true_positives: 41773796.0000 - val_false_positives: 7260038.0000 - val_true_negatives: 53625304.0000 - val_false_negatives: 3312569.0000 - val_precision: 0.8519 - val_recall: 0.9265\n",
      "Epoch 239/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0206 - accuracy: 0.9834 - binary_iou: 0.9662 - true_positives: 128541440.0000 - false_positives: 2651249.0000 - true_negatives: 185659968.0000 - false_negatives: 2668087.0000 - precision: 0.9798 - recall: 0.9797 - val_loss: 0.1158 - val_accuracy: 0.8979 - val_binary_iou: 0.8131 - val_true_positives: 42096108.0000 - val_false_positives: 7750150.0000 - val_true_negatives: 53058472.0000 - val_false_negatives: 3066974.0000 - val_precision: 0.8445 - val_recall: 0.9321\n",
      "Epoch 240/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0207 - accuracy: 0.9833 - binary_iou: 0.9662 - true_positives: 128500640.0000 - false_positives: 2663736.0000 - true_negatives: 185693968.0000 - false_negatives: 2662441.0000 - precision: 0.9797 - recall: 0.9797 - val_loss: 0.1138 - val_accuracy: 0.8998 - val_binary_iou: 0.8160 - val_true_positives: 41829296.0000 - val_false_positives: 7389672.0000 - val_true_negatives: 53526864.0000 - val_false_negatives: 3225895.0000 - val_precision: 0.8499 - val_recall: 0.9284\n",
      "Epoch 241/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0203 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128580736.0000 - false_positives: 2649525.0000 - true_negatives: 185682592.0000 - false_negatives: 2607897.0000 - precision: 0.9798 - recall: 0.9801 - val_loss: 0.1153 - val_accuracy: 0.8995 - val_binary_iou: 0.8155 - val_true_positives: 41841192.0000 - val_false_positives: 7421262.0000 - val_true_negatives: 53476124.0000 - val_false_negatives: 3233128.0000 - val_precision: 0.8494 - val_recall: 0.9283\n",
      "Epoch 242/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9666 - true_positives: 128521352.0000 - false_positives: 2649756.0000 - true_negatives: 185743680.0000 - false_negatives: 2606011.0000 - precision: 0.9798 - recall: 0.9801 - val_loss: 0.1143 - val_accuracy: 0.8998 - val_binary_iou: 0.8160 - val_true_positives: 41808344.0000 - val_false_positives: 7343820.0000 - val_true_negatives: 53544484.0000 - val_false_negatives: 3275061.0000 - val_precision: 0.8506 - val_recall: 0.9274\n",
      "Epoch 243/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128402152.0000 - false_positives: 2623418.0000 - true_negatives: 185883728.0000 - false_negatives: 2611438.0000 - precision: 0.9800 - recall: 0.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 464ms/step - loss: 0.0202 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128402152.0000 - false_positives: 2623418.0000 - true_negatives: 185883728.0000 - false_negatives: 2611438.0000 - precision: 0.9800 - recall: 0.9801 - val_loss: 0.1111 - val_accuracy: 0.9034 - val_binary_iou: 0.8218 - val_true_positives: 41699968.0000 - val_false_positives: 6868364.0000 - val_true_negatives: 54031540.0000 - val_false_negatives: 3371844.0000 - val_precision: 0.8586 - val_recall: 0.9252\n",
      "Epoch 244/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0207 - accuracy: 0.9832 - binary_iou: 0.9660 - true_positives: 128418976.0000 - false_positives: 2719425.0000 - true_negatives: 185746064.0000 - false_negatives: 2636346.0000 - precision: 0.9793 - recall: 0.9799 - val_loss: 0.1138 - val_accuracy: 0.9001 - val_binary_iou: 0.8165 - val_true_positives: 41823016.0000 - val_false_positives: 7252716.0000 - val_true_negatives: 53562416.0000 - val_false_negatives: 3333575.0000 - val_precision: 0.8522 - val_recall: 0.9262\n",
      "Epoch 245/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128550520.0000 - false_positives: 2637383.0000 - true_negatives: 185706480.0000 - false_negatives: 2626401.0000 - precision: 0.9799 - recall: 0.9800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 463ms/step - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128550520.0000 - false_positives: 2637383.0000 - true_negatives: 185706480.0000 - false_negatives: 2626401.0000 - precision: 0.9799 - recall: 0.9800 - val_loss: 0.1106 - val_accuracy: 0.9034 - val_binary_iou: 0.8218 - val_true_positives: 41785572.0000 - val_false_positives: 6869876.0000 - val_true_negatives: 53947796.0000 - val_false_negatives: 3368461.0000 - val_precision: 0.8588 - val_recall: 0.9254\n",
      "Epoch 246/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0202 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128516448.0000 - false_positives: 2623908.0000 - true_negatives: 185772992.0000 - false_negatives: 2607411.0000 - precision: 0.9800 - recall: 0.9801 - val_loss: 0.1140 - val_accuracy: 0.9005 - val_binary_iou: 0.8171 - val_true_positives: 41744192.0000 - val_false_positives: 7249535.0000 - val_true_negatives: 53682808.0000 - val_false_negatives: 3295179.0000 - val_precision: 0.8520 - val_recall: 0.9268\n",
      "Epoch 247/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128474696.0000 - false_positives: 2627858.0000 - true_negatives: 185803584.0000 - false_negatives: 2614650.0000 - precision: 0.9800 - recall: 0.9801 - val_loss: 0.1138 - val_accuracy: 0.9007 - val_binary_iou: 0.8174 - val_true_positives: 41666696.0000 - val_false_positives: 7072940.0000 - val_true_negatives: 53781332.0000 - val_false_negatives: 3450746.0000 - val_precision: 0.8549 - val_recall: 0.9235\n",
      "Epoch 248/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0202 - accuracy: 0.9837 - binary_iou: 0.9668 - true_positives: 128550520.0000 - false_positives: 2619491.0000 - true_negatives: 185747104.0000 - false_negatives: 2603737.0000 - precision: 0.9800 - recall: 0.9801 - val_loss: 0.1160 - val_accuracy: 0.8981 - val_binary_iou: 0.8132 - val_true_positives: 41781632.0000 - val_false_positives: 7533344.0000 - val_true_negatives: 53388816.0000 - val_false_negatives: 3267907.0000 - val_precision: 0.8472 - val_recall: 0.9275\n",
      "Epoch 249/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0199 - accuracy: 0.9839 - binary_iou: 0.9672 - true_positives: 128599864.0000 - false_positives: 2590407.0000 - true_negatives: 185762576.0000 - false_negatives: 2567935.0000 - precision: 0.9803 - recall: 0.9804 - val_loss: 0.1134 - val_accuracy: 0.9016 - val_binary_iou: 0.8187 - val_true_positives: 41525496.0000 - val_false_positives: 6877623.0000 - val_true_negatives: 54017616.0000 - val_false_negatives: 3550985.0000 - val_precision: 0.8579 - val_recall: 0.9212\n",
      "Epoch 250/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0202 - accuracy: 0.9838 - binary_iou: 0.9670 - true_positives: 128536440.0000 - false_positives: 2598632.0000 - true_negatives: 185798720.0000 - false_negatives: 2586977.0000 - precision: 0.9802 - recall: 0.9803 - val_loss: 0.1157 - val_accuracy: 0.8980 - val_binary_iou: 0.8130 - val_true_positives: 41776624.0000 - val_false_positives: 7491026.0000 - val_true_negatives: 53386180.0000 - val_false_negatives: 3317886.0000 - val_precision: 0.8480 - val_recall: 0.9264\n",
      "Epoch 251/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0199 - accuracy: 0.9839 - binary_iou: 0.9673 - true_positives: 128551072.0000 - false_positives: 2571447.0000 - true_negatives: 185827696.0000 - false_negatives: 2570399.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.1150 - val_accuracy: 0.8997 - val_binary_iou: 0.8158 - val_true_positives: 41778488.0000 - val_false_positives: 7309705.0000 - val_true_negatives: 53564560.0000 - val_false_negatives: 3318961.0000 - val_precision: 0.8511 - val_recall: 0.9264\n",
      "Epoch 252/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0198 - accuracy: 0.9840 - binary_iou: 0.9675 - true_positives: 128649632.0000 - false_positives: 2562459.0000 - true_negatives: 185766704.0000 - false_negatives: 2541981.0000 - precision: 0.9805 - recall: 0.9806 - val_loss: 0.1140 - val_accuracy: 0.8998 - val_binary_iou: 0.8161 - val_true_positives: 41950944.0000 - val_false_positives: 7518271.0000 - val_true_negatives: 53405020.0000 - val_false_negatives: 3097467.0000 - val_precision: 0.8480 - val_recall: 0.9312\n",
      "Epoch 253/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0199 - accuracy: 0.9839 - binary_iou: 0.9673 - true_positives: 128579984.0000 - false_positives: 2580144.0000 - true_negatives: 185800912.0000 - false_negatives: 2559705.0000 - precision: 0.9803 - recall: 0.9805 - val_loss: 0.1143 - val_accuracy: 0.8999 - val_binary_iou: 0.8162 - val_true_positives: 41845880.0000 - val_false_positives: 7353202.0000 - val_true_negatives: 53516652.0000 - val_false_negatives: 3255987.0000 - val_precision: 0.8505 - val_recall: 0.9278\n",
      "Epoch 254/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0197 - accuracy: 0.9841 - binary_iou: 0.9676 - true_positives: 128666128.0000 - false_positives: 2543341.0000 - true_negatives: 185765936.0000 - false_negatives: 2545346.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.1123 - val_accuracy: 0.9018 - val_binary_iou: 0.8192 - val_true_positives: 41724920.0000 - val_false_positives: 7101346.0000 - val_true_negatives: 53840936.0000 - val_false_negatives: 3304530.0000 - val_precision: 0.8546 - val_recall: 0.9266\n",
      "Epoch 255/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9677 - true_positives: 128653040.0000 - false_positives: 2542802.0000 - true_negatives: 185783632.0000 - false_negatives: 2541211.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.1162 - val_accuracy: 0.8981 - val_binary_iou: 0.8133 - val_true_positives: 41921612.0000 - val_false_positives: 7553551.0000 - val_true_negatives: 53249292.0000 - val_false_negatives: 3247260.0000 - val_precision: 0.8473 - val_recall: 0.9281\n",
      "Epoch 256/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9681 - true_positives: 128653656.0000 - false_positives: 2542062.0000 - true_negatives: 185850960.0000 - false_negatives: 2474106.0000 - precision: 0.9806 - recall: 0.9811 - val_loss: 0.1146 - val_accuracy: 0.8991 - val_binary_iou: 0.8150 - val_true_positives: 42016264.0000 - val_false_positives: 7507095.0000 - val_true_negatives: 53262612.0000 - val_false_negatives: 3185742.0000 - val_precision: 0.8484 - val_recall: 0.9295\n",
      "Epoch 257/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128634664.0000 - false_positives: 2534242.0000 - true_negatives: 185820096.0000 - false_negatives: 2531815.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1149 - val_accuracy: 0.8991 - val_binary_iou: 0.8149 - val_true_positives: 41857916.0000 - val_false_positives: 7411954.0000 - val_true_negatives: 53421648.0000 - val_false_negatives: 3280175.0000 - val_precision: 0.8496 - val_recall: 0.9273\n",
      "Epoch 258/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9842 - binary_iou: 0.9680 - true_positives: 128591024.0000 - false_positives: 2529718.0000 - true_negatives: 185891248.0000 - false_negatives: 2508781.0000 - precision: 0.9807 - recall: 0.9809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0194 - accuracy: 0.9842 - binary_iou: 0.9680 - true_positives: 128591024.0000 - false_positives: 2529718.0000 - true_negatives: 185891248.0000 - false_negatives: 2508781.0000 - precision: 0.9807 - recall: 0.9809 - val_loss: 0.1109 - val_accuracy: 0.9039 - val_binary_iou: 0.8225 - val_true_positives: 41595752.0000 - val_false_positives: 6662338.0000 - val_true_negatives: 54190104.0000 - val_false_negatives: 3523512.0000 - val_precision: 0.8619 - val_recall: 0.9219\n",
      "Epoch 259/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0193 - accuracy: 0.9843 - binary_iou: 0.9681 - true_positives: 128646104.0000 - false_positives: 2554959.0000 - true_negatives: 185855008.0000 - false_negatives: 2464716.0000 - precision: 0.9805 - recall: 0.9812 - val_loss: 0.1118 - val_accuracy: 0.9021 - val_binary_iou: 0.8196 - val_true_positives: 41670656.0000 - val_false_positives: 6930192.0000 - val_true_negatives: 53922120.0000 - val_false_negatives: 3448746.0000 - val_precision: 0.8574 - val_recall: 0.9236\n",
      "Epoch 260/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9681 - true_positives: 128586608.0000 - false_positives: 2514293.0000 - true_negatives: 185918112.0000 - false_negatives: 2501799.0000 - precision: 0.9808 - recall: 0.9809 - val_loss: 0.1125 - val_accuracy: 0.9016 - val_binary_iou: 0.8190 - val_true_positives: 41777832.0000 - val_false_positives: 7095240.0000 - val_true_negatives: 53770116.0000 - val_false_negatives: 3328506.0000 - val_precision: 0.8548 - val_recall: 0.9262\n",
      "Epoch 261/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0192 - accuracy: 0.9844 - binary_iou: 0.9683 - true_positives: 128704936.0000 - false_positives: 2518736.0000 - true_negatives: 185834976.0000 - false_negatives: 2462199.0000 - precision: 0.9808 - recall: 0.9812 - val_loss: 0.1135 - val_accuracy: 0.9014 - val_binary_iou: 0.8185 - val_true_positives: 41703472.0000 - val_false_positives: 7028378.0000 - val_true_negatives: 53817756.0000 - val_false_negatives: 3422112.0000 - val_precision: 0.8558 - val_recall: 0.9242\n",
      "Epoch 262/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9682 - true_positives: 128659136.0000 - false_positives: 2506069.0000 - true_negatives: 185854224.0000 - false_negatives: 2501302.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.1135 - val_accuracy: 0.9003 - val_binary_iou: 0.8168 - val_true_positives: 41720944.0000 - val_false_positives: 7203539.0000 - val_true_negatives: 53687696.0000 - val_false_negatives: 3359527.0000 - val_precision: 0.8528 - val_recall: 0.9255\n",
      "Epoch 263/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9685 - true_positives: 128669544.0000 - false_positives: 2483781.0000 - true_negatives: 185907312.0000 - false_negatives: 2460108.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1123 - val_accuracy: 0.9021 - val_binary_iou: 0.8195 - val_true_positives: 41538048.0000 - val_false_positives: 6910017.0000 - val_true_negatives: 54053944.0000 - val_false_negatives: 3469701.0000 - val_precision: 0.8574 - val_recall: 0.9229\n",
      "Epoch 264/500\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0192 - accuracy: 0.9845 - binary_iou: 0.9684 - true_positives: 128733992.0000 - false_positives: 2505122.0000 - true_negatives: 185819328.0000 - false_negatives: 2462331.0000 - precision: 0.9809 - recall: 0.9812 - val_loss: 0.1171 - val_accuracy: 0.8967 - val_binary_iou: 0.8109 - val_true_positives: 41912072.0000 - val_false_positives: 7682793.0000 - val_true_negatives: 53107876.0000 - val_false_negatives: 3268977.0000 - val_precision: 0.8451 - val_recall: 0.9276\n",
      "Epoch 265/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9686 - true_positives: 128693816.0000 - false_positives: 2474021.0000 - true_negatives: 185883632.0000 - false_negatives: 2469344.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1105 - val_accuracy: 0.9037 - val_binary_iou: 0.8222 - val_true_positives: 41619872.0000 - val_false_positives: 6670543.0000 - val_true_negatives: 54143088.0000 - val_false_negatives: 3538222.0000 - val_precision: 0.8619 - val_recall: 0.9216\n",
      "Epoch 266/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0190 - accuracy: 0.9846 - binary_iou: 0.9686 - true_positives: 128674688.0000 - false_positives: 2466281.0000 - true_negatives: 185911808.0000 - false_negatives: 2468058.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.1125 - val_accuracy: 0.9014 - val_binary_iou: 0.8186 - val_true_positives: 41715100.0000 - val_false_positives: 7047824.0000 - val_true_negatives: 53811580.0000 - val_false_negatives: 3397214.0000 - val_precision: 0.8555 - val_recall: 0.9247\n",
      "Epoch 267/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9686 - true_positives: 128651208.0000 - false_positives: 2484602.0000 - true_negatives: 185940688.0000 - false_negatives: 2444230.0000 - precision: 0.9811 - recall: 0.9814 - val_loss: 0.1115 - val_accuracy: 0.9030 - val_binary_iou: 0.8212 - val_true_positives: 41646624.0000 - val_false_positives: 6848226.0000 - val_true_negatives: 54048256.0000 - val_false_negatives: 3428609.0000 - val_precision: 0.8588 - val_recall: 0.9239\n",
      "Epoch 268/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9687 - true_positives: 128709144.0000 - false_positives: 2466778.0000 - true_negatives: 185891360.0000 - false_negatives: 2453543.0000 - precision: 0.9812 - recall: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.8994 - val_binary_iou: 0.8154 - val_true_positives: 41811880.0000 - val_false_positives: 7387013.0000 - val_true_negatives: 53500480.0000 - val_false_negatives: 3272330.0000 - val_precision: 0.8499 - val_recall: 0.9274\n",
      "Epoch 269/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128677936.0000 - false_positives: 2450193.0000 - true_negatives: 185962224.0000 - false_negatives: 2430379.0000 - precision: 0.9813 - recall: 0.9815 - val_loss: 0.1125 - val_accuracy: 0.9026 - val_binary_iou: 0.8203 - val_true_positives: 41533200.0000 - val_false_positives: 6807660.0000 - val_true_negatives: 54112872.0000 - val_false_negatives: 3517985.0000 - val_precision: 0.8592 - val_recall: 0.9219\n",
      "Epoch 270/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9686 - true_positives: 128648304.0000 - false_positives: 2478776.0000 - true_negatives: 185932480.0000 - false_negatives: 2461154.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1129 - val_accuracy: 0.9013 - val_binary_iou: 0.8185 - val_true_positives: 41790856.0000 - val_false_positives: 7185779.0000 - val_true_negatives: 53725008.0000 - val_false_negatives: 3270071.0000 - val_precision: 0.8533 - val_recall: 0.9274\n",
      "Epoch 271/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9686 - true_positives: 128711200.0000 - false_positives: 2480670.0000 - true_negatives: 185874448.0000 - false_negatives: 2454476.0000 - precision: 0.9811 - recall: 0.9813 - val_loss: 0.1143 - val_accuracy: 0.8991 - val_binary_iou: 0.8150 - val_true_positives: 41962384.0000 - val_false_positives: 7468110.0000 - val_true_negatives: 53322036.0000 - val_false_negatives: 3219202.0000 - val_precision: 0.8489 - val_recall: 0.9287\n",
      "Epoch 272/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9848 - binary_iou: 0.9691 - true_positives: 128775128.0000 - false_positives: 2459925.0000 - true_negatives: 185881648.0000 - false_negatives: 2404066.0000 - precision: 0.9813 - recall: 0.9817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 465ms/step - loss: 0.0188 - accuracy: 0.9848 - binary_iou: 0.9691 - true_positives: 128775128.0000 - false_positives: 2459925.0000 - true_negatives: 185881648.0000 - false_negatives: 2404066.0000 - precision: 0.9813 - recall: 0.9817 - val_loss: 0.1103 - val_accuracy: 0.9039 - val_binary_iou: 0.8227 - val_true_positives: 41669812.0000 - val_false_positives: 6777670.0000 - val_true_negatives: 54122052.0000 - val_false_negatives: 3402191.0000 - val_precision: 0.8601 - val_recall: 0.9245\n",
      "Epoch 273/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0187 - accuracy: 0.9849 - binary_iou: 0.9692 - true_positives: 128660432.0000 - false_positives: 2426068.0000 - true_negatives: 186025632.0000 - false_negatives: 2408576.0000 - precision: 0.9815 - recall: 0.9816 - val_loss: 0.1143 - val_accuracy: 0.9001 - val_binary_iou: 0.8164 - val_true_positives: 41819336.0000 - val_false_positives: 7277949.0000 - val_true_negatives: 53562764.0000 - val_false_negatives: 3311656.0000 - val_precision: 0.8518 - val_recall: 0.9266\n",
      "Epoch 274/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0186 - accuracy: 0.9849 - binary_iou: 0.9693 - true_positives: 128762672.0000 - false_positives: 2412749.0000 - true_negatives: 185935632.0000 - false_negatives: 2409785.0000 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.1146 - val_accuracy: 0.9002 - val_binary_iou: 0.8166 - val_true_positives: 41773112.0000 - val_false_positives: 7337543.0000 - val_true_negatives: 53622788.0000 - val_false_negatives: 3238269.0000 - val_precision: 0.8506 - val_recall: 0.9281\n",
      "Epoch 275/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128756096.0000 - false_positives: 2457165.0000 - true_negatives: 185881408.0000 - false_negatives: 2426059.0000 - precision: 0.9813 - recall: 0.9815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 466ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128756096.0000 - false_positives: 2457165.0000 - true_negatives: 185881408.0000 - false_negatives: 2426059.0000 - precision: 0.9813 - recall: 0.9815 - val_loss: 0.1102 - val_accuracy: 0.9043 - val_binary_iou: 0.8232 - val_true_positives: 41678080.0000 - val_false_positives: 6686684.0000 - val_true_negatives: 54147388.0000 - val_false_negatives: 3459543.0000 - val_precision: 0.8617 - val_recall: 0.9234\n",
      "Epoch 276/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128772024.0000 - false_positives: 2466103.0000 - true_negatives: 185861600.0000 - false_negatives: 2421046.0000 - precision: 0.9812 - recall: 0.9815 - val_loss: 0.1125 - val_accuracy: 0.9014 - val_binary_iou: 0.8185 - val_true_positives: 41755752.0000 - val_false_positives: 7122392.0000 - val_true_negatives: 53761984.0000 - val_false_negatives: 3331582.0000 - val_precision: 0.8543 - val_recall: 0.9261\n",
      "Epoch 277/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0187 - accuracy: 0.9849 - binary_iou: 0.9693 - true_positives: 128690816.0000 - false_positives: 2417723.0000 - true_negatives: 186005344.0000 - false_negatives: 2406892.0000 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.1121 - val_accuracy: 0.9030 - val_binary_iou: 0.8212 - val_true_positives: 41576832.0000 - val_false_positives: 6770797.0000 - val_true_negatives: 54120712.0000 - val_false_negatives: 3503385.0000 - val_precision: 0.8600 - val_recall: 0.9223\n",
      "Epoch 278/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9851 - binary_iou: 0.9697 - true_positives: 128731488.0000 - false_positives: 2383617.0000 - true_negatives: 186032656.0000 - false_negatives: 2373002.0000 - precision: 0.9818 - recall: 0.9819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_True_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 465ms/step - loss: 0.0184 - accuracy: 0.9851 - binary_iou: 0.9697 - true_positives: 128731488.0000 - false_positives: 2383617.0000 - true_negatives: 186032656.0000 - false_negatives: 2373002.0000 - precision: 0.9818 - recall: 0.9819 - val_loss: 0.1097 - val_accuracy: 0.9048 - val_binary_iou: 0.8241 - val_true_positives: 41778132.0000 - val_false_positives: 6708904.0000 - val_true_negatives: 54103348.0000 - val_false_negatives: 3381325.0000 - val_precision: 0.8616 - val_recall: 0.9251\n",
      "Epoch 279/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0184 - accuracy: 0.9852 - binary_iou: 0.9698 - true_positives: 128754816.0000 - false_positives: 2380799.0000 - true_negatives: 186021568.0000 - false_negatives: 2363591.0000 - precision: 0.9818 - recall: 0.9820 - val_loss: 0.1143 - val_accuracy: 0.8995 - val_binary_iou: 0.8155 - val_true_positives: 41936540.0000 - val_false_positives: 7470143.0000 - val_true_negatives: 53381976.0000 - val_false_negatives: 3183074.0000 - val_precision: 0.8488 - val_recall: 0.9295\n",
      "Epoch 280/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0182 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128846616.0000 - false_positives: 2383520.0000 - true_negatives: 185949264.0000 - false_negatives: 2341356.0000 - precision: 0.9818 - recall: 0.9822 - val_loss: 0.1122 - val_accuracy: 0.9023 - val_binary_iou: 0.8200 - val_true_positives: 41705012.0000 - val_false_positives: 7031538.0000 - val_true_negatives: 53915680.0000 - val_false_negatives: 3319478.0000 - val_precision: 0.8557 - val_recall: 0.9263\n",
      "Epoch 281/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128676336.0000 - false_positives: 2375154.0000 - true_negatives: 186112400.0000 - false_negatives: 2356893.0000 - precision: 0.9819 - recall: 0.9820 - val_loss: 0.1103 - val_accuracy: 0.9043 - val_binary_iou: 0.8231 - val_true_positives: 41498292.0000 - val_false_positives: 6621754.0000 - val_true_negatives: 54327880.0000 - val_false_negatives: 3523780.0000 - val_precision: 0.8624 - val_recall: 0.9217\n",
      "Epoch 282/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0185 - accuracy: 0.9850 - binary_iou: 0.9696 - true_positives: 128808112.0000 - false_positives: 2395395.0000 - true_negatives: 185934880.0000 - false_negatives: 2382325.0000 - precision: 0.9817 - recall: 0.9818 - val_loss: 0.1107 - val_accuracy: 0.9040 - val_binary_iou: 0.8228 - val_true_positives: 41681004.0000 - val_false_positives: 6730972.0000 - val_true_negatives: 54119864.0000 - val_false_negatives: 3439864.0000 - val_precision: 0.8610 - val_recall: 0.9238\n",
      "Epoch 283/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0184 - accuracy: 0.9852 - binary_iou: 0.9698 - true_positives: 128702944.0000 - false_positives: 2366758.0000 - true_negatives: 186080624.0000 - false_negatives: 2370428.0000 - precision: 0.9819 - recall: 0.9819 - val_loss: 0.1118 - val_accuracy: 0.9022 - val_binary_iou: 0.8200 - val_true_positives: 41956192.0000 - val_false_positives: 7162590.0000 - val_true_negatives: 53651616.0000 - val_false_negatives: 3201308.0000 - val_precision: 0.8542 - val_recall: 0.9291\n",
      "Epoch 284/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9702 - true_positives: 128822136.0000 - false_positives: 2358170.0000 - true_negatives: 186024464.0000 - false_negatives: 2315949.0000 - precision: 0.9820 - recall: 0.9823 - val_loss: 0.1106 - val_accuracy: 0.9034 - val_binary_iou: 0.8218 - val_true_positives: 41690460.0000 - val_false_positives: 6856644.0000 - val_true_negatives: 54042504.0000 - val_false_negatives: 3382103.0000 - val_precision: 0.8588 - val_recall: 0.9250\n",
      "Epoch 285/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9703 - true_positives: 128808864.0000 - false_positives: 2338732.0000 - true_negatives: 186046976.0000 - false_negatives: 2326211.0000 - precision: 0.9822 - recall: 0.9823 - val_loss: 0.1118 - val_accuracy: 0.9023 - val_binary_iou: 0.8200 - val_true_positives: 41714240.0000 - val_false_positives: 6990454.0000 - val_true_negatives: 53900544.0000 - val_false_negatives: 3366478.0000 - val_precision: 0.8565 - val_recall: 0.9253\n",
      "Epoch 286/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0185 - accuracy: 0.9850 - binary_iou: 0.9695 - true_positives: 128791040.0000 - false_positives: 2423598.0000 - true_negatives: 185940672.0000 - false_negatives: 2365447.0000 - precision: 0.9815 - recall: 0.9820 - val_loss: 0.1125 - val_accuracy: 0.9023 - val_binary_iou: 0.8198 - val_true_positives: 41465728.0000 - val_false_positives: 6817713.0000 - val_true_negatives: 54147420.0000 - val_false_negatives: 3540843.0000 - val_precision: 0.8588 - val_recall: 0.9213\n",
      "Epoch 287/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0185 - accuracy: 0.9850 - binary_iou: 0.9695 - true_positives: 128802848.0000 - false_positives: 2422009.0000 - true_negatives: 185924880.0000 - false_negatives: 2371068.0000 - precision: 0.9815 - recall: 0.9819 - val_loss: 0.1109 - val_accuracy: 0.9039 - val_binary_iou: 0.8226 - val_true_positives: 41564724.0000 - val_false_positives: 6597744.0000 - val_true_negatives: 54227060.0000 - val_false_negatives: 3582174.0000 - val_precision: 0.8630 - val_recall: 0.9207\n",
      "Epoch 288/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9702 - true_positives: 128794632.0000 - false_positives: 2341401.0000 - true_negatives: 186045904.0000 - false_negatives: 2338844.0000 - precision: 0.9821 - recall: 0.9822 - val_loss: 0.1110 - val_accuracy: 0.9033 - val_binary_iou: 0.8217 - val_true_positives: 41790668.0000 - val_false_positives: 6866870.0000 - val_true_negatives: 53934812.0000 - val_false_negatives: 3379348.0000 - val_precision: 0.8589 - val_recall: 0.9252\n",
      "Epoch 289/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9698 - true_positives: 128797912.0000 - false_positives: 2382672.0000 - true_negatives: 185979792.0000 - false_negatives: 2360365.0000 - precision: 0.9818 - recall: 0.9820 - val_loss: 0.1144 - val_accuracy: 0.8999 - val_binary_iou: 0.8161 - val_true_positives: 41721368.0000 - val_false_positives: 7254765.0000 - val_true_negatives: 53643368.0000 - val_false_negatives: 3352207.0000 - val_precision: 0.8519 - val_recall: 0.9256\n",
      "Epoch 290/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128797280.0000 - false_positives: 2372434.0000 - true_negatives: 185990544.0000 - false_negatives: 2360454.0000 - precision: 0.9819 - recall: 0.9820 - val_loss: 0.1117 - val_accuracy: 0.9022 - val_binary_iou: 0.8199 - val_true_positives: 41732208.0000 - val_false_positives: 6955070.0000 - val_true_negatives: 53877700.0000 - val_false_negatives: 3406740.0000 - val_precision: 0.8571 - val_recall: 0.9245\n",
      "Epoch 291/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0180 - accuracy: 0.9855 - binary_iou: 0.9705 - true_positives: 128841032.0000 - false_positives: 2333045.0000 - true_negatives: 186041104.0000 - false_negatives: 2305571.0000 - precision: 0.9822 - recall: 0.9824 - val_loss: 0.1124 - val_accuracy: 0.9017 - val_binary_iou: 0.8190 - val_true_positives: 41657300.0000 - val_false_positives: 6937088.0000 - val_true_negatives: 53896060.0000 - val_false_negatives: 3481272.0000 - val_precision: 0.8572 - val_recall: 0.9229\n",
      "Epoch 292/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0179 - accuracy: 0.9855 - binary_iou: 0.9706 - true_positives: 128810192.0000 - false_positives: 2322562.0000 - true_negatives: 186092624.0000 - false_negatives: 2295332.0000 - precision: 0.9823 - recall: 0.9825 - val_loss: 0.1135 - val_accuracy: 0.9004 - val_binary_iou: 0.8169 - val_true_positives: 41661196.0000 - val_false_positives: 7164479.0000 - val_true_negatives: 53757984.0000 - val_false_negatives: 3388041.0000 - val_precision: 0.8533 - val_recall: 0.9248\n",
      "Epoch 293/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0178 - accuracy: 0.9856 - binary_iou: 0.9708 - true_positives: 128833936.0000 - false_positives: 2304987.0000 - true_negatives: 186097568.0000 - false_negatives: 2284186.0000 - precision: 0.9824 - recall: 0.9826 - val_loss: 0.1114 - val_accuracy: 0.9035 - val_binary_iou: 0.8220 - val_true_positives: 41699876.0000 - val_false_positives: 6855472.0000 - val_true_negatives: 54050136.0000 - val_false_negatives: 3366216.0000 - val_precision: 0.8588 - val_recall: 0.9253\n",
      "Epoch 294/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0179 - accuracy: 0.9855 - binary_iou: 0.9706 - true_positives: 128916400.0000 - false_positives: 2323303.0000 - true_negatives: 185985056.0000 - false_negatives: 2295933.0000 - precision: 0.9823 - recall: 0.9825 - val_loss: 0.1137 - val_accuracy: 0.9013 - val_binary_iou: 0.8184 - val_true_positives: 41779160.0000 - val_false_positives: 7107378.0000 - val_true_negatives: 53734644.0000 - val_false_negatives: 3350532.0000 - val_precision: 0.8546 - val_recall: 0.9258\n",
      "Epoch 295/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0177 - accuracy: 0.9857 - binary_iou: 0.9709 - true_positives: 128876232.0000 - false_positives: 2294949.0000 - true_negatives: 186074048.0000 - false_negatives: 2275585.0000 - precision: 0.9825 - recall: 0.9826 - val_loss: 0.1117 - val_accuracy: 0.9035 - val_binary_iou: 0.8219 - val_true_positives: 41556440.0000 - val_false_positives: 6646782.0000 - val_true_negatives: 54193432.0000 - val_false_negatives: 3575048.0000 - val_precision: 0.8621 - val_recall: 0.9208\n",
      "Epoch 296/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0177 - accuracy: 0.9857 - binary_iou: 0.9709 - true_positives: 128862096.0000 - false_positives: 2301180.0000 - true_negatives: 186092576.0000 - false_negatives: 2264974.0000 - precision: 0.9825 - recall: 0.9827 - val_loss: 0.1109 - val_accuracy: 0.9043 - val_binary_iou: 0.8232 - val_true_positives: 41462132.0000 - val_false_positives: 6540987.0000 - val_true_negatives: 54370256.0000 - val_false_negatives: 3598331.0000 - val_precision: 0.8637 - val_recall: 0.9201\n",
      "Epoch 297/500\n",
      "199/199 [==============================] - 78s 392ms/step - loss: 0.0175 - accuracy: 0.9858 - binary_iou: 0.9711 - true_positives: 128864184.0000 - false_positives: 2285772.0000 - true_negatives: 186122224.0000 - false_negatives: 2248508.0000 - precision: 0.9826 - recall: 0.9829 - val_loss: 0.1110 - val_accuracy: 0.9038 - val_binary_iou: 0.8224 - val_true_positives: 41637168.0000 - val_false_positives: 6741116.0000 - val_true_negatives: 54135504.0000 - val_false_negatives: 3457928.0000 - val_precision: 0.8607 - val_recall: 0.9233\n",
      "Epoch 298/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0176 - accuracy: 0.9857 - binary_iou: 0.9710 - true_positives: 128872680.0000 - false_positives: 2308370.0000 - true_negatives: 186094288.0000 - false_negatives: 2245451.0000 - precision: 0.9824 - recall: 0.9829 - val_loss: 0.1139 - val_accuracy: 0.9001 - val_binary_iou: 0.8165 - val_true_positives: 41835244.0000 - val_false_positives: 7289771.0000 - val_true_negatives: 53549248.0000 - val_false_negatives: 3297455.0000 - val_precision: 0.8516 - val_recall: 0.9269\n",
      "Epoch 299/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0177 - accuracy: 0.9858 - binary_iou: 0.9710 - true_positives: 128787568.0000 - false_positives: 2287632.0000 - true_negatives: 186183392.0000 - false_negatives: 2262150.0000 - precision: 0.9825 - recall: 0.9827 - val_loss: 0.1119 - val_accuracy: 0.9020 - val_binary_iou: 0.8194 - val_true_positives: 41640808.0000 - val_false_positives: 6999996.0000 - val_true_negatives: 53942196.0000 - val_false_negatives: 3388718.0000 - val_precision: 0.8561 - val_recall: 0.9247\n",
      "Epoch 300/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0174 - accuracy: 0.9859 - binary_iou: 0.9712 - true_positives: 128935160.0000 - false_positives: 2285132.0000 - true_negatives: 186068400.0000 - false_negatives: 2232157.0000 - precision: 0.9826 - recall: 0.9830 - val_loss: 0.1115 - val_accuracy: 0.9027 - val_binary_iou: 0.8206 - val_true_positives: 41591132.0000 - val_false_positives: 6805975.0000 - val_true_negatives: 54073368.0000 - val_false_negatives: 3501234.0000 - val_precision: 0.8594 - val_recall: 0.9224\n",
      "Epoch 301/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0172 - accuracy: 0.9860 - binary_iou: 0.9715 - true_positives: 128836336.0000 - false_positives: 2225863.0000 - true_negatives: 186215360.0000 - false_negatives: 2243199.0000 - precision: 0.9830 - recall: 0.9829 - val_loss: 0.1121 - val_accuracy: 0.9017 - val_binary_iou: 0.8191 - val_true_positives: 41869400.0000 - val_false_positives: 7167811.0000 - val_true_negatives: 53685936.0000 - val_false_negatives: 3248562.0000 - val_precision: 0.8538 - val_recall: 0.9280\n",
      "Epoch 302/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0173 - accuracy: 0.9860 - binary_iou: 0.9715 - true_positives: 128919104.0000 - false_positives: 2258078.0000 - true_negatives: 186120752.0000 - false_negatives: 2222805.0000 - precision: 0.9828 - recall: 0.9831 - val_loss: 0.1121 - val_accuracy: 0.9010 - val_binary_iou: 0.8181 - val_true_positives: 42100024.0000 - val_false_positives: 7407340.0000 - val_true_negatives: 53381180.0000 - val_false_negatives: 3083159.0000 - val_precision: 0.8504 - val_recall: 0.9318\n",
      "Epoch 303/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0174 - accuracy: 0.9859 - binary_iou: 0.9713 - true_positives: 128901280.0000 - false_positives: 2257945.0000 - true_negatives: 186117264.0000 - false_negatives: 2244275.0000 - precision: 0.9828 - recall: 0.9829 - val_loss: 0.1118 - val_accuracy: 0.9017 - val_binary_iou: 0.8191 - val_true_positives: 41893372.0000 - val_false_positives: 7174834.0000 - val_true_negatives: 53657856.0000 - val_false_negatives: 3245656.0000 - val_precision: 0.8538 - val_recall: 0.9281\n",
      "Epoch 304/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0172 - accuracy: 0.9861 - binary_iou: 0.9717 - true_positives: 128954128.0000 - false_positives: 2238777.0000 - true_negatives: 186120528.0000 - false_negatives: 2207262.0000 - precision: 0.9829 - recall: 0.9832 - val_loss: 0.1119 - val_accuracy: 0.9021 - val_binary_iou: 0.8197 - val_true_positives: 41742552.0000 - val_false_positives: 7085058.0000 - val_true_negatives: 53852580.0000 - val_false_negatives: 3291528.0000 - val_precision: 0.8549 - val_recall: 0.9269\n",
      "Epoch 305/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0172 - accuracy: 0.9861 - binary_iou: 0.9717 - true_positives: 128987232.0000 - false_positives: 2232102.0000 - true_negatives: 186089696.0000 - false_negatives: 2211757.0000 - precision: 0.9830 - recall: 0.9831 - val_loss: 0.1140 - val_accuracy: 0.9002 - val_binary_iou: 0.8166 - val_true_positives: 41719300.0000 - val_false_positives: 7222977.0000 - val_true_negatives: 53676496.0000 - val_false_negatives: 3352940.0000 - val_precision: 0.8524 - val_recall: 0.9256\n",
      "Epoch 306/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0173 - accuracy: 0.9860 - binary_iou: 0.9716 - true_positives: 128826840.0000 - false_positives: 2243704.0000 - true_negatives: 186232592.0000 - false_negatives: 2217625.0000 - precision: 0.9829 - recall: 0.9831 - val_loss: 0.1124 - val_accuracy: 0.9018 - val_binary_iou: 0.8192 - val_true_positives: 41698252.0000 - val_false_positives: 6982497.0000 - val_true_negatives: 53869992.0000 - val_false_negatives: 3420981.0000 - val_precision: 0.8566 - val_recall: 0.9242\n",
      "Epoch 307/500\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0171 - accuracy: 0.9861 - binary_iou: 0.9718 - true_positives: 128913024.0000 - false_positives: 2235114.0000 - true_negatives: 186180320.0000 - false_negatives: 2192249.0000 - precision: 0.9830 - recall: 0.9833 - val_loss: 0.1115 - val_accuracy: 0.9030 - val_binary_iou: 0.8212 - val_true_positives: 41667216.0000 - val_false_positives: 6914148.0000 - val_true_negatives: 54027392.0000 - val_false_negatives: 3362945.0000 - val_precision: 0.8577 - val_recall: 0.9253\n",
      "Epoch 308/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0169 - accuracy: 0.9863 - binary_iou: 0.9721 - true_positives: 128943944.0000 - false_positives: 2192402.0000 - true_negatives: 186206448.0000 - false_negatives: 2177947.0000 - precision: 0.9833 - recall: 0.9834 - val_loss: 0.1125 - val_accuracy: 0.9013 - val_binary_iou: 0.8185 - val_true_positives: 41860388.0000 - val_false_positives: 7136126.0000 - val_true_negatives: 53654312.0000 - val_false_negatives: 3320896.0000 - val_precision: 0.8544 - val_recall: 0.9265\n",
      "Epoch 309/500\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0170 - accuracy: 0.9862 - binary_iou: 0.9719 - true_positives: 128945496.0000 - false_positives: 2224262.0000 - true_negatives: 186168224.0000 - false_negatives: 2182878.0000 - precision: 0.9830 - recall: 0.9834 - val_loss: 0.1127 - val_accuracy: 0.9010 - val_binary_iou: 0.8180 - val_true_positives: 41940020.0000 - val_false_positives: 7320225.0000 - val_true_negatives: 53535324.0000 - val_false_negatives: 3176128.0000 - val_precision: 0.8514 - val_recall: 0.9296\n",
      "Epoch 310/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0168 - accuracy: 0.9863 - binary_iou: 0.9722 - true_positives: 129022936.0000 - false_positives: 2199327.0000 - true_negatives: 186132640.0000 - false_negatives: 2165903.0000 - precision: 0.9832 - recall: 0.9835 - val_loss: 0.1120 - val_accuracy: 0.9024 - val_binary_iou: 0.8203 - val_true_positives: 41834900.0000 - val_false_positives: 7035371.0000 - val_true_negatives: 53794420.0000 - val_false_negatives: 3307030.0000 - val_precision: 0.8560 - val_recall: 0.9267\n",
      "Epoch 311/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0170 - accuracy: 0.9862 - binary_iou: 0.9719 - true_positives: 128921272.0000 - false_positives: 2220305.0000 - true_negatives: 186191680.0000 - false_negatives: 2187474.0000 - precision: 0.9831 - recall: 0.9833 - val_loss: 0.1111 - val_accuracy: 0.9029 - val_binary_iou: 0.8210 - val_true_positives: 41638904.0000 - val_false_positives: 6878219.0000 - val_true_negatives: 54047060.0000 - val_false_negatives: 3407521.0000 - val_precision: 0.8582 - val_recall: 0.9244\n",
      "Epoch 312/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0169 - accuracy: 0.9863 - binary_iou: 0.9721 - true_positives: 128901640.0000 - false_positives: 2187246.0000 - true_negatives: 186240928.0000 - false_negatives: 2190874.0000 - precision: 0.9833 - recall: 0.9833 - val_loss: 0.1100 - val_accuracy: 0.9040 - val_binary_iou: 0.8228 - val_true_positives: 41680680.0000 - val_false_positives: 6712320.0000 - val_true_negatives: 54118360.0000 - val_false_negatives: 3460336.0000 - val_precision: 0.8613 - val_recall: 0.9233\n",
      "Epoch 313/500\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0169 - accuracy: 0.9863 - binary_iou: 0.9722 - true_positives: 128866376.0000 - false_positives: 2203370.0000 - true_negatives: 186288560.0000 - false_negatives: 2162540.0000 - precision: 0.9832 - recall: 0.9835 - val_loss: 0.1111 - val_accuracy: 0.9031 - val_binary_iou: 0.8213 - val_true_positives: 41691944.0000 - val_false_positives: 6861400.0000 - val_true_negatives: 54007332.0000 - val_false_negatives: 3411038.0000 - val_precision: 0.8587 - val_recall: 0.9244\n",
      "Epoch 314/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0170 - accuracy: 0.9863 - binary_iou: 0.9720 - true_positives: 128866136.0000 - false_positives: 2197116.0000 - true_negatives: 186266176.0000 - false_negatives: 2191269.0000 - precision: 0.9832 - recall: 0.9833 - val_loss: 0.1139 - val_accuracy: 0.8997 - val_binary_iou: 0.8159 - val_true_positives: 41901396.0000 - val_false_positives: 7386072.0000 - val_true_negatives: 53441728.0000 - val_false_negatives: 3242522.0000 - val_precision: 0.8501 - val_recall: 0.9282\n",
      "Epoch 315/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0171 - accuracy: 0.9862 - binary_iou: 0.9719 - true_positives: 128920992.0000 - false_positives: 2192260.0000 - true_negatives: 186187760.0000 - false_negatives: 2219761.0000 - precision: 0.9833 - recall: 0.9831 - val_loss: 0.1124 - val_accuracy: 0.9019 - val_binary_iou: 0.8192 - val_true_positives: 41583256.0000 - val_false_positives: 6886647.0000 - val_true_negatives: 53991092.0000 - val_false_negatives: 3510712.0000 - val_precision: 0.8579 - val_recall: 0.9221\n",
      "Epoch 316/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0168 - accuracy: 0.9864 - binary_iou: 0.9723 - true_positives: 128897472.0000 - false_positives: 2187409.0000 - true_negatives: 186283088.0000 - false_negatives: 2152800.0000 - precision: 0.9833 - recall: 0.9836 - val_loss: 0.1160 - val_accuracy: 0.8978 - val_binary_iou: 0.8129 - val_true_positives: 42045544.0000 - val_false_positives: 7734855.0000 - val_true_negatives: 53096592.0000 - val_false_negatives: 3094708.0000 - val_precision: 0.8446 - val_recall: 0.9314\n",
      "Epoch 317/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0167 - accuracy: 0.9865 - binary_iou: 0.9725 - true_positives: 128982768.0000 - false_positives: 2164681.0000 - true_negatives: 186217104.0000 - false_negatives: 2156243.0000 - precision: 0.9835 - recall: 0.9836 - val_loss: 0.1132 - val_accuracy: 0.9019 - val_binary_iou: 0.8194 - val_true_positives: 41662532.0000 - val_false_positives: 6978819.0000 - val_true_negatives: 53915100.0000 - val_false_negatives: 3415270.0000 - val_precision: 0.8565 - val_recall: 0.9242\n",
      "Epoch 318/500\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0166 - accuracy: 0.9865 - binary_iou: 0.9725 - true_positives: 129009360.0000 - false_positives: 2166798.0000 - true_negatives: 186200144.0000 - false_negatives: 2144463.0000 - precision: 0.9835 - recall: 0.9836 - val_loss: 0.1118 - val_accuracy: 0.9023 - val_binary_iou: 0.8200 - val_true_positives: 41846512.0000 - val_false_positives: 7094336.0000 - val_true_negatives: 53768020.0000 - val_false_negatives: 3262837.0000 - val_precision: 0.8550 - val_recall: 0.9277\n",
      "Epoch 318: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix, early_stop)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "# Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\n",
    "shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= initial_epochs)\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 11s 134ms/step - loss: 371.4270 - accuracy: 0.9031 - binary_iou: 0.8207 - true_positives: 40878420.0000 - false_positives: 6961469.0000 - true_negatives: 54823276.0000 - false_negatives: 3308549.0000 - precision: 0.8545 - recall: 0.9251\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_name = 'testlauf_fine_tune_first_layerFalse'\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "# Zusammenführen von Training- und Fine-Tuning-History\n",
    "iou = model_history.history['binary_iou']\n",
    "iou += history_fine.history['binary_iou']\n",
    "\n",
    "val_iou = model_history.history['val_binary_iou']\n",
    "val_iou += history_fine.history['val_binary_iou']\n",
    "\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "# Schreiben der Eval-Ergebnisse in csv\n",
    "with open('../output/final_runs.csv', 'a') as f_object:\n",
    "    row = []\n",
    "    \n",
    "    row.append(model_name)\n",
    "\n",
    "    for x in eval_out:\n",
    "        row.append(x)\n",
    "\n",
    "    # Einfügen der Trainingszeit in Minuten\n",
    "    row.append(training_time/60)\n",
    "\n",
    "    # Einfügen der maximalen Val-IoU\n",
    "    row.append(max(val_iou))\n",
    "\n",
    "    # Einfügen des Index der maximalen Val-IoU\n",
    "    row.append(np.argmax(val_iou))\n",
    "\n",
    "    writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "    writer_object.writerow(row)\n",
    "\n",
    "\n",
    "# Plotten\n",
    "\n",
    "#acc = model_history.history['accuracy']\n",
    "#val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(val_iou)+1)\n",
    "\n",
    "#plt.plot(epochs, acc, 'y', label= 'Training accuracy')\n",
    "#plt.plot(epochs, val_acc, 'r', label= 'Validation accuracy')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], iou[0:(len(val_iou) - 1)], 'g', label= 'Training IoU')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_iou[0:(len(val_iou) - 1)], 'b', label= 'Validation IoU')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "#plt.title('Train & Val accuracy & IoU')\n",
    "plt.title('Training & Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/IoU/iou_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model_history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = model_history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], loss[0:(len(val_iou) - 1)], 'g', label= 'Training Loss')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_loss[0:(len(val_iou) - 1)], 'b', label= 'Validation Loss')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/Loss/loss_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "#unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "#compile_model(unet, learning_rate)\n",
    "\n",
    "# Prognose mit Hilfe des geladenen besten Modells\n",
    "prediction = unet.predict(test_data_generator)\n",
    "\n",
    "# Erstellung einer binären Maske aus den wahrscheinlichkeiten, Schwellwert 0.5\n",
    "out = (prediction > 0.5).astype(np.uint8)\n",
    "\n",
    "# lediglich halbe Batch Size in eine Abbildung wegen Übersichtlichkeit\n",
    "rows = int(batch_size / 2)\n",
    "columns = 3\n",
    "\n",
    "# Anzahl verfügbarer Batches des Data-Generators\n",
    "no_of_batches = test_data_generator.__len__()\n",
    "\n",
    "# Prognose kommt als Tensor mit der Länge der Anzahl der Beispiele\n",
    "out_idx = 0\n",
    "\n",
    "# Erstellen des Prognosen-Ordners\n",
    "if not os.path.isdir(f'../output/predictions/{model_name}'):\n",
    "    os.makedirs(f'../output/predictions/{model_name}')\n",
    "\n",
    "# Input und Masken kommen als Batches, über die iteriert wird\n",
    "for batch_no in range(0, no_of_batches):\n",
    "\n",
    "    # iterieren über erste Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_I.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # iterieren über zweite Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][rows + i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][rows + i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_II.png', bbox_inches='tight', dpi= 400)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "#model_name = \"Final_AVG_rgbDrop_0_earlyStop_True_e500\"\n",
    "# Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "    # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "    outfile.write('sep=,\\n')\n",
    "\n",
    "    for i, fname in enumerate(filenames):\n",
    "        with open(fname) as infile:\n",
    "            reader = csv.reader(infile)\n",
    "\n",
    "            for j, row in enumerate(reader):\n",
    "                # überspringen des 2. Headers\n",
    "                if i == 1 and j == 0:\n",
    "                    continue\n",
    "\n",
    "                delimiter = ','\n",
    "                list_to_string = delimiter.join(row)\n",
    "                list_to_string += '\\n'\n",
    "\n",
    "                outfile.write(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"Final_AVG_rgbDrop_0_earlyStop_True_e500\"\n",
    "# Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "    # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "    outfile.write('sep=,\\n')\n",
    "\n",
    "    for i, fname in enumerate(filenames):\n",
    "        with open(fname) as infile:\n",
    "            reader = csv.reader(infile)\n",
    "\n",
    "            for j, row in enumerate(reader):\n",
    "                # überspringen des 2. Headers\n",
    "                if i == 1 and j == 0:\n",
    "                    continue\n",
    "\n",
    "                delimiter = ','\n",
    "                list_to_string = delimiter.join(row)\n",
    "                list_to_string += '\\n'\n",
    "\n",
    "                outfile.write(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.7961242198944092', '0.6587730646133423', '20309084.0', '44833484.0', '0.24731293320655823', '0.7116237282752991', '0.8449028730392456', '143743008.0', '110635216.0', '0.8323593139648438', '0.7104504108428955', '6571040.0', '11194135.0', '0.19853559136390686', '0.7745783925056458', '0.8540922403335571', '49742008.0', '38464532.0']\n",
      "['1', '0.8555810451507568', '0.7428621053695679', '19262012.0', '26882816.0', '0.17415392398834229', '0.8062108755111694', '0.8530752658843994', '161536704.0', '111839176.0', '0.8509215116500854', '0.7363330125808716', '7721061.0', '8077029.0', '0.17862582206726074', '0.8224303126335144', '0.8289172649383545', '52764112.0', '37409496.0']\n",
      "['2', '0.868036687374115', '0.7619959115982056', '18203548.0', '23961460.0', '0.15954600274562836', '0.8248876929283142', '0.8611232042312622', '164482416.0', '112873368.0', '0.855846107006073', '0.7469853162765503', '3632307.0', '11643931.0', '0.15823477506637573', '0.7808046936988831', '0.9194782376289368', '49218136.0', '41477340.0']\n",
      "['3', '0.8770635724067688', '0.7761090993881226', '17652532.0', '21628236.0', '0.14948749542236328', '0.8399236798286438', '0.8653879761695862', '166756288.0', '113483792.0', '0.8836488127708435', '0.7868425846099854', '7168806.0', '5161118.0', '0.1418834626674652', '0.8805040121078491', '0.8413925170898438', '55612164.0', '38029616.0']\n",
      "['4', '0.883385956287384', '0.7862225770950317', '16949292.0', '20311302.0', '0.14213760197162628', '0.8488912582397461', '0.8706685900688171', '168156272.0', '114103848.0', '0.8866237998008728', '0.7932666540145874', '5359944.0', '6654737.0', '0.13384389877319336', '0.8567112684249878', '0.8812807202339172', '54168920.0', '39788112.0']\n",
      "['5', '0.8867051005363464', '0.7916681170463562', '16491997.0', '19708040.0', '0.13844023644924164', '0.8533272743225098', '0.8742521405220032', '168661360.0', '114659360.0', '0.8920537829399109', '0.8013637065887451', '5901398.0', '5537848.0', '0.12899699807167053', '0.8761326670646667', '0.8690656423568726', '55362416.0', '39170048.0']\n",
      "['6', '0.8899984359741211', '0.797005295753479', '16219609.0', '18928164.0', '0.13410015404224396', '0.8585999608039856', '0.8763315081596375', '169438704.0', '114934304.0', '0.8933471441268921', '0.8045114278793335', '4735190.0', '6566981.0', '0.12450148910284042', '0.8601561188697815', '0.8950710296630859', '54277184.0', '40392380.0']\n",
      "['7', '0.8955606818199158', '0.8061417937278748', '15626842.0', '17743680.0', '0.1278112232685089', '0.866841197013855', '0.8808341026306152', '170641936.0', '115508360.0', '0.8974204063415527', '0.8101271390914917', '5816458.0', '5054095.0', '0.12367336452007294', '0.8860129714012146', '0.8710364103317261', '55816044.0', '39285116.0']\n",
      "['8', '0.8968602418899536', '0.8083475828170776', '15260560.0', '17694812.0', '0.12622345983982086', '0.8674541115760803', '0.8835651874542236', '170760672.0', '115804736.0', '0.898605465888977', '0.8104246854782104', '7315006.0', '3429948.0', '0.12633559107780457', '0.916635274887085', '0.8375488519668579', '57512820.0', '37713940.0']\n",
      "['9', '0.900827169418335', '0.814872145652771', '15107959.0', '16579737.0', '0.1218128651380539', '0.8749462366104126', '0.8847680687904358', '171831952.0', '116001152.0', '0.8998227715492249', '0.8146814703941345', '5080673.0', '5535273.0', '0.11853206157684326', '0.8784630298614502', '0.8873198628425598', '55347104.0', '40008656.0']\n",
      "['10', '0.9033365249633789', '0.8191630840301514', '14566899.0', '16319088.0', '0.1187213733792305', '0.8771561980247498', '0.8888803720474243', '172109632.0', '116525144.0', '0.9009268283843994', '0.8165515661239624', '5037168.0', '5461766.0', '0.11778794229030609', '0.8800939917564392', '0.8883749842643738', '55384136.0', '40088640.0']\n",
      "['11', '0.9063057899475098', '0.8241333961486816', '14384998.0', '15552271.0', '0.11546950787305832', '0.8824447989463806', '0.8902999758720398', '172838176.0', '116745344.0', '0.8959559202194214', '0.8076335787773132', '5974802.0', '5050926.0', '0.12591783702373505', '0.8857436776161194', '0.8676116466522217', '55789924.0', '39156056.0']\n",
      "['12', '0.9102160334587097', '0.8309040665626526', '13612249.0', '15075643.0', '0.10997866094112396', '0.8863572478294373', '0.8962439894676208', '173250304.0', '117582520.0', '0.9019008874893188', '0.8180277347564697', '5200968.0', '5194741.0', '0.11701411753892899', '0.8849327564239502', '0.8848106861114502', '55625476.0', '39950520.0']\n",
      "['13', '0.9113559722900391', '0.8327949643135071', '13592185.0', '14731369.0', '0.10891933739185333', '0.8886242508888245', '0.8963442444801331', '173661312.0', '117535936.0', '0.9012283086776733', '0.8175053596496582', '4434233.0', '6032764.0', '0.11556345224380493', '0.8707954287528992', '0.9016647934913635', '54845904.0', '40658800.0']\n",
      "['14', '0.9112589955329895', '0.8326512575149536', '13557967.0', '14796571.0', '0.10920999199151993', '0.8882356882095337', '0.8966241478919983', '173571968.0', '117594240.0', '0.9038447737693787', '0.8203587532043457', '6198846.0', '3990891.0', '0.11703916639089584', '0.9071902632713318', '0.862883985042572', '56772072.0', '39009900.0']\n",
      "['15', '0.9150487780570984', '0.8391707539558411', '13070933.0', '14072871.0', '0.10437954217195511', '0.893510639667511', '0.9003366827964783', '174296912.0', '118079960.0', '0.9026321172714233', '0.81894850730896', '5502799.0', '4815433.0', '0.11641963571310043', '0.8916648030281067', '0.8780860304832458', '56019548.0', '39633948.0']\n",
      "['16', '0.9170372486114502', '0.8425793647766113', '12875547.0', '13632801.0', '0.10238707065582275', '0.8966102004051208', '0.901789128780365', '174786896.0', '118225480.0', '0.9023330807685852', '0.8191585540771484', '4628317.0', '5721616.0', '0.11487342417240143', '0.8761098980903625', '0.8973531723022461', '55160384.0', '40461384.0']\n",
      "['17', '0.9163618683815002', '0.8415076732635498', '12748003.0', '13976263.0', '0.10324450582265854', '0.8944720029830933', '0.902845025062561', '174331424.0', '118465040.0', '0.9080192446708679', '0.82755446434021', '5744502.0', '4002860.0', '0.11195121705532074', '0.9076095223426819', '0.8725345134735107', '56901776.0', '39322596.0']\n",
      "['18', '0.9190995693206787', '0.8461706042289734', '12620972.0', '13228408.0', '0.0997830331325531', '0.8995869159698486', '0.9037539958953857', '175159920.0', '118511456.0', '0.9019047021865845', '0.8167356252670288', '6489242.0', '3906086.0', '0.12046819925308228', '0.9080408215522766', '0.8559849858283997', '57006160.0', '38570224.0']\n",
      "['19', '0.9203644394874573', '0.8483947515487671', '12331894.0', '13113312.0', '0.09815822541713715', '0.9005417823791504', '0.905910849571228', '175341472.0', '118734152.0', '0.9094333648681641', '0.830341100692749', '5351531.0', '4245958.0', '0.10895109176635742', '0.9036170840263367', '0.8814947605133057', '56567128.0', '39807088.0']\n"
     ]
    }
   ],
   "source": [
    "with open(f'../output/{output_folder_prefix}_logger/{model_name}_I.log') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " split_input (Lambda)           [(None, 224, 224, 1  0           ['input[0][0]']                  \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dropout_r (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_g (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][1]']            \n",
      "                                                                                                  \n",
      " dropout_b (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][2]']            \n",
      "                                                                                                  \n",
      " dropout_ir (Dropout)           (None, 224, 224, 1)  0           ['split_input[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_dropout (Concatena  (None, 224, 224, 4)  0          ['dropout_r[0][0]',              \n",
      " te)                                                              'dropout_g[0][0]',              \n",
      "                                                                  'dropout_b[0][0]',              \n",
      "                                                                  'dropout_ir[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 2048  0           ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 2304  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 256)  5308416     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 14, 256)  1024       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 14, 256)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 256)  589824      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  442368      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  147456      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   110592      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36864       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_3[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 32  36864       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 112, 112, 32  9216        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 36  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 16  5184        ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 224, 224, 16  2304        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 16  64         ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 1)  145         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 18,787,025\n",
      "Non-trainable params: 11,474,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives', 'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', 'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', 'val_precision', 'val_recall'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives',\n",
    "                    'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', \n",
    "                    'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', \n",
    "                    'val_precision', 'val_recall']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(20):\n",
    "        writer.writerow({'loss': dict_data['loss'][i], 'accuracy': dict_data['accuracy'][i], 'binary_iou': dict_data['binary_iou'][i], 'true_positives': dict_data['true_positives'][i],\n",
    "                        'false_positives': dict_data['false_positives'][i], 'true_negatives': dict_data['true_negatives'][i], 'false_negatives': dict_data['false_negatives'][i],\n",
    "                        'precision': dict_data['precision'][i], 'recall': dict_data['recall'][i], 'val_loss': dict_data['val_loss'][i], 'val_accuracy': dict_data['val_accuracy'][i],\n",
    "                        'val_binary_iou': dict_data['val_binary_iou'][i], 'val_true_positives': dict_data['val_true_positives'][i], 'val_false_positives': dict_data['val_false_positives'][i],\n",
    "                        'val_true_negatives': dict_data['val_true_negatives'][i], 'val_false_negatives': dict_data['val_false_negatives'][i], 'val_precision': dict_data['val_precision'][i],\n",
    "                        'val_recall': dict_data['val_recall'][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': '0.25298193097114563', 'accuracy': '0.7866721749305725', 'binary_iou': '0.6463431119918823', 'true_positives': '111043808.0', 'false_positives': '48262192.0', 'true_negatives': '140314272.0', 'false_negatives': '19900488.0', 'precision': '0.697047233581543', 'recall': '0.8480232357978821', 'val_loss': '0.21770402789115906', 'val_accuracy': '0.8242917656898499', 'val_binary_iou': '0.6967154741287231', 'val_true_positives': '36183816.0', 'val_false_positives': '9768367.0', 'val_true_negatives': '51167764.0', 'val_false_negatives': '8851754.0', 'val_precision': '0.7874231934547424', 'val_recall': '0.8034497499465942'}\n",
      "{'loss': '0.17970937490463257', 'accuracy': '0.8502960205078125', 'binary_iou': '0.7348068356513977', 'true_positives': '111206328.0', 'false_positives': '27865604.0', 'true_negatives': '160480896.0', 'false_negatives': '19967952.0', 'precision': '0.7996317148208618', 'recall': '0.847775399684906', 'val_loss': '0.17682895064353943', 'val_accuracy': '0.8498079180717468', 'val_binary_iou': '0.7352555990219116', 'val_true_positives': '37936588.0', 'val_false_positives': '8678695.0', 'val_true_negatives': '52119008.0', 'val_false_negatives': '7237421.0', 'val_precision': '0.8138229250907898', 'val_recall': '0.8397879600524902'}\n",
      "{'loss': '0.16944220662117004', 'accuracy': '0.8586176633834839', 'binary_iou': '0.747620701789856', 'true_positives': '112447392.0', 'false_positives': '26535964.0', 'true_negatives': '161898704.0', 'false_negatives': '18638656.0', 'precision': '0.809070885181427', 'recall': '0.8578135967254639', 'val_loss': '0.16960737109184265', 'val_accuracy': '0.8433647751808167', 'val_binary_iou': '0.7283757328987122', 'val_true_positives': '41406300.0', 'val_false_positives': '12919748.0', 'val_true_negatives': '47966524.0', 'val_false_negatives': '3679141.0', 'val_precision': '0.7621813416481018', 'val_recall': '0.9183962941169739'}\n",
      "{'loss': '0.15938016772270203', 'accuracy': '0.8675968050956726', 'binary_iou': '0.7613716125488281', 'true_positives': '112991728.0', 'false_positives': '24180304.0', 'true_negatives': '164223536.0', 'false_negatives': '18125208.0', 'precision': '0.823722779750824', 'recall': '0.8617630004882812', 'val_loss': '0.18082629144191742', 'val_accuracy': '0.8287520408630371', 'val_binary_iou': '0.7072028517723083', 'val_true_positives': '41683936.0', 'val_false_positives': '14784452.0', 'val_true_negatives': '46140320.0', 'val_false_negatives': '3362991.0', 'val_precision': '0.7381817698478699', 'val_recall': '0.925344705581665'}\n",
      "{'loss': '0.15386037528514862', 'accuracy': '0.8729592561721802', 'binary_iou': '0.7696713209152222', 'true_positives': '113235904.0', 'false_positives': '22661028.0', 'true_negatives': '165692640.0', 'false_negatives': '17931140.0', 'precision': '0.8332484364509583', 'recall': '0.8632954359054565', 'val_loss': '0.20721104741096497', 'val_accuracy': '0.8287599682807922', 'val_binary_iou': '0.701651930809021', 'val_true_positives': '35156024.0', 'val_false_positives': '8233098.0', 'val_true_negatives': '52669072.0', 'val_false_negatives': '9913514.0', 'val_precision': '0.8102497458457947', 'val_recall': '0.7800396084785461'}\n",
      "{'loss': '0.14730830490589142', 'accuracy': '0.8784143328666687', 'binary_iou': '0.7784072160720825', 'true_positives': '114011392.0', 'false_positives': '21770962.0', 'true_negatives': '166660272.0', 'false_negatives': '17078148.0', 'precision': '0.8396627902984619', 'recall': '0.869721531867981', 'val_loss': '0.16745591163635254', 'val_accuracy': '0.8436726331710815', 'val_binary_iou': '0.7289546728134155', 'val_true_positives': '41680636.0', 'val_false_positives': '13103984.0', 'val_true_negatives': '47724816.0', 'val_false_negatives': '3462292.0', 'val_precision': '0.760809063911438', 'val_recall': '0.9233037829399109'}\n",
      "{'loss': '0.14401723444461823', 'accuracy': '0.8810575008392334', 'binary_iou': '0.7826745510101318', 'true_positives': '114393776.0', 'false_positives': '21271064.0', 'true_negatives': '167122240.0', 'false_negatives': '16733604.0', 'precision': '0.8432087898254395', 'recall': '0.8723866939544678', 'val_loss': '0.16687346994876862', 'val_accuracy': '0.8602073192596436', 'val_binary_iou': '0.7504729628562927', 'val_true_positives': '37713636.0', 'val_false_positives': '7516429.0', 'val_true_negatives': '53444012.0', 'val_false_negatives': '7297637.0', 'val_precision': '0.8338178992271423', 'val_recall': '0.8378708958625793'}\n",
      "{'loss': '0.13967755436897278', 'accuracy': '0.8848918080329895', 'binary_iou': '0.7889226675033569', 'true_positives': '114999336.0', 'false_positives': '20679376.0', 'true_negatives': '167741888.0', 'false_negatives': '16100101.0', 'precision': '0.8475856781005859', 'recall': '0.8771916627883911', 'val_loss': '0.1353950798511505', 'val_accuracy': '0.8823829293251038', 'val_binary_iou': '0.7869912385940552', 'val_true_positives': '40299460.0', 'val_false_positives': '7671211.0', 'val_true_negatives': '53208184.0', 'val_false_negatives': '4792872.0', 'val_precision': '0.8400853872299194', 'val_recall': '0.8937098383903503'}\n",
      "{'loss': '0.1352715641260147', 'accuracy': '0.8892213702201843', 'binary_iou': '0.7956593036651611', 'true_positives': '114638944.0', 'false_positives': '18970384.0', 'true_negatives': '169485760.0', 'false_negatives': '16425623.0', 'precision': '0.8580160140991211', 'recall': '0.8746753334999084', 'val_loss': '0.1568543165922165', 'val_accuracy': '0.8584086894989014', 'val_binary_iou': '0.7504804134368896', 'val_true_positives': '40856560.0', 'val_false_positives': '10655894.0', 'val_true_negatives': '50110464.0', 'val_false_negatives': '4348781.0', 'val_precision': '0.7931394577026367', 'val_recall': '0.9037994146347046'}\n",
      "{'loss': '0.12936197221279144', 'accuracy': '0.893817663192749', 'binary_iou': '0.8033660054206848', 'true_positives': '115608840.0', 'false_positives': '18361112.0', 'true_negatives': '169984368.0', 'false_negatives': '15566396.0', 'precision': '0.8629460334777832', 'recall': '0.8813313245773315', 'val_loss': '0.256801575422287', 'val_accuracy': '0.813231885433197', 'val_binary_iou': '0.6692835092544556', 'val_true_positives': '29273444.0', 'val_false_positives': '3966531.0', 'val_true_negatives': '56906144.0', 'val_false_negatives': '15825595.0', 'val_precision': '0.8806698322296143', 'val_recall': '0.6490923762321472'}\n",
      "{'loss': '0.12777672708034515', 'accuracy': '0.8952571153640747', 'binary_iou': '0.8057264089584351', 'true_positives': '115722160.0', 'false_positives': '18096608.0', 'true_negatives': '170331008.0', 'false_negatives': '15370898.0', 'precision': '0.8647677898406982', 'recall': '0.8827481865882874', 'val_loss': '0.13223814964294434', 'val_accuracy': '0.8917816877365112', 'val_binary_iou': '0.799962043762207', 'val_true_positives': '38216200.0', 'val_false_positives': '4436075.0', 'val_true_negatives': '56287440.0', 'val_false_negatives': '7032006.0', 'val_precision': '0.8959943652153015', 'val_recall': '0.8445903658866882'}\n",
      "{'loss': '0.12335705757141113', 'accuracy': '0.8994724750518799', 'binary_iou': '0.8126584887504578', 'true_positives': '115993240.0', 'false_positives': '17039420.0', 'true_negatives': '171406992.0', 'false_negatives': '15081117.0', 'precision': '0.8719155192375183', 'recall': '0.8849422335624695', 'val_loss': '0.13863824307918549', 'val_accuracy': '0.87993323802948', 'val_binary_iou': '0.7830523252487183', 'val_true_positives': '40182664.0', 'val_false_positives': '7800029.0', 'val_true_negatives': '53065372.0', 'val_false_negatives': '4923645.0', 'val_precision': '0.8374407887458801', 'val_recall': '0.8908435702323914'}\n",
      "{'loss': '0.12128963321447372', 'accuracy': '0.9008952975273132', 'binary_iou': '0.8151732683181763', 'true_positives': '116559416.0', 'false_positives': '17118276.0', 'true_negatives': '171295424.0', 'false_negatives': '14547673.0', 'precision': '0.8719436526298523', 'recall': '0.8890397548675537', 'val_loss': '0.1420867145061493', 'val_accuracy': '0.874578595161438', 'val_binary_iou': '0.7750580310821533', 'val_true_positives': '40642440.0', 'val_false_positives': '8783600.0', 'val_true_negatives': '52038120.0', 'val_false_negatives': '4507543.0', 'val_precision': '0.8222880363464355', 'val_recall': '0.9001650810241699'}\n",
      "{'loss': '0.11935042589902878', 'accuracy': '0.9026272892951965', 'binary_iou': '0.8180391788482666', 'true_positives': '116646776.0', 'false_positives': '16637965.0', 'true_negatives': '171761392.0', 'false_negatives': '14474606.0', 'precision': '0.8751697540283203', 'recall': '0.8896090984344482', 'val_loss': '0.16962216794490814', 'val_accuracy': '0.8450703620910645', 'val_binary_iou': '0.7304768562316895', 'val_true_positives': '40641952.0', 'val_false_positives': '11934879.0', 'val_true_negatives': '48911596.0', 'val_false_negatives': '4483273.0', 'val_precision': '0.7730011343955994', 'val_recall': '0.9006481766700745'}\n",
      "{'loss': '0.11748106777667999', 'accuracy': '0.9039813876152039', 'binary_iou': '0.8203401565551758', 'true_positives': '116874728.0', 'false_positives': '16479334.0', 'true_negatives': '171966000.0', 'false_negatives': '14200654.0', 'precision': '0.8764241933822632', 'recall': '0.8916603922843933', 'val_loss': '0.16435684263706207', 'val_accuracy': '0.8604539036750793', 'val_binary_iou': '0.7515079975128174', 'val_true_positives': '38347908.0', 'val_false_positives': '7986545.0', 'val_true_negatives': '52835852.0', 'val_false_negatives': '6801397.0', 'val_precision': '0.8276327252388', 'val_recall': '0.8493576645851135'}\n",
      "{'loss': '0.11296495795249939', 'accuracy': '0.9077730774879456', 'binary_iou': '0.8267014622688293', 'true_positives': '117159816.0', 'false_positives': '15511851.0', 'true_negatives': '172892432.0', 'false_negatives': '13956604.0', 'precision': '0.8830808997154236', 'recall': '0.8935556411743164', 'val_loss': '0.17737410962581635', 'val_accuracy': '0.8445158004760742', 'val_binary_iou': '0.7282230257987976', 'val_true_positives': '38698016.0', 'val_false_positives': '10038660.0', 'val_true_negatives': '50796784.0', 'val_false_negatives': '6438257.0', 'val_precision': '0.7940225005149841', 'val_recall': '0.8573595881462097'}\n",
      "{'loss': '0.1116277351975441', 'accuracy': '0.9087814092636108', 'binary_iou': '0.8284687399864197', 'true_positives': '117442272.0', 'false_positives': '15450539.0', 'true_negatives': '172932256.0', 'false_negatives': '13695691.0', 'precision': '0.8837368488311768', 'recall': '0.8955627679824829', 'val_loss': '0.22158901393413544', 'val_accuracy': '0.8260716795921326', 'val_binary_iou': '0.6940493583679199', 'val_true_positives': '32733368.0', 'val_false_positives': '6001649.0', 'val_true_negatives': '54806864.0', 'val_false_negatives': '12429828.0', 'val_precision': '0.8450588583946228', 'val_recall': '0.7247797250747681'}\n",
      "{'loss': '0.11073320358991623', 'accuracy': '0.9101096987724304', 'binary_iou': '0.8306362628936768', 'true_positives': '117300144.0', 'false_positives': '14963131.0', 'true_negatives': '173498800.0', 'false_negatives': '13758712.0', 'precision': '0.8868685960769653', 'recall': '0.8950188159942627', 'val_loss': '0.1295718252658844', 'val_accuracy': '0.8888552188873291', 'val_binary_iou': '0.7969772815704346', 'val_true_positives': '39977888.0', 'val_false_positives': '6724283.0', 'val_true_negatives': '54215616.0', 'val_false_negatives': '5053912.0', 'val_precision': '0.8560177683830261', 'val_recall': '0.8877701759338379'}\n",
      "{'loss': '0.11055346578359604', 'accuracy': '0.9099255800247192', 'binary_iou': '0.8303505182266235', 'true_positives': '117366416.0', 'false_positives': '14966230.0', 'true_negatives': '173373680.0', 'false_negatives': '13814412.0', 'precision': '0.8869044780731201', 'recall': '0.8946918249130249', 'val_loss': '0.1266525238752365', 'val_accuracy': '0.8892303705215454', 'val_binary_iou': '0.7984521389007568', 'val_true_positives': '41107320.0', 'val_false_positives': '7720637.0', 'val_true_negatives': '53125932.0', 'val_false_negatives': '4017818.0', 'val_precision': '0.8418807983398438', 'val_recall': '0.9109628200531006'}\n",
      "{'loss': '0.10677679628133774', 'accuracy': '0.9130255579948425', 'binary_iou': '0.8356871604919434', 'true_positives': '117830272.0', 'false_positives': '14455578.0', 'true_negatives': '173900384.0', 'false_negatives': '13334564.0', 'precision': '0.8907247185707092', 'recall': '0.8983373641967773', 'val_loss': '0.15511789917945862', 'val_accuracy': '0.8591651320457458', 'val_binary_iou': '0.7518163919448853', 'val_true_positives': '41172792.0', 'val_false_positives': '10981330.0', 'val_true_negatives': '49874412.0', 'val_false_negatives': '3943181.0', 'val_precision': '0.7894446849822998', 'val_recall': '0.9125990271568298'}\n"
     ]
    }
   ],
   "source": [
    "complete_csv = {}\n",
    "\n",
    "path = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "with open('../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log', 'r') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log') as f:\n",
    "    file_data = csv.reader(f)\n",
    "    headers = next(file_data)\n",
    "    new_dict = [dict(zip(headers,i)) for i in file_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': '0.25298193097114563',\n",
       "  'accuracy': '0.7866721749305725',\n",
       "  'binary_iou': '0.6463431119918823',\n",
       "  'true_positives': '111043808.0',\n",
       "  'false_positives': '48262192.0',\n",
       "  'true_negatives': '140314272.0',\n",
       "  'false_negatives': '19900488.0',\n",
       "  'precision': '0.697047233581543',\n",
       "  'recall': '0.8480232357978821',\n",
       "  'val_loss': '0.21770402789115906',\n",
       "  'val_accuracy': '0.8242917656898499',\n",
       "  'val_binary_iou': '0.6967154741287231',\n",
       "  'val_true_positives': '36183816.0',\n",
       "  'val_false_positives': '9768367.0',\n",
       "  'val_true_negatives': '51167764.0',\n",
       "  'val_false_negatives': '8851754.0',\n",
       "  'val_precision': '0.7874231934547424',\n",
       "  'val_recall': '0.8034497499465942'},\n",
       " {'loss': '0.17970937490463257',\n",
       "  'accuracy': '0.8502960205078125',\n",
       "  'binary_iou': '0.7348068356513977',\n",
       "  'true_positives': '111206328.0',\n",
       "  'false_positives': '27865604.0',\n",
       "  'true_negatives': '160480896.0',\n",
       "  'false_negatives': '19967952.0',\n",
       "  'precision': '0.7996317148208618',\n",
       "  'recall': '0.847775399684906',\n",
       "  'val_loss': '0.17682895064353943',\n",
       "  'val_accuracy': '0.8498079180717468',\n",
       "  'val_binary_iou': '0.7352555990219116',\n",
       "  'val_true_positives': '37936588.0',\n",
       "  'val_false_positives': '8678695.0',\n",
       "  'val_true_negatives': '52119008.0',\n",
       "  'val_false_negatives': '7237421.0',\n",
       "  'val_precision': '0.8138229250907898',\n",
       "  'val_recall': '0.8397879600524902'},\n",
       " {'loss': '0.16944220662117004',\n",
       "  'accuracy': '0.8586176633834839',\n",
       "  'binary_iou': '0.747620701789856',\n",
       "  'true_positives': '112447392.0',\n",
       "  'false_positives': '26535964.0',\n",
       "  'true_negatives': '161898704.0',\n",
       "  'false_negatives': '18638656.0',\n",
       "  'precision': '0.809070885181427',\n",
       "  'recall': '0.8578135967254639',\n",
       "  'val_loss': '0.16960737109184265',\n",
       "  'val_accuracy': '0.8433647751808167',\n",
       "  'val_binary_iou': '0.7283757328987122',\n",
       "  'val_true_positives': '41406300.0',\n",
       "  'val_false_positives': '12919748.0',\n",
       "  'val_true_negatives': '47966524.0',\n",
       "  'val_false_negatives': '3679141.0',\n",
       "  'val_precision': '0.7621813416481018',\n",
       "  'val_recall': '0.9183962941169739'},\n",
       " {'loss': '0.15938016772270203',\n",
       "  'accuracy': '0.8675968050956726',\n",
       "  'binary_iou': '0.7613716125488281',\n",
       "  'true_positives': '112991728.0',\n",
       "  'false_positives': '24180304.0',\n",
       "  'true_negatives': '164223536.0',\n",
       "  'false_negatives': '18125208.0',\n",
       "  'precision': '0.823722779750824',\n",
       "  'recall': '0.8617630004882812',\n",
       "  'val_loss': '0.18082629144191742',\n",
       "  'val_accuracy': '0.8287520408630371',\n",
       "  'val_binary_iou': '0.7072028517723083',\n",
       "  'val_true_positives': '41683936.0',\n",
       "  'val_false_positives': '14784452.0',\n",
       "  'val_true_negatives': '46140320.0',\n",
       "  'val_false_negatives': '3362991.0',\n",
       "  'val_precision': '0.7381817698478699',\n",
       "  'val_recall': '0.925344705581665'},\n",
       " {'loss': '0.15386037528514862',\n",
       "  'accuracy': '0.8729592561721802',\n",
       "  'binary_iou': '0.7696713209152222',\n",
       "  'true_positives': '113235904.0',\n",
       "  'false_positives': '22661028.0',\n",
       "  'true_negatives': '165692640.0',\n",
       "  'false_negatives': '17931140.0',\n",
       "  'precision': '0.8332484364509583',\n",
       "  'recall': '0.8632954359054565',\n",
       "  'val_loss': '0.20721104741096497',\n",
       "  'val_accuracy': '0.8287599682807922',\n",
       "  'val_binary_iou': '0.701651930809021',\n",
       "  'val_true_positives': '35156024.0',\n",
       "  'val_false_positives': '8233098.0',\n",
       "  'val_true_negatives': '52669072.0',\n",
       "  'val_false_negatives': '9913514.0',\n",
       "  'val_precision': '0.8102497458457947',\n",
       "  'val_recall': '0.7800396084785461'},\n",
       " {'loss': '0.14730830490589142',\n",
       "  'accuracy': '0.8784143328666687',\n",
       "  'binary_iou': '0.7784072160720825',\n",
       "  'true_positives': '114011392.0',\n",
       "  'false_positives': '21770962.0',\n",
       "  'true_negatives': '166660272.0',\n",
       "  'false_negatives': '17078148.0',\n",
       "  'precision': '0.8396627902984619',\n",
       "  'recall': '0.869721531867981',\n",
       "  'val_loss': '0.16745591163635254',\n",
       "  'val_accuracy': '0.8436726331710815',\n",
       "  'val_binary_iou': '0.7289546728134155',\n",
       "  'val_true_positives': '41680636.0',\n",
       "  'val_false_positives': '13103984.0',\n",
       "  'val_true_negatives': '47724816.0',\n",
       "  'val_false_negatives': '3462292.0',\n",
       "  'val_precision': '0.760809063911438',\n",
       "  'val_recall': '0.9233037829399109'},\n",
       " {'loss': '0.14401723444461823',\n",
       "  'accuracy': '0.8810575008392334',\n",
       "  'binary_iou': '0.7826745510101318',\n",
       "  'true_positives': '114393776.0',\n",
       "  'false_positives': '21271064.0',\n",
       "  'true_negatives': '167122240.0',\n",
       "  'false_negatives': '16733604.0',\n",
       "  'precision': '0.8432087898254395',\n",
       "  'recall': '0.8723866939544678',\n",
       "  'val_loss': '0.16687346994876862',\n",
       "  'val_accuracy': '0.8602073192596436',\n",
       "  'val_binary_iou': '0.7504729628562927',\n",
       "  'val_true_positives': '37713636.0',\n",
       "  'val_false_positives': '7516429.0',\n",
       "  'val_true_negatives': '53444012.0',\n",
       "  'val_false_negatives': '7297637.0',\n",
       "  'val_precision': '0.8338178992271423',\n",
       "  'val_recall': '0.8378708958625793'},\n",
       " {'loss': '0.13967755436897278',\n",
       "  'accuracy': '0.8848918080329895',\n",
       "  'binary_iou': '0.7889226675033569',\n",
       "  'true_positives': '114999336.0',\n",
       "  'false_positives': '20679376.0',\n",
       "  'true_negatives': '167741888.0',\n",
       "  'false_negatives': '16100101.0',\n",
       "  'precision': '0.8475856781005859',\n",
       "  'recall': '0.8771916627883911',\n",
       "  'val_loss': '0.1353950798511505',\n",
       "  'val_accuracy': '0.8823829293251038',\n",
       "  'val_binary_iou': '0.7869912385940552',\n",
       "  'val_true_positives': '40299460.0',\n",
       "  'val_false_positives': '7671211.0',\n",
       "  'val_true_negatives': '53208184.0',\n",
       "  'val_false_negatives': '4792872.0',\n",
       "  'val_precision': '0.8400853872299194',\n",
       "  'val_recall': '0.8937098383903503'},\n",
       " {'loss': '0.1352715641260147',\n",
       "  'accuracy': '0.8892213702201843',\n",
       "  'binary_iou': '0.7956593036651611',\n",
       "  'true_positives': '114638944.0',\n",
       "  'false_positives': '18970384.0',\n",
       "  'true_negatives': '169485760.0',\n",
       "  'false_negatives': '16425623.0',\n",
       "  'precision': '0.8580160140991211',\n",
       "  'recall': '0.8746753334999084',\n",
       "  'val_loss': '0.1568543165922165',\n",
       "  'val_accuracy': '0.8584086894989014',\n",
       "  'val_binary_iou': '0.7504804134368896',\n",
       "  'val_true_positives': '40856560.0',\n",
       "  'val_false_positives': '10655894.0',\n",
       "  'val_true_negatives': '50110464.0',\n",
       "  'val_false_negatives': '4348781.0',\n",
       "  'val_precision': '0.7931394577026367',\n",
       "  'val_recall': '0.9037994146347046'},\n",
       " {'loss': '0.12936197221279144',\n",
       "  'accuracy': '0.893817663192749',\n",
       "  'binary_iou': '0.8033660054206848',\n",
       "  'true_positives': '115608840.0',\n",
       "  'false_positives': '18361112.0',\n",
       "  'true_negatives': '169984368.0',\n",
       "  'false_negatives': '15566396.0',\n",
       "  'precision': '0.8629460334777832',\n",
       "  'recall': '0.8813313245773315',\n",
       "  'val_loss': '0.256801575422287',\n",
       "  'val_accuracy': '0.813231885433197',\n",
       "  'val_binary_iou': '0.6692835092544556',\n",
       "  'val_true_positives': '29273444.0',\n",
       "  'val_false_positives': '3966531.0',\n",
       "  'val_true_negatives': '56906144.0',\n",
       "  'val_false_negatives': '15825595.0',\n",
       "  'val_precision': '0.8806698322296143',\n",
       "  'val_recall': '0.6490923762321472'},\n",
       " {'loss': '0.12777672708034515',\n",
       "  'accuracy': '0.8952571153640747',\n",
       "  'binary_iou': '0.8057264089584351',\n",
       "  'true_positives': '115722160.0',\n",
       "  'false_positives': '18096608.0',\n",
       "  'true_negatives': '170331008.0',\n",
       "  'false_negatives': '15370898.0',\n",
       "  'precision': '0.8647677898406982',\n",
       "  'recall': '0.8827481865882874',\n",
       "  'val_loss': '0.13223814964294434',\n",
       "  'val_accuracy': '0.8917816877365112',\n",
       "  'val_binary_iou': '0.799962043762207',\n",
       "  'val_true_positives': '38216200.0',\n",
       "  'val_false_positives': '4436075.0',\n",
       "  'val_true_negatives': '56287440.0',\n",
       "  'val_false_negatives': '7032006.0',\n",
       "  'val_precision': '0.8959943652153015',\n",
       "  'val_recall': '0.8445903658866882'},\n",
       " {'loss': '0.12335705757141113',\n",
       "  'accuracy': '0.8994724750518799',\n",
       "  'binary_iou': '0.8126584887504578',\n",
       "  'true_positives': '115993240.0',\n",
       "  'false_positives': '17039420.0',\n",
       "  'true_negatives': '171406992.0',\n",
       "  'false_negatives': '15081117.0',\n",
       "  'precision': '0.8719155192375183',\n",
       "  'recall': '0.8849422335624695',\n",
       "  'val_loss': '0.13863824307918549',\n",
       "  'val_accuracy': '0.87993323802948',\n",
       "  'val_binary_iou': '0.7830523252487183',\n",
       "  'val_true_positives': '40182664.0',\n",
       "  'val_false_positives': '7800029.0',\n",
       "  'val_true_negatives': '53065372.0',\n",
       "  'val_false_negatives': '4923645.0',\n",
       "  'val_precision': '0.8374407887458801',\n",
       "  'val_recall': '0.8908435702323914'},\n",
       " {'loss': '0.12128963321447372',\n",
       "  'accuracy': '0.9008952975273132',\n",
       "  'binary_iou': '0.8151732683181763',\n",
       "  'true_positives': '116559416.0',\n",
       "  'false_positives': '17118276.0',\n",
       "  'true_negatives': '171295424.0',\n",
       "  'false_negatives': '14547673.0',\n",
       "  'precision': '0.8719436526298523',\n",
       "  'recall': '0.8890397548675537',\n",
       "  'val_loss': '0.1420867145061493',\n",
       "  'val_accuracy': '0.874578595161438',\n",
       "  'val_binary_iou': '0.7750580310821533',\n",
       "  'val_true_positives': '40642440.0',\n",
       "  'val_false_positives': '8783600.0',\n",
       "  'val_true_negatives': '52038120.0',\n",
       "  'val_false_negatives': '4507543.0',\n",
       "  'val_precision': '0.8222880363464355',\n",
       "  'val_recall': '0.9001650810241699'},\n",
       " {'loss': '0.11935042589902878',\n",
       "  'accuracy': '0.9026272892951965',\n",
       "  'binary_iou': '0.8180391788482666',\n",
       "  'true_positives': '116646776.0',\n",
       "  'false_positives': '16637965.0',\n",
       "  'true_negatives': '171761392.0',\n",
       "  'false_negatives': '14474606.0',\n",
       "  'precision': '0.8751697540283203',\n",
       "  'recall': '0.8896090984344482',\n",
       "  'val_loss': '0.16962216794490814',\n",
       "  'val_accuracy': '0.8450703620910645',\n",
       "  'val_binary_iou': '0.7304768562316895',\n",
       "  'val_true_positives': '40641952.0',\n",
       "  'val_false_positives': '11934879.0',\n",
       "  'val_true_negatives': '48911596.0',\n",
       "  'val_false_negatives': '4483273.0',\n",
       "  'val_precision': '0.7730011343955994',\n",
       "  'val_recall': '0.9006481766700745'},\n",
       " {'loss': '0.11748106777667999',\n",
       "  'accuracy': '0.9039813876152039',\n",
       "  'binary_iou': '0.8203401565551758',\n",
       "  'true_positives': '116874728.0',\n",
       "  'false_positives': '16479334.0',\n",
       "  'true_negatives': '171966000.0',\n",
       "  'false_negatives': '14200654.0',\n",
       "  'precision': '0.8764241933822632',\n",
       "  'recall': '0.8916603922843933',\n",
       "  'val_loss': '0.16435684263706207',\n",
       "  'val_accuracy': '0.8604539036750793',\n",
       "  'val_binary_iou': '0.7515079975128174',\n",
       "  'val_true_positives': '38347908.0',\n",
       "  'val_false_positives': '7986545.0',\n",
       "  'val_true_negatives': '52835852.0',\n",
       "  'val_false_negatives': '6801397.0',\n",
       "  'val_precision': '0.8276327252388',\n",
       "  'val_recall': '0.8493576645851135'},\n",
       " {'loss': '0.11296495795249939',\n",
       "  'accuracy': '0.9077730774879456',\n",
       "  'binary_iou': '0.8267014622688293',\n",
       "  'true_positives': '117159816.0',\n",
       "  'false_positives': '15511851.0',\n",
       "  'true_negatives': '172892432.0',\n",
       "  'false_negatives': '13956604.0',\n",
       "  'precision': '0.8830808997154236',\n",
       "  'recall': '0.8935556411743164',\n",
       "  'val_loss': '0.17737410962581635',\n",
       "  'val_accuracy': '0.8445158004760742',\n",
       "  'val_binary_iou': '0.7282230257987976',\n",
       "  'val_true_positives': '38698016.0',\n",
       "  'val_false_positives': '10038660.0',\n",
       "  'val_true_negatives': '50796784.0',\n",
       "  'val_false_negatives': '6438257.0',\n",
       "  'val_precision': '0.7940225005149841',\n",
       "  'val_recall': '0.8573595881462097'},\n",
       " {'loss': '0.1116277351975441',\n",
       "  'accuracy': '0.9087814092636108',\n",
       "  'binary_iou': '0.8284687399864197',\n",
       "  'true_positives': '117442272.0',\n",
       "  'false_positives': '15450539.0',\n",
       "  'true_negatives': '172932256.0',\n",
       "  'false_negatives': '13695691.0',\n",
       "  'precision': '0.8837368488311768',\n",
       "  'recall': '0.8955627679824829',\n",
       "  'val_loss': '0.22158901393413544',\n",
       "  'val_accuracy': '0.8260716795921326',\n",
       "  'val_binary_iou': '0.6940493583679199',\n",
       "  'val_true_positives': '32733368.0',\n",
       "  'val_false_positives': '6001649.0',\n",
       "  'val_true_negatives': '54806864.0',\n",
       "  'val_false_negatives': '12429828.0',\n",
       "  'val_precision': '0.8450588583946228',\n",
       "  'val_recall': '0.7247797250747681'},\n",
       " {'loss': '0.11073320358991623',\n",
       "  'accuracy': '0.9101096987724304',\n",
       "  'binary_iou': '0.8306362628936768',\n",
       "  'true_positives': '117300144.0',\n",
       "  'false_positives': '14963131.0',\n",
       "  'true_negatives': '173498800.0',\n",
       "  'false_negatives': '13758712.0',\n",
       "  'precision': '0.8868685960769653',\n",
       "  'recall': '0.8950188159942627',\n",
       "  'val_loss': '0.1295718252658844',\n",
       "  'val_accuracy': '0.8888552188873291',\n",
       "  'val_binary_iou': '0.7969772815704346',\n",
       "  'val_true_positives': '39977888.0',\n",
       "  'val_false_positives': '6724283.0',\n",
       "  'val_true_negatives': '54215616.0',\n",
       "  'val_false_negatives': '5053912.0',\n",
       "  'val_precision': '0.8560177683830261',\n",
       "  'val_recall': '0.8877701759338379'},\n",
       " {'loss': '0.11055346578359604',\n",
       "  'accuracy': '0.9099255800247192',\n",
       "  'binary_iou': '0.8303505182266235',\n",
       "  'true_positives': '117366416.0',\n",
       "  'false_positives': '14966230.0',\n",
       "  'true_negatives': '173373680.0',\n",
       "  'false_negatives': '13814412.0',\n",
       "  'precision': '0.8869044780731201',\n",
       "  'recall': '0.8946918249130249',\n",
       "  'val_loss': '0.1266525238752365',\n",
       "  'val_accuracy': '0.8892303705215454',\n",
       "  'val_binary_iou': '0.7984521389007568',\n",
       "  'val_true_positives': '41107320.0',\n",
       "  'val_false_positives': '7720637.0',\n",
       "  'val_true_negatives': '53125932.0',\n",
       "  'val_false_negatives': '4017818.0',\n",
       "  'val_precision': '0.8418807983398438',\n",
       "  'val_recall': '0.9109628200531006'},\n",
       " {'loss': '0.10677679628133774',\n",
       "  'accuracy': '0.9130255579948425',\n",
       "  'binary_iou': '0.8356871604919434',\n",
       "  'true_positives': '117830272.0',\n",
       "  'false_positives': '14455578.0',\n",
       "  'true_negatives': '173900384.0',\n",
       "  'false_negatives': '13334564.0',\n",
       "  'precision': '0.8907247185707092',\n",
       "  'recall': '0.8983373641967773',\n",
       "  'val_loss': '0.15511789917945862',\n",
       "  'val_accuracy': '0.8591651320457458',\n",
       "  'val_binary_iou': '0.7518163919448853',\n",
       "  'val_true_positives': '41172792.0',\n",
       "  'val_false_positives': '10981330.0',\n",
       "  'val_true_negatives': '49874412.0',\n",
       "  'val_false_negatives': '3943181.0',\n",
       "  'val_precision': '0.7894446849822998',\n",
       "  'val_recall': '0.9125990271568298'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': ['0.21770402789115906',\n",
       "  '0.17682895064353943',\n",
       "  '0.16960737109184265',\n",
       "  '0.18082629144191742',\n",
       "  '0.20721104741096497',\n",
       "  '0.16745591163635254',\n",
       "  '0.16687346994876862',\n",
       "  '0.1353950798511505',\n",
       "  '0.1568543165922165',\n",
       "  '0.256801575422287',\n",
       "  '0.13223814964294434',\n",
       "  '0.13863824307918549',\n",
       "  '0.1420867145061493',\n",
       "  '0.16962216794490814',\n",
       "  '0.16435684263706207',\n",
       "  '0.17737410962581635',\n",
       "  '0.22158901393413544',\n",
       "  '0.1295718252658844',\n",
       "  '0.1266525238752365',\n",
       "  '0.15511789917945862',\n",
       "  '0.1532878875732422',\n",
       "  '0.16470210254192352',\n",
       "  '0.15835809707641602',\n",
       "  '0.19020085036754608',\n",
       "  '0.17323553562164307',\n",
       "  '0.16869047284126282',\n",
       "  '0.16905471682548523',\n",
       "  '0.15957488119602203',\n",
       "  '0.17302271723747253',\n",
       "  '0.1479262411594391',\n",
       "  '0.14105425775051117',\n",
       "  '0.1601693034172058',\n",
       "  '0.14341682195663452',\n",
       "  '0.15757280588150024',\n",
       "  '0.15655525028705597',\n",
       "  '0.14383921027183533',\n",
       "  '0.1519373208284378',\n",
       "  '0.15273939073085785',\n",
       "  '0.13735027611255646',\n",
       "  '0.14573928713798523',\n",
       "  '0.15171602368354797',\n",
       "  '0.15392346680164337',\n",
       "  '0.16573938727378845',\n",
       "  '0.1597735434770584',\n",
       "  '0.13420899212360382',\n",
       "  '0.15384750068187714',\n",
       "  '0.15482977032661438',\n",
       "  '0.15159671008586884',\n",
       "  '0.14477665722370148',\n",
       "  '0.12236810475587845',\n",
       "  '0.14028839766979218',\n",
       "  '0.13311035931110382',\n",
       "  '0.1331200748682022',\n",
       "  '0.12476728856563568',\n",
       "  '0.12796032428741455',\n",
       "  '0.14442332088947296',\n",
       "  '0.1294504702091217',\n",
       "  '0.1249454990029335',\n",
       "  '0.13955040276050568',\n",
       "  '0.14369337260723114',\n",
       "  '0.13317513465881348',\n",
       "  '0.12440110743045807',\n",
       "  '0.12849245965480804',\n",
       "  '0.13226884603500366',\n",
       "  '0.1242087259888649',\n",
       "  '0.12489843368530273',\n",
       "  '0.12735304236412048',\n",
       "  '0.12549789249897003',\n",
       "  '0.13851229846477509',\n",
       "  '0.1473730504512787',\n",
       "  '0.1362791657447815',\n",
       "  '0.13168039917945862',\n",
       "  '0.126186341047287',\n",
       "  '0.12581415474414825',\n",
       "  '0.13660959899425507',\n",
       "  '0.13213157653808594',\n",
       "  '0.13012538850307465',\n",
       "  '0.13274507224559784',\n",
       "  '0.13762229681015015',\n",
       "  '0.12109001725912094',\n",
       "  '0.1188807338476181',\n",
       "  '0.13117694854736328',\n",
       "  '0.12731844186782837',\n",
       "  '0.1247730702161789',\n",
       "  '0.13369794189929962',\n",
       "  '0.11847555637359619',\n",
       "  '0.11922792345285416',\n",
       "  '0.1173231229186058',\n",
       "  '0.12573279440402985',\n",
       "  '0.14296342432498932',\n",
       "  '0.12769436836242676',\n",
       "  '0.13821688294410706',\n",
       "  '0.1270095407962799',\n",
       "  '0.12398946285247803',\n",
       "  '0.12144827097654343',\n",
       "  '0.12075302004814148',\n",
       "  '0.11783315986394882',\n",
       "  '0.12379972636699677',\n",
       "  '0.11779506504535675',\n",
       "  '0.12219167500734329',\n",
       "  '0.12229105830192566',\n",
       "  '0.12620393931865692',\n",
       "  '0.1147293820977211',\n",
       "  '0.11959604173898697',\n",
       "  '0.1166437640786171',\n",
       "  '0.11983519047498703',\n",
       "  '0.12043052911758423',\n",
       "  '0.11732880026102066',\n",
       "  '0.12237317860126495',\n",
       "  '0.12248948216438293',\n",
       "  '0.1247672438621521',\n",
       "  '0.12426847219467163',\n",
       "  '0.12358038127422333',\n",
       "  '0.11900582909584045',\n",
       "  '0.12076747417449951',\n",
       "  '0.1199825257062912',\n",
       "  '0.1199617087841034',\n",
       "  '0.12244444340467453',\n",
       "  '0.11729475110769272',\n",
       "  '0.1220301017165184',\n",
       "  '0.11887235939502716',\n",
       "  '0.11579880863428116',\n",
       "  '0.11833526939153671',\n",
       "  '0.11629320681095123',\n",
       "  '0.12073512375354767',\n",
       "  '0.12064170837402344',\n",
       "  '0.11893913894891739',\n",
       "  '0.11864928156137466',\n",
       "  '0.1191859245300293',\n",
       "  '0.11809110641479492',\n",
       "  '0.12140107899904251',\n",
       "  '0.11622099578380585',\n",
       "  '0.11712513864040375',\n",
       "  '0.11704415827989578',\n",
       "  '0.11579082161188126',\n",
       "  '0.11940192431211472',\n",
       "  '0.11721847206354141',\n",
       "  '0.11930017918348312',\n",
       "  '0.12150349467992783',\n",
       "  '0.12000486999750137',\n",
       "  '0.11688486486673355',\n",
       "  '0.12043492496013641',\n",
       "  '0.11513802409172058',\n",
       "  '0.11638107150793076',\n",
       "  '0.1149480938911438',\n",
       "  '0.1178000196814537',\n",
       "  '0.11645808815956116',\n",
       "  '0.11759473383426666',\n",
       "  '0.12082542479038239',\n",
       "  '0.11767257750034332',\n",
       "  '0.11661818623542786',\n",
       "  '0.11676521599292755',\n",
       "  '0.11694347858428955',\n",
       "  '0.11652178317308426',\n",
       "  '0.11690908670425415',\n",
       "  '0.11815569549798965',\n",
       "  '0.11460810154676437',\n",
       "  '0.11440238356590271',\n",
       "  '0.11823490262031555',\n",
       "  '0.11763251572847366',\n",
       "  '0.11677468568086624',\n",
       "  '0.11830823123455048',\n",
       "  '0.12119510769844055',\n",
       "  '0.11619402468204498',\n",
       "  '0.11396702378988266',\n",
       "  '0.11789123713970184',\n",
       "  '0.12078561633825302',\n",
       "  '0.11906962096691132',\n",
       "  '0.1156567633152008',\n",
       "  '0.11936014890670776',\n",
       "  '0.11512753367424011',\n",
       "  '0.11443984508514404',\n",
       "  '0.1159466952085495',\n",
       "  '0.11403097212314606',\n",
       "  '0.1165010929107666',\n",
       "  '0.11725557595491409',\n",
       "  '0.11765151470899582',\n",
       "  '0.11462093144655228',\n",
       "  '0.11723525822162628',\n",
       "  '0.11727699637413025',\n",
       "  '0.1169344112277031',\n",
       "  '0.11783318966627121',\n",
       "  '0.11990607529878616',\n",
       "  '0.1172911673784256',\n",
       "  '0.11439813673496246',\n",
       "  '0.11680661886930466',\n",
       "  '0.11593670397996902',\n",
       "  '0.11325681209564209',\n",
       "  '0.11605221778154373',\n",
       "  '0.11778043955564499',\n",
       "  '0.12012208998203278',\n",
       "  '0.11470621824264526',\n",
       "  '0.11317934840917587',\n",
       "  '0.11376090347766876',\n",
       "  '0.11499509960412979',\n",
       "  '0.11758579313755035',\n",
       "  '0.114342600107193',\n",
       "  '0.11828690767288208',\n",
       "  '0.11599338054656982',\n",
       "  '0.11690444499254227',\n",
       "  '0.1180187314748764',\n",
       "  '0.11817086488008499',\n",
       "  '0.11539346724748611',\n",
       "  '0.11245646327733994',\n",
       "  '0.1132143884897232',\n",
       "  '0.11324066668748856',\n",
       "  '0.11788246780633926',\n",
       "  '0.11375032365322113',\n",
       "  '0.1165195107460022',\n",
       "  '0.11665957421064377',\n",
       "  '0.11553255468606949',\n",
       "  '0.1156017929315567',\n",
       "  '0.11280359327793121',\n",
       "  '0.1146276444196701',\n",
       "  '0.11525095254182816',\n",
       "  '0.12001452594995499',\n",
       "  '0.11563926935195923',\n",
       "  '0.11840638518333435',\n",
       "  '0.11456241458654404',\n",
       "  '0.11544135212898254',\n",
       "  '0.11569689214229584',\n",
       "  '0.11408401280641556',\n",
       "  '0.11816465854644775',\n",
       "  '0.1149558499455452',\n",
       "  '0.11554516851902008',\n",
       "  '0.1133972704410553',\n",
       "  '0.11669003963470459',\n",
       "  '0.12003932893276215',\n",
       "  '0.11462179571390152',\n",
       "  '0.11765571683645248',\n",
       "  '0.1160205826163292',\n",
       "  '0.1159721165895462',\n",
       "  '0.11221522092819214',\n",
       "  '0.11429080367088318',\n",
       "  '0.11230839043855667',\n",
       "  '0.11320412904024124',\n",
       "  '0.11715869605541229',\n",
       "  '0.11401700973510742',\n",
       "  '0.11329974234104156',\n",
       "  '0.11398975551128387',\n",
       "  '0.11479958891868591',\n",
       "  '0.11706393212080002',\n",
       "  '0.11529475450515747',\n",
       "  '0.11355168372392654',\n",
       "  '0.11431055516004562',\n",
       "  '0.11417941004037857',\n",
       "  '0.11306194216012955',\n",
       "  '0.11349113285541534',\n",
       "  '0.11603450030088425',\n",
       "  '0.1160237118601799',\n",
       "  '0.11194554716348648',\n",
       "  '0.11267965286970139',\n",
       "  '0.11156198382377625',\n",
       "  '0.11465377360582352',\n",
       "  '0.11431556940078735',\n",
       "  '0.11516668647527695',\n",
       "  '0.11326157301664352',\n",
       "  '0.11290623992681503',\n",
       "  '0.11337651312351227',\n",
       "  '0.1122761145234108',\n",
       "  '0.11302945017814636',\n",
       "  '0.11160043627023697',\n",
       "  '0.11289632320404053',\n",
       "  '0.11282484233379364',\n",
       "  '0.11320070922374725',\n",
       "  '0.11408361047506332',\n",
       "  '0.11183971166610718',\n",
       "  '0.11375568062067032',\n",
       "  '0.11217398941516876',\n",
       "  '0.11428642272949219',\n",
       "  '0.11035120487213135',\n",
       "  '0.11318475008010864',\n",
       "  '0.11404812335968018',\n",
       "  '0.11345578730106354',\n",
       "  '0.11391288042068481',\n",
       "  '0.11250997334718704',\n",
       "  '0.11197409778833389',\n",
       "  '0.11286426335573196',\n",
       "  '0.11300475895404816',\n",
       "  '0.1131753921508789',\n",
       "  '0.11340207606554031',\n",
       "  '0.11346419155597687',\n",
       "  '0.11457433551549911',\n",
       "  '0.11424950510263443',\n",
       "  '0.11337873339653015',\n",
       "  '0.11325903981924057',\n",
       "  '0.1132345199584961',\n",
       "  '0.11304116249084473',\n",
       "  '0.11380644142627716',\n",
       "  '0.11117787659168243',\n",
       "  '0.11097700148820877',\n",
       "  '0.1133204773068428',\n",
       "  '0.1117781326174736',\n",
       "  '0.11514399200677872',\n",
       "  '0.11479592323303223',\n",
       "  '0.11253302544355392',\n",
       "  '0.11566536128520966',\n",
       "  '0.11490102112293243',\n",
       "  '0.11388024687767029',\n",
       "  '0.11300020664930344',\n",
       "  '0.11575763672590256'],\n",
       " 'val_recall': ['0.8034497499465942',\n",
       "  '0.8397879600524902',\n",
       "  '0.9183962941169739',\n",
       "  '0.925344705581665',\n",
       "  '0.7800396084785461',\n",
       "  '0.9233037829399109',\n",
       "  '0.8378708958625793',\n",
       "  '0.8937098383903503',\n",
       "  '0.9037994146347046',\n",
       "  '0.6490923762321472',\n",
       "  '0.8445903658866882',\n",
       "  '0.8908435702323914',\n",
       "  '0.9001650810241699',\n",
       "  '0.9006481766700745',\n",
       "  '0.8493576645851135',\n",
       "  '0.8573595881462097',\n",
       "  '0.7247797250747681',\n",
       "  '0.8877701759338379',\n",
       "  '0.9109628200531006',\n",
       "  '0.9125990271568298',\n",
       "  '0.8681316375732422',\n",
       "  '0.8698943257331848',\n",
       "  '0.8648158311843872',\n",
       "  '0.8132686018943787',\n",
       "  '0.8367692828178406',\n",
       "  '0.8379760384559631',\n",
       "  '0.8239779472351074',\n",
       "  '0.8643971681594849',\n",
       "  '0.8218018412590027',\n",
       "  '0.8505344986915588',\n",
       "  '0.8805814385414124',\n",
       "  '0.8445643186569214',\n",
       "  '0.8804050087928772',\n",
       "  '0.8525071740150452',\n",
       "  '0.854682445526123',\n",
       "  '0.8626556992530823',\n",
       "  '0.8526890277862549',\n",
       "  '0.8534736037254333',\n",
       "  '0.8964869976043701',\n",
       "  '0.8732181787490845',\n",
       "  '0.8408482670783997',\n",
       "  '0.8741795420646667',\n",
       "  '0.8412203788757324',\n",
       "  '0.8402198553085327',\n",
       "  '0.8770241141319275',\n",
       "  '0.8366045355796814',\n",
       "  '0.8409819602966309',\n",
       "  '0.8393517136573792',\n",
       "  '0.9027755260467529',\n",
       "  '0.9095205664634705',\n",
       "  '0.8910811543464661',\n",
       "  '0.9084098935127258',\n",
       "  '0.8921440839767456',\n",
       "  '0.9045875668525696',\n",
       "  '0.9000638127326965',\n",
       "  '0.879349410533905',\n",
       "  '0.9103804230690002',\n",
       "  '0.9021161794662476',\n",
       "  '0.8844022750854492',\n",
       "  '0.877945601940155',\n",
       "  '0.8918641805648804',\n",
       "  '0.8956597447395325',\n",
       "  '0.9074963331222534',\n",
       "  '0.8828051686286926',\n",
       "  '0.8963316679000854',\n",
       "  '0.9023861289024353',\n",
       "  '0.8917412161827087',\n",
       "  '0.9056563973426819',\n",
       "  '0.881592869758606',\n",
       "  '0.8533007502555847',\n",
       "  '0.8720873594284058',\n",
       "  '0.8910010457038879',\n",
       "  '0.9054935574531555',\n",
       "  '0.8927657008171082',\n",
       "  '0.8877168893814087',\n",
       "  '0.8862788081169128',\n",
       "  '0.8924893736839294',\n",
       "  '0.8921104073524475',\n",
       "  '0.8734277486801147',\n",
       "  '0.9031172394752502',\n",
       "  '0.8922602534294128',\n",
       "  '0.8810566067695618',\n",
       "  '0.892907977104187',\n",
       "  '0.900300920009613',\n",
       "  '0.8822528123855591',\n",
       "  '0.9056819081306458',\n",
       "  '0.9041309356689453',\n",
       "  '0.9083422422409058',\n",
       "  '0.8951994776725769',\n",
       "  '0.8586760759353638',\n",
       "  '0.8993447422981262',\n",
       "  '0.8885667324066162',\n",
       "  '0.9025124907493591',\n",
       "  '0.9057181477546692',\n",
       "  '0.8952162265777588',\n",
       "  '0.9096670746803284',\n",
       "  '0.9114355444908142',\n",
       "  '0.9151189923286438',\n",
       "  '0.9161510467529297',\n",
       "  '0.893447756767273',\n",
       "  '0.9091493487358093',\n",
       "  '0.893306314945221',\n",
       "  '0.9013187885284424',\n",
       "  '0.9130269289016724',\n",
       "  '0.9009261131286621',\n",
       "  '0.9115952253341675',\n",
       "  '0.9108734726905823',\n",
       "  '0.9069623947143555',\n",
       "  '0.9052621722221375',\n",
       "  '0.9025774598121643',\n",
       "  '0.8897026181221008',\n",
       "  '0.9080055952072144',\n",
       "  '0.8930554986000061',\n",
       "  '0.9010698199272156',\n",
       "  '0.8974961638450623',\n",
       "  '0.90845787525177',\n",
       "  '0.9101932048797607',\n",
       "  '0.901776134967804',\n",
       "  '0.9028364419937134',\n",
       "  '0.8952406048774719',\n",
       "  '0.9039737582206726',\n",
       "  '0.9086753129959106',\n",
       "  '0.9046904444694519',\n",
       "  '0.9024057984352112',\n",
       "  '0.8908393383026123',\n",
       "  '0.908892810344696',\n",
       "  '0.9170272350311279',\n",
       "  '0.9047291874885559',\n",
       "  '0.8967289328575134',\n",
       "  '0.914959728717804',\n",
       "  '0.9145568609237671',\n",
       "  '0.9000033736228943',\n",
       "  '0.9140010476112366',\n",
       "  '0.9076323509216309',\n",
       "  '0.9123165607452393',\n",
       "  '0.9133268594741821',\n",
       "  '0.9193007349967957',\n",
       "  '0.9053952693939209',\n",
       "  '0.9078467488288879',\n",
       "  '0.9072677493095398',\n",
       "  '0.9049867391586304',\n",
       "  '0.895412802696228',\n",
       "  '0.9160388708114624',\n",
       "  '0.9104902744293213',\n",
       "  '0.9093319177627563',\n",
       "  '0.9099108576774597',\n",
       "  '0.9077826738357544',\n",
       "  '0.9196755886077881',\n",
       "  '0.9097458124160767',\n",
       "  '0.905867338180542',\n",
       "  '0.9109106063842773',\n",
       "  '0.9099176526069641',\n",
       "  '0.9133888483047485',\n",
       "  '0.9110626578330994',\n",
       "  '0.9133310317993164',\n",
       "  '0.9092443585395813',\n",
       "  '0.9149479269981384',\n",
       "  '0.9091638922691345',\n",
       "  '0.9156341552734375',\n",
       "  '0.9077345132827759',\n",
       "  '0.9120107889175415',\n",
       "  '0.9134351015090942',\n",
       "  '0.9132845401763916',\n",
       "  '0.9185037016868591',\n",
       "  '0.9165863394737244',\n",
       "  '0.913665771484375',\n",
       "  '0.9122361540794373',\n",
       "  '0.912835419178009',\n",
       "  '0.9134685397148132',\n",
       "  '0.9062337279319763',\n",
       "  '0.918868899345398',\n",
       "  '0.9063910245895386',\n",
       "  '0.9154727458953857',\n",
       "  '0.9153134226799011',\n",
       "  '0.9098594784736633',\n",
       "  '0.9106874465942383',\n",
       "  '0.9148927927017212',\n",
       "  '0.9120746850967407',\n",
       "  '0.920434832572937',\n",
       "  '0.9064165353775024',\n",
       "  '0.9162482023239136',\n",
       "  '0.9025009870529175',\n",
       "  '0.9099728465080261',\n",
       "  '0.9164579510688782',\n",
       "  '0.9148892164230347',\n",
       "  '0.9177864789962769',\n",
       "  '0.9119742512702942',\n",
       "  '0.915755569934845',\n",
       "  '0.9154274463653564',\n",
       "  '0.9201580882072449',\n",
       "  '0.9202529191970825',\n",
       "  '0.9153046607971191',\n",
       "  '0.9187358021736145',\n",
       "  '0.9147254824638367',\n",
       "  '0.9126228094100952',\n",
       "  '0.9139297604560852',\n",
       "  '0.9130886197090149',\n",
       "  '0.9108365774154663',\n",
       "  '0.9209015965461731',\n",
       "  '0.9181728959083557',\n",
       "  '0.9201520085334778',\n",
       "  '0.9101868867874146',\n",
       "  '0.9192184209823608',\n",
       "  '0.9076467752456665',\n",
       "  '0.9145250916481018',\n",
       "  '0.911400556564331',\n",
       "  '0.9127548336982727',\n",
       "  '0.9115918874740601',\n",
       "  '0.9182314872741699',\n",
       "  '0.9117229580879211',\n",
       "  '0.9165856838226318',\n",
       "  '0.918455183506012',\n",
       "  '0.910864531993866',\n",
       "  '0.9106550812721252',\n",
       "  '0.9091745615005493',\n",
       "  '0.9162465333938599',\n",
       "  '0.9127001762390137',\n",
       "  '0.9112803936004639',\n",
       "  '0.9170609712600708',\n",
       "  '0.9181414246559143',\n",
       "  '0.9221186637878418',\n",
       "  '0.9176177978515625',\n",
       "  '0.9097387194633484',\n",
       "  '0.9179956316947937',\n",
       "  '0.9127970933914185',\n",
       "  '0.9115978479385376',\n",
       "  '0.9081261157989502',\n",
       "  '0.9224645495414734',\n",
       "  '0.9129247069358826',\n",
       "  '0.9157043099403381',\n",
       "  '0.9089363217353821',\n",
       "  '0.9156010746955872',\n",
       "  '0.9083479046821594',\n",
       "  '0.9186058640480042',\n",
       "  '0.9111701250076294',\n",
       "  '0.9235313534736633',\n",
       "  '0.9173887372016907',\n",
       "  '0.9153755307197571',\n",
       "  '0.9166662693023682',\n",
       "  '0.9118124842643738',\n",
       "  '0.9124084711074829',\n",
       "  '0.920568585395813',\n",
       "  '0.9169029593467712',\n",
       "  '0.9185730814933777',\n",
       "  '0.9142057299613953',\n",
       "  '0.9119232892990112',\n",
       "  '0.9176174998283386',\n",
       "  '0.9206912517547607',\n",
       "  '0.9150436520576477',\n",
       "  '0.918765127658844',\n",
       "  '0.9212852716445923',\n",
       "  '0.920566201210022',\n",
       "  '0.914833664894104',\n",
       "  '0.9178637862205505',\n",
       "  '0.9196422696113586',\n",
       "  '0.913414478302002',\n",
       "  '0.9197643995285034',\n",
       "  '0.9200530052185059',\n",
       "  '0.9145254492759705',\n",
       "  '0.9177091717720032',\n",
       "  '0.9191275238990784',\n",
       "  '0.9205524921417236',\n",
       "  '0.9197447896003723',\n",
       "  '0.9203625321388245',\n",
       "  '0.9207009673118591',\n",
       "  '0.91944819688797',\n",
       "  '0.91544508934021',\n",
       "  '0.920981228351593',\n",
       "  '0.9119866490364075',\n",
       "  '0.919940710067749',\n",
       "  '0.9109920263290405',\n",
       "  '0.9177347421646118',\n",
       "  '0.9137817025184631',\n",
       "  '0.92356938123703',\n",
       "  '0.923754870891571',\n",
       "  '0.9191481471061707',\n",
       "  '0.9194711446762085',\n",
       "  '0.9197134375572205',\n",
       "  '0.9179508686065674',\n",
       "  '0.9179187417030334',\n",
       "  '0.9200094938278198',\n",
       "  '0.916538655757904',\n",
       "  '0.9200593829154968',\n",
       "  '0.9162121415138245',\n",
       "  '0.9179103374481201',\n",
       "  '0.9202543497085571',\n",
       "  '0.9191972613334656',\n",
       "  '0.9140179753303528',\n",
       "  '0.9194062948226929',\n",
       "  '0.9162887930870056',\n",
       "  '0.9187495708465576',\n",
       "  '0.9178752303123474',\n",
       "  '0.9178215861320496',\n",
       "  '0.9242412447929382',\n",
       "  '0.9206775426864624',\n",
       "  '0.9150415658950806',\n",
       "  '0.9188150763511658',\n",
       "  '0.9216482639312744',\n",
       "  '0.9180718064308167',\n",
       "  '0.9219462275505066',\n",
       "  '0.921051025390625'],\n",
       " 'val_false_positives': ['9768367.0',\n",
       "  '8678695.0',\n",
       "  '12919748.0',\n",
       "  '14784452.0',\n",
       "  '8233098.0',\n",
       "  '13103984.0',\n",
       "  '7516429.0',\n",
       "  '7671211.0',\n",
       "  '10655894.0',\n",
       "  '3966531.0',\n",
       "  '4436075.0',\n",
       "  '7800029.0',\n",
       "  '8783600.0',\n",
       "  '11934879.0',\n",
       "  '7986545.0',\n",
       "  '10038660.0',\n",
       "  '6001649.0',\n",
       "  '6724283.0',\n",
       "  '7720637.0',\n",
       "  '10981330.0',\n",
       "  '7995532.0',\n",
       "  '9388413.0',\n",
       "  '8310546.0',\n",
       "  '8564972.0',\n",
       "  '8171298.0',\n",
       "  '7846076.0',\n",
       "  '6882977.0',\n",
       "  '8430896.0',\n",
       "  '7301166.0',\n",
       "  '6451831.0',\n",
       "  '7515209.0',\n",
       "  '7337428.0',\n",
       "  '7793475.0',\n",
       "  '7554219.0',\n",
       "  '7472669.0',\n",
       "  '6708055.0',\n",
       "  '6990396.0',\n",
       "  '7111299.0',\n",
       "  '8003803.0',\n",
       "  '7511030.0',\n",
       "  '6186966.0',\n",
       "  '8510896.0',\n",
       "  '7752052.0',\n",
       "  '7051738.0',\n",
       "  '6547396.0',\n",
       "  '6182531.0',\n",
       "  '6595123.0',\n",
       "  '6008902.0',\n",
       "  '9089778.0',\n",
       "  '7188811.0',\n",
       "  '7955312.0',\n",
       "  '8270205.0',\n",
       "  '7313449.0',\n",
       "  '7144993.0',\n",
       "  '7241171.0',\n",
       "  '7789454.0',\n",
       "  '7990725.0',\n",
       "  '7059497.0',\n",
       "  '7650451.0',\n",
       "  '7570976.0',\n",
       "  '7133141.0',\n",
       "  '6587527.0',\n",
       "  '7736609.0',\n",
       "  '6661618.0',\n",
       "  '6696174.0',\n",
       "  '7040544.0',\n",
       "  '6751547.0',\n",
       "  '7320436.0',\n",
       "  '7306383.0',\n",
       "  '6493311.0',\n",
       "  '6473311.0',\n",
       "  '7147035.0',\n",
       "  '7349679.0',\n",
       "  '6541107.0',\n",
       "  '7431242.0',\n",
       "  '6848179.0',\n",
       "  '7076109.0',\n",
       "  '7286132.0',\n",
       "  '6671738.0',\n",
       "  '6655291.0',\n",
       "  '5827465.0',\n",
       "  '6454110.0',\n",
       "  '6693823.0',\n",
       "  '6863397.0',\n",
       "  '6837606.0',\n",
       "  '6608031.0',\n",
       "  '6512216.0',\n",
       "  '6562191.0',\n",
       "  '6745363.0',\n",
       "  '6268144.0',\n",
       "  '7164729.0',\n",
       "  '7683408.0',\n",
       "  '7237269.0',\n",
       "  '7231613.0',\n",
       "  '6310184.0',\n",
       "  '7017896.0',\n",
       "  '6882456.0',\n",
       "  '7650375.0',\n",
       "  '7093535.0',\n",
       "  '6169027.0',\n",
       "  '7182040.0',\n",
       "  '6688132.0',\n",
       "  '6000315.0',\n",
       "  '7072328.0',\n",
       "  '6111206.0',\n",
       "  '7022818.0',\n",
       "  '7072027.0',\n",
       "  '6507236.0',\n",
       "  '6969499.0',\n",
       "  '6833923.0',\n",
       "  '6287806.0',\n",
       "  '7340763.0',\n",
       "  '6302173.0',\n",
       "  '6338738.0',\n",
       "  '6356568.0',\n",
       "  '6884398.0',\n",
       "  '7049656.0',\n",
       "  '6850225.0',\n",
       "  '6249336.0',\n",
       "  '6321843.0',\n",
       "  '6491146.0',\n",
       "  '6519950.0',\n",
       "  '6468702.0',\n",
       "  '6143717.0',\n",
       "  '5999407.0',\n",
       "  '6977920.0',\n",
       "  '7258941.0',\n",
       "  '6435423.0',\n",
       "  '6178631.0',\n",
       "  '7060847.0',\n",
       "  '7356539.0',\n",
       "  '6004807.0',\n",
       "  '6831848.0',\n",
       "  '6549019.0',\n",
       "  '6663939.0',\n",
       "  '7066731.0',\n",
       "  '7189002.0',\n",
       "  '6604726.0',\n",
       "  '6973299.0',\n",
       "  '6762992.0',\n",
       "  '6432876.0',\n",
       "  '6188659.0',\n",
       "  '6840811.0',\n",
       "  '6617569.0',\n",
       "  '6352211.0',\n",
       "  '6731872.0',\n",
       "  '6457385.0',\n",
       "  '7238208.0',\n",
       "  '7063887.0',\n",
       "  '6421701.0',\n",
       "  '6626373.0',\n",
       "  '6592848.0',\n",
       "  '6831751.0',\n",
       "  '6621291.0',\n",
       "  '6852340.0',\n",
       "  '6685736.0',\n",
       "  '6643525.0',\n",
       "  '6355423.0',\n",
       "  '7083548.0',\n",
       "  '6533151.0',\n",
       "  '6693123.0',\n",
       "  '7045977.0',\n",
       "  '7271796.0',\n",
       "  '7010789.0',\n",
       "  '6741147.0',\n",
       "  '7013738.0',\n",
       "  '7138950.0',\n",
       "  '7029609.0',\n",
       "  '6702185.0',\n",
       "  '6682764.0',\n",
       "  '6892815.0',\n",
       "  '6184756.0',\n",
       "  '6786822.0',\n",
       "  '6625081.0',\n",
       "  '6627620.0',\n",
       "  '6701753.0',\n",
       "  '6990843.0',\n",
       "  '6602763.0',\n",
       "  '7271121.0',\n",
       "  '6503394.0',\n",
       "  '6920385.0',\n",
       "  '6346590.0',\n",
       "  '6883486.0',\n",
       "  '7073157.0',\n",
       "  '6565922.0',\n",
       "  '7056995.0',\n",
       "  '6652428.0',\n",
       "  '6575537.0',\n",
       "  '6851404.0',\n",
       "  '7365267.0',\n",
       "  '7605111.0',\n",
       "  '6719768.0',\n",
       "  '6826572.0',\n",
       "  '6564801.0',\n",
       "  '6627336.0',\n",
       "  '6971668.0',\n",
       "  '6543941.0',\n",
       "  '6871320.0',\n",
       "  '7089894.0',\n",
       "  '7079218.0',\n",
       "  '7243105.0',\n",
       "  '6815943.0',\n",
       "  '6899521.0',\n",
       "  '6058089.0',\n",
       "  '6542881.0',\n",
       "  '6322329.0',\n",
       "  '6746400.0',\n",
       "  '6380405.0',\n",
       "  '7049475.0',\n",
       "  '6688924.0',\n",
       "  '6847416.0',\n",
       "  '6927529.0',\n",
       "  '6315100.0',\n",
       "  '6464787.0',\n",
       "  '6408100.0',\n",
       "  '7292969.0',\n",
       "  '6680109.0',\n",
       "  '6819014.0',\n",
       "  '6799947.0',\n",
       "  '6883265.0',\n",
       "  '7138391.0',\n",
       "  '6784169.0',\n",
       "  '6748843.0',\n",
       "  '6876187.0',\n",
       "  '6637981.0',\n",
       "  '6337296.0',\n",
       "  '6532334.0',\n",
       "  '7647113.0',\n",
       "  '6549969.0',\n",
       "  '7080541.0',\n",
       "  '6481059.0',\n",
       "  '6887706.0',\n",
       "  '6073201.0',\n",
       "  '6841121.0',\n",
       "  '6227347.0',\n",
       "  '7090025.0',\n",
       "  '7134353.0',\n",
       "  '6647790.0',\n",
       "  '6663395.0',\n",
       "  '6413070.0',\n",
       "  '6631169.0',\n",
       "  '7198609.0',\n",
       "  '6905649.0',\n",
       "  '6761663.0',\n",
       "  '6651015.0',\n",
       "  '6499834.0',\n",
       "  '6658399.0',\n",
       "  '6949805.0',\n",
       "  '6820235.0',\n",
       "  '6988728.0',\n",
       "  '6830655.0',\n",
       "  '6854208.0',\n",
       "  '6326229.0',\n",
       "  '6750144.0',\n",
       "  '6853814.0',\n",
       "  '6657131.0',\n",
       "  '6852045.0',\n",
       "  '6848949.0',\n",
       "  '6512282.0',\n",
       "  '6632358.0',\n",
       "  '6814214.0',\n",
       "  '6704797.0',\n",
       "  '6816795.0',\n",
       "  '6779581.0',\n",
       "  '6799552.0',\n",
       "  '6842265.0',\n",
       "  '6430027.0',\n",
       "  '6910828.0',\n",
       "  '6272876.0',\n",
       "  '6925499.0',\n",
       "  '6007034.0',\n",
       "  '6679837.0',\n",
       "  '6499658.0',\n",
       "  '7028003.0',\n",
       "  '7053894.0',\n",
       "  '6674978.0',\n",
       "  '6655624.0',\n",
       "  '6752666.0',\n",
       "  '6647952.0',\n",
       "  '6671173.0',\n",
       "  '6846696.0',\n",
       "  '6654268.0',\n",
       "  '6900936.0',\n",
       "  '6777069.0',\n",
       "  '6727720.0',\n",
       "  '6860239.0',\n",
       "  '6808160.0',\n",
       "  '6450340.0',\n",
       "  '6794321.0',\n",
       "  '6436595.0',\n",
       "  '6572012.0',\n",
       "  '6752783.0',\n",
       "  '6633046.0',\n",
       "  '7235276.0',\n",
       "  '6958019.0',\n",
       "  '6478292.0',\n",
       "  '6958231.0',\n",
       "  '7072367.0',\n",
       "  '6793908.0',\n",
       "  '6906495.0',\n",
       "  '7202194.0'],\n",
       " 'false_positives': ['48262192.0',\n",
       "  '27865604.0',\n",
       "  '26535964.0',\n",
       "  '24180304.0',\n",
       "  '22661028.0',\n",
       "  '21770962.0',\n",
       "  '21271064.0',\n",
       "  '20679376.0',\n",
       "  '18970384.0',\n",
       "  '18361112.0',\n",
       "  '18096608.0',\n",
       "  '17039420.0',\n",
       "  '17118276.0',\n",
       "  '16637965.0',\n",
       "  '16479334.0',\n",
       "  '15511851.0',\n",
       "  '15450539.0',\n",
       "  '14963131.0',\n",
       "  '14966230.0',\n",
       "  '14455578.0',\n",
       "  '14923478.0',\n",
       "  '13476758.0',\n",
       "  '12346751.0',\n",
       "  '11795770.0',\n",
       "  '11190987.0',\n",
       "  '10688978.0',\n",
       "  '10302724.0',\n",
       "  '10085414.0',\n",
       "  '9757199.0',\n",
       "  '9446453.0',\n",
       "  '9056807.0',\n",
       "  '8896953.0',\n",
       "  '8745585.0',\n",
       "  '8491503.0',\n",
       "  '8436640.0',\n",
       "  '8213388.0',\n",
       "  '8102850.0',\n",
       "  '7931892.0',\n",
       "  '7859627.0',\n",
       "  '7685584.0',\n",
       "  '7598116.0',\n",
       "  '7551386.0',\n",
       "  '7305634.0',\n",
       "  '7193699.0',\n",
       "  '7295953.0',\n",
       "  '6977136.0',\n",
       "  '7033529.0',\n",
       "  '6925606.0',\n",
       "  '6757289.0',\n",
       "  '6691404.0',\n",
       "  '6805104.0',\n",
       "  '6662078.0',\n",
       "  '6480976.0',\n",
       "  '6523479.0',\n",
       "  '6408760.0',\n",
       "  '6377012.0',\n",
       "  '6317833.0',\n",
       "  '6252158.0',\n",
       "  '6166478.0',\n",
       "  '6008575.0',\n",
       "  '6153825.0',\n",
       "  '6058574.0',\n",
       "  '5936787.0',\n",
       "  '5856439.0',\n",
       "  '5799776.0',\n",
       "  '5794920.0',\n",
       "  '5726393.0',\n",
       "  '5695700.0',\n",
       "  '5638060.0',\n",
       "  '5670895.0',\n",
       "  '5535413.0',\n",
       "  '5511531.0',\n",
       "  '5464186.0',\n",
       "  '5453836.0',\n",
       "  '5499757.0',\n",
       "  '5360537.0',\n",
       "  '5336545.0',\n",
       "  '5306695.0',\n",
       "  '5185485.0',\n",
       "  '5214493.0',\n",
       "  '5149075.0',\n",
       "  '5218970.0',\n",
       "  '5151220.0',\n",
       "  '5149368.0',\n",
       "  '5017609.0',\n",
       "  '5043673.0',\n",
       "  '4980750.0',\n",
       "  '4942512.0',\n",
       "  '4950957.0',\n",
       "  '4895951.0',\n",
       "  '4800330.0',\n",
       "  '4785030.0',\n",
       "  '4797218.0',\n",
       "  '4743315.0',\n",
       "  '4774565.0',\n",
       "  '4776206.0',\n",
       "  '4638195.0',\n",
       "  '4674102.0',\n",
       "  '4633043.0',\n",
       "  '4689436.0',\n",
       "  '4636033.0',\n",
       "  '4573718.0',\n",
       "  '4558592.0',\n",
       "  '4524074.0',\n",
       "  '4507274.0',\n",
       "  '4483441.0',\n",
       "  '4453989.0',\n",
       "  '4422716.0',\n",
       "  '4353448.0',\n",
       "  '4406292.0',\n",
       "  '4321262.0',\n",
       "  '4319419.0',\n",
       "  '4309674.0',\n",
       "  '4312104.0',\n",
       "  '4276012.0',\n",
       "  '4291189.0',\n",
       "  '4201263.0',\n",
       "  '4209346.0',\n",
       "  '4148367.0',\n",
       "  '4167234.0',\n",
       "  '4125654.0',\n",
       "  '4076635.0',\n",
       "  '4112492.0',\n",
       "  '4100056.0',\n",
       "  '4061460.0',\n",
       "  '4029320.0',\n",
       "  '3986961.0',\n",
       "  '4055427.0',\n",
       "  '3926520.0',\n",
       "  '3931477.0',\n",
       "  '3925494.0',\n",
       "  '3956162.0',\n",
       "  '3913470.0',\n",
       "  '3867753.0',\n",
       "  '3856483.0',\n",
       "  '3848838.0',\n",
       "  '3882576.0',\n",
       "  '3844139.0',\n",
       "  '3828746.0',\n",
       "  '3787471.0',\n",
       "  '3766693.0',\n",
       "  '3760504.0',\n",
       "  '3789311.0',\n",
       "  '3744909.0',\n",
       "  '3725566.0',\n",
       "  '3745761.0',\n",
       "  '3696886.0',\n",
       "  '3701427.0',\n",
       "  '3670820.0',\n",
       "  '3640265.0',\n",
       "  '3627322.0',\n",
       "  '3574210.0',\n",
       "  '3663855.0',\n",
       "  '3591113.0',\n",
       "  '3538539.0',\n",
       "  '3572413.0',\n",
       "  '3524928.0',\n",
       "  '3522666.0',\n",
       "  '3498442.0',\n",
       "  '3523648.0',\n",
       "  '3503752.0',\n",
       "  '3471980.0',\n",
       "  '3457734.0',\n",
       "  '3405003.0',\n",
       "  '3420937.0',\n",
       "  '3400371.0',\n",
       "  '3408320.0',\n",
       "  '3417672.0',\n",
       "  '3350895.0',\n",
       "  '3392186.0',\n",
       "  '3342055.0',\n",
       "  '3387724.0',\n",
       "  '3364236.0',\n",
       "  '3285680.0',\n",
       "  '3272809.0',\n",
       "  '3303584.0',\n",
       "  '3226868.0',\n",
       "  '3250217.0',\n",
       "  '3296341.0',\n",
       "  '3256854.0',\n",
       "  '3214578.0',\n",
       "  '3199457.0',\n",
       "  '3214982.0',\n",
       "  '3166264.0',\n",
       "  '3190944.0',\n",
       "  '3153454.0',\n",
       "  '3161783.0',\n",
       "  '3124180.0',\n",
       "  '3147553.0',\n",
       "  '3151528.0',\n",
       "  '3144492.0',\n",
       "  '3160958.0',\n",
       "  '3089482.0',\n",
       "  '3077849.0',\n",
       "  '3078480.0',\n",
       "  '3050934.0',\n",
       "  '3052508.0',\n",
       "  '3055503.0',\n",
       "  '3028320.0',\n",
       "  '3039186.0',\n",
       "  '3008838.0',\n",
       "  '3019790.0',\n",
       "  '2981492.0',\n",
       "  '2971915.0',\n",
       "  '2969834.0',\n",
       "  '2948257.0',\n",
       "  '2930083.0',\n",
       "  '2948914.0',\n",
       "  '2919696.0',\n",
       "  '2935377.0',\n",
       "  '2890336.0',\n",
       "  '2870986.0',\n",
       "  '2870278.0',\n",
       "  '2881179.0',\n",
       "  '2872737.0',\n",
       "  '2871438.0',\n",
       "  '2854257.0',\n",
       "  '2790112.0',\n",
       "  '2824485.0',\n",
       "  '2814743.0',\n",
       "  '2802968.0',\n",
       "  '2799793.0',\n",
       "  '2814145.0',\n",
       "  '2851942.0',\n",
       "  '2800065.0',\n",
       "  '2785106.0',\n",
       "  '2780180.0',\n",
       "  '2780619.0',\n",
       "  '2791923.0',\n",
       "  '2732154.0',\n",
       "  '2733607.0',\n",
       "  '2737083.0',\n",
       "  '2717650.0',\n",
       "  '2697423.0',\n",
       "  '2706938.0',\n",
       "  '2707609.0',\n",
       "  '2681006.0',\n",
       "  '2683420.0',\n",
       "  '2679773.0',\n",
       "  '2671078.0',\n",
       "  '2648008.0',\n",
       "  '2657006.0',\n",
       "  '2657097.0',\n",
       "  '2627216.0',\n",
       "  '2619869.0',\n",
       "  '2620297.0',\n",
       "  '2598437.0',\n",
       "  '2610172.0',\n",
       "  '2597846.0',\n",
       "  '2588350.0',\n",
       "  '2571593.0',\n",
       "  '2585270.0',\n",
       "  '2547578.0',\n",
       "  '2556228.0',\n",
       "  '2537565.0',\n",
       "  '2536045.0',\n",
       "  '2531201.0',\n",
       "  '2541572.0',\n",
       "  '2544261.0',\n",
       "  '2525410.0',\n",
       "  '2549737.0',\n",
       "  '2488910.0',\n",
       "  '2472894.0',\n",
       "  '2502730.0',\n",
       "  '2488037.0',\n",
       "  '2465519.0',\n",
       "  '2482039.0',\n",
       "  '2459343.0',\n",
       "  '2467060.0',\n",
       "  '2446806.0',\n",
       "  '2453907.0',\n",
       "  '2423557.0',\n",
       "  '2472127.0',\n",
       "  '2461035.0',\n",
       "  '2464759.0',\n",
       "  '2467648.0',\n",
       "  '2420361.0',\n",
       "  '2393306.0',\n",
       "  '2420212.0',\n",
       "  '2391623.0',\n",
       "  '2375937.0',\n",
       "  '2362100.0',\n",
       "  '2343349.0',\n",
       "  '2353676.0',\n",
       "  '2354418.0',\n",
       "  '2363764.0',\n",
       "  '2374772.0',\n",
       "  '2321844.0',\n",
       "  '2335339.0',\n",
       "  '2318334.0',\n",
       "  '2328175.0',\n",
       "  '2299515.0',\n",
       "  '2330644.0',\n",
       "  '2324739.0',\n",
       "  '2308411.0',\n",
       "  '2285841.0',\n",
       "  '2282146.0',\n",
       "  '2305035.0',\n",
       "  '2269177.0',\n",
       "  '2262741.0',\n",
       "  '2256550.0'],\n",
       " 'val_false_negatives': ['8851754.0',\n",
       "  '7237421.0',\n",
       "  '3679141.0',\n",
       "  '3362991.0',\n",
       "  '9913514.0',\n",
       "  '3462292.0',\n",
       "  '7297637.0',\n",
       "  '4792872.0',\n",
       "  '4348781.0',\n",
       "  '15825595.0',\n",
       "  '7032006.0',\n",
       "  '4923645.0',\n",
       "  '4507543.0',\n",
       "  '4483273.0',\n",
       "  '6801397.0',\n",
       "  '6438257.0',\n",
       "  '12429828.0',\n",
       "  '5053912.0',\n",
       "  '4017818.0',\n",
       "  '3943181.0',\n",
       "  '5944726.0',\n",
       "  '5869113.0',\n",
       "  '6079232.0',\n",
       "  '8435806.0',\n",
       "  '7374033.0',\n",
       "  '7312886.0',\n",
       "  '7922662.0',\n",
       "  '6120405.0',\n",
       "  '8034445.0',\n",
       "  '6742119.0',\n",
       "  '5381316.0',\n",
       "  '7004659.0',\n",
       "  '5397325.0',\n",
       "  '6646050.0',\n",
       "  '6559521.0',\n",
       "  '6200927.0',\n",
       "  '6651964.0',\n",
       "  '6606818.0',\n",
       "  '4672042.0',\n",
       "  '5724489.0',\n",
       "  '7192793.0',\n",
       "  '5665198.0',\n",
       "  '7167131.0',\n",
       "  '7211865.0',\n",
       "  '5555375.0',\n",
       "  '7374142.0',\n",
       "  '7175543.0',\n",
       "  '7238884.0',\n",
       "  '4391015.0',\n",
       "  '4083851.0',\n",
       "  '4909676.0',\n",
       "  '4137891.0',\n",
       "  '4873532.0',\n",
       "  '4311807.0',\n",
       "  '4515256.0',\n",
       "  '5443997.0',\n",
       "  '4037752.0',\n",
       "  '4417087.0',\n",
       "  '5212937.0',\n",
       "  '5509264.0',\n",
       "  '4880562.0',\n",
       "  '4717113.0',\n",
       "  '4174647.0',\n",
       "  '5284727.0',\n",
       "  '4678049.0',\n",
       "  '4404009.0',\n",
       "  '4882457.0',\n",
       "  '4256534.0',\n",
       "  '5328217.0',\n",
       "  '6620081.0',\n",
       "  '5779911.0',\n",
       "  '4922173.0',\n",
       "  '4263487.0',\n",
       "  '4831756.0',\n",
       "  '5068548.0',\n",
       "  '5134937.0',\n",
       "  '4849707.0',\n",
       "  '4871201.0',\n",
       "  '5709995.0',\n",
       "  '4364945.0',\n",
       "  '4859781.0',\n",
       "  '5362147.0',\n",
       "  '4827539.0',\n",
       "  '4485626.0',\n",
       "  '5307799.0',\n",
       "  '4255472.0',\n",
       "  '4323036.0',\n",
       "  '4140038.0',\n",
       "  '4725118.0',\n",
       "  '6366061.0',\n",
       "  '4541184.0',\n",
       "  '5019541.0',\n",
       "  '4398084.0',\n",
       "  '4260752.0',\n",
       "  '4731966.0',\n",
       "  '4077258.0',\n",
       "  '3997543.0',\n",
       "  '3828801.0',\n",
       "  '3779963.0',\n",
       "  '4805478.0',\n",
       "  '4099892.0',\n",
       "  '4816332.0',\n",
       "  '4448775.0',\n",
       "  '3923283.0',\n",
       "  '4466386.0',\n",
       "  '3983785.0',\n",
       "  '4019699.0',\n",
       "  '4195031.0',\n",
       "  '4277085.0',\n",
       "  '4398924.0',\n",
       "  '4972009.0',\n",
       "  '4151176.0',\n",
       "  '4817497.0',\n",
       "  '4454201.0',\n",
       "  '4622399.0',\n",
       "  '4133972.0',\n",
       "  '4059752.0',\n",
       "  '4425233.0',\n",
       "  '4386014.0',\n",
       "  '4723219.0',\n",
       "  '4323671.0',\n",
       "  '4125756.0',\n",
       "  '4299205.0',\n",
       "  '4408369.0',\n",
       "  '4919555.0',\n",
       "  '4104398.0',\n",
       "  '3745912.0',\n",
       "  '4293373.0',\n",
       "  '4662822.0',\n",
       "  '3834225.0',\n",
       "  '3854301.0',\n",
       "  '4505818.0',\n",
       "  '3873416.0',\n",
       "  '4174883.0',\n",
       "  '3956546.0',\n",
       "  '3903798.0',\n",
       "  '3640779.0',\n",
       "  '4269425.0',\n",
       "  '4158451.0',\n",
       "  '4181506.0',\n",
       "  '4285346.0',\n",
       "  '4721465.0',\n",
       "  '3782813.0',\n",
       "  '4042456.0',\n",
       "  '4083054.0',\n",
       "  '4067203.0',\n",
       "  '4159970.0',\n",
       "  '3627388.0',\n",
       "  '4073743.0',\n",
       "  '4248326.0',\n",
       "  '4022974.0',\n",
       "  '4068191.0',\n",
       "  '3910098.0',\n",
       "  '4006225.0',\n",
       "  '3910667.0',\n",
       "  '4093077.0',\n",
       "  '3832406.0',\n",
       "  '4093079.0',\n",
       "  '3807113.0',\n",
       "  '4156799.0',\n",
       "  '3975219.0',\n",
       "  '3906967.0',\n",
       "  '3915282.0',\n",
       "  '3672975.0',\n",
       "  '3757701.0',\n",
       "  '3885812.0',\n",
       "  '3951036.0',\n",
       "  '3942104.0',\n",
       "  '3907745.0',\n",
       "  '4217597.0',\n",
       "  '3659413.0',\n",
       "  '4226772.0',\n",
       "  '3809376.0',\n",
       "  '3826343.0',\n",
       "  '4065343.0',\n",
       "  '4035276.0',\n",
       "  '3836654.0',\n",
       "  '3964954.0',\n",
       "  '3593952.0',\n",
       "  '4222464.0',\n",
       "  '3779069.0',\n",
       "  '4403358.0',\n",
       "  '4055663.0',\n",
       "  '3770166.0',\n",
       "  '3833913.0',\n",
       "  '3715323.0',\n",
       "  '3976984.0',\n",
       "  '3802905.0',\n",
       "  '3815686.0',\n",
       "  '3602536.0',\n",
       "  '3600022.0',\n",
       "  '3819738.0',\n",
       "  '3667189.0',\n",
       "  '3847634.0',\n",
       "  '3945320.0',\n",
       "  '3882817.0',\n",
       "  '3914452.0',\n",
       "  '4022807.0',\n",
       "  '3570578.0',\n",
       "  '3684307.0',\n",
       "  '3598006.0',\n",
       "  '4053576.0',\n",
       "  '3641939.0',\n",
       "  '4165202.0',\n",
       "  '3856103.0',\n",
       "  '4002054.0',\n",
       "  '3932562.0',\n",
       "  '3981526.0',\n",
       "  '3685156.0',\n",
       "  '3985841.0',\n",
       "  '3765053.0',\n",
       "  '3681856.0',\n",
       "  '4017687.0',\n",
       "  '4030852.0',\n",
       "  '4097469.0',\n",
       "  '3776639.0',\n",
       "  '3934714.0',\n",
       "  '4005198.0',\n",
       "  '3735626.0',\n",
       "  '3681517.0',\n",
       "  '3512221.0',\n",
       "  '3727722.0',\n",
       "  '4069980.0',\n",
       "  '3693351.0',\n",
       "  '3930117.0',\n",
       "  '3991730.0',\n",
       "  '4141527.0',\n",
       "  '3495998.0',\n",
       "  '3920567.0',\n",
       "  '3805576.0',\n",
       "  '4101306.0',\n",
       "  '3812515.0',\n",
       "  '4135232.0',\n",
       "  '3674059.0',\n",
       "  '4009458.0',\n",
       "  '3446657.0',\n",
       "  '3725783.0',\n",
       "  '3821632.0',\n",
       "  '3756677.0',\n",
       "  '3977635.0',\n",
       "  '3953346.0',\n",
       "  '3588100.0',\n",
       "  '3740698.0',\n",
       "  '3667972.0',\n",
       "  '3875219.0',\n",
       "  '3971746.0',\n",
       "  '3717691.0',\n",
       "  '3585060.0',\n",
       "  '3833637.0',\n",
       "  '3664065.0',\n",
       "  '3549449.0',\n",
       "  '3582448.0',\n",
       "  '3837162.0',\n",
       "  '3707448.0',\n",
       "  '3625418.0',\n",
       "  '3906031.0',\n",
       "  '3624403.0',\n",
       "  '3613424.0',\n",
       "  '3854231.0',\n",
       "  '3714308.0',\n",
       "  '3651075.0',\n",
       "  '3587633.0',\n",
       "  '3612929.0',\n",
       "  '3585531.0',\n",
       "  '3584905.0',\n",
       "  '3637206.0',\n",
       "  '3815304.0',\n",
       "  '3561362.0',\n",
       "  '3974073.0',\n",
       "  '3607607.0',\n",
       "  '4006192.0',\n",
       "  '3713291.0',\n",
       "  '3880041.0',\n",
       "  '3441981.0',\n",
       "  '3432880.0',\n",
       "  '3649593.0',\n",
       "  '3639290.0',\n",
       "  '3614906.0',\n",
       "  '3700470.0',\n",
       "  '3695401.0',\n",
       "  '3612131.0',\n",
       "  '3764174.0',\n",
       "  '3603080.0',\n",
       "  '3782310.0',\n",
       "  '3704335.0',\n",
       "  '3598604.0',\n",
       "  '3639829.0',\n",
       "  '3875966.0',\n",
       "  '3627405.0',\n",
       "  '3775872.0',\n",
       "  '3670300.0',\n",
       "  '3704838.0',\n",
       "  '3708258.0',\n",
       "  '3419039.0',\n",
       "  '3572159.0',\n",
       "  '3835599.0',\n",
       "  '3652833.0',\n",
       "  '3525975.0',\n",
       "  '3701828.0',\n",
       "  '3522083.0',\n",
       "  '3566638.0'],\n",
       " 'false_negatives': ['19900488.0',\n",
       "  '19967952.0',\n",
       "  '18638656.0',\n",
       "  '18125208.0',\n",
       "  '17931140.0',\n",
       "  '17078148.0',\n",
       "  '16733604.0',\n",
       "  '16100101.0',\n",
       "  '16425623.0',\n",
       "  '15566396.0',\n",
       "  '15370898.0',\n",
       "  '15081117.0',\n",
       "  '14547673.0',\n",
       "  '14474606.0',\n",
       "  '14200654.0',\n",
       "  '13956604.0',\n",
       "  '13695691.0',\n",
       "  '13758712.0',\n",
       "  '13814412.0',\n",
       "  '13334564.0',\n",
       "  '13774491.0',\n",
       "  '12456214.0',\n",
       "  '11824045.0',\n",
       "  '11292713.0',\n",
       "  '10695585.0',\n",
       "  '10409802.0',\n",
       "  '10179642.0',\n",
       "  '10076909.0',\n",
       "  '9755018.0',\n",
       "  '9449476.0',\n",
       "  '9256750.0',\n",
       "  '9079421.0',\n",
       "  '8936645.0',\n",
       "  '8805240.0',\n",
       "  '8580699.0',\n",
       "  '8422407.0',\n",
       "  '8313276.0',\n",
       "  '8098081.0',\n",
       "  '7992009.0',\n",
       "  '7895927.0',\n",
       "  '7721942.0',\n",
       "  '7698929.0',\n",
       "  '7716311.0',\n",
       "  '7479139.0',\n",
       "  '7439621.0',\n",
       "  '7292541.0',\n",
       "  '7151389.0',\n",
       "  '7075720.0',\n",
       "  '6998804.0',\n",
       "  '6994768.0',\n",
       "  '6944451.0',\n",
       "  '6756795.0',\n",
       "  '6601561.0',\n",
       "  '6641210.0',\n",
       "  '6585380.0',\n",
       "  '6545674.0',\n",
       "  '6551179.0',\n",
       "  '6399873.0',\n",
       "  '6344825.0',\n",
       "  '6221096.0',\n",
       "  '6222892.0',\n",
       "  '6152393.0',\n",
       "  '6047171.0',\n",
       "  '5962358.0',\n",
       "  '5916113.0',\n",
       "  '5889951.0',\n",
       "  '5907227.0',\n",
       "  '5842164.0',\n",
       "  '5812179.0',\n",
       "  '5704159.0',\n",
       "  '5708037.0',\n",
       "  '5666645.0',\n",
       "  '5637824.0',\n",
       "  '5695352.0',\n",
       "  '5507007.0',\n",
       "  '5490982.0',\n",
       "  '5424925.0',\n",
       "  '5399117.0',\n",
       "  '5354359.0',\n",
       "  '5380905.0',\n",
       "  '5296792.0',\n",
       "  '5265047.0',\n",
       "  '5258341.0',\n",
       "  '5179859.0',\n",
       "  '5157383.0',\n",
       "  '5112826.0',\n",
       "  '5079390.0',\n",
       "  '4976309.0',\n",
       "  '5058277.0',\n",
       "  '4981623.0',\n",
       "  '4930250.0',\n",
       "  '4907744.0',\n",
       "  '4887910.0',\n",
       "  '4840680.0',\n",
       "  '4824698.0',\n",
       "  '4757637.0',\n",
       "  '4771950.0',\n",
       "  '4786496.0',\n",
       "  '4753429.0',\n",
       "  '4672542.0',\n",
       "  '4633946.0',\n",
       "  '4669383.0',\n",
       "  '4650407.0',\n",
       "  '4586364.0',\n",
       "  '4597953.0',\n",
       "  '4578510.0',\n",
       "  '4426219.0',\n",
       "  '4387830.0',\n",
       "  '4437575.0',\n",
       "  '4431659.0',\n",
       "  '4398581.0',\n",
       "  '4354285.0',\n",
       "  '4283788.0',\n",
       "  '4409442.0',\n",
       "  '4331404.0',\n",
       "  '4292143.0',\n",
       "  '4306548.0',\n",
       "  '4212304.0',\n",
       "  '4218108.0',\n",
       "  '4254941.0',\n",
       "  '4141013.0',\n",
       "  '4136190.0',\n",
       "  '4129769.0',\n",
       "  '4155481.0',\n",
       "  '4090377.0',\n",
       "  '4174135.0',\n",
       "  '4085929.0',\n",
       "  '3971176.0',\n",
       "  '3973600.0',\n",
       "  '3974138.0',\n",
       "  '3979753.0',\n",
       "  '3948602.0',\n",
       "  '3937098.0',\n",
       "  '3896461.0',\n",
       "  '3884075.0',\n",
       "  '3880238.0',\n",
       "  '3888314.0',\n",
       "  '3881591.0',\n",
       "  '3849760.0',\n",
       "  '3814971.0',\n",
       "  '3825096.0',\n",
       "  '3801381.0',\n",
       "  '3775301.0',\n",
       "  '3778853.0',\n",
       "  '3757482.0',\n",
       "  '3729971.0',\n",
       "  '3730972.0',\n",
       "  '3733321.0',\n",
       "  '3682265.0',\n",
       "  '3664363.0',\n",
       "  '3622166.0',\n",
       "  '3625748.0',\n",
       "  '3600609.0',\n",
       "  '3571582.0',\n",
       "  '3543061.0',\n",
       "  '3523531.0',\n",
       "  '3501227.0',\n",
       "  '3489810.0',\n",
       "  '3579801.0',\n",
       "  '3551397.0',\n",
       "  '3507038.0',\n",
       "  '3476990.0',\n",
       "  '3505537.0',\n",
       "  '3434011.0',\n",
       "  '3420299.0',\n",
       "  '3441011.0',\n",
       "  '3379333.0',\n",
       "  '3420794.0',\n",
       "  '3382089.0',\n",
       "  '3397677.0',\n",
       "  '3411008.0',\n",
       "  '3324052.0',\n",
       "  '3350064.0',\n",
       "  '3280082.0',\n",
       "  '3306630.0',\n",
       "  '3271547.0',\n",
       "  '3286013.0',\n",
       "  '3214479.0',\n",
       "  '3283885.0',\n",
       "  '3242600.0',\n",
       "  '3238921.0',\n",
       "  '3160728.0',\n",
       "  '3204691.0',\n",
       "  '3199423.0',\n",
       "  '3199192.0',\n",
       "  '3168139.0',\n",
       "  '3144432.0',\n",
       "  '3118269.0',\n",
       "  '3161487.0',\n",
       "  '3177523.0',\n",
       "  '3155487.0',\n",
       "  '3154906.0',\n",
       "  '3136134.0',\n",
       "  '3089563.0',\n",
       "  '3078381.0',\n",
       "  '3070897.0',\n",
       "  '3060126.0',\n",
       "  '3061035.0',\n",
       "  '3028634.0',\n",
       "  '3013764.0',\n",
       "  '3030603.0',\n",
       "  '3011872.0',\n",
       "  '2976513.0',\n",
       "  '2965596.0',\n",
       "  '2974227.0',\n",
       "  '2952696.0',\n",
       "  '2967524.0',\n",
       "  '2935602.0',\n",
       "  '2969994.0',\n",
       "  '2924641.0',\n",
       "  '2901695.0',\n",
       "  '2863919.0',\n",
       "  '2887874.0',\n",
       "  '2895362.0',\n",
       "  '2870677.0',\n",
       "  '2834042.0',\n",
       "  '2842906.0',\n",
       "  '2857141.0',\n",
       "  '2844481.0',\n",
       "  '2784641.0',\n",
       "  '2799859.0',\n",
       "  '2790885.0',\n",
       "  '2836969.0',\n",
       "  '2779580.0',\n",
       "  '2808618.0',\n",
       "  '2798226.0',\n",
       "  '2761038.0',\n",
       "  '2812276.0',\n",
       "  '2776870.0',\n",
       "  '2735230.0',\n",
       "  '2712106.0',\n",
       "  '2723699.0',\n",
       "  '2710047.0',\n",
       "  '2727516.0',\n",
       "  '2667492.0',\n",
       "  '2693101.0',\n",
       "  '2677470.0',\n",
       "  '2694406.0',\n",
       "  '2652483.0',\n",
       "  '2646931.0',\n",
       "  '2665805.0',\n",
       "  '2622465.0',\n",
       "  '2629733.0',\n",
       "  '2634946.0',\n",
       "  '2613577.0',\n",
       "  '2600066.0',\n",
       "  '2581945.0',\n",
       "  '2600954.0',\n",
       "  '2609746.0',\n",
       "  '2589062.0',\n",
       "  '2557613.0',\n",
       "  '2560945.0',\n",
       "  '2562371.0',\n",
       "  '2570496.0',\n",
       "  '2522806.0',\n",
       "  '2566710.0',\n",
       "  '2536195.0',\n",
       "  '2526659.0',\n",
       "  '2520332.0',\n",
       "  '2543439.0',\n",
       "  '2502508.0',\n",
       "  '2516789.0',\n",
       "  '2454100.0',\n",
       "  '2480853.0',\n",
       "  '2477781.0',\n",
       "  '2462479.0',\n",
       "  '2466692.0',\n",
       "  '2446730.0',\n",
       "  '2455142.0',\n",
       "  '2460500.0',\n",
       "  '2422895.0',\n",
       "  '2423496.0',\n",
       "  '2465940.0',\n",
       "  '2449502.0',\n",
       "  '2467842.0',\n",
       "  '2424521.0',\n",
       "  '2399873.0',\n",
       "  '2375769.0',\n",
       "  '2379899.0',\n",
       "  '2390066.0',\n",
       "  '2385008.0',\n",
       "  '2373792.0',\n",
       "  '2351293.0',\n",
       "  '2328959.0',\n",
       "  '2350035.0',\n",
       "  '2321748.0',\n",
       "  '2381085.0',\n",
       "  '2360157.0',\n",
       "  '2308323.0',\n",
       "  '2315825.0',\n",
       "  '2319660.0',\n",
       "  '2294015.0',\n",
       "  '2320784.0',\n",
       "  '2333152.0',\n",
       "  '2262419.0',\n",
       "  '2266169.0',\n",
       "  '2299723.0',\n",
       "  '2270489.0',\n",
       "  '2249524.0',\n",
       "  '2260259.0',\n",
       "  '2241727.0'],\n",
       " 'binary_iou': ['0.6463431119918823',\n",
       "  '0.7348068356513977',\n",
       "  '0.747620701789856',\n",
       "  '0.7613716125488281',\n",
       "  '0.7696713209152222',\n",
       "  '0.7784072160720825',\n",
       "  '0.7826745510101318',\n",
       "  '0.7889226675033569',\n",
       "  '0.7956593036651611',\n",
       "  '0.8033660054206848',\n",
       "  '0.8057264089584351',\n",
       "  '0.8126584887504578',\n",
       "  '0.8151732683181763',\n",
       "  '0.8180391788482666',\n",
       "  '0.8203401565551758',\n",
       "  '0.8267014622688293',\n",
       "  '0.8284687399864197',\n",
       "  '0.8306362628936768',\n",
       "  '0.8303505182266235',\n",
       "  '0.8356871604919434',\n",
       "  '0.8307786583900452',\n",
       "  '0.8457794785499573',\n",
       "  '0.8553969860076904',\n",
       "  '0.8614142537117004',\n",
       "  '0.868125319480896',\n",
       "  '0.8725545406341553',\n",
       "  '0.8760201334953308',\n",
       "  '0.8778135776519775',\n",
       "  '0.8815160393714905',\n",
       "  '0.8850257396697998',\n",
       "  '0.888355553150177',\n",
       "  '0.8903061151504517',\n",
       "  '0.8920028209686279',\n",
       "  '0.8941923379898071',\n",
       "  '0.8958249688148499',\n",
       "  '0.8980337381362915',\n",
       "  '0.8993145227432251',\n",
       "  '0.9015920758247375',\n",
       "  '0.9026288986206055',\n",
       "  '0.9041920304298401',\n",
       "  '0.9057389497756958',\n",
       "  '0.9061377048492432',\n",
       "  '0.907437801361084',\n",
       "  '0.9095010757446289',\n",
       "  '0.9091638326644897',\n",
       "  '0.9118812084197998',\n",
       "  '0.9123821258544922',\n",
       "  '0.9134726524353027',\n",
       "  '0.914912223815918',\n",
       "  '0.9153347015380859',\n",
       "  '0.9149683713912964',\n",
       "  '0.9169280529022217',\n",
       "  '0.9189176559448242',\n",
       "  '0.9184274673461914',\n",
       "  '0.9194422960281372',\n",
       "  '0.9198662042617798',\n",
       "  '0.9201915860176086',\n",
       "  '0.9214795827865601',\n",
       "  '0.9223148226737976',\n",
       "  '0.9239821434020996',\n",
       "  '0.9231289625167847',\n",
       "  '0.9241070747375488',\n",
       "  '0.925462007522583',\n",
       "  '0.9264479875564575',\n",
       "  '0.9270750284194946',\n",
       "  '0.9272448420524597',\n",
       "  '0.9275543689727783',\n",
       "  '0.9281450510025024',\n",
       "  '0.9286621809005737',\n",
       "  '0.9291150569915771',\n",
       "  '0.9299004077911377',\n",
       "  '0.9303044080734253',\n",
       "  '0.9307574033737183',\n",
       "  '0.9304519891738892',\n",
       "  '0.9313454627990723',\n",
       "  '0.9322675466537476',\n",
       "  '0.9328056573867798',\n",
       "  '0.9331461191177368',\n",
       "  '0.9341280460357666',\n",
       "  '0.9338160157203674',\n",
       "  '0.9347089529037476',\n",
       "  '0.9344909191131592',\n",
       "  '0.9349321722984314',\n",
       "  '0.9354203939437866',\n",
       "  '0.9363428354263306',\n",
       "  '0.9364622831344604',\n",
       "  '0.9370462894439697',\n",
       "  '0.9379115104675293',\n",
       "  '0.9373600482940674',\n",
       "  '0.9381507039070129',\n",
       "  '0.9390319585800171',\n",
       "  '0.9392772316932678',\n",
       "  '0.9393184185028076',\n",
       "  '0.9399396181106567',\n",
       "  '0.9398436546325684',\n",
       "  '0.9402405023574829',\n",
       "  '0.9409937262535095',\n",
       "  '0.9406806230545044',\n",
       "  '0.9411288499832153',\n",
       "  '0.9412825703620911',\n",
       "  '0.9418526887893677',\n",
       "  '0.9420011043548584',\n",
       "  '0.942203164100647',\n",
       "  '0.9428107142448425',\n",
       "  '0.9428485035896301',\n",
       "  '0.9431092143058777',\n",
       "  '0.9442176818847656',\n",
       "  '0.944657564163208',\n",
       "  '0.9447546005249023',\n",
       "  '0.9444881677627563',\n",
       "  '0.9451987147331238',\n",
       "  '0.9454934597015381',\n",
       "  '0.9459710121154785',\n",
       "  '0.9451897740364075',\n",
       "  '0.9458852410316467',\n",
       "  '0.946039080619812',\n",
       "  '0.9464861154556274',\n",
       "  '0.9470257759094238',\n",
       "  '0.9473624229431152',\n",
       "  '0.9470081329345703',\n",
       "  '0.9479737281799316',\n",
       "  '0.9483059644699097',\n",
       "  '0.9481172561645508',\n",
       "  '0.9480379819869995',\n",
       "  '0.9486700892448425',\n",
       "  '0.9483453631401062',\n",
       "  '0.9491568803787231',\n",
       "  '0.9494479298591614',\n",
       "  '0.9502225518226624',\n",
       "  '0.9501833319664001',\n",
       "  '0.9501864910125732',\n",
       "  '0.950194776058197',\n",
       "  '0.9505174160003662',\n",
       "  '0.9510514140129089',\n",
       "  '0.9512079358100891',\n",
       "  '0.9512725472450256',\n",
       "  '0.951006293296814',\n",
       "  '0.9512829780578613',\n",
       "  '0.9515807628631592',\n",
       "  '0.9520518779754639',\n",
       "  '0.9521178007125854',\n",
       "  '0.952293336391449',\n",
       "  '0.9522887468338013',\n",
       "  '0.9525346755981445',\n",
       "  '0.9527779221534729',\n",
       "  '0.9528325796127319',\n",
       "  '0.9531174302101135',\n",
       "  '0.9530863165855408',\n",
       "  '0.9535777568817139',\n",
       "  '0.953882098197937',\n",
       "  '0.9542238116264343',\n",
       "  '0.9545319676399231',\n",
       "  '0.9541395902633667',\n",
       "  '0.954757034778595',\n",
       "  '0.955251932144165',\n",
       "  '0.9551671743392944',\n",
       "  '0.9555932283401489',\n",
       "  '0.9556859731674194',\n",
       "  '0.9552804231643677',\n",
       "  '0.9552948474884033',\n",
       "  '0.9556993246078491',\n",
       "  '0.9560810327529907',\n",
       "  '0.9559879899024963',\n",
       "  '0.956756591796875',\n",
       "  '0.956744909286499',\n",
       "  '0.9567466974258423',\n",
       "  '0.95708167552948',\n",
       "  '0.9567611217498779',\n",
       "  '0.9574123620986938',\n",
       "  '0.9570596218109131',\n",
       "  '0.9572944641113281',\n",
       "  '0.9575443267822266',\n",
       "  '0.9575228691101074',\n",
       "  '0.9584395289421082',\n",
       "  '0.9583616852760315',\n",
       "  '0.9583941102027893',\n",
       "  '0.9587695002555847',\n",
       "  '0.9590719938278198',\n",
       "  '0.9583548307418823',\n",
       "  '0.9588630199432373',\n",
       "  '0.9591360688209534',\n",
       "  '0.9597306251525879',\n",
       "  '0.9593549966812134',\n",
       "  '0.9596807956695557',\n",
       "  '0.9595361948013306',\n",
       "  '0.9599641561508179',\n",
       "  '0.9600595235824585',\n",
       "  '0.9604499340057373',\n",
       "  '0.9600396156311035',\n",
       "  '0.9599118232727051',\n",
       "  '0.9600924253463745',\n",
       "  '0.959997832775116',\n",
       "  '0.9605569839477539',\n",
       "  '0.9609225988388062',\n",
       "  '0.9609907269477844',\n",
       "  '0.9612011909484863',\n",
       "  '0.9612506628036499',\n",
       "  '0.9612300992012024',\n",
       "  '0.9616038203239441',\n",
       "  '0.9616371989250183',\n",
       "  '0.9617115259170532',\n",
       "  '0.9617648124694824',\n",
       "  '0.9622265100479126',\n",
       "  '0.9623495936393738',\n",
       "  '0.962309718132019',\n",
       "  '0.9625685214996338',\n",
       "  '0.9625928401947021',\n",
       "  '0.9626742601394653',\n",
       "  '0.9626451134681702',\n",
       "  '0.9628369212150574',\n",
       "  '0.9632529020309448',\n",
       "  '0.9636056423187256',\n",
       "  '0.9634585380554199',\n",
       "  '0.9633501768112183',\n",
       "  '0.9635521769523621',\n",
       "  '0.963796079158783',\n",
       "  '0.9638373851776123',\n",
       "  '0.9641528129577637',\n",
       "  '0.9640124440193176',\n",
       "  '0.9644572138786316',\n",
       "  '0.9644287824630737',\n",
       "  '0.9645090103149414',\n",
       "  '0.9641269445419312',\n",
       "  '0.9642531871795654',\n",
       "  '0.9643934965133667',\n",
       "  '0.9645569324493408',\n",
       "  '0.9648051261901855',\n",
       "  '0.9644951820373535',\n",
       "  '0.9646401405334473',\n",
       "  '0.9652748107910156',\n",
       "  '0.965410590171814',\n",
       "  '0.9653187990188599',\n",
       "  '0.9655271768569946',\n",
       "  '0.9655369520187378',\n",
       "  '0.9658544063568115',\n",
       "  '0.9656943678855896',\n",
       "  '0.9659565687179565',\n",
       "  '0.9658337235450745',\n",
       "  '0.9661163091659546',\n",
       "  '0.9662092924118042',\n",
       "  '0.9662353992462158',\n",
       "  '0.9664489030838013',\n",
       "  '0.9664077758789062',\n",
       "  '0.9665595889091492',\n",
       "  '0.9667350053787231',\n",
       "  '0.9668211936950684',\n",
       "  '0.9670693874359131',\n",
       "  '0.9668775796890259',\n",
       "  '0.9668961763381958',\n",
       "  '0.967085599899292',\n",
       "  '0.9673880934715271',\n",
       "  '0.967279314994812',\n",
       "  '0.9675093293190002',\n",
       "  '0.9673990607261658',\n",
       "  '0.9678204655647278',\n",
       "  '0.9675456285476685',\n",
       "  '0.9677739143371582',\n",
       "  '0.9677676558494568',\n",
       "  '0.9677947759628296',\n",
       "  '0.9677653908729553',\n",
       "  '0.9678707122802734',\n",
       "  '0.9681564569473267',\n",
       "  '0.968650758266449',\n",
       "  '0.9682900309562683',\n",
       "  '0.9684078693389893',\n",
       "  '0.9686489105224609',\n",
       "  '0.9685139656066895',\n",
       "  '0.968783438205719',\n",
       "  '0.9686816930770874',\n",
       "  '0.9687737226486206',\n",
       "  '0.9689664840698242',\n",
       "  '0.969149112701416',\n",
       "  '0.9685797691345215',\n",
       "  '0.9687550067901611',\n",
       "  '0.9686169624328613',\n",
       "  '0.9688738584518433',\n",
       "  '0.9693179130554199',\n",
       "  '0.9696440100669861',\n",
       "  '0.9694465398788452',\n",
       "  '0.9695612192153931',\n",
       "  '0.9696956872940063',\n",
       "  '0.9698456525802612',\n",
       "  '0.9701052904129028',\n",
       "  '0.970186710357666',\n",
       "  '0.9700493216514587',\n",
       "  '0.9701622724533081',\n",
       "  '0.9697232246398926',\n",
       "  '0.97017902135849',\n",
       "  '0.9704197645187378',\n",
       "  '0.9704894423484802',\n",
       "  '0.9704045057296753',\n",
       "  '0.9707427024841309',\n",
       "  '0.9703803062438965',\n",
       "  '0.9703353643417358',\n",
       "  '0.9708892107009888',\n",
       "  '0.971001148223877',\n",
       "  '0.9708172082901001',\n",
       "  '0.9708541631698608',\n",
       "  '0.9712101221084595',\n",
       "  '0.9711898565292358',\n",
       "  '0.9713348150253296'],\n",
       " 'loss': ['0.25298193097114563',\n",
       "  '0.17970937490463257',\n",
       "  '0.16944220662117004',\n",
       "  '0.15938016772270203',\n",
       "  '0.15386037528514862',\n",
       "  '0.14730830490589142',\n",
       "  '0.14401723444461823',\n",
       "  '0.13967755436897278',\n",
       "  '0.1352715641260147',\n",
       "  '0.12936197221279144',\n",
       "  '0.12777672708034515',\n",
       "  '0.12335705757141113',\n",
       "  '0.12128963321447372',\n",
       "  '0.11935042589902878',\n",
       "  '0.11748106777667999',\n",
       "  '0.11296495795249939',\n",
       "  '0.1116277351975441',\n",
       "  '0.11073320358991623',\n",
       "  '0.11055346578359604',\n",
       "  '0.10677679628133774',\n",
       "  '0.11020775139331818',\n",
       "  '0.09975660592317581',\n",
       "  '0.0935378223657608',\n",
       "  '0.0894191786646843',\n",
       "  '0.08441867679357529',\n",
       "  '0.08155381679534912',\n",
       "  '0.07915724068880081',\n",
       "  '0.07844380289316177',\n",
       "  '0.07533737272024155',\n",
       "  '0.07316134124994278',\n",
       "  '0.07119274884462357',\n",
       "  '0.06957931816577911',\n",
       "  '0.06880433857440948',\n",
       "  '0.06713059544563293',\n",
       "  '0.06614269316196442',\n",
       "  '0.06454344838857651',\n",
       "  '0.06352739781141281',\n",
       "  '0.06210588291287422',\n",
       "  '0.06124335527420044',\n",
       "  '0.0604797787964344',\n",
       "  '0.05925912410020828',\n",
       "  '0.059359148144721985',\n",
       "  '0.058401912450790405',\n",
       "  '0.05686119571328163',\n",
       "  '0.05698848143219948',\n",
       "  '0.055322013795375824',\n",
       "  '0.05488469824194908',\n",
       "  '0.05423285439610481',\n",
       "  '0.05342765152454376',\n",
       "  '0.05310150235891342',\n",
       "  '0.053259093314409256',\n",
       "  '0.05196375772356987',\n",
       "  '0.050651054829359055',\n",
       "  '0.05102226510643959',\n",
       "  '0.05042153224349022',\n",
       "  '0.05005910247564316',\n",
       "  '0.04988605156540871',\n",
       "  '0.049086082726716995',\n",
       "  '0.04858037456870079',\n",
       "  '0.04743805527687073',\n",
       "  '0.048179324716329575',\n",
       "  '0.047389645129442215',\n",
       "  '0.04667980968952179',\n",
       "  '0.04567601904273033',\n",
       "  '0.045331407338380814',\n",
       "  '0.04546033591032028',\n",
       "  '0.045165326446294785',\n",
       "  '0.04490531235933304',\n",
       "  '0.04451688006520271',\n",
       "  '0.044179368764162064',\n",
       "  '0.043642349541187286',\n",
       "  '0.04324305057525635',\n",
       "  '0.042909324169158936',\n",
       "  '0.04333086684346199',\n",
       "  '0.042637646198272705',\n",
       "  '0.04206259548664093',\n",
       "  '0.04178716242313385',\n",
       "  '0.04139517620205879',\n",
       "  '0.04087722301483154',\n",
       "  '0.041012492030858994',\n",
       "  '0.04040880128741264',\n",
       "  '0.04063909500837326',\n",
       "  '0.04024669900536537',\n",
       "  '0.03990807756781578',\n",
       "  '0.03947186842560768',\n",
       "  '0.03948971629142761',\n",
       "  '0.03897038474678993',\n",
       "  '0.038472533226013184',\n",
       "  '0.0388808511197567',\n",
       "  '0.038243088871240616',\n",
       "  '0.03778625279664993',\n",
       "  '0.0374939851462841',\n",
       "  '0.037650033831596375',\n",
       "  '0.03713776916265488',\n",
       "  '0.03717006742954254',\n",
       "  '0.03689578175544739',\n",
       "  '0.036380864679813385',\n",
       "  '0.03668750450015068',\n",
       "  '0.036511167883872986',\n",
       "  '0.03616529330611229',\n",
       "  '0.0358094647526741',\n",
       "  '0.035910651087760925',\n",
       "  '0.03576977550983429',\n",
       "  '0.03523630648851395',\n",
       "  '0.03528541326522827',\n",
       "  '0.03503312170505524',\n",
       "  '0.03434037044644356',\n",
       "  '0.03405272960662842',\n",
       "  '0.034186575561761856',\n",
       "  '0.034115344285964966',\n",
       "  '0.033719997853040695',\n",
       "  '0.033633362501859665',\n",
       "  '0.03327028453350067',\n",
       "  '0.03376934304833412',\n",
       "  '0.03337562084197998',\n",
       "  '0.03322942182421684',\n",
       "  '0.0329010970890522',\n",
       "  '0.03256067633628845',\n",
       "  '0.03230657801032066',\n",
       "  '0.0326424203813076',\n",
       "  '0.031988855451345444',\n",
       "  '0.03182803839445114',\n",
       "  '0.03201259672641754',\n",
       "  '0.03195665776729584',\n",
       "  '0.03154204785823822',\n",
       "  '0.03181702271103859',\n",
       "  '0.031236199662089348',\n",
       "  '0.031091155484318733',\n",
       "  '0.030587730929255486',\n",
       "  '0.030694084241986275',\n",
       "  '0.030709784477949142',\n",
       "  '0.030608592554926872',\n",
       "  '0.030400224030017853',\n",
       "  '0.02995280735194683',\n",
       "  '0.029955169185996056',\n",
       "  '0.029823295772075653',\n",
       "  '0.0301505159586668',\n",
       "  '0.02998911589384079',\n",
       "  '0.029631642624735832',\n",
       "  '0.02942471019923687',\n",
       "  '0.029456211254000664',\n",
       "  '0.02926347218453884',\n",
       "  '0.029269060119986534',\n",
       "  '0.0291194599121809',\n",
       "  '0.02887488156557083',\n",
       "  '0.028933987021446228',\n",
       "  '0.02876264415681362',\n",
       "  '0.02879377081990242',\n",
       "  '0.02842693403363228',\n",
       "  '0.028267063200473785',\n",
       "  '0.028050124645233154',\n",
       "  '0.027815895155072212',\n",
       "  '0.028151940554380417',\n",
       "  '0.027655677869915962',\n",
       "  '0.027402225881814957',\n",
       "  '0.02753579244017601',\n",
       "  '0.027193043380975723',\n",
       "  '0.027035370469093323',\n",
       "  '0.02741950750350952',\n",
       "  '0.027362549677491188',\n",
       "  '0.027141286060214043',\n",
       "  '0.02684197761118412',\n",
       "  '0.026949914172291756',\n",
       "  '0.026453619822859764',\n",
       "  '0.02653789333999157',\n",
       "  '0.026512756943702698',\n",
       "  '0.02627013996243477',\n",
       "  '0.02649555914103985',\n",
       "  '0.026049574837088585',\n",
       "  '0.026223544031381607',\n",
       "  '0.026102259755134583',\n",
       "  '0.02601204253733158',\n",
       "  '0.026011519134044647',\n",
       "  '0.025400273501873016',\n",
       "  '0.025432514026761055',\n",
       "  '0.025453517213463783',\n",
       "  '0.025237347930669785',\n",
       "  '0.025057435035705566',\n",
       "  '0.025517495349049568',\n",
       "  '0.025136135518550873',\n",
       "  '0.024966491386294365',\n",
       "  '0.024614546447992325',\n",
       "  '0.024860525503754616',\n",
       "  '0.02466304786503315',\n",
       "  '0.024760419502854347',\n",
       "  '0.0244610533118248',\n",
       "  '0.024419482797384262',\n",
       "  '0.024113750085234642',\n",
       "  '0.024364639073610306',\n",
       "  '0.024472786113619804',\n",
       "  '0.024284522980451584',\n",
       "  '0.02442179247736931',\n",
       "  '0.024051785469055176',\n",
       "  '0.023845814168453217',\n",
       "  '0.0238355565816164',\n",
       "  '0.0237477645277977',\n",
       "  '0.023641664534807205',\n",
       "  '0.023671846836805344',\n",
       "  '0.02347804605960846',\n",
       "  '0.023367898538708687',\n",
       "  '0.02338794432580471',\n",
       "  '0.023331087082624435',\n",
       "  '0.023118793964385986',\n",
       "  '0.02300393208861351',\n",
       "  '0.023024188354611397',\n",
       "  '0.022737283259630203',\n",
       "  '0.022799182683229446',\n",
       "  '0.022743115201592445',\n",
       "  '0.022742096334695816',\n",
       "  '0.022695431485772133',\n",
       "  '0.022346075624227524',\n",
       "  '0.022098196670413017',\n",
       "  '0.022262483835220337',\n",
       "  '0.022295206785202026',\n",
       "  '0.022260960191488266',\n",
       "  '0.022079939022660255',\n",
       "  '0.02204226702451706',\n",
       "  '0.02181226946413517',\n",
       "  '0.02198566310107708',\n",
       "  '0.02160509303212166',\n",
       "  '0.021674975752830505',\n",
       "  '0.021771440282464027',\n",
       "  '0.021848324686288834',\n",
       "  '0.021814528852701187',\n",
       "  '0.021694783121347427',\n",
       "  '0.021509965881705284',\n",
       "  '0.02141561172902584',\n",
       "  '0.021715613082051277',\n",
       "  '0.021523291245102882',\n",
       "  '0.021186692640185356',\n",
       "  '0.021051986142992973',\n",
       "  '0.021091332659125328',\n",
       "  '0.020963270217180252',\n",
       "  '0.02101760171353817',\n",
       "  '0.020862434059381485',\n",
       "  '0.02087472938001156',\n",
       "  '0.020755549892783165',\n",
       "  '0.02076469361782074',\n",
       "  '0.020626451820135117',\n",
       "  '0.020545991137623787',\n",
       "  '0.02056698314845562',\n",
       "  '0.020442644134163857',\n",
       "  '0.020444365218281746',\n",
       "  '0.020397920161485672',\n",
       "  '0.02027166076004505',\n",
       "  '0.020236508920788765',\n",
       "  '0.020067749544978142',\n",
       "  '0.02007519267499447',\n",
       "  '0.020170187577605247',\n",
       "  '0.020037593320012093',\n",
       "  '0.019843928515911102',\n",
       "  '0.019932905212044716',\n",
       "  '0.019728975370526314',\n",
       "  '0.01984328404068947',\n",
       "  '0.019544079899787903',\n",
       "  '0.019800538197159767',\n",
       "  '0.01957654394209385',\n",
       "  '0.01961866393685341',\n",
       "  '0.01960464008152485',\n",
       "  '0.01957906037569046',\n",
       "  '0.019605927169322968',\n",
       "  '0.019392583519220352',\n",
       "  '0.019025709480047226',\n",
       "  '0.01934180222451687',\n",
       "  '0.019213715568184853',\n",
       "  '0.019065704196691513',\n",
       "  '0.01910104975104332',\n",
       "  '0.018979066982865334',\n",
       "  '0.0190699715167284',\n",
       "  '0.01899358071386814',\n",
       "  '0.018863290548324585',\n",
       "  '0.01872098445892334',\n",
       "  '0.019087815657258034',\n",
       "  '0.01901715062558651',\n",
       "  '0.01909731887280941',\n",
       "  '0.018950389698147774',\n",
       "  '0.018677333369851112',\n",
       "  '0.018390804529190063',\n",
       "  '0.01858551613986492',\n",
       "  '0.018494045361876488',\n",
       "  '0.01839270442724228',\n",
       "  '0.018283557146787643',\n",
       "  '0.01821291074156761',\n",
       "  '0.0180937759578228',\n",
       "  '0.018169986084103584',\n",
       "  '0.018149053677916527',\n",
       "  '0.01845473423600197',\n",
       "  '0.01811436004936695',\n",
       "  '0.017980244010686874',\n",
       "  '0.017887592315673828',\n",
       "  '0.018056198954582214',\n",
       "  '0.017805663868784904',\n",
       "  '0.017993444576859474',\n",
       "  '0.018040742725133896',\n",
       "  '0.01764015667140484',\n",
       "  '0.017645591869950294',\n",
       "  '0.017720764502882957',\n",
       "  '0.017698783427476883',\n",
       "  '0.017493467777967453',\n",
       "  '0.01749074086546898',\n",
       "  '0.01736176572740078'],\n",
       " 'val_true_positives': ['36183816.0',\n",
       "  '37936588.0',\n",
       "  '41406300.0',\n",
       "  '41683936.0',\n",
       "  '35156024.0',\n",
       "  '41680636.0',\n",
       "  '37713636.0',\n",
       "  '40299460.0',\n",
       "  '40856560.0',\n",
       "  '29273444.0',\n",
       "  '38216200.0',\n",
       "  '40182664.0',\n",
       "  '40642440.0',\n",
       "  '40641952.0',\n",
       "  '38347908.0',\n",
       "  '38698016.0',\n",
       "  '32733368.0',\n",
       "  '39977888.0',\n",
       "  '41107320.0',\n",
       "  '41172792.0',\n",
       "  '39136048.0',\n",
       "  '39241244.0',\n",
       "  '38890768.0',\n",
       "  '36740352.0',\n",
       "  '37801488.0',\n",
       "  '37821720.0',\n",
       "  '37086832.0',\n",
       "  '39014384.0',\n",
       "  '37052692.0',\n",
       "  '38366088.0',\n",
       "  '39681324.0',\n",
       "  '38060028.0',\n",
       "  '39732704.0',\n",
       "  '38414088.0',\n",
       "  '38579700.0',\n",
       "  '38947864.0',\n",
       "  '38503968.0',\n",
       "  '38482804.0',\n",
       "  '40462768.0',\n",
       "  '39427800.0',\n",
       "  '38001772.0',\n",
       "  '39360844.0',\n",
       "  '37971728.0',\n",
       "  '37924304.0',\n",
       "  '39619136.0',\n",
       "  '37756504.0',\n",
       "  '37948540.0',\n",
       "  '37821568.0',\n",
       "  '40772680.0',\n",
       "  '41051852.0',\n",
       "  '40166796.0',\n",
       "  '41040476.0',\n",
       "  '40312048.0',\n",
       "  '40879444.0',\n",
       "  '40666132.0',\n",
       "  '39678008.0',\n",
       "  '41016612.0',\n",
       "  '40708744.0',\n",
       "  '39882548.0',\n",
       "  '39628516.0',\n",
       "  '40253084.0',\n",
       "  '40491824.0',\n",
       "  '40954904.0',\n",
       "  '39808800.0',\n",
       "  '40447092.0',\n",
       "  '40712612.0',\n",
       "  '40217396.0',\n",
       "  '40860812.0',\n",
       "  '39670904.0',\n",
       "  '38506796.0',\n",
       "  '39406496.0',\n",
       "  '40235800.0',\n",
       "  '40849704.0',\n",
       "  '40226168.0',\n",
       "  '40072232.0',\n",
       "  '40018788.0',\n",
       "  '40259408.0',\n",
       "  '40278660.0',\n",
       "  '39402556.0',\n",
       "  '40688928.0',\n",
       "  '40246868.0',\n",
       "  '39719364.0',\n",
       "  '40250888.0',\n",
       "  '40506000.0',\n",
       "  '39770140.0',\n",
       "  '40862840.0',\n",
       "  '40770092.0',\n",
       "  '41028432.0',\n",
       "  '40361652.0',\n",
       "  '38679812.0',\n",
       "  '40575024.0',\n",
       "  '40025704.0',\n",
       "  '40716256.0',\n",
       "  '40930880.0',\n",
       "  '40427384.0',\n",
       "  '41058668.0',\n",
       "  '41139564.0',\n",
       "  '41279044.0',\n",
       "  '41300664.0',\n",
       "  '40294264.0',\n",
       "  '41027936.0',\n",
       "  '40325340.0',\n",
       "  '40633532.0',\n",
       "  '41185892.0',\n",
       "  '40614952.0',\n",
       "  '41079212.0',\n",
       "  '41081364.0',\n",
       "  '40894608.0',\n",
       "  '40869436.0',\n",
       "  '40754128.0',\n",
       "  '40106208.0',\n",
       "  '40973048.0',\n",
       "  '40229208.0',\n",
       "  '40569468.0',\n",
       "  '40472488.0',\n",
       "  '41025252.0',\n",
       "  '41145660.0',\n",
       "  '40627280.0',\n",
       "  '40754492.0',\n",
       "  '40363136.0',\n",
       "  '40702264.0',\n",
       "  '41051032.0',\n",
       "  '40808588.0',\n",
       "  '40762016.0',\n",
       "  '40147552.0',\n",
       "  '40945824.0',\n",
       "  '41400384.0',\n",
       "  '40771548.0',\n",
       "  '40488488.0',\n",
       "  '41252936.0',\n",
       "  '41255220.0',\n",
       "  '40553900.0',\n",
       "  '41166852.0',\n",
       "  '41023680.0',\n",
       "  '41166504.0',\n",
       "  '41136628.0',\n",
       "  '41474620.0',\n",
       "  '40859644.0',\n",
       "  '40966956.0',\n",
       "  '40910736.0',\n",
       "  '40817276.0',\n",
       "  '40422340.0',\n",
       "  '41271528.0',\n",
       "  '41119728.0',\n",
       "  '40949936.0',\n",
       "  '41079236.0',\n",
       "  '40950520.0',\n",
       "  '41531848.0',\n",
       "  '41062588.0',\n",
       "  '40882960.0',\n",
       "  '41133632.0',\n",
       "  '41092612.0',\n",
       "  '41235320.0',\n",
       "  '41039228.0',\n",
       "  '41211216.0',\n",
       "  '41006880.0',\n",
       "  '41227084.0',\n",
       "  '40966972.0',\n",
       "  '41319120.0',\n",
       "  '40895800.0',\n",
       "  '41203288.0',\n",
       "  '41226444.0',\n",
       "  '41235644.0',\n",
       "  '41396272.0',\n",
       "  '41291284.0',\n",
       "  '41123112.0',\n",
       "  '41067920.0',\n",
       "  '41283888.0',\n",
       "  '41252068.0',\n",
       "  '40762280.0',\n",
       "  '41445524.0',\n",
       "  '40926720.0',\n",
       "  '41257456.0',\n",
       "  '41356084.0',\n",
       "  '41034720.0',\n",
       "  '41146240.0',\n",
       "  '41243624.0',\n",
       "  '41129644.0',\n",
       "  '41575972.0',\n",
       "  '40897308.0',\n",
       "  '41343176.0',\n",
       "  '40759760.0',\n",
       "  '40993664.0',\n",
       "  '41358824.0',\n",
       "  '41212236.0',\n",
       "  '41475832.0',\n",
       "  '41202804.0',\n",
       "  '41338408.0',\n",
       "  '41301604.0',\n",
       "  '41518312.0',\n",
       "  '41542956.0',\n",
       "  '41279984.0',\n",
       "  '41459544.0',\n",
       "  '41272912.0',\n",
       "  '41207412.0',\n",
       "  '41229376.0',\n",
       "  '41125112.0',\n",
       "  '41094436.0',\n",
       "  '41570352.0',\n",
       "  '41341228.0',\n",
       "  '41462712.0',\n",
       "  '41079872.0',\n",
       "  '41441860.0',\n",
       "  '40935580.0',\n",
       "  '41257772.0',\n",
       "  '41168108.0',\n",
       "  '41142248.0',\n",
       "  '41054212.0',\n",
       "  '41383000.0',\n",
       "  '41165656.0',\n",
       "  '41371720.0',\n",
       "  '41469468.0',\n",
       "  '41056252.0',\n",
       "  '41084784.0',\n",
       "  '41016200.0',\n",
       "  '41315712.0',\n",
       "  '41136544.0',\n",
       "  '41139272.0',\n",
       "  '41304984.0',\n",
       "  '41292596.0',\n",
       "  '41584860.0',\n",
       "  '41521412.0',\n",
       "  '41021128.0',\n",
       "  '41345120.0',\n",
       "  '41138532.0',\n",
       "  '41162456.0',\n",
       "  '40936864.0',\n",
       "  '41593056.0',\n",
       "  '41104464.0',\n",
       "  '41339968.0',\n",
       "  '40936456.0',\n",
       "  '41360056.0',\n",
       "  '40983572.0',\n",
       "  '41465048.0',\n",
       "  '41126904.0',\n",
       "  '41626148.0',\n",
       "  '41374424.0',\n",
       "  '41338272.0',\n",
       "  '41323232.0',\n",
       "  '41126668.0',\n",
       "  '41180528.0',\n",
       "  '41584196.0',\n",
       "  '41275312.0',\n",
       "  '41378220.0',\n",
       "  '41293516.0',\n",
       "  '41122408.0',\n",
       "  '41409512.0',\n",
       "  '41618788.0',\n",
       "  '41291124.0',\n",
       "  '41440504.0',\n",
       "  '41543104.0',\n",
       "  '41517344.0',\n",
       "  '41217736.0',\n",
       "  '41430336.0',\n",
       "  '41490552.0',\n",
       "  '41205800.0',\n",
       "  '41547612.0',\n",
       "  '41584316.0',\n",
       "  '41237916.0',\n",
       "  '41422060.0',\n",
       "  '41495024.0',\n",
       "  '41569632.0',\n",
       "  '41405056.0',\n",
       "  '41437632.0',\n",
       "  '41622512.0',\n",
       "  '41516388.0',\n",
       "  '41306892.0',\n",
       "  '41508476.0',\n",
       "  '41179000.0',\n",
       "  '41454112.0',\n",
       "  '41003172.0',\n",
       "  '41424740.0',\n",
       "  '41122468.0',\n",
       "  '41592052.0',\n",
       "  '41591380.0',\n",
       "  '41489672.0',\n",
       "  '41553100.0',\n",
       "  '41410120.0',\n",
       "  '41400224.0',\n",
       "  '41325852.0',\n",
       "  '41544864.0',\n",
       "  '41336620.0',\n",
       "  '41468872.0',\n",
       "  '41359216.0',\n",
       "  '41421144.0',\n",
       "  '41527412.0',\n",
       "  '41406008.0',\n",
       "  '41202840.0',\n",
       "  '41381116.0',\n",
       "  '41330056.0',\n",
       "  '41502376.0',\n",
       "  '41407480.0',\n",
       "  '41416184.0',\n",
       "  '41711576.0',\n",
       "  '41461224.0',\n",
       "  '41311176.0',\n",
       "  '41341124.0',\n",
       "  '41475908.0',\n",
       "  '41481992.0',\n",
       "  '41601732.0',\n",
       "  '41609896.0'],\n",
       " 'accuracy': ['0.7866721749305725',\n",
       "  '0.8502960205078125',\n",
       "  '0.8586176633834839',\n",
       "  '0.8675968050956726',\n",
       "  '0.8729592561721802',\n",
       "  '0.8784143328666687',\n",
       "  '0.8810575008392334',\n",
       "  '0.8848918080329895',\n",
       "  '0.8892213702201843',\n",
       "  '0.893817663192749',\n",
       "  '0.8952571153640747',\n",
       "  '0.8994724750518799',\n",
       "  '0.9008952975273132',\n",
       "  '0.9026272892951965',\n",
       "  '0.9039813876152039',\n",
       "  '0.9077730774879456',\n",
       "  '0.9087814092636108',\n",
       "  '0.9101096987724304',\n",
       "  '0.9099255800247192',\n",
       "  '0.9130255579948425',\n",
       "  '0.9101842641830444',\n",
       "  '0.9188379645347595',\n",
       "  '0.9243528842926025',\n",
       "  '0.9277404546737671',\n",
       "  '0.9315019249916077',\n",
       "  '0.9339674115180969',\n",
       "  '0.9358965754508972',\n",
       "  '0.9368982911109924',\n",
       "  '0.9389329552650452',\n",
       "  '0.9408616423606873',\n",
       "  '0.9426844716072083',\n",
       "  '0.9437398314476013',\n",
       "  '0.9446602463722229',\n",
       "  '0.9458666443824768',\n",
       "  '0.9467413425445557',\n",
       "  '0.9479352235794067',\n",
       "  '0.9486230611801147',\n",
       "  '0.9498308897018433',\n",
       "  '0.9503896236419678',\n",
       "  '0.9512351751327515',\n",
       "  '0.952052891254425',\n",
       "  '0.9522713422775269',\n",
       "  '0.9529857635498047',\n",
       "  '0.954078733921051',\n",
       "  '0.9538822174072266',\n",
       "  '0.9553405046463013',\n",
       "  '0.9556058049201965',\n",
       "  '0.9561804533004761',\n",
       "  '0.9569474458694458',\n",
       "  '0.9571662545204163',\n",
       "  '0.9569679498672485',\n",
       "  '0.9580029249191284',\n",
       "  '0.9590557813644409',\n",
       "  '0.9587987065315247',\n",
       "  '0.9593325853347778',\n",
       "  '0.9595559239387512',\n",
       "  '0.9597237706184387',\n",
       "  '0.9604030847549438',\n",
       "  '0.9608437418937683',\n",
       "  '0.9617250561714172',\n",
       "  '0.9612649083137512',\n",
       "  '0.961783766746521',\n",
       "  '0.9624940156936646',\n",
       "  '0.9630106091499329',\n",
       "  '0.9633328914642334',\n",
       "  '0.9634300470352173',\n",
       "  '0.9635903835296631',\n",
       "  '0.9638897180557251',\n",
       "  '0.9641643166542053',\n",
       "  '0.9643999934196472',\n",
       "  '0.9648113250732422',\n",
       "  '0.9650158882141113',\n",
       "  '0.9652544856071472',\n",
       "  '0.9651066660881042',\n",
       "  '0.9655526280403137',\n",
       "  '0.9660382270812988',\n",
       "  '0.9663198590278625',\n",
       "  '0.9664940237998962',\n",
       "  '0.9670131802558899',\n",
       "  '0.966839611530304',\n",
       "  '0.9673075675964355',\n",
       "  '0.9671878814697266',\n",
       "  '0.9674212336540222',\n",
       "  '0.9676727652549744',\n",
       "  '0.9681555032730103',\n",
       "  '0.9682132005691528',\n",
       "  '0.9685147404670715',\n",
       "  '0.9689568877220154',\n",
       "  '0.9686740636825562',\n",
       "  '0.969086229801178',\n",
       "  '0.9695460796356201',\n",
       "  '0.9696651697158813',\n",
       "  '0.9696887135505676',\n",
       "  '0.9700053930282593',\n",
       "  '0.9699566960334778',\n",
       "  '0.9701620936393738',\n",
       "  '0.9705491065979004',\n",
       "  '0.9703913331031799',\n",
       "  '0.9706234335899353',\n",
       "  '0.9706999063491821',\n",
       "  '0.9709877371788025',\n",
       "  '0.9710717797279358',\n",
       "  '0.9711788296699524',\n",
       "  '0.9714871048927307',\n",
       "  '0.9715031981468201',\n",
       "  '0.9716389179229736',\n",
       "  '0.97220778465271',\n",
       "  '0.9724256992340088',\n",
       "  '0.9724870920181274',\n",
       "  '0.9723404049873352',\n",
       "  '0.9727097153663635',\n",
       "  '0.97285395860672',\n",
       "  '0.9731056094169617',\n",
       "  '0.9727044105529785',\n",
       "  '0.9730615615844727',\n",
       "  '0.9731366634368896',\n",
       "  '0.9733731150627136',\n",
       "  '0.9736427068710327',\n",
       "  '0.9738155603408813',\n",
       "  '0.9736412167549133',\n",
       "  '0.9741281270980835',\n",
       "  '0.974296510219574',\n",
       "  '0.9742044806480408',\n",
       "  '0.9741623997688293',\n",
       "  '0.9744873046875',\n",
       "  '0.9743252396583557',\n",
       "  '0.9747347831726074',\n",
       "  '0.9748795032501221',\n",
       "  '0.9752750992774963',\n",
       "  '0.9752578735351562',\n",
       "  '0.9752590656280518',\n",
       "  '0.9752612709999084',\n",
       "  '0.9754300117492676',\n",
       "  '0.975700318813324',\n",
       "  '0.9757744073867798',\n",
       "  '0.975810170173645',\n",
       "  '0.9756794571876526',\n",
       "  '0.9758206605911255',\n",
       "  '0.9759688973426819',\n",
       "  '0.9762064814567566',\n",
       "  '0.9762402176856995',\n",
       "  '0.9763335585594177',\n",
       "  '0.9763255715370178',\n",
       "  '0.9764530062675476',\n",
       "  '0.9765798449516296',\n",
       "  '0.9766028523445129',\n",
       "  '0.9767524600028992',\n",
       "  '0.9767316579818726',\n",
       "  '0.976987361907959',\n",
       "  '0.9771389365196228',\n",
       "  '0.9773113131523132',\n",
       "  '0.9774660468101501',\n",
       "  '0.9772643446922302',\n",
       "  '0.977583110332489',\n",
       "  '0.9778372049331665',\n",
       "  '0.977791965007782',\n",
       "  '0.9780105948448181',\n",
       "  '0.9780532121658325',\n",
       "  '0.9778478145599365',\n",
       "  '0.9778573513031006',\n",
       "  '0.9780583381652832',\n",
       "  '0.9782520532608032',\n",
       "  '0.978206992149353',\n",
       "  '0.9785961508750916',\n",
       "  '0.9785886406898499',\n",
       "  '0.9785885214805603',\n",
       "  '0.9787567853927612',\n",
       "  '0.9785975217819214',\n",
       "  '0.9789280295372009',\n",
       "  '0.9787497520446777',\n",
       "  '0.9788649678230286',\n",
       "  '0.9789945483207703',\n",
       "  '0.9789864420890808',\n",
       "  '0.9794509410858154',\n",
       "  '0.9794080853462219',\n",
       "  '0.9794222116470337',\n",
       "  '0.9796169996261597',\n",
       "  '0.9797673225402832',\n",
       "  '0.97940593957901',\n",
       "  '0.9796585440635681',\n",
       "  '0.9798025488853455',\n",
       "  '0.9800949096679688',\n",
       "  '0.9799081087112427',\n",
       "  '0.9800771474838257',\n",
       "  '0.9800007343292236',\n",
       "  '0.9802155494689941',\n",
       "  '0.9802635312080383',\n",
       "  '0.9804631471633911',\n",
       "  '0.9802547097206116',\n",
       "  '0.980192244052887',\n",
       "  '0.9802829623222351',\n",
       "  '0.9802334904670715',\n",
       "  '0.9805155992507935',\n",
       "  '0.9806979894638062',\n",
       "  '0.9807311296463013',\n",
       "  '0.9808405041694641',\n",
       "  '0.9808690547943115',\n",
       "  '0.980857253074646',\n",
       "  '0.9810439944267273',\n",
       "  '0.9810562133789062',\n",
       "  '0.9810981750488281',\n",
       "  '0.9811225533485413',\n",
       "  '0.9813528656959534',\n",
       "  '0.9814172983169556',\n",
       "  '0.9813969135284424',\n",
       "  '0.9815321564674377',\n",
       "  '0.9815422296524048',\n",
       "  '0.9815832376480103',\n",
       "  '0.9815673828125',\n",
       "  '0.9816599488258362',\n",
       "  '0.9818724393844604',\n",
       "  '0.9820517301559448',\n",
       "  '0.9819785952568054',\n",
       "  '0.9819213151931763',\n",
       "  '0.9820252060890198',\n",
       "  '0.9821434617042542',\n",
       "  '0.9821696877479553',\n",
       "  '0.9823258519172668',\n",
       "  '0.9822579026222229',\n",
       "  '0.9824756383895874',\n",
       "  '0.9824650287628174',\n",
       "  '0.9825031161308289',\n",
       "  '0.9823139309883118',\n",
       "  '0.9823747873306274',\n",
       "  '0.9824464321136475',\n",
       "  '0.9825255274772644',\n",
       "  '0.9826576113700867',\n",
       "  '0.9824960827827454',\n",
       "  '0.9825716018676758',\n",
       "  '0.9828890562057495',\n",
       "  '0.9829562902450562',\n",
       "  '0.9829095005989075',\n",
       "  '0.983012855052948',\n",
       "  '0.9830217957496643',\n",
       "  '0.9831798076629639',\n",
       "  '0.9830976128578186',\n",
       "  '0.9832297563552856',\n",
       "  '0.9831690788269043',\n",
       "  '0.9833117127418518',\n",
       "  '0.9833559989929199',\n",
       "  '0.9833694100379944',\n",
       "  '0.9834769368171692',\n",
       "  '0.9834538102149963',\n",
       "  '0.98353111743927',\n",
       "  '0.9836212992668152',\n",
       "  '0.983661949634552',\n",
       "  '0.9837870001792908',\n",
       "  '0.9836908578872681',\n",
       "  '0.9837017059326172',\n",
       "  '0.9837964177131653',\n",
       "  '0.9839473366737366',\n",
       "  '0.9838942885398865',\n",
       "  '0.9840072393417358',\n",
       "  '0.9839548468589783',\n",
       "  '0.9841625690460205',\n",
       "  '0.9840300679206848',\n",
       "  '0.9841405749320984',\n",
       "  '0.9841382503509521',\n",
       "  '0.9841493368148804',\n",
       "  '0.984136164188385',\n",
       "  '0.9841880202293396',\n",
       "  '0.9843336343765259',\n",
       "  '0.9845798015594482',\n",
       "  '0.9844028353691101',\n",
       "  '0.9844589233398438',\n",
       "  '0.9845772981643677',\n",
       "  '0.9845120906829834',\n",
       "  '0.9846457242965698',\n",
       "  '0.9845951199531555',\n",
       "  '0.9846413731575012',\n",
       "  '0.9847368597984314',\n",
       "  '0.9848296642303467',\n",
       "  '0.9845450520515442',\n",
       "  '0.984631359577179',\n",
       "  '0.9845625758171082',\n",
       "  '0.9846891760826111',\n",
       "  '0.9849144220352173',\n",
       "  '0.985074520111084',\n",
       "  '0.9849773049354553',\n",
       "  '0.9850347638130188',\n",
       "  '0.9850997924804688',\n",
       "  '0.985178530216217',\n",
       "  '0.9853072166442871',\n",
       "  '0.9853448271751404',\n",
       "  '0.9852765798568726',\n",
       "  '0.9853355288505554',\n",
       "  '0.9851157069206238',\n",
       "  '0.9853466749191284',\n",
       "  '0.985466718673706',\n",
       "  '0.9854965806007385',\n",
       "  '0.9854538440704346',\n",
       "  '0.9856242537498474',\n",
       "  '0.9854425191879272',\n",
       "  '0.9854223728179932',\n",
       "  '0.9856945872306824',\n",
       "  '0.9857537746429443',\n",
       "  '0.9856598973274231',\n",
       "  '0.9856796264648438',\n",
       "  '0.9858578443527222',\n",
       "  '0.9858441948890686',\n",
       "  '0.9859217405319214'],\n",
       " 'recall': ['0.8480232357978821',\n",
       "  '0.847775399684906',\n",
       "  '0.8578135967254639',\n",
       "  '0.8617630004882812',\n",
       "  '0.8632954359054565',\n",
       "  '0.869721531867981',\n",
       "  '0.8723866939544678',\n",
       "  '0.8771916627883911',\n",
       "  '0.8746753334999084',\n",
       "  '0.8813313245773315',\n",
       "  '0.8827481865882874',\n",
       "  '0.8849422335624695',\n",
       "  '0.8890397548675537',\n",
       "  '0.8896090984344482',\n",
       "  '0.8916603922843933',\n",
       "  '0.8935556411743164',\n",
       "  '0.8955627679824829',\n",
       "  '0.8950188159942627',\n",
       "  '0.8946918249130249',\n",
       "  '0.8983373641967773',\n",
       "  '0.8949553370475769',\n",
       "  '0.9050225019454956',\n",
       "  '0.9098093509674072',\n",
       "  '0.9138765335083008',\n",
       "  '0.9183986186981201',\n",
       "  '0.9206288456916809',\n",
       "  '0.9223816394805908',\n",
       "  '0.9231461882591248',\n",
       "  '0.9256098866462708',\n",
       "  '0.9279149770736694',\n",
       "  '0.9294142127037048',\n",
       "  '0.9307874441146851',\n",
       "  '0.9318816065788269',\n",
       "  '0.9328294992446899',\n",
       "  '0.93453449010849',\n",
       "  '0.935748279094696',\n",
       "  '0.9365903735160828',\n",
       "  '0.9382877349853516',\n",
       "  '0.939081072807312',\n",
       "  '0.9397986531257629',\n",
       "  '0.9411449432373047',\n",
       "  '0.9413038492202759',\n",
       "  '0.9411420822143555',\n",
       "  '0.9429518580436707',\n",
       "  '0.9432936310768127',\n",
       "  '0.9443961381912231',\n",
       "  '0.9454336166381836',\n",
       "  '0.9460331797599792',\n",
       "  '0.9466171860694885',\n",
       "  '0.9466803669929504',\n",
       "  '0.9470500349998474',\n",
       "  '0.9484767317771912',\n",
       "  '0.949652910232544',\n",
       "  '0.9493446350097656',\n",
       "  '0.9497860074043274',\n",
       "  '0.9500853419303894',\n",
       "  '0.9500697255134583',\n",
       "  '0.9511996507644653',\n",
       "  '0.9516183733940125',\n",
       "  '0.9525389075279236',\n",
       "  '0.952553391456604',\n",
       "  '0.9530709981918335',\n",
       "  '0.9538722634315491',\n",
       "  '0.9545135498046875',\n",
       "  '0.9548915028572083',\n",
       "  '0.955052375793457',\n",
       "  '0.9549404978752136',\n",
       "  '0.9554666876792908',\n",
       "  '0.9556812644004822',\n",
       "  '0.9564850330352783',\n",
       "  '0.9564670324325562',\n",
       "  '0.956805408000946',\n",
       "  '0.9570174217224121',\n",
       "  '0.9565423130989075',\n",
       "  '0.9580205678939819',\n",
       "  '0.9581351280212402',\n",
       "  '0.9586223363876343',\n",
       "  '0.9588302373886108',\n",
       "  '0.9591415524482727',\n",
       "  '0.9589893817901611',\n",
       "  '0.9596066474914551',\n",
       "  '0.9598596692085266',\n",
       "  '0.9599018692970276',\n",
       "  '0.9604947566986084',\n",
       "  '0.9606603384017944',\n",
       "  '0.9610061049461365',\n",
       "  '0.9612671732902527',\n",
       "  '0.9620633125305176',\n",
       "  '0.9614412784576416',\n",
       "  '0.9620071649551392',\n",
       "  '0.9623833298683167',\n",
       "  '0.9625878930091858',\n",
       "  '0.9627233743667603',\n",
       "  '0.9630999565124512',\n",
       "  '0.9632080793380737',\n",
       "  '0.9637092351913452',\n",
       "  '0.963624119758606',\n",
       "  '0.9634964466094971',\n",
       "  '0.963744580745697',\n",
       "  '0.9643527865409851',\n",
       "  '0.9646713137626648',\n",
       "  '0.9643818736076355',\n",
       "  '0.964514434337616',\n",
       "  '0.9650144577026367',\n",
       "  '0.9649425745010376',\n",
       "  '0.9650852084159851',\n",
       "  '0.9662312269210815',\n",
       "  '0.9665544629096985',\n",
       "  '0.9661432504653931',\n",
       "  '0.9662235379219055',\n",
       "  '0.9664601683616638',\n",
       "  '0.9668197631835938',\n",
       "  '0.9673227667808533',\n",
       "  '0.9663830399513245',\n",
       "  '0.9669689536094666',\n",
       "  '0.9672753810882568',\n",
       "  '0.9671475887298584',\n",
       "  '0.9678800702095032',\n",
       "  '0.9678419232368469',\n",
       "  '0.9675348401069641',\n",
       "  '0.9684235453605652',\n",
       "  '0.9684708714485168',\n",
       "  '0.9684972763061523',\n",
       "  '0.9683099985122681',\n",
       "  '0.9687960743904114',\n",
       "  '0.9681534171104431',\n",
       "  '0.9688442945480347',\n",
       "  '0.9697126746177673',\n",
       "  '0.9697063565254211',\n",
       "  '0.9696900844573975',\n",
       "  '0.9696504473686218',\n",
       "  '0.9698919653892517',\n",
       "  '0.9699622988700867',\n",
       "  '0.97027987241745',\n",
       "  '0.9703974723815918',\n",
       "  '0.9704146385192871',\n",
       "  '0.9703308939933777',\n",
       "  '0.9703838229179382',\n",
       "  '0.9706404805183411',\n",
       "  '0.9709135890007019',\n",
       "  '0.970840573310852',\n",
       "  '0.9710018634796143',\n",
       "  '0.971220076084137',\n",
       "  '0.9711870551109314',\n",
       "  '0.9713342785835266',\n",
       "  '0.9715588688850403',\n",
       "  '0.9715358018875122',\n",
       "  '0.9715413451194763',\n",
       "  '0.9719045162200928',\n",
       "  '0.9720543026924133',\n",
       "  '0.972376823425293',\n",
       "  '0.972361147403717',\n",
       "  '0.9725518822669983',\n",
       "  '0.9727566242218018',\n",
       "  '0.9729651808738708',\n",
       "  '0.9731165170669556',\n",
       "  '0.9732797741889954',\n",
       "  '0.9733828902244568',\n",
       "  '0.9727092385292053',\n",
       "  '0.9729092121124268',\n",
       "  '0.9732610583305359',\n",
       "  '0.9734901189804077',\n",
       "  '0.9732670783996582',\n",
       "  '0.9738123416900635',\n",
       "  '0.9739181399345398',\n",
       "  '0.9737699627876282',\n",
       "  '0.9742390513420105',\n",
       "  '0.9739130139350891',\n",
       "  '0.974208414554596',\n",
       "  '0.9740850925445557',\n",
       "  '0.974004864692688',\n",
       "  '0.9746434092521667',\n",
       "  '0.9744377732276917',\n",
       "  '0.9749665260314941',\n",
       "  '0.9747819304466248',\n",
       "  '0.9750550985336304',\n",
       "  '0.9749324917793274',\n",
       "  '0.9754772782325745',\n",
       "  '0.9749469757080078',\n",
       "  '0.9752779006958008',\n",
       "  '0.9752854704856873',\n",
       "  '0.9759088754653931',\n",
       "  '0.975562334060669',\n",
       "  '0.9755879044532776',\n",
       "  '0.9756020307540894',\n",
       "  '0.9758456349372864',\n",
       "  '0.9760231971740723',\n",
       "  '0.9762130975723267',\n",
       "  '0.9758912324905396',\n",
       "  '0.9757624864578247',\n",
       "  '0.9759297370910645',\n",
       "  '0.9759405851364136',\n",
       "  '0.9760869741439819',\n",
       "  '0.9764476418495178',\n",
       "  '0.97653728723526',\n",
       "  '0.9765815734863281',\n",
       "  '0.9766469597816467',\n",
       "  '0.9766473770141602',\n",
       "  '0.9769013524055481',\n",
       "  '0.9770299196243286',\n",
       "  '0.9768857359886169',\n",
       "  '0.9770361185073853',\n",
       "  '0.9773139953613281',\n",
       "  '0.9773882031440735',\n",
       "  '0.9773252606391907',\n",
       "  '0.9774702787399292',\n",
       "  '0.9773671627044678',\n",
       "  '0.9776062369346619',\n",
       "  '0.9773558378219604',\n",
       "  '0.9777112603187561',\n",
       "  '0.9778733849525452',\n",
       "  '0.9781539440155029',\n",
       "  '0.9779683351516724',\n",
       "  '0.9779237508773804',\n",
       "  '0.9781017303466797',\n",
       "  '0.9783942699432373',\n",
       "  '0.97830730676651',\n",
       "  '0.9782145619392395',\n",
       "  '0.9782965779304504',\n",
       "  '0.9787717461585999',\n",
       "  '0.9786435961723328',\n",
       "  '0.9787206649780273',\n",
       "  '0.9783605933189392',\n",
       "  '0.9787992238998413',\n",
       "  '0.9785803556442261',\n",
       "  '0.9786709547042847',\n",
       "  '0.9789227843284607',\n",
       "  '0.9785611033439636',\n",
       "  '0.9788163304328918',\n",
       "  '0.9791402816772461',\n",
       "  '0.9793158769607544',\n",
       "  '0.9792325496673584',\n",
       "  '0.9793412089347839',\n",
       "  '0.9791959524154663',\n",
       "  '0.9796527624130249',\n",
       "  '0.9794673919677734',\n",
       "  '0.9795846343040466',\n",
       "  '0.97945237159729',\n",
       "  '0.9797654151916504',\n",
       "  '0.9798160195350647',\n",
       "  '0.9796754717826843',\n",
       "  '0.9799999594688416',\n",
       "  '0.9799549579620361',\n",
       "  '0.9799131155014038',\n",
       "  '0.980067253112793',\n",
       "  '0.9801781177520752',\n",
       "  '0.980313241481781',\n",
       "  '0.9801694750785828',\n",
       "  '0.9800967574119568',\n",
       "  '0.9802554845809937',\n",
       "  '0.9804967641830444',\n",
       "  '0.9804653525352478',\n",
       "  '0.9804641604423523',\n",
       "  '0.980391263961792',\n",
       "  '0.9807659983634949',\n",
       "  '0.9804145693778992',\n",
       "  '0.9806599617004395',\n",
       "  '0.9807291030883789',\n",
       "  '0.9807859063148499',\n",
       "  '0.9806069731712341',\n",
       "  '0.9809174537658691',\n",
       "  '0.9808027148246765',\n",
       "  '0.9812811613082886',\n",
       "  '0.9810635447502136',\n",
       "  '0.9811011552810669',\n",
       "  '0.981227457523346',\n",
       "  '0.9811840057373047',\n",
       "  '0.9813412427902222',\n",
       "  '0.9812755584716797',\n",
       "  '0.981234073638916',\n",
       "  '0.9815212488174438',\n",
       "  '0.9815114140510559',\n",
       "  '0.9811882376670837',\n",
       "  '0.9813189506530762',\n",
       "  '0.9811803102493286',\n",
       "  '0.981515109539032',\n",
       "  '0.9816917181015015',\n",
       "  '0.98188716173172',\n",
       "  '0.9818477630615234',\n",
       "  '0.9817715287208557',\n",
       "  '0.9818201661109924',\n",
       "  '0.9818913340568542',\n",
       "  '0.9820648431777954',\n",
       "  '0.9822453856468201',\n",
       "  '0.9820848107337952',\n",
       "  '0.9822863936424255',\n",
       "  '0.9818407893180847',\n",
       "  '0.981988251209259',\n",
       "  '0.9823799133300781',\n",
       "  '0.9823445677757263',\n",
       "  '0.9823166131973267',\n",
       "  '0.9825076460838318',\n",
       "  '0.9823046922683716',\n",
       "  '0.9822025299072266',\n",
       "  '0.9827539324760437',\n",
       "  '0.9827147722244263',\n",
       "  '0.9824684262275696',\n",
       "  '0.9826821088790894',\n",
       "  '0.9828414916992188',\n",
       "  '0.982774555683136',\n",
       "  '0.982894241809845'],\n",
       " 'val_precision': ['0.7874231934547424',\n",
       "  '0.8138229250907898',\n",
       "  '0.7621813416481018',\n",
       "  '0.7381817698478699',\n",
       "  '0.8102497458457947',\n",
       "  '0.760809063911438',\n",
       "  '0.8338178992271423',\n",
       "  '0.8400853872299194',\n",
       "  '0.7931394577026367',\n",
       "  '0.8806698322296143',\n",
       "  '0.8959943652153015',\n",
       "  '0.8374407887458801',\n",
       "  '0.8222880363464355',\n",
       "  '0.7730011343955994',\n",
       "  '0.8276327252388',\n",
       "  '0.7940225005149841',\n",
       "  '0.8450588583946228',\n",
       "  '0.8560177683830261',\n",
       "  '0.8418807983398438',\n",
       "  '0.7894446849822998',\n",
       "  '0.8303572535514832',\n",
       "  '0.8069406151771545',\n",
       "  '0.823934018611908',\n",
       "  '0.810949981212616',\n",
       "  '0.8222579956054688',\n",
       "  '0.8281923532485962',\n",
       "  '0.8434613347053528',\n",
       "  '0.8223027586936951',\n",
       "  '0.8353883028030396',\n",
       "  '0.8560434579849243',\n",
       "  '0.8407678008079529',\n",
       "  '0.838373601436615',\n",
       "  '0.8360171914100647',\n",
       "  '0.8356646299362183',\n",
       "  '0.8377354145050049',\n",
       "  '0.8530737161636353',\n",
       "  '0.8463459014892578',\n",
       "  '0.8440302610397339',\n",
       "  '0.834859311580658',\n",
       "  '0.8399825692176819',\n",
       "  '0.859987735748291',\n",
       "  '0.8222146034240723',\n",
       "  '0.8304590582847595',\n",
       "  '0.84321129322052',\n",
       "  '0.8581787347793579',\n",
       "  '0.8592929244041443',\n",
       "  '0.8519402742385864',\n",
       "  '0.8629058003425598',\n",
       "  '0.8177030086517334',\n",
       "  '0.8509802222251892',\n",
       "  '0.8346849083900452',\n",
       "  '0.8322837352752686',\n",
       "  '0.8464384078979492',\n",
       "  '0.8512217402458191',\n",
       "  '0.8488503694534302',\n",
       "  '0.8358990550041199',\n",
       "  '0.8369483947753906',\n",
       "  '0.8522136211395264',\n",
       "  '0.8390496969223022',\n",
       "  '0.8395962119102478',\n",
       "  '0.8494680523872375',\n",
       "  '0.8600760698318481',\n",
       "  '0.8411096930503845',\n",
       "  '0.8566482663154602',\n",
       "  '0.8579612374305725',\n",
       "  '0.8525637984275818',\n",
       "  '0.856255054473877',\n",
       "  '0.8480646014213562',\n",
       "  '0.8444698452949524',\n",
       "  '0.8557045459747314',\n",
       "  '0.858907163143158',\n",
       "  '0.8491640090942383',\n",
       "  '0.8475150465965271',\n",
       "  '0.8601349592208862',\n",
       "  '0.8435642719268799',\n",
       "  '0.8538804650306702',\n",
       "  '0.8505116701126099',\n",
       "  '0.8468167185783386',\n",
       "  '0.8551960587501526',\n",
       "  '0.8594275712966919',\n",
       "  '0.8735203742980957',\n",
       "  '0.8602204322814941',\n",
       "  '0.8574104905128479',\n",
       "  '0.8551090955734253',\n",
       "  '0.8532946705818176',\n",
       "  '0.860798180103302',\n",
       "  '0.8622695207595825',\n",
       "  '0.8621116876602173',\n",
       "  '0.8568076491355896',\n",
       "  '0.8605466485023499',\n",
       "  '0.8499211072921753',\n",
       "  '0.8389530181884766',\n",
       "  '0.8490774631500244',\n",
       "  '0.8498497009277344',\n",
       "  '0.8649868965148926',\n",
       "  '0.8540266752243042',\n",
       "  '0.856681227684021',\n",
       "  '0.8436446785926819',\n",
       "  '0.8534217476844788',\n",
       "  '0.8672279119491577',\n",
       "  '0.8510258793830872',\n",
       "  '0.8577401041984558',\n",
       "  '0.8713313341140747',\n",
       "  '0.853448212146759',\n",
       "  '0.86921226978302',\n",
       "  '0.8540015816688538',\n",
       "  '0.8531354069709778',\n",
       "  '0.862721860408783',\n",
       "  '0.8543132543563843',\n",
       "  '0.8563941121101379',\n",
       "  '0.8644694089889526',\n",
       "  '0.8480607867240906',\n",
       "  '0.8645608425140381',\n",
       "  '0.8648692965507507',\n",
       "  '0.864260196685791',\n",
       "  '0.8563045859336853',\n",
       "  '0.8537273406982422',\n",
       "  '0.8557164072990417',\n",
       "  '0.8670462369918823',\n",
       "  '0.8645850419998169',\n",
       "  '0.8624565601348877',\n",
       "  '0.8629426956176758',\n",
       "  '0.8631753325462341',\n",
       "  '0.8690199255943298',\n",
       "  '0.8699934482574463',\n",
       "  '0.85439532995224',\n",
       "  '0.8508211970329285',\n",
       "  '0.8636764287948608',\n",
       "  '0.8676020503044128',\n",
       "  '0.8538543581962585',\n",
       "  '0.8486675024032593',\n",
       "  '0.8710271716117859',\n",
       "  '0.8576659560203552',\n",
       "  '0.8623365759849548',\n",
       "  '0.8606757521629333',\n",
       "  '0.8533975481987',\n",
       "  '0.8522714972496033',\n",
       "  '0.8608487844467163',\n",
       "  '0.8545418977737427',\n",
       "  '0.8581400513648987',\n",
       "  '0.8638548851013184',\n",
       "  '0.8672274947166443',\n",
       "  '0.8578158617019653',\n",
       "  '0.8613753318786621',\n",
       "  '0.8657098412513733',\n",
       "  '0.8591985702514648',\n",
       "  '0.8637909889221191',\n",
       "  '0.8515849709510803',\n",
       "  '0.8532224297523499',\n",
       "  '0.8642480373382568',\n",
       "  '0.8612568974494934',\n",
       "  '0.8617430329322815',\n",
       "  '0.8578704595565796',\n",
       "  '0.8610738515853882',\n",
       "  '0.8574317097663879',\n",
       "  '0.8598161339759827',\n",
       "  '0.8612191677093506',\n",
       "  '0.8656994700431824',\n",
       "  '0.8536537885665894',\n",
       "  '0.8622539043426514',\n",
       "  '0.8602583408355713',\n",
       "  '0.8540372252464294',\n",
       "  '0.8500890731811523',\n",
       "  '0.8551701307296753',\n",
       "  '0.8596542477607727',\n",
       "  '0.8542959094047546',\n",
       "  '0.8519100546836853',\n",
       "  '0.8545001149177551',\n",
       "  '0.8602379560470581',\n",
       "  '0.8591472506523132',\n",
       "  '0.8574047684669495',\n",
       "  '0.8687208294868469',\n",
       "  '0.858738124370575',\n",
       "  '0.861923336982727',\n",
       "  '0.8609464168548584',\n",
       "  '0.8599365949630737',\n",
       "  '0.8550654053688049',\n",
       "  '0.8616712689399719',\n",
       "  '0.8511452674865723',\n",
       "  '0.8627995848655701',\n",
       "  '0.8566126227378845',\n",
       "  '0.8652709722518921',\n",
       "  '0.8562260270118713',\n",
       "  '0.853956937789917',\n",
       "  '0.8625747561454773',\n",
       "  '0.8545933365821838',\n",
       "  '0.8609884977340698',\n",
       "  '0.8627636432647705',\n",
       "  '0.8577159643173218',\n",
       "  '0.8493304252624512',\n",
       "  '0.8452612161636353',\n",
       "  '0.8600041270256042',\n",
       "  '0.8586224913597107',\n",
       "  '0.862769365310669',\n",
       "  '0.8614535331726074',\n",
       "  '0.8553627133369446',\n",
       "  '0.8627214431762695',\n",
       "  '0.8567453026771545',\n",
       "  '0.8542979955673218',\n",
       "  '0.8537968993186951',\n",
       "  '0.8512887358665466',\n",
       "  '0.857692301273346',\n",
       "  '0.8572750687599182',\n",
       "  '0.8710871338844299',\n",
       "  '0.863121509552002',\n",
       "  '0.8668715357780457',\n",
       "  '0.859123170375824',\n",
       "  '0.8654905557632446',\n",
       "  '0.8544473052024841',\n",
       "  '0.8602239489555359',\n",
       "  '0.8579937815666199',\n",
       "  '0.8568603992462158',\n",
       "  '0.8666894435882568',\n",
       "  '0.8640410900115967',\n",
       "  '0.8648772835731506',\n",
       "  '0.8499657511711121',\n",
       "  '0.860297441482544',\n",
       "  '0.8578135967254639',\n",
       "  '0.8586434125900269',\n",
       "  '0.8571221232414246',\n",
       "  '0.8534910678863525',\n",
       "  '0.8595572710037231',\n",
       "  '0.8587220311164856',\n",
       "  '0.8574035167694092',\n",
       "  '0.8610618710517883',\n",
       "  '0.8665825724601746',\n",
       "  '0.8623878955841064',\n",
       "  '0.8446977138519287',\n",
       "  '0.8625528216362',\n",
       "  '0.853769838809967',\n",
       "  '0.8633192777633667',\n",
       "  '0.857243001461029',\n",
       "  '0.8709388971328735',\n",
       "  '0.8583800196647644',\n",
       "  '0.86849445104599',\n",
       "  '0.8544626235961914',\n",
       "  '0.8529265522956848',\n",
       "  '0.8614640831947327',\n",
       "  '0.8611405491828918',\n",
       "  '0.8651009202003479',\n",
       "  '0.8613065481185913',\n",
       "  '0.8524355292320251',\n",
       "  '0.8566727042198181',\n",
       "  '0.8595413565635681',\n",
       "  '0.8612768650054932',\n",
       "  '0.8635126948356628',\n",
       "  '0.8614793419837952',\n",
       "  '0.8569074273109436',\n",
       "  '0.8582406044006348',\n",
       "  '0.8556919693946838',\n",
       "  '0.8587942123413086',\n",
       "  '0.8583008646965027',\n",
       "  '0.8669394254684448',\n",
       "  '0.8598988056182861',\n",
       "  '0.8582292795181274',\n",
       "  '0.860912561416626',\n",
       "  '0.8584278225898743',\n",
       "  '0.8585900068283081',\n",
       "  '0.8636176586151123',\n",
       "  '0.8619824051856995',\n",
       "  '0.858945906162262',\n",
       "  '0.8611108064651489',\n",
       "  '0.8586367964744568',\n",
       "  '0.8593950271606445',\n",
       "  '0.8595774173736572',\n",
       "  '0.8585100173950195',\n",
       "  '0.8653028011322021',\n",
       "  '0.8572711944580078',\n",
       "  '0.867805540561676',\n",
       "  '0.8568508625030518',\n",
       "  '0.8722184896469116',\n",
       "  '0.8611392974853516',\n",
       "  '0.8635159730911255',\n",
       "  '0.8554505109786987',\n",
       "  '0.8549932837486267',\n",
       "  '0.8614133596420288',\n",
       "  '0.8619415163993835',\n",
       "  '0.8597949743270874',\n",
       "  '0.8616398572921753',\n",
       "  '0.8610086441040039',\n",
       "  '0.858514666557312',\n",
       "  '0.8613430857658386',\n",
       "  '0.8573296666145325',\n",
       "  '0.8592108488082886',\n",
       "  '0.8602725267410278',\n",
       "  '0.8582233190536499',\n",
       "  '0.8587933778762817',\n",
       "  '0.8646398782730103',\n",
       "  '0.858967125415802',\n",
       "  '0.8652491569519043',\n",
       "  '0.8632949590682983',\n",
       "  '0.8597851395606995',\n",
       "  '0.86195307970047',\n",
       "  '0.8521809577941895',\n",
       "  '0.8562964200973511',\n",
       "  '0.8644410371780396',\n",
       "  '0.855935275554657',\n",
       "  '0.8543229699134827',\n",
       "  '0.8592691421508789',\n",
       "  '0.8576221466064453',\n",
       "  '0.8524506688117981'],\n",
       " 'val_true_negatives': ['51167764.0',\n",
       "  '52119008.0',\n",
       "  '47966524.0',\n",
       "  '46140320.0',\n",
       "  '52669072.0',\n",
       "  '47724816.0',\n",
       "  '53444012.0',\n",
       "  '53208184.0',\n",
       "  '50110464.0',\n",
       "  '56906144.0',\n",
       "  '56287440.0',\n",
       "  '53065372.0',\n",
       "  '52038120.0',\n",
       "  '48911596.0',\n",
       "  '52835852.0',\n",
       "  '50796784.0',\n",
       "  '54806864.0',\n",
       "  '54215616.0',\n",
       "  '53125932.0',\n",
       "  '49874412.0',\n",
       "  '52895400.0',\n",
       "  '51472936.0',\n",
       "  '52691164.0',\n",
       "  '52230576.0',\n",
       "  '52624892.0',\n",
       "  '52991028.0',\n",
       "  '54079244.0',\n",
       "  '52406036.0',\n",
       "  '53583392.0',\n",
       "  '54411688.0',\n",
       "  '53393864.0',\n",
       "  '53569596.0',\n",
       "  '53048208.0',\n",
       "  '53357360.0',\n",
       "  '53359820.0',\n",
       "  '54114864.0',\n",
       "  '53825388.0',\n",
       "  '53770800.0',\n",
       "  '52833096.0',\n",
       "  '53308404.0',\n",
       "  '54590168.0',\n",
       "  '52434776.0',\n",
       "  '53080808.0',\n",
       "  '53783808.0',\n",
       "  '54249804.0',\n",
       "  '54658532.0',\n",
       "  '54252516.0',\n",
       "  '54902364.0',\n",
       "  '51718232.0',\n",
       "  '53647204.0',\n",
       "  '52939928.0',\n",
       "  '52523124.0',\n",
       "  '53472680.0',\n",
       "  '53635480.0',\n",
       "  '53549152.0',\n",
       "  '53060240.0',\n",
       "  '52926616.0',\n",
       "  '53786380.0',\n",
       "  '53225792.0',\n",
       "  '53262956.0',\n",
       "  '53704920.0',\n",
       "  '54175248.0',\n",
       "  '53105536.0',\n",
       "  '54216584.0',\n",
       "  '54150400.0',\n",
       "  '53814552.0',\n",
       "  '54120324.0',\n",
       "  '53533928.0',\n",
       "  '53666224.0',\n",
       "  '54351536.0',\n",
       "  '54311988.0',\n",
       "  '53666704.0',\n",
       "  '53508840.0',\n",
       "  '54372680.0',\n",
       "  '53399696.0',\n",
       "  '53969800.0',\n",
       "  '53786484.0',\n",
       "  '53535720.0',\n",
       "  '54187432.0',\n",
       "  '54262540.0',\n",
       "  '55037596.0',\n",
       "  '54436096.0',\n",
       "  '54199444.0',\n",
       "  '54116696.0',\n",
       "  '54056176.0',\n",
       "  '54245340.0',\n",
       "  '54366352.0',\n",
       "  '54241048.0',\n",
       "  '54139580.0',\n",
       "  '54657684.0',\n",
       "  '53690784.0',\n",
       "  '53243064.0',\n",
       "  '53620108.0',\n",
       "  '53548472.0',\n",
       "  '54502188.0',\n",
       "  '53817884.0',\n",
       "  '53952144.0',\n",
       "  '53213488.0',\n",
       "  '53797556.0',\n",
       "  '54702936.0',\n",
       "  '53661840.0',\n",
       "  '54141900.0',\n",
       "  '54889100.0',\n",
       "  '53790224.0',\n",
       "  '54779160.0',\n",
       "  '53885896.0',\n",
       "  '53798608.0',\n",
       "  '54374840.0',\n",
       "  '53855688.0',\n",
       "  '53984744.0',\n",
       "  '54605688.0',\n",
       "  '53506712.0',\n",
       "  '54622848.0',\n",
       "  '54609308.0',\n",
       "  '54520264.0',\n",
       "  '53928084.0',\n",
       "  '53716640.0',\n",
       "  '54068968.0',\n",
       "  '54581868.0',\n",
       "  '54563520.0',\n",
       "  '54454612.0',\n",
       "  '54274980.0',\n",
       "  '54395220.0',\n",
       "  '54657596.0',\n",
       "  '54905200.0',\n",
       "  '53943568.0',\n",
       "  '53566468.0',\n",
       "  '54471360.0',\n",
       "  '54641768.0',\n",
       "  '53823708.0',\n",
       "  '53505660.0',\n",
       "  '54907204.0',\n",
       "  '54099592.0',\n",
       "  '54224140.0',\n",
       "  '54184724.0',\n",
       "  '53864568.0',\n",
       "  '53667312.0',\n",
       "  '54237924.0',\n",
       "  '53873016.0',\n",
       "  '54116472.0',\n",
       "  '54436216.0',\n",
       "  '54639248.0',\n",
       "  '54076548.0',\n",
       "  '54191968.0',\n",
       "  '54586504.0',\n",
       "  '54093396.0',\n",
       "  '54403836.0',\n",
       "  '53574268.0',\n",
       "  '53771504.0',\n",
       "  '54418720.0',\n",
       "  '54188732.0',\n",
       "  '54218044.0',\n",
       "  '53994548.0',\n",
       "  '54304972.0',\n",
       "  '53997484.0',\n",
       "  '54186024.0',\n",
       "  '54268696.0',\n",
       "  '54556240.0',\n",
       "  '53761936.0',\n",
       "  '54385952.0',\n",
       "  '54100088.0',\n",
       "  '53792324.0',\n",
       "  '53548988.0',\n",
       "  '53891672.0',\n",
       "  '54181572.0',\n",
       "  '53949048.0',\n",
       "  '53813808.0',\n",
       "  '53716116.0',\n",
       "  '54109704.0',\n",
       "  '54309080.0',\n",
       "  '53973952.0',\n",
       "  '54633464.0',\n",
       "  '54118056.0',\n",
       "  '54164216.0',\n",
       "  '54244028.0',\n",
       "  '54088448.0',\n",
       "  '53900584.0',\n",
       "  '54274344.0',\n",
       "  '53530672.0',\n",
       "  '54348532.0',\n",
       "  '53929080.0',\n",
       "  '54462016.0',\n",
       "  '54038896.0',\n",
       "  '53769552.0',\n",
       "  '54359640.0',\n",
       "  '53723568.0',\n",
       "  '54139496.0',\n",
       "  '54254872.0',\n",
       "  '54003020.0',\n",
       "  '53485600.0',\n",
       "  '53223612.0',\n",
       "  '54152224.0',\n",
       "  '54018408.0',\n",
       "  '54286376.0',\n",
       "  '54191636.0',\n",
       "  '53887848.0',\n",
       "  '54388200.0',\n",
       "  '53983152.0',\n",
       "  '53740884.0',\n",
       "  '53866960.0',\n",
       "  '53667888.0',\n",
       "  '54022320.0',\n",
       "  '53988396.0',\n",
       "  '54812840.0',\n",
       "  '54314956.0',\n",
       "  '54479224.0',\n",
       "  '54150504.0',\n",
       "  '54555576.0',\n",
       "  '53854088.0',\n",
       "  '54131304.0',\n",
       "  '53987532.0',\n",
       "  '53892852.0',\n",
       "  '54582672.0',\n",
       "  '54391280.0',\n",
       "  '54449944.0',\n",
       "  '53586376.0',\n",
       "  '54220336.0',\n",
       "  '54008240.0',\n",
       "  '54131156.0',\n",
       "  '54114332.0',\n",
       "  '53736236.0',\n",
       "  '53938420.0',\n",
       "  '54131744.0',\n",
       "  '54057060.0',\n",
       "  '54265084.0',\n",
       "  '54480236.0',\n",
       "  '54360984.0',\n",
       "  '53235544.0',\n",
       "  '54396712.0',\n",
       "  '53745636.0',\n",
       "  '54452896.0',\n",
       "  '53911420.0',\n",
       "  '54779708.0',\n",
       "  '53991488.0',\n",
       "  '54608020.0',\n",
       "  '53808892.0',\n",
       "  '53737164.0',\n",
       "  '54164036.0',\n",
       "  '54228412.0',\n",
       "  '54454328.0',\n",
       "  '54206668.0',\n",
       "  '53600792.0',\n",
       "  '54050048.0',\n",
       "  '54163852.0',\n",
       "  '54151960.0',\n",
       "  '54377704.0',\n",
       "  '54186120.0',\n",
       "  '53818048.0',\n",
       "  '54026720.0',\n",
       "  '53878416.0',\n",
       "  '54048488.0',\n",
       "  '54017720.0',\n",
       "  '54590596.0',\n",
       "  '54083784.0',\n",
       "  '54001928.0',\n",
       "  '54202760.0',\n",
       "  '53947664.0',\n",
       "  '53925004.0',\n",
       "  '54367280.0',\n",
       "  '54202992.0',\n",
       "  '54011384.0',\n",
       "  '54109644.0',\n",
       "  '54136928.0',\n",
       "  '54168964.0',\n",
       "  '53964752.0',\n",
       "  '53975856.0',\n",
       "  '54419496.0',\n",
       "  '53991036.0',\n",
       "  '54545760.0',\n",
       "  '53984488.0',\n",
       "  '54955320.0',\n",
       "  '54153840.0',\n",
       "  '54469528.0',\n",
       "  '53909660.0',\n",
       "  '53893552.0',\n",
       "  '54157488.0',\n",
       "  '54123708.0',\n",
       "  '54194028.0',\n",
       "  '54223072.0',\n",
       "  '54279288.0',\n",
       "  '53968028.0',\n",
       "  '54216652.0',\n",
       "  '53998820.0',\n",
       "  '54053116.0',\n",
       "  '54118508.0',\n",
       "  '53985448.0',\n",
       "  '54117728.0',\n",
       "  '54442572.0',\n",
       "  '54168864.0',\n",
       "  '54429184.0',\n",
       "  '54227028.0',\n",
       "  '54106604.0',\n",
       "  '54214216.0',\n",
       "  '53605824.0',\n",
       "  '53980316.0',\n",
       "  '54346648.0',\n",
       "  '54019520.0',\n",
       "  '53897468.0',\n",
       "  '53993988.0',\n",
       "  '53941408.0',\n",
       "  '53592992.0'],\n",
       " 'true_positives': ['111043808.0',\n",
       "  '111206328.0',\n",
       "  '112447392.0',\n",
       "  '112991728.0',\n",
       "  '113235904.0',\n",
       "  '114011392.0',\n",
       "  '114393776.0',\n",
       "  '114999336.0',\n",
       "  '114638944.0',\n",
       "  '115608840.0',\n",
       "  '115722160.0',\n",
       "  '115993240.0',\n",
       "  '116559416.0',\n",
       "  '116646776.0',\n",
       "  '116874728.0',\n",
       "  '117159816.0',\n",
       "  '117442272.0',\n",
       "  '117300144.0',\n",
       "  '117366416.0',\n",
       "  '117830272.0',\n",
       "  '117355328.0',\n",
       "  '118692888.0',\n",
       "  '119276576.0',\n",
       "  '119829672.0',\n",
       "  '120375520.0',\n",
       "  '120743664.0',\n",
       "  '120970208.0',\n",
       "  '121040984.0',\n",
       "  '121378176.0',\n",
       "  '121638552.0',\n",
       "  '121885136.0',\n",
       "  '122102336.0',\n",
       "  '122256176.0',\n",
       "  '122282704.0',\n",
       "  '122491304.0',\n",
       "  '122662144.0',\n",
       "  '122791104.0',\n",
       "  '123125144.0',\n",
       "  '123198872.0',\n",
       "  '123262672.0',\n",
       "  '123480720.0',\n",
       "  '123466816.0',\n",
       "  '123384384.0',\n",
       "  '123623008.0',\n",
       "  '123755928.0',\n",
       "  '123859272.0',\n",
       "  '123907208.0',\n",
       "  '124036728.0',\n",
       "  '124107008.0',\n",
       "  '124190864.0',\n",
       "  '124206712.0',\n",
       "  '124383808.0',\n",
       "  '124519472.0',\n",
       "  '124464448.0',\n",
       "  '124560848.0',\n",
       "  '124591528.0',\n",
       "  '124655336.0',\n",
       "  '124744160.0',\n",
       "  '124796360.0',\n",
       "  '124856752.0',\n",
       "  '124932784.0',\n",
       "  '124947544.0',\n",
       "  '125049016.0',\n",
       "  '125117640.0',\n",
       "  '125236832.0',\n",
       "  '125150472.0',\n",
       "  '125190992.0',\n",
       "  '125344096.0',\n",
       "  '125332760.0',\n",
       "  '125380920.0',\n",
       "  '125411872.0',\n",
       "  '125522208.0',\n",
       "  '125527552.0',\n",
       "  '125359712.0',\n",
       "  '125676456.0',\n",
       "  '125668784.0',\n",
       "  '125682656.0',\n",
       "  '125743640.0',\n",
       "  '125692192.0',\n",
       "  '125826584.0',\n",
       "  '125833560.0',\n",
       "  '125901040.0',\n",
       "  '125878616.0',\n",
       "  '125938240.0',\n",
       "  '125941432.0',\n",
       "  '126005840.0',\n",
       "  '126059808.0',\n",
       "  '126197784.0',\n",
       "  '126125472.0',\n",
       "  '126138448.0',\n",
       "  '126135312.0',\n",
       "  '126272896.0',\n",
       "  '126237488.0',\n",
       "  '126342984.0',\n",
       "  '126309928.0',\n",
       "  '126340080.0',\n",
       "  '126412504.0',\n",
       "  '126337528.0',\n",
       "  '126356104.0',\n",
       "  '126404904.0',\n",
       "  '126532776.0',\n",
       "  '126426304.0',\n",
       "  '126400232.0',\n",
       "  '126506848.0',\n",
       "  '126556816.0',\n",
       "  '126555448.0',\n",
       "  '126648080.0',\n",
       "  '126805408.0',\n",
       "  '126631680.0',\n",
       "  '126773728.0',\n",
       "  '126746392.0',\n",
       "  '126877072.0',\n",
       "  '126810136.0',\n",
       "  '126757632.0',\n",
       "  '126799784.0',\n",
       "  '126867360.0',\n",
       "  '126780976.0',\n",
       "  '126930632.0',\n",
       "  '126949784.0',\n",
       "  '126806992.0',\n",
       "  '127001424.0',\n",
       "  '127050280.0',\n",
       "  '126962608.0',\n",
       "  '126973488.0',\n",
       "  '126995048.0',\n",
       "  '126895880.0',\n",
       "  '127059504.0',\n",
       "  '127145520.0',\n",
       "  '127195808.0',\n",
       "  '127142512.0',\n",
       "  '127150640.0',\n",
       "  '127199000.0',\n",
       "  '127134680.0',\n",
       "  '127208888.0',\n",
       "  '127323376.0',\n",
       "  '127273752.0',\n",
       "  '127167712.0',\n",
       "  '127181704.0',\n",
       "  '127275040.0',\n",
       "  '127344912.0',\n",
       "  '127353744.0',\n",
       "  '127289176.0',\n",
       "  '127402960.0',\n",
       "  '127372464.0',\n",
       "  '127321792.0',\n",
       "  '127417072.0',\n",
       "  '127344952.0',\n",
       "  '127450744.0',\n",
       "  '127380160.0',\n",
       "  '127459984.0',\n",
       "  '127505640.0',\n",
       "  '127557152.0',\n",
       "  '127578080.0',\n",
       "  '127527616.0',\n",
       "  '127512560.0',\n",
       "  '127543024.0',\n",
       "  '127531592.0',\n",
       "  '127621552.0',\n",
       "  '127592680.0',\n",
       "  '127541160.0',\n",
       "  '127651416.0',\n",
       "  '127681488.0',\n",
       "  '127626128.0',\n",
       "  '127696808.0',\n",
       "  '127716656.0',\n",
       "  '127744656.0',\n",
       "  '127801288.0',\n",
       "  '127709456.0',\n",
       "  '127749496.0',\n",
       "  '127711536.0',\n",
       "  '127806288.0',\n",
       "  '127768096.0',\n",
       "  '127705200.0',\n",
       "  '127747752.0',\n",
       "  '127814912.0',\n",
       "  '127879320.0',\n",
       "  '127800784.0',\n",
       "  '127867272.0',\n",
       "  '127793752.0',\n",
       "  '127919408.0',\n",
       "  '127814216.0',\n",
       "  '128038000.0',\n",
       "  '127932456.0',\n",
       "  '127859384.0',\n",
       "  '127926184.0',\n",
       "  '127993776.0',\n",
       "  '128000320.0',\n",
       "  '127973736.0',\n",
       "  '127973032.0',\n",
       "  '127921728.0',\n",
       "  '127939256.0',\n",
       "  '127974712.0',\n",
       "  '128011528.0',\n",
       "  '128088728.0',\n",
       "  '128124896.0',\n",
       "  '128060624.0',\n",
       "  '127977456.0',\n",
       "  '128017808.0',\n",
       "  '128088576.0',\n",
       "  '128189872.0',\n",
       "  '128083184.0',\n",
       "  '128144936.0',\n",
       "  '128228320.0',\n",
       "  '128186712.0',\n",
       "  '128194960.0',\n",
       "  '128105040.0',\n",
       "  '128148376.0',\n",
       "  '128154472.0',\n",
       "  '128189280.0',\n",
       "  '128291304.0',\n",
       "  '128238920.0',\n",
       "  '128231512.0',\n",
       "  '128190448.0',\n",
       "  '128257208.0',\n",
       "  '128221048.0',\n",
       "  '128336712.0',\n",
       "  '128210720.0',\n",
       "  '128292192.0',\n",
       "  '128217032.0',\n",
       "  '128391344.0',\n",
       "  '128301776.0',\n",
       "  '128364120.0',\n",
       "  '128264944.0',\n",
       "  '128327544.0',\n",
       "  '128314824.0',\n",
       "  '128395000.0',\n",
       "  '128235376.0',\n",
       "  '128363824.0',\n",
       "  '128308464.0',\n",
       "  '128389704.0',\n",
       "  '128408064.0',\n",
       "  '128428536.0',\n",
       "  '128471360.0',\n",
       "  '128377568.0',\n",
       "  '128430672.0',\n",
       "  '128469040.0',\n",
       "  '128472400.0',\n",
       "  '128435648.0',\n",
       "  '128433832.0',\n",
       "  '128492984.0',\n",
       "  '128496160.0',\n",
       "  '128500416.0',\n",
       "  '128561656.0',\n",
       "  '128542400.0',\n",
       "  '128506152.0',\n",
       "  '128571360.0',\n",
       "  '128569288.0',\n",
       "  '128557976.0',\n",
       "  '128511664.0',\n",
       "  '128539136.0',\n",
       "  '128580336.0',\n",
       "  '128536624.0',\n",
       "  '128600120.0',\n",
       "  '128518968.0',\n",
       "  '128641216.0',\n",
       "  '128485280.0',\n",
       "  '128600696.0',\n",
       "  '128585984.0',\n",
       "  '128650944.0',\n",
       "  '128608912.0',\n",
       "  '128638720.0',\n",
       "  '128584624.0',\n",
       "  '128649224.0',\n",
       "  '128528488.0',\n",
       "  '128629728.0',\n",
       "  '128712024.0',\n",
       "  '128628544.0',\n",
       "  '128683480.0',\n",
       "  '128664464.0',\n",
       "  '128655080.0',\n",
       "  '128695104.0',\n",
       "  '128657064.0',\n",
       "  '128619336.0',\n",
       "  '128673088.0',\n",
       "  '128662808.0',\n",
       "  '128737696.0',\n",
       "  '128681392.0',\n",
       "  '128789304.0',\n",
       "  '128727744.0',\n",
       "  '128727048.0',\n",
       "  '128804792.0',\n",
       "  '128712336.0',\n",
       "  '128748488.0',\n",
       "  '128846128.0',\n",
       "  '128825416.0',\n",
       "  '128749456.0',\n",
       "  '128741728.0',\n",
       "  '128674112.0',\n",
       "  '128696832.0',\n",
       "  '128851760.0',\n",
       "  '128857528.0',\n",
       "  '128849904.0',\n",
       "  '128831672.0',\n",
       "  '128761456.0',\n",
       "  '128922088.0',\n",
       "  '128838072.0',\n",
       "  '128876328.0',\n",
       "  '128836184.0',\n",
       "  '128852928.0',\n",
       "  '128955920.0',\n",
       "  '128809344.0'],\n",
       " 'val_accuracy': ['0.8242917656898499',\n",
       "  '0.8498079180717468',\n",
       "  '0.8433647751808167',\n",
       "  '0.8287520408630371',\n",
       "  '0.8287599682807922',\n",
       "  '0.8436726331710815',\n",
       "  '0.8602073192596436',\n",
       "  '0.8823829293251038',\n",
       "  '0.8584086894989014',\n",
       "  '0.813231885433197',\n",
       "  '0.8917816877365112',\n",
       "  '0.87993323802948',\n",
       "  '0.874578595161438',\n",
       "  '0.8450703620910645',\n",
       "  '0.8604539036750793',\n",
       "  '0.8445158004760742',\n",
       "  '0.8260716795921326',\n",
       "  '0.8888552188873291',\n",
       "  '0.8892303705215454',\n",
       "  '0.8591651320457458',\n",
       "  '0.8684530258178711',\n",
       "  '0.8560224175453186',\n",
       "  '0.8642113208770752',\n",
       "  '0.8395726680755615',\n",
       "  '0.8533067107200623',\n",
       "  '0.8569526076316833',\n",
       "  '0.8602868914604187',\n",
       "  '0.862686812877655',\n",
       "  '0.8552858233451843',\n",
       "  '0.8754955530166626',\n",
       "  '0.8783020973205566',\n",
       "  '0.8646611571311951',\n",
       "  '0.8755253553390503',\n",
       "  '0.8659992814064026',\n",
       "  '0.8675855398178101',\n",
       "  '0.8781846165657043',\n",
       "  '0.8712639808654785',\n",
       "  '0.8705491423606873',\n",
       "  '0.8803845047950745',\n",
       "  '0.8751032948493958',\n",
       "  '0.8737421631813049',\n",
       "  '0.8662274479866028',\n",
       "  '0.8592154383659363',\n",
       "  '0.8654018044471741',\n",
       "  '0.8857923746109009',\n",
       "  '0.8720723986625671',\n",
       "  '0.8700535297393799',\n",
       "  '0.8749876022338867',\n",
       "  '0.872788667678833',\n",
       "  '0.8936258554458618',\n",
       "  '0.878600001335144',\n",
       "  '0.8829112648963928',\n",
       "  '0.8849976658821106',\n",
       "  '0.8918882608413696',\n",
       "  '0.8890605568885803',\n",
       "  '0.8751226663589478',\n",
       "  '0.8864935636520386',\n",
       "  '0.8917012810707092',\n",
       "  '0.8786147832870483',\n",
       "  '0.8765685558319092',\n",
       "  '0.886633038520813',\n",
       "  '0.8933241367340088',\n",
       "  '0.8875998854637146',\n",
       "  '0.8872687220573425',\n",
       "  '0.8926673531532288',\n",
       "  '0.8920038342475891',\n",
       "  '0.8902159333229065',\n",
       "  '0.890754222869873',\n",
       "  '0.8807737827301025',\n",
       "  '0.8762558102607727',\n",
       "  '0.8843727111816406',\n",
       "  '0.8861092329025269',\n",
       "  '0.8904123902320862',\n",
       "  '0.8926801681518555',\n",
       "  '0.8820460438728333',\n",
       "  '0.8869215250015259',\n",
       "  '0.8874621987342834',\n",
       "  '0.8852776288986206',\n",
       "  '0.8831599950790405',\n",
       "  '0.8960076570510864',\n",
       "  '0.899150013923645',\n",
       "  '0.8884961009025574',\n",
       "  '0.891278862953186',\n",
       "  '0.892905056476593',\n",
       "  '0.8853901028633118',\n",
       "  '0.8974866271018982',\n",
       "  '0.8977532386779785',\n",
       "  '0.8990088701248169',\n",
       "  '0.8917590975761414',\n",
       "  '0.8807775974273682',\n",
       "  '0.8895372152328491',\n",
       "  '0.8801289200782776',\n",
       "  '0.890203058719635',\n",
       "  '0.8915525674819946',\n",
       "  '0.8958012461662292',\n",
       "  '0.8953007459640503',\n",
       "  '0.897331178188324',\n",
       "  '0.8916771411895752',\n",
       "  '0.8973925709724426',\n",
       "  '0.8964393138885498',\n",
       "  '0.8935382962226868',\n",
       "  '0.891438364982605',\n",
       "  '0.901397168636322',\n",
       "  '0.896240234375',\n",
       "  '0.9001848101615906',\n",
       "  '0.8961367607116699',\n",
       "  '0.8953332901000977',\n",
       "  '0.8990083932876587',\n",
       "  '0.8938716650009155',\n",
       "  '0.8940012454986572',\n",
       "  '0.8937467932701111',\n",
       "  '0.8915566205978394',\n",
       "  '0.8950695991516113',\n",
       "  '0.898152768611908',\n",
       "  '0.8963971734046936',\n",
       "  '0.8960254788398743',\n",
       "  '0.8951661586761475',\n",
       "  '0.8935993313789368',\n",
       "  '0.8996397852897644',\n",
       "  '0.8957734704017639',\n",
       "  '0.8979461789131165',\n",
       "  '0.899541974067688',\n",
       "  '0.8983888626098633',\n",
       "  '0.9004254937171936',\n",
       "  '0.896963357925415',\n",
       "  '0.8954219222068787',\n",
       "  '0.8961529731750488',\n",
       "  '0.8987581133842468',\n",
       "  '0.8976947069168091',\n",
       "  '0.8971890211105347',\n",
       "  '0.8942090272903442',\n",
       "  '0.9008165597915649',\n",
       "  '0.898979902267456',\n",
       "  '0.898804247379303',\n",
       "  '0.8997799158096313',\n",
       "  '0.8964767456054688',\n",
       "  '0.8978047966957092',\n",
       "  '0.8973862528800964',\n",
       "  '0.894955575466156',\n",
       "  '0.8967226147651672',\n",
       "  '0.8988575339317322',\n",
       "  '0.8970469236373901',\n",
       "  '0.8997504711151123',\n",
       "  '0.899406909942627',\n",
       "  '0.9015278220176697',\n",
       "  '0.8980947732925415',\n",
       "  '0.8998093605041504',\n",
       "  '0.897466778755188',\n",
       "  '0.8948997259140015',\n",
       "  '0.8993126153945923',\n",
       "  '0.8995078206062317',\n",
       "  '0.8993973135948181',\n",
       "  '0.8986347317695618',\n",
       "  '0.8997136950492859',\n",
       "  '0.8984349966049194',\n",
       "  '0.8982857465744019',\n",
       "  '0.9011440873146057',\n",
       "  '0.9014029502868652',\n",
       "  '0.8972306251525879',\n",
       "  '0.8991243839263916',\n",
       "  '0.8993282318115234',\n",
       "  '0.896642804145813',\n",
       "  '0.8944332003593445',\n",
       "  '0.8991830348968506',\n",
       "  '0.9009276628494263',\n",
       "  '0.8971466422080994',\n",
       "  '0.8953496813774109',\n",
       "  '0.8964655995368958',\n",
       "  '0.8998795747756958',\n",
       "  '0.8971389532089233',\n",
       "  '0.9004243016242981',\n",
       "  '0.9017519950866699',\n",
       "  '0.9000090956687927',\n",
       "  '0.9013753533363342',\n",
       "  '0.8990960121154785',\n",
       "  '0.8986802101135254',\n",
       "  '0.8978266716003418',\n",
       "  '0.900277853012085',\n",
       "  '0.897472083568573',\n",
       "  '0.8987855911254883',\n",
       "  '0.8990347981452942',\n",
       "  '0.8985582590103149',\n",
       "  '0.8967729210853577',\n",
       "  '0.8976773023605347',\n",
       "  '0.9018622636795044',\n",
       "  '0.8983471989631653',\n",
       "  '0.8996958136558533',\n",
       "  '0.9020639061927795',\n",
       "  '0.8993401527404785',\n",
       "  '0.8965025544166565',\n",
       "  '0.8942627906799316',\n",
       "  '0.9005441665649414',\n",
       "  '0.9009757041931152',\n",
       "  '0.9017431139945984',\n",
       "  '0.9002312421798706',\n",
       "  '0.8975719213485718',\n",
       "  '0.901309609413147',\n",
       "  '0.8971978425979614',\n",
       "  '0.8994025588035583',\n",
       "  '0.898430347442627',\n",
       "  '0.8976981043815613',\n",
       "  '0.897429883480072',\n",
       "  '0.9005255103111267',\n",
       "  '0.9035282135009766',\n",
       "  '0.9018701314926147',\n",
       "  '0.9025741219520569',\n",
       "  '0.8992281556129456',\n",
       "  '0.9022198915481567',\n",
       "  '0.8987030982971191',\n",
       "  '0.899267852306366',\n",
       "  '0.899855375289917',\n",
       "  '0.899884819984436',\n",
       "  '0.9024949669837952',\n",
       "  '0.9009581804275513',\n",
       "  '0.9008644223213196',\n",
       "  '0.8955419063568115',\n",
       "  '0.8998335003852844',\n",
       "  '0.8978575468063354',\n",
       "  '0.9005813002586365',\n",
       "  '0.9003056883811951',\n",
       "  '0.899495542049408',\n",
       "  '0.9008046984672546',\n",
       "  '0.8979083299636841',\n",
       "  '0.9002606272697449',\n",
       "  '0.9002745151519775',\n",
       "  '0.9025304317474365',\n",
       "  '0.8992761969566345',\n",
       "  '0.894848108291626',\n",
       "  '0.9011947512626648',\n",
       "  '0.8972732424736023',\n",
       "  '0.9001396894454956',\n",
       "  '0.8990277051925659',\n",
       "  '0.903668224811554',\n",
       "  '0.900773823261261',\n",
       "  '0.9034006595611572',\n",
       "  '0.9005709290504456',\n",
       "  '0.8975184559822083',\n",
       "  '0.9012057185173035',\n",
       "  '0.901671290397644',\n",
       "  '0.901948094367981',\n",
       "  '0.9001194834709167',\n",
       "  '0.8982113003730774',\n",
       "  '0.8995358943939209',\n",
       "  '0.9015809297561646',\n",
       "  '0.900669515132904',\n",
       "  '0.901185154914856',\n",
       "  '0.9020863175392151',\n",
       "  '0.9005879759788513',\n",
       "  '0.8994649648666382',\n",
       "  '0.8994749784469604',\n",
       "  '0.9020484089851379',\n",
       "  '0.9015147686004639',\n",
       "  '0.9040935635566711',\n",
       "  '0.9013170599937439',\n",
       "  '0.9011128544807434',\n",
       "  '0.9003209471702576',\n",
       "  '0.9011392593383789',\n",
       "  '0.9012719392776489',\n",
       "  '0.9021766185760498',\n",
       "  '0.9023639559745789',\n",
       "  '0.9012442231178284',\n",
       "  '0.9028757214546204',\n",
       "  '0.9015802145004272',\n",
       "  '0.9021894931793213',\n",
       "  '0.9020072221755981',\n",
       "  '0.9011106491088867',\n",
       "  '0.9033202528953552',\n",
       "  '0.9011791348457336',\n",
       "  '0.9033049941062927',\n",
       "  '0.9006044864654541',\n",
       "  '0.9055103063583374',\n",
       "  '0.9019255042076111',\n",
       "  '0.9020522236824036',\n",
       "  '0.9012000560760498',\n",
       "  '0.9010416865348816',\n",
       "  '0.902572512626648',\n",
       "  '0.9028521776199341',\n",
       "  '0.9021664261817932',\n",
       "  '0.9023473858833313',\n",
       "  '0.9021760821342468',\n",
       "  '0.9013053774833679',\n",
       "  '0.9016866087913513',\n",
       "  '0.9008788466453552',\n",
       "  '0.9003567099571228',\n",
       "  '0.9015581011772156',\n",
       "  '0.9013053774833679',\n",
       "  '0.9014074206352234',\n",
       "  '0.9025560617446899',\n",
       "  '0.9016554951667786',\n",
       "  '0.9036301970481873',\n",
       "  '0.9033485651016235',\n",
       "  '0.9013168811798096',\n",
       "  '0.9024145603179932',\n",
       "  '0.8994607329368591',\n",
       "  '0.9006325602531433',\n",
       "  '0.9026731252670288',\n",
       "  '0.8998688459396362',\n",
       "  '0.8999889492988586',\n",
       "  '0.9009572863578796',\n",
       "  '0.9015909433364868',\n",
       "  '0.8983802199363708'],\n",
       " 'true_negatives': ['140314272.0',\n",
       "  '160480896.0',\n",
       "  '161898704.0',\n",
       "  '164223536.0',\n",
       "  '165692640.0',\n",
       "  '166660272.0',\n",
       "  '167122240.0',\n",
       "  '167741888.0',\n",
       "  '169485760.0',\n",
       "  '169984368.0',\n",
       "  '170331008.0',\n",
       "  '171406992.0',\n",
       "  '171295424.0',\n",
       "  '171761392.0',\n",
       "  '171966000.0',\n",
       "  '172892432.0',\n",
       "  '172932256.0',\n",
       "  '173498800.0',\n",
       "  '173373680.0',\n",
       "  '173900384.0',\n",
       "  '173467456.0',\n",
       "  '174894880.0',\n",
       "  '176073328.0',\n",
       "  '176602592.0',\n",
       "  '177258720.0',\n",
       "  '177678368.0',\n",
       "  '178068112.0',\n",
       "  '178317440.0',\n",
       "  '178630304.0',\n",
       "  '178986208.0',\n",
       "  '179322080.0',\n",
       "  '179442128.0',\n",
       "  '179582352.0',\n",
       "  '179941312.0',\n",
       "  '180012096.0',\n",
       "  '180222832.0',\n",
       "  '180313472.0',\n",
       "  '180365584.0',\n",
       "  '180470272.0',\n",
       "  '180676544.0',\n",
       "  '180720064.0',\n",
       "  '180803632.0',\n",
       "  '181114448.0',\n",
       "  '181224928.0',\n",
       "  '181029200.0',\n",
       "  '181391808.0',\n",
       "  '181428624.0',\n",
       "  '181482672.0',\n",
       "  '181657632.0',\n",
       "  '181643760.0',\n",
       "  '181564480.0',\n",
       "  '181718064.0',\n",
       "  '181918720.0',\n",
       "  '181891648.0',\n",
       "  '181965760.0',\n",
       "  '182006560.0',\n",
       "  '181996416.0',\n",
       "  '182124560.0',\n",
       "  '182213040.0',\n",
       "  '182434432.0',\n",
       "  '182211328.0',\n",
       "  '182362272.0',\n",
       "  '182487808.0',\n",
       "  '182584368.0',\n",
       "  '182567968.0',\n",
       "  '182685408.0',\n",
       "  '182696160.0',\n",
       "  '182638784.0',\n",
       "  '182737760.0',\n",
       "  '182764752.0',\n",
       "  '182865456.0',\n",
       "  '182820384.0',\n",
       "  '182891200.0',\n",
       "  '183011856.0',\n",
       "  '182837584.0',\n",
       "  '183000464.0',\n",
       "  '183076640.0',\n",
       "  '183071360.0',\n",
       "  '183288688.0',\n",
       "  '183098784.0',\n",
       "  '183241344.0',\n",
       "  '183135776.0',\n",
       "  '183232640.0',\n",
       "  '183253344.0',\n",
       "  '183404352.0',\n",
       "  '183358432.0',\n",
       "  '183400688.0',\n",
       "  '183404160.0',\n",
       "  '183386096.0',\n",
       "  '183504720.0',\n",
       "  '183654912.0',\n",
       "  '183555168.0',\n",
       "  '183598096.0',\n",
       "  '183593824.0',\n",
       "  '183611648.0',\n",
       "  '183646800.0',\n",
       "  '183698160.0',\n",
       "  '183722624.0',\n",
       "  '183778144.0',\n",
       "  '183753872.0',\n",
       "  '183718000.0',\n",
       "  '183851296.0',\n",
       "  '183911504.0',\n",
       "  '183903488.0',\n",
       "  '183858720.0',\n",
       "  '183903296.0',\n",
       "  '183992480.0',\n",
       "  '183904784.0',\n",
       "  '184098048.0',\n",
       "  '183909056.0',\n",
       "  '184054512.0',\n",
       "  '183970032.0',\n",
       "  '184117152.0',\n",
       "  '184041616.0',\n",
       "  '184113600.0',\n",
       "  '184070112.0',\n",
       "  '184232048.0',\n",
       "  '184168512.0',\n",
       "  '184204544.0',\n",
       "  '184291552.0',\n",
       "  '184252656.0',\n",
       "  '184257664.0',\n",
       "  '184315872.0',\n",
       "  '184291776.0',\n",
       "  '184373920.0',\n",
       "  '184421472.0',\n",
       "  '184388512.0',\n",
       "  '184348656.0',\n",
       "  '184424848.0',\n",
       "  '184472576.0',\n",
       "  '184464912.0',\n",
       "  '184417056.0',\n",
       "  '184535472.0',\n",
       "  '184547712.0',\n",
       "  '184456832.0',\n",
       "  '184517968.0',\n",
       "  '184582176.0',\n",
       "  '184613296.0',\n",
       "  '184567248.0',\n",
       "  '184573328.0',\n",
       "  '184575248.0',\n",
       "  '184669744.0',\n",
       "  '184553184.0',\n",
       "  '184624608.0',\n",
       "  '184715936.0',\n",
       "  '184627920.0',\n",
       "  '184747904.0',\n",
       "  '184635280.0',\n",
       "  '184787472.0',\n",
       "  '184756192.0',\n",
       "  '184765648.0',\n",
       "  '184763600.0',\n",
       "  '184678288.0',\n",
       "  '184830528.0',\n",
       "  '184926672.0',\n",
       "  '184881792.0',\n",
       "  '184963040.0',\n",
       "  '184886672.0',\n",
       "  '184849744.0',\n",
       "  '184904544.0',\n",
       "  '184858592.0',\n",
       "  '184890352.0',\n",
       "  '184931328.0',\n",
       "  '184984960.0',\n",
       "  '184962912.0',\n",
       "  '184934720.0',\n",
       "  '184931824.0',\n",
       "  '184972816.0',\n",
       "  '185038368.0',\n",
       "  '185019408.0',\n",
       "  '184961472.0',\n",
       "  '185040960.0',\n",
       "  '185101280.0',\n",
       "  '185207280.0',\n",
       "  '185126480.0',\n",
       "  '185066176.0',\n",
       "  '185207072.0',\n",
       "  '185188784.0',\n",
       "  '185146784.0',\n",
       "  '185101840.0',\n",
       "  '185253104.0',\n",
       "  '185122576.0',\n",
       "  '185168608.0',\n",
       "  '185295696.0',\n",
       "  '185204528.0',\n",
       "  '185205328.0',\n",
       "  '185214320.0',\n",
       "  '185304560.0',\n",
       "  '185238720.0',\n",
       "  '185269936.0',\n",
       "  '185281488.0',\n",
       "  '185230224.0',\n",
       "  '185283600.0',\n",
       "  '185264560.0',\n",
       "  '185239072.0',\n",
       "  '185338304.0',\n",
       "  '185430688.0',\n",
       "  '185386464.0',\n",
       "  '185375264.0',\n",
       "  '185277968.0',\n",
       "  '185398176.0',\n",
       "  '185344208.0',\n",
       "  '185334432.0',\n",
       "  '185396560.0',\n",
       "  '185381728.0',\n",
       "  '185514768.0',\n",
       "  '185474736.0',\n",
       "  '185481808.0',\n",
       "  '185441808.0',\n",
       "  '185369440.0',\n",
       "  '185489840.0',\n",
       "  '185554320.0',\n",
       "  '185572160.0',\n",
       "  '185487008.0',\n",
       "  '185556240.0',\n",
       "  '185478576.0',\n",
       "  '185612848.0',\n",
       "  '185581232.0',\n",
       "  '185634688.0',\n",
       "  '185530080.0',\n",
       "  '185616064.0',\n",
       "  '185565984.0',\n",
       "  '185604752.0',\n",
       "  '185561632.0',\n",
       "  '185597200.0',\n",
       "  '185542448.0',\n",
       "  '185744128.0',\n",
       "  '185564032.0',\n",
       "  '185643552.0',\n",
       "  '185663616.0',\n",
       "  '185666960.0',\n",
       "  '185631504.0',\n",
       "  '185621792.0',\n",
       "  '185718304.0',\n",
       "  '185715616.0',\n",
       "  '185651008.0',\n",
       "  '185689888.0',\n",
       "  '185707344.0',\n",
       "  '185754672.0',\n",
       "  '185709808.0',\n",
       "  '185710800.0',\n",
       "  '185740896.0',\n",
       "  '185672320.0',\n",
       "  '185716224.0',\n",
       "  '185781152.0',\n",
       "  '185729040.0',\n",
       "  '185771088.0',\n",
       "  '185751712.0',\n",
       "  '185801520.0',\n",
       "  '185804176.0',\n",
       "  '185811264.0',\n",
       "  '185837904.0',\n",
       "  '185810672.0',\n",
       "  '185875072.0',\n",
       "  '185819200.0',\n",
       "  '185932736.0',\n",
       "  '185852688.0',\n",
       "  '185866496.0',\n",
       "  '185805200.0',\n",
       "  '185843040.0',\n",
       "  '185829760.0',\n",
       "  '185930480.0',\n",
       "  '185944560.0',\n",
       "  '186008736.0',\n",
       "  '185925360.0',\n",
       "  '185880736.0',\n",
       "  '185943488.0',\n",
       "  '185931296.0',\n",
       "  '185934144.0',\n",
       "  '185958336.0',\n",
       "  '185948848.0',\n",
       "  '186016576.0',\n",
       "  '185963312.0',\n",
       "  '185937120.0',\n",
       "  '185925360.0',\n",
       "  '185890848.0',\n",
       "  '186019104.0',\n",
       "  '185962288.0',\n",
       "  '185992912.0',\n",
       "  '186012096.0',\n",
       "  '185955072.0',\n",
       "  '186072544.0',\n",
       "  '186077632.0',\n",
       "  '185991936.0',\n",
       "  '185990960.0',\n",
       "  '186085792.0',\n",
       "  '186023168.0',\n",
       "  '186164688.0',\n",
       "  '186180176.0',\n",
       "  '186034864.0',\n",
       "  '186015328.0',\n",
       "  '186077312.0',\n",
       "  '186037648.0',\n",
       "  '186101456.0',\n",
       "  '186027872.0',\n",
       "  '186130592.0',\n",
       "  '186062464.0',\n",
       "  '186109088.0',\n",
       "  '186149104.0',\n",
       "  '186041824.0',\n",
       "  '186213136.0'],\n",
       " 'precision': ['0.697047233581543',\n",
       "  '0.7996317148208618',\n",
       "  '0.809070885181427',\n",
       "  '0.823722779750824',\n",
       "  '0.8332484364509583',\n",
       "  '0.8396627902984619',\n",
       "  '0.8432087898254395',\n",
       "  '0.8475856781005859',\n",
       "  '0.8580160140991211',\n",
       "  '0.8629460334777832',\n",
       "  '0.8647677898406982',\n",
       "  '0.8719155192375183',\n",
       "  '0.8719436526298523',\n",
       "  '0.8751697540283203',\n",
       "  '0.8764241933822632',\n",
       "  '0.8830808997154236',\n",
       "  '0.8837368488311768',\n",
       "  '0.8868685960769653',\n",
       "  '0.8869044780731201',\n",
       "  '0.8907247185707092',\n",
       "  '0.8871816396713257',\n",
       "  '0.898034393787384',\n",
       "  '0.9061962962150574',\n",
       "  '0.9103838205337524',\n",
       "  '0.9149404764175415',\n",
       "  '0.9186733365058899',\n",
       "  '0.9215167760848999',\n",
       "  '0.9230862855911255',\n",
       "  '0.9255944490432739',\n",
       "  '0.9279364347457886',\n",
       "  '0.9308333992958069',\n",
       "  '0.9320839643478394',\n",
       "  '0.9332407116889954',\n",
       "  '0.9350674152374268',\n",
       "  '0.9355627298355103',\n",
       "  '0.9372427463531494',\n",
       "  '0.9380961060523987',\n",
       "  '0.9394775032997131',\n",
       "  '0.9400296211242676',\n",
       "  '0.9413082599639893',\n",
       "  '0.9420340061187744',\n",
       "  '0.9423638582229614',\n",
       "  '0.9440995454788208',\n",
       "  '0.9450093507766724',\n",
       "  '0.9443277716636658',\n",
       "  '0.946672797203064',\n",
       "  '0.9462846517562866',\n",
       "  '0.9471175670623779',\n",
       "  '0.9483641386032104',\n",
       "  '0.9488745927810669',\n",
       "  '0.9480573534965515',\n",
       "  '0.9491622447967529',\n",
       "  '0.9505270719528198',\n",
       "  '0.9501978754997253',\n",
       "  '0.951066792011261',\n",
       "  '0.9513087868690491',\n",
       "  '0.9517623782157898',\n",
       "  '0.9522722363471985',\n",
       "  '0.952914297580719',\n",
       "  '0.9540858268737793',\n",
       "  '0.9530552625656128',\n",
       "  '0.9537534713745117',\n",
       "  '0.9546761512756348',\n",
       "  '0.9552854895591736',\n",
       "  '0.9557392597198486',\n",
       "  '0.95574551820755',\n",
       "  '0.9562594890594482',\n",
       "  '0.9565346240997314',\n",
       "  '0.9569517970085144',\n",
       "  '0.9567278623580933',\n",
       "  '0.9577279090881348',\n",
       "  '0.9579380750656128',\n",
       "  '0.9582860469818115',\n",
       "  '0.9583082795143127',\n",
       "  '0.9580734968185425',\n",
       "  '0.9590890407562256',\n",
       "  '0.9592689871788025',\n",
       "  '0.9595064520835876',\n",
       "  '0.9603791236877441',\n",
       "  '0.9602071642875671',\n",
       "  '0.9606888890266418',\n",
       "  '0.9601970314979553',\n",
       "  '0.9606866240501404',\n",
       "  '0.9607180953025818',\n",
       "  '0.9616856575012207',\n",
       "  '0.9615132212638855',\n",
       "  '0.9619907736778259',\n",
       "  '0.9623112678527832',\n",
       "  '0.9622284770011902',\n",
       "  '0.9626361131668091',\n",
       "  '0.9633382558822632',\n",
       "  '0.9634891748428345',\n",
       "  '0.9633897542953491',\n",
       "  '0.9638153314590454',\n",
       "  '0.9635764360427856',\n",
       "  '0.9635727405548096',\n",
       "  '0.9646076560020447',\n",
       "  '0.9643229842185974',\n",
       "  '0.9646303653717041',\n",
       "  '0.9642285704612732',\n",
       "  '0.9646559953689575',\n",
       "  '0.9650861024856567',\n",
       "  '0.9651906490325928',\n",
       "  '0.9654732346534729',\n",
       "  '0.965610146522522',\n",
       "  '0.9657854437828064',\n",
       "  '0.9660265445709229',\n",
       "  '0.966297447681427',\n",
       "  '0.9667637944221497',\n",
       "  '0.9664103984832764',\n",
       "  '0.9670302867889404',\n",
       "  '0.9670767188072205',\n",
       "  '0.9671317934989929',\n",
       "  '0.9671006798744202',\n",
       "  '0.9673776030540466',\n",
       "  '0.9672824144363403',\n",
       "  '0.967924952507019',\n",
       "  '0.967901885509491',\n",
       "  '0.9683567881584167',\n",
       "  '0.9681828022003174',\n",
       "  '0.9685369729995728',\n",
       "  '0.968910813331604',\n",
       "  '0.9686248898506165',\n",
       "  '0.9687194228172302',\n",
       "  '0.9690098166465759',\n",
       "  '0.9692242741584778',\n",
       "  '0.9695760011672974',\n",
       "  '0.9690899848937988',\n",
       "  '0.9700545072555542',\n",
       "  '0.9700056314468384',\n",
       "  '0.9700517654418945',\n",
       "  '0.9698360562324524',\n",
       "  '0.9701371192932129',\n",
       "  '0.970492422580719',\n",
       "  '0.9706015586853027',\n",
       "  '0.9706470370292664',\n",
       "  '0.9703733921051025',\n",
       "  '0.9706612229347229',\n",
       "  '0.9707961082458496',\n",
       "  '0.9711171984672546',\n",
       "  '0.9712730050086975',\n",
       "  '0.9713047742843628',\n",
       "  '0.9711163640022278',\n",
       "  '0.971438467502594',\n",
       "  '0.9715708494186401',\n",
       "  '0.971441924571991',\n",
       "  '0.9717884659767151',\n",
       "  '0.971777617931366',\n",
       "  '0.9719893932342529',\n",
       "  '0.97223299741745',\n",
       "  '0.9723386168479919',\n",
       "  '0.9727432727813721',\n",
       "  '0.9720832109451294',\n",
       "  '0.9726117253303528',\n",
       "  '0.9729987978935242',\n",
       "  '0.972753643989563',\n",
       "  '0.9731037616729736',\n",
       "  '0.9731389880180359',\n",
       "  '0.9733129143714905',\n",
       "  '0.9731152057647705',\n",
       "  '0.973285436630249',\n",
       "  '0.9735273122787476',\n",
       "  '0.9736219644546509',\n",
       "  '0.9740278124809265',\n",
       "  '0.9739133715629578',\n",
       "  '0.9740716814994812',\n",
       "  '0.9740238785743713',\n",
       "  '0.9739362001419067',\n",
       "  '0.9744402170181274',\n",
       "  '0.9741259813308716',\n",
       "  '0.9745169878005981',\n",
       "  '0.9741702079772949',\n",
       "  '0.9743323922157288',\n",
       "  '0.9749248623847961',\n",
       "  '0.9750334620475769',\n",
       "  '0.9748169779777527',\n",
       "  '0.9753726720809937',\n",
       "  '0.9752114415168762',\n",
       "  '0.9748543500900269',\n",
       "  '0.9751719236373901',\n",
       "  '0.9754666686058044',\n",
       "  '0.9756208658218384',\n",
       "  '0.9754857420921326',\n",
       "  '0.9758347868919373',\n",
       "  '0.975663423538208',\n",
       "  '0.9759548306465149',\n",
       "  '0.9758940935134888',\n",
       "  '0.9761691093444824',\n",
       "  '0.9759950041770935',\n",
       "  '0.9759559631347656',\n",
       "  '0.9760116338729858',\n",
       "  '0.9758955240249634',\n",
       "  '0.9764343500137329',\n",
       "  '0.9765348434448242',\n",
       "  '0.9765365719795227',\n",
       "  '0.976730227470398',\n",
       "  '0.9767037034034729',\n",
       "  '0.9766885638237',\n",
       "  '0.9769036769866943',\n",
       "  '0.976840615272522',\n",
       "  '0.977047860622406',\n",
       "  '0.9769771099090576',\n",
       "  '0.9772769212722778',\n",
       "  '0.9773411154747009',\n",
       "  '0.9773579835891724',\n",
       "  '0.9775033593177795',\n",
       "  '0.9776463508605957',\n",
       "  '0.9775069952011108',\n",
       "  '0.9777307510375977',\n",
       "  '0.9776312708854675',\n",
       "  '0.9779581427574158',\n",
       "  '0.9781012535095215',\n",
       "  '0.9780996441841125',\n",
       "  '0.9780294895172119',\n",
       "  '0.9780864119529724',\n",
       "  '0.9781153798103333',\n",
       "  '0.9782226085662842',\n",
       "  '0.9787148237228394',\n",
       "  '0.978445827960968',\n",
       "  '0.9785471558570862',\n",
       "  '0.9786204099655151',\n",
       "  '0.9786542654037476',\n",
       "  '0.9785309433937073',\n",
       "  '0.9782592058181763',\n",
       "  '0.9786441922187805',\n",
       "  '0.9787688255310059',\n",
       "  '0.9787797927856445',\n",
       "  '0.9787973165512085',\n",
       "  '0.9787039756774902',\n",
       "  '0.9791632890701294',\n",
       "  '0.9791553020477295',\n",
       "  '0.9791326522827148',\n",
       "  '0.9792844653129578',\n",
       "  '0.9794207811355591',\n",
       "  '0.9793580770492554',\n",
       "  '0.9793590903282166',\n",
       "  '0.9795582294464111',\n",
       "  '0.9795344471931458',\n",
       "  '0.979561448097229',\n",
       "  '0.9796355962753296',\n",
       "  '0.9798083901405334',\n",
       "  '0.9797418117523193',\n",
       "  '0.9797506332397461',\n",
       "  '0.9799708724021912',\n",
       "  '0.9800202250480652',\n",
       "  '0.9800269603729248',\n",
       "  '0.9801899194717407',\n",
       "  '0.9801005721092224',\n",
       "  '0.9801856875419617',\n",
       "  '0.9802607893943787',\n",
       "  '0.9803922772407532',\n",
       "  '0.9802834391593933',\n",
       "  '0.9805747270584106',\n",
       "  '0.9804979562759399',\n",
       "  '0.9806556701660156',\n",
       "  '0.9806439876556396',\n",
       "  '0.9806972742080688',\n",
       "  '0.9806175827980042',\n",
       "  '0.9806070327758789',\n",
       "  '0.9807417988777161',\n",
       "  '0.9805643558502197',\n",
       "  '0.9810113310813904',\n",
       "  '0.9811404943466187',\n",
       "  '0.9808997511863708',\n",
       "  '0.9810243844985962',\n",
       "  '0.9812046885490417',\n",
       "  '0.9810690879821777',\n",
       "  '0.981246829032898',\n",
       "  '0.9811863899230957',\n",
       "  '0.9813365936279297',\n",
       "  '0.9812892079353333',\n",
       "  '0.9815109372138977',\n",
       "  '0.981141984462738',\n",
       "  '0.9812327027320862',\n",
       "  '0.9812033176422119',\n",
       "  '0.9811924695968628',\n",
       "  '0.9815382957458496',\n",
       "  '0.9817559123039246',\n",
       "  '0.9815459847450256',\n",
       "  '0.9817598462104797',\n",
       "  '0.9818880558013916',\n",
       "  '0.9819789528846741',\n",
       "  '0.9821243286132812',\n",
       "  '0.9820603132247925',\n",
       "  '0.9820519685745239',\n",
       "  '0.9819716215133667',\n",
       "  '0.9818881154060364',\n",
       "  '0.9822754859924316',\n",
       "  '0.9821773767471313',\n",
       "  '0.9823257327079773',\n",
       "  '0.982252836227417',\n",
       "  '0.982466459274292',\n",
       "  '0.9822307825088501',\n",
       "  '0.9822655916213989',\n",
       "  '0.9824095368385315',\n",
       "  '0.982567310333252',\n",
       "  '0.9826000928878784',\n",
       "  '0.9824233055114746',\n",
       "  '0.982694149017334',\n",
       "  '0.9827558994293213',\n",
       "  '0.9827830791473389'],\n",
       " 'val_binary_iou': ['0.6967154741287231',\n",
       "  '0.7352555990219116',\n",
       "  '0.7283757328987122',\n",
       "  '0.7072028517723083',\n",
       "  '0.701651930809021',\n",
       "  '0.7289546728134155',\n",
       "  '0.7504729628562927',\n",
       "  '0.7869912385940552',\n",
       "  '0.7504804134368896',\n",
       "  '0.6692835092544556',\n",
       "  '0.799962043762207',\n",
       "  '0.7830523252487183',\n",
       "  '0.7750580310821533',\n",
       "  '0.7304768562316895',\n",
       "  '0.7515079975128174',\n",
       "  '0.7282230257987976',\n",
       "  '0.6940493583679199',\n",
       "  '0.7969772815704346',\n",
       "  '0.7984521389007568',\n",
       "  '0.7518163919448853',\n",
       "  '0.7643896341323853',\n",
       "  '0.7456974983215332',\n",
       "  '0.7577053308486938',\n",
       "  '0.7190448045730591',\n",
       "  '0.7402808666229248',\n",
       "  '0.745721161365509',\n",
       "  '0.7498765587806702',\n",
       "  '0.7555123567581177',\n",
       "  '0.7423769235610962',\n",
       "  '0.7744722962379456',\n",
       "  '0.7800848484039307',\n",
       "  '0.7575598955154419',\n",
       "  '0.7758088707923889',\n",
       "  '0.7599557638168335',\n",
       "  '0.7625356912612915',\n",
       "  '0.779231071472168',\n",
       "  '0.7680887579917908',\n",
       "  '0.7669703960418701',\n",
       "  '0.783979594707489',\n",
       "  '0.7748888731002808',\n",
       "  '0.7713758945465088',\n",
       "  '0.7611948251724243',\n",
       "  '0.749262809753418',\n",
       "  '0.7585374712944031',\n",
       "  '0.7918010354042053',\n",
       "  '0.7685357332229614',\n",
       "  '0.7656505107879639',\n",
       "  '0.7731005549430847',\n",
       "  '0.7723791599273682',\n",
       "  '0.8054614067077637',\n",
       "  '0.7809540033340454',\n",
       "  '0.7883769273757935',\n",
       "  '0.7911272644996643',\n",
       "  '0.8025419116020203',\n",
       "  '0.7978577613830566',\n",
       "  '0.7751379013061523',\n",
       "  '0.7940295934677124',\n",
       "  '0.8021144270896912',\n",
       "  '0.7807443141937256',\n",
       "  '0.7773395776748657',\n",
       "  '0.7936707139015198',\n",
       "  '0.8045529127120972',\n",
       "  '0.7957438230514526',\n",
       "  '0.7943081259727478',\n",
       "  '0.8034619092941284',\n",
       "  '0.8026022911071777',\n",
       "  '0.7993482351303101',\n",
       "  '0.8007103800773621',\n",
       "  '0.7839406728744507',\n",
       "  '0.7757952213287354',\n",
       "  '0.7893651723861694',\n",
       "  '0.7928259372711182',\n",
       "  '0.8001554012298584',\n",
       "  '0.8033041954040527',\n",
       "  '0.7862776517868042',\n",
       "  '0.793936014175415',\n",
       "  '0.7949930429458618',\n",
       "  '0.791543185710907',\n",
       "  '0.7874499559402466',\n",
       "  '0.809036374092102',\n",
       "  '0.8137847185134888',\n",
       "  '0.7961822748184204',\n",
       "  '0.8010764718055725',\n",
       "  '0.803890585899353',\n",
       "  '0.7912968397140503',\n",
       "  '0.8115648627281189',\n",
       "  '0.8119277358055115',\n",
       "  '0.8141613602638245',\n",
       "  '0.8019356727600098',\n",
       "  '0.7830171585083008',\n",
       "  '0.798548698425293',\n",
       "  '0.7832310199737549',\n",
       "  '0.7997206449508667',\n",
       "  '0.8020412921905518',\n",
       "  '0.8084969520568848',\n",
       "  '0.8081687688827515',\n",
       "  '0.8115149736404419',\n",
       "  '0.8024887442588806',\n",
       "  '0.8117283582687378',\n",
       "  '0.8094222545623779',\n",
       "  '0.8053032159805298',\n",
       "  '0.8013923764228821',\n",
       "  '0.8177619576454163',\n",
       "  '0.8097795248031616',\n",
       "  '0.8157662153244019',\n",
       "  '0.8095352649688721',\n",
       "  '0.8082374334335327',\n",
       "  '0.8140619397163391',\n",
       "  '0.8057242631912231',\n",
       "  '0.8058465719223022',\n",
       "  '0.8049204349517822',\n",
       "  '0.8020786046981812',\n",
       "  '0.8071545362472534',\n",
       "  '0.8124215602874756',\n",
       "  '0.809497594833374',\n",
       "  '0.8093163967132568',\n",
       "  '0.808013916015625',\n",
       "  '0.8051018714904785',\n",
       "  '0.814984917640686',\n",
       "  '0.8084009885787964',\n",
       "  '0.8121891021728516',\n",
       "  '0.8150467872619629',\n",
       "  '0.8129895925521851',\n",
       "  '0.8162726163864136',\n",
       "  '0.8101503849029541',\n",
       "  '0.808282196521759',\n",
       "  '0.8097876310348511',\n",
       "  '0.8135617971420288',\n",
       "  '0.8116140365600586',\n",
       "  '0.8113645911216736',\n",
       "  '0.8065460324287415',\n",
       "  '0.816750168800354',\n",
       "  '0.814214825630188',\n",
       "  '0.8138250112533569',\n",
       "  '0.8155183792114258',\n",
       "  '0.8101277351379395',\n",
       "  '0.8125179409980774',\n",
       "  '0.8113994598388672',\n",
       "  '0.8075441122055054',\n",
       "  '0.8103611469268799',\n",
       "  '0.8137588500976562',\n",
       "  '0.8105100989341736',\n",
       "  '0.8155444860458374',\n",
       "  '0.8148764371871948',\n",
       "  '0.8182160258293152',\n",
       "  '0.8127116560935974',\n",
       "  '0.8154093027114868',\n",
       "  '0.8120075464248657',\n",
       "  '0.8075240850448608',\n",
       "  '0.8145487308502197',\n",
       "  '0.8150507211685181',\n",
       "  '0.8148412108421326',\n",
       "  '0.8137015700340271',\n",
       "  '0.8153181672096252',\n",
       "  '0.8133596181869507',\n",
       "  '0.8129698038101196',\n",
       "  '0.8177893161773682',\n",
       "  '0.818024218082428',\n",
       "  '0.8114784955978394',\n",
       "  '0.8142521381378174',\n",
       "  '0.8148083686828613',\n",
       "  '0.8104604482650757',\n",
       "  '0.8068940043449402',\n",
       "  '0.8147063255310059',\n",
       "  '0.8174810409545898',\n",
       "  '0.8112038373947144',\n",
       "  '0.8082543611526489',\n",
       "  '0.8102136850357056',\n",
       "  '0.8157415986061096',\n",
       "  '0.810924768447876',\n",
       "  '0.8167648315429688',\n",
       "  '0.8185654878616333',\n",
       "  '0.8159568309783936',\n",
       "  '0.8182584047317505',\n",
       "  '0.8143084049224854',\n",
       "  '0.8137122392654419',\n",
       "  '0.8123931884765625',\n",
       "  '0.8163043260574341',\n",
       "  '0.8120450973510742',\n",
       "  '0.8137015104293823',\n",
       "  '0.8144283294677734',\n",
       "  '0.8132280707359314',\n",
       "  '0.8105040192604065',\n",
       "  '0.8122310638427734',\n",
       "  '0.8189541697502136',\n",
       "  '0.8134002685546875',\n",
       "  '0.8154067993164062',\n",
       "  '0.8193738460540771',\n",
       "  '0.8148969411849976',\n",
       "  '0.8104338645935059',\n",
       "  '0.8068288564682007',\n",
       "  '0.8168461322784424',\n",
       "  '0.8176761269569397',\n",
       "  '0.8188024759292603',\n",
       "  '0.8162839412689209',\n",
       "  '0.8119697570800781',\n",
       "  '0.8179870843887329',\n",
       "  '0.8112662434577942',\n",
       "  '0.8151825666427612',\n",
       "  '0.8134429454803467',\n",
       "  '0.8123361468315125',\n",
       "  '0.811632513999939',\n",
       "  '0.8169282674789429',\n",
       "  '0.8214859962463379',\n",
       "  '0.8189995884895325',\n",
       "  '0.8200896978378296',\n",
       "  '0.814601480960846',\n",
       "  '0.8194261789321899',\n",
       "  '0.813915491104126',\n",
       "  '0.8146827220916748',\n",
       "  '0.8157861232757568',\n",
       "  '0.8159006834030151',\n",
       "  '0.8198785781860352',\n",
       "  '0.8173830509185791',\n",
       "  '0.8171799182891846',\n",
       "  '0.808740496635437',\n",
       "  '0.8155840635299683',\n",
       "  '0.8123694658279419',\n",
       "  '0.8169243335723877',\n",
       "  '0.8164654970169067',\n",
       "  '0.8153438568115234',\n",
       "  '0.8174383640289307',\n",
       "  '0.8123666048049927',\n",
       "  '0.8164288401603699',\n",
       "  '0.8163049221038818',\n",
       "  '0.820013701915741',\n",
       "  '0.8145298957824707',\n",
       "  '0.8078068494796753',\n",
       "  '0.8177846670150757',\n",
       "  '0.8115624189376831',\n",
       "  '0.8159373998641968',\n",
       "  '0.8144282102584839',\n",
       "  '0.8217519521713257',\n",
       "  '0.8173494338989258',\n",
       "  '0.8214167356491089',\n",
       "  '0.8171262741088867',\n",
       "  '0.8119842410087585',\n",
       "  '0.8179681301116943',\n",
       "  '0.818719744682312',\n",
       "  '0.8190338611602783',\n",
       "  '0.8160821199417114',\n",
       "  '0.8132522106170654',\n",
       "  '0.8151975870132446',\n",
       "  '0.8186101913452148',\n",
       "  '0.8170602321624756',\n",
       "  '0.8177815675735474',\n",
       "  '0.8194594383239746',\n",
       "  '0.8171494007110596',\n",
       "  '0.815092921257019',\n",
       "  '0.8152129054069519',\n",
       "  '0.8194885849952698',\n",
       "  '0.8185970783233643',\n",
       "  '0.8226210474967957',\n",
       "  '0.8182144165039062',\n",
       "  '0.81792151927948',\n",
       "  '0.8164290189743042',\n",
       "  '0.8180030584335327',\n",
       "  '0.8182449340820312',\n",
       "  '0.8194875717163086',\n",
       "  '0.8199233412742615',\n",
       "  '0.8181396722793579',\n",
       "  '0.8208634853363037',\n",
       "  '0.8186273574829102',\n",
       "  '0.8196486830711365',\n",
       "  '0.8194745779037476',\n",
       "  '0.8179353475570679',\n",
       "  '0.8214128017425537',\n",
       "  '0.8180422782897949',\n",
       "  '0.8212970495223999',\n",
       "  '0.8170655965805054',\n",
       "  '0.8248006105422974',\n",
       "  '0.8192065954208374',\n",
       "  '0.8192009925842285',\n",
       "  '0.8181326389312744',\n",
       "  '0.8178730010986328',\n",
       "  '0.8203117251396179',\n",
       "  '0.820813775062561',\n",
       "  '0.819591760635376',\n",
       "  '0.8198810815811157',\n",
       "  '0.8195486068725586',\n",
       "  '0.8182732462882996',\n",
       "  '0.8187543153762817',\n",
       "  '0.817524254322052',\n",
       "  '0.816595196723938',\n",
       "  '0.8186025023460388',\n",
       "  '0.8182612061500549',\n",
       "  '0.8183460235595703',\n",
       "  '0.8200847506523132',\n",
       "  '0.8187344670295715',\n",
       "  '0.8219387531280518',\n",
       "  '0.821594774723053',\n",
       "  '0.8181982040405273',\n",
       "  '0.8200022578239441',\n",
       "  '0.8153705596923828',\n",
       "  '0.8171155452728271',\n",
       "  '0.820353627204895',\n",
       "  '0.8157865405082703',\n",
       "  '0.8160750865936279',\n",
       "  '0.817660927772522',\n",
       "  '0.8187786340713501',\n",
       "  '0.8135436773300171']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file1 = \"C:/Users/manue/OneDrive/Desktop/THESIS_NEU/output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log\"\n",
    "csv_file2 = \"C:/Users/manue/OneDrive/Desktop/THESIS_NEU/output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False.log\"\n",
    "\n",
    "def parse_csv_to_dict(file_path):\n",
    "    data = {}\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            for key, value in row.items():\n",
    "                if key in data:\n",
    "                    data[key].append(value)\n",
    "                else:\n",
    "                    data[key] = [value]\n",
    "    return data\n",
    "\n",
    "\n",
    "# CSV-Datei als Dictionary parsen\n",
    "csv_data1 = parse_csv_to_dict(csv_file1)\n",
    "csv_data2 = parse_csv_to_dict(csv_file2)\n",
    "csv_data2.pop('epoch')\n",
    "\n",
    "\n",
    "def merge_dictionaries(dict1, dict2):\n",
    "    merged_dict = {}\n",
    "    keys = set(dict1.keys()) | set(dict2.keys())\n",
    "    for key in keys:\n",
    "        merged_dict[key] = dict1.get(key, []) + dict2.get(key, [])\n",
    "    return merged_dict\n",
    "\n",
    "# Beispiel-Dictionaries\n",
    "dict1 = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "dict2 = {'A': [7, 8, 9], 'C': [10, 11, 12]}\n",
    "\n",
    "# Fusionieren der Dictionaries\n",
    "merged_dict = merge_dictionaries(csv_data1, csv_data2)\n",
    "\n",
    "# Ausgabe des fusionierten Dictionaries\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        headers = ['Keys'] + list(data.keys())\n",
    "        writer.writerow(headers)\n",
    "        max_len = max(len(values) for values in data.values())\n",
    "        for i in range(max_len):\n",
    "            row = [i] + [data[key][i] if i < len(data[key]) else '' for key in data.keys()]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def write_dict_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        headers = list(data.keys())\n",
    "        writer.writerow(['Keys'] + headers)\n",
    "        max_len = max(len(values) for values in data.values())\n",
    "        for i in range(max_len):\n",
    "            row = [data[key][i] if i < len(data[key]) else '' for key in headers]\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Schreibe das Dictionary in die CSV-Datei\n",
    "write_dict_to_csv(csv_file, data)\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "combi_file = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "# Schreibe das Dictionary in die CSV-Datei\n",
    "write_dict_to_csv(combi_file, merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_file = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "dict_data = merged_dict\n",
    "\n",
    "with open(combi_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives',\n",
    "                    'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', \n",
    "                    'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', \n",
    "                    'val_precision', 'val_recall']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(20):\n",
    "        writer.writerow({'loss': dict_data['loss'][i], 'accuracy': dict_data['accuracy'][i], 'binary_iou': dict_data['binary_iou'][i], 'true_positives': dict_data['true_positives'][i],\n",
    "                        'false_positives': dict_data['false_positives'][i], 'true_negatives': dict_data['true_negatives'][i], 'false_negatives': dict_data['false_negatives'][i],\n",
    "                        'precision': dict_data['precision'][i], 'recall': dict_data['recall'][i], 'val_loss': dict_data['val_loss'][i], 'val_accuracy': dict_data['val_accuracy'][i],\n",
    "                        'val_binary_iou': dict_data['val_binary_iou'][i], 'val_true_positives': dict_data['val_true_positives'][i], 'val_false_positives': dict_data['val_false_positives'][i],\n",
    "                        'val_true_negatives': dict_data['val_true_negatives'][i], 'val_false_negatives': dict_data['val_false_negatives'][i], 'val_precision': dict_data['val_precision'][i],\n",
    "                        'val_recall': dict_data['val_recall'][i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
