{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auszuführen mit Environment \"tf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importe & Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "import shutil\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufällige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            # Transformation in \"channels_last\"-Format\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            # Erstellen einer zusätzlichen Achse um Tensor-Dimension zu erreichen\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            # Skalierung der Werte\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "# Definition des Dice-Koeffizienten\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# Ableitung einer zu minimierenden Loss-Funktion aus Dice-Koeffzient\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Rückgängig machen der Normalisierung zur korrekten Anzeige der Bilder\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    # Speicherpfade der verschiedenen Architekturen\n",
    "    model_dict = {\n",
    "        'BN': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    # Auswahl der Architektur entsprechend der verwendeten Variante\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    # Laden der JSON\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    # Laden des Modells aus JSON\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulässt, werden immer die selben zufällig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    # entsprechend der Variante müssen Gewichte unterschiedlich gesetzt werden\n",
    "    if model_type == 'BN':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte können übernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte zufällig\n",
    "    if option == 'RNDM':\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren über geladene Gewichte und zufällige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Für 1. Conv-Layer stimmt shape nicht überein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte für RGB-Channel werden übernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen überein und können übernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufügen der zufälligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zusätzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer für RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die später übersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere über Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden für diesen Layer, iteriere über diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese können daher nicht übernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # für die übrigen Layer werden die Gewichte übernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zufälligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind für erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False):\n",
    "    # Anzahl der trainierbaren Encoder Layer, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= 27\n",
    "\n",
    "    # Encoder bleibt größtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM']:\n",
    "\n",
    "    # Für das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafür werden die Layer jetzt rückwärts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # für train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, output_folder_prefix, do_early_stop):\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{output_folder_prefix}_logger/{model_name}'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + '.log')\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "    if do_early_stop:\n",
    "        early_stop =  tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_binary_iou',\n",
    "                    min_delta=0,\n",
    "                    patience=40,\n",
    "                    verbose=1,\n",
    "                    mode='max',\n",
    "                    )\n",
    "\n",
    "        callbacks.append(early_stop)  \n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def combine_log_files(output_folder_prefix, model_name):\n",
    "    # Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "    filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "    with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "        # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "        outfile.write('sep=,\\n')\n",
    "\n",
    "        for i, fname in enumerate(filenames):\n",
    "            with open(fname) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                for j, row in enumerate(reader):\n",
    "                    # überspringen des 2. Headers\n",
    "                    if i == 1 and j == 0:\n",
    "                        continue\n",
    "\n",
    "                    delimiter = ','\n",
    "                    list_to_string = delimiter.join(row)\n",
    "                    list_to_string += '\\n'\n",
    "\n",
    "                    outfile.write(list_to_string)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuchsreihe Freeze-From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 233s 546ms/step - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288 - val_loss: 0.1324 - val_accuracy: 0.7237 - val_binary_iou: 0.5219 - val_true_positives: 17575076.0000 - val_false_positives: 1821869.0000 - val_true_negatives: 59114264.0000 - val_false_negatives: 27460492.0000 - val_precision: 0.9061 - val_recall: 0.3902\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.1008 - accuracy: 0.8260 - binary_iou: 0.6955 - true_positives: 101502720.0000 - false_positives: 25956264.0000 - true_negatives: 162417888.0000 - false_negatives: 29643882.0000 - precision: 0.7964 - recall: 0.7740 - val_loss: 0.3162 - val_accuracy: 0.5801 - val_binary_iou: 0.2986 - val_true_positives: 944899.0000 - val_false_positives: 370912.0000 - val_true_negatives: 60533532.0000 - val_false_negatives: 44122376.0000 - val_precision: 0.7181 - val_recall: 0.0210\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834 - val_loss: 0.1000 - val_accuracy: 0.8302 - val_binary_iou: 0.6984 - val_true_positives: 31970022.0000 - val_false_positives: 4808101.0000 - val_true_negatives: 56008240.0000 - val_false_negatives: 13185362.0000 - val_precision: 0.8693 - val_recall: 0.7080\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 137s 343ms/step - loss: 0.0970 - accuracy: 0.8354 - binary_iou: 0.7095 - true_positives: 102972568.0000 - false_positives: 24451394.0000 - true_negatives: 163957824.0000 - false_negatives: 28139152.0000 - precision: 0.8081 - recall: 0.7854 - val_loss: 0.1056 - val_accuracy: 0.8190 - val_binary_iou: 0.6918 - val_true_positives: 38703920.0000 - val_false_positives: 12815742.0000 - val_true_negatives: 48088272.0000 - val_false_negatives: 6363783.0000 - val_precision: 0.7512 - val_recall: 0.8588\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0961 - accuracy: 0.8378 - binary_iou: 0.7132 - true_positives: 103382480.0000 - false_positives: 24086258.0000 - true_negatives: 164319424.0000 - false_negatives: 27732654.0000 - precision: 0.8110 - recall: 0.7885 - val_loss: 0.1097 - val_accuracy: 0.8059 - val_binary_iou: 0.6742 - val_true_positives: 39755736.0000 - val_false_positives: 15181283.0000 - val_true_negatives: 45644488.0000 - val_false_negatives: 5390192.0000 - val_precision: 0.7237 - val_recall: 0.8806\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0937 - accuracy: 0.8421 - binary_iou: 0.7197 - true_positives: 104078240.0000 - false_positives: 23499364.0000 - true_negatives: 164992912.0000 - false_negatives: 26950208.0000 - precision: 0.8158 - recall: 0.7943 - val_loss: 0.1153 - val_accuracy: 0.7939 - val_binary_iou: 0.6582 - val_true_positives: 41479488.0000 - val_false_positives: 18216578.0000 - val_true_negatives: 42647984.0000 - val_false_negatives: 3627668.0000 - val_precision: 0.6948 - val_recall: 0.9196\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0933 - accuracy: 0.8443 - binary_iou: 0.7231 - true_positives: 104509376.0000 - false_positives: 23135430.0000 - true_negatives: 165270080.0000 - false_negatives: 26605972.0000 - precision: 0.8188 - recall: 0.7971 - val_loss: 0.1052 - val_accuracy: 0.8228 - val_binary_iou: 0.6981 - val_true_positives: 40455752.0000 - val_false_positives: 14088869.0000 - val_true_negatives: 46733252.0000 - val_false_negatives: 4693854.0000 - val_precision: 0.7417 - val_recall: 0.8960\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024 - val_loss: 0.0954 - val_accuracy: 0.8371 - val_binary_iou: 0.7186 - val_true_positives: 40248520.0000 - val_false_positives: 12413144.0000 - val_true_negatives: 48463540.0000 - val_false_negatives: 4846510.0000 - val_precision: 0.7643 - val_recall: 0.8925\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0901 - accuracy: 0.8508 - binary_iou: 0.7330 - true_positives: 105533640.0000 - false_positives: 22092700.0000 - true_negatives: 166309040.0000 - false_negatives: 25585432.0000 - precision: 0.8269 - recall: 0.8049 - val_loss: 0.1245 - val_accuracy: 0.7245 - val_binary_iou: 0.5193 - val_true_positives: 16856334.0000 - val_false_positives: 888026.0000 - val_true_negatives: 59925316.0000 - val_false_negatives: 28302036.0000 - val_precision: 0.9500 - val_recall: 0.3733\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0893 - accuracy: 0.8526 - binary_iou: 0.7359 - true_positives: 105886944.0000 - false_positives: 21818420.0000 - true_negatives: 166548864.0000 - false_negatives: 25266544.0000 - precision: 0.8292 - recall: 0.8074 - val_loss: 0.1029 - val_accuracy: 0.8326 - val_binary_iou: 0.7124 - val_true_positives: 40830816.0000 - val_false_positives: 13431411.0000 - val_true_negatives: 47404960.0000 - val_false_negatives: 4304522.0000 - val_precision: 0.7525 - val_recall: 0.9046\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0876 - accuracy: 0.8564 - binary_iou: 0.7417 - true_positives: 106360520.0000 - false_positives: 21117784.0000 - true_negatives: 167273232.0000 - false_negatives: 24769200.0000 - precision: 0.8343 - recall: 0.8111 - val_loss: 0.1123 - val_accuracy: 0.8113 - val_binary_iou: 0.6824 - val_true_positives: 41546704.0000 - val_false_positives: 16377837.0000 - val_true_negatives: 44430472.0000 - val_false_negatives: 3616706.0000 - val_precision: 0.7173 - val_recall: 0.9199\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0871 - accuracy: 0.8573 - binary_iou: 0.7432 - true_positives: 106628432.0000 - false_positives: 21060946.0000 - true_negatives: 167308336.0000 - false_negatives: 24523056.0000 - precision: 0.8351 - recall: 0.8130 - val_loss: 0.1330 - val_accuracy: 0.7197 - val_binary_iou: 0.5101 - val_true_positives: 16018910.0000 - val_false_positives: 714509.0000 - val_true_negatives: 60247680.0000 - val_false_negatives: 28990608.0000 - val_precision: 0.9573 - val_recall: 0.3559\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166 - val_loss: 0.0904 - val_accuracy: 0.8501 - val_binary_iou: 0.7374 - val_true_positives: 39858736.0000 - val_false_positives: 10601939.0000 - val_true_negatives: 50232448.0000 - val_false_negatives: 5278578.0000 - val_precision: 0.7899 - val_recall: 0.8831\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0849 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107398296.0000 - false_positives: 20543202.0000 - true_negatives: 167856336.0000 - false_negatives: 23722896.0000 - precision: 0.8394 - recall: 0.8191 - val_loss: 0.1110 - val_accuracy: 0.8005 - val_binary_iou: 0.6440 - val_true_positives: 26109266.0000 - val_false_positives: 2097758.0000 - val_true_negatives: 58726144.0000 - val_false_negatives: 19038536.0000 - val_precision: 0.9256 - val_recall: 0.5783\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0847 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107239304.0000 - false_positives: 20393872.0000 - true_negatives: 168027744.0000 - false_negatives: 23859782.0000 - precision: 0.8402 - recall: 0.8180 - val_loss: 0.0989 - val_accuracy: 0.8373 - val_binary_iou: 0.7068 - val_true_positives: 31232048.0000 - val_false_positives: 3293441.0000 - val_true_negatives: 57497820.0000 - val_false_negatives: 13948394.0000 - val_precision: 0.9046 - val_recall: 0.6913\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215 - val_loss: 0.0895 - val_accuracy: 0.8523 - val_binary_iou: 0.7406 - val_true_positives: 39827064.0000 - val_false_positives: 10344540.0000 - val_true_negatives: 50490480.0000 - val_false_negatives: 5309619.0000 - val_precision: 0.7938 - val_recall: 0.8824\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211 - val_loss: 0.0852 - val_accuracy: 0.8639 - val_binary_iou: 0.7554 - val_true_positives: 37170488.0000 - val_false_positives: 6445220.0000 - val_true_negatives: 54378644.0000 - val_false_negatives: 7977376.0000 - val_precision: 0.8522 - val_recall: 0.8233\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 131s 327ms/step - loss: 0.0821 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108301392.0000 - false_positives: 19837088.0000 - true_negatives: 168606352.0000 - false_negatives: 22776036.0000 - precision: 0.8452 - recall: 0.8262 - val_loss: 0.1531 - val_accuracy: 0.7313 - val_binary_iou: 0.5348 - val_true_positives: 18643914.0000 - val_false_positives: 1994139.0000 - val_true_negatives: 58851064.0000 - val_false_negatives: 26482600.0000 - val_precision: 0.9034 - val_recall: 0.4131\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0818 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108285344.0000 - false_positives: 19770572.0000 - true_negatives: 168614816.0000 - false_negatives: 22850008.0000 - precision: 0.8456 - recall: 0.8258 - val_loss: 0.1024 - val_accuracy: 0.8322 - val_binary_iou: 0.7115 - val_true_positives: 40046760.0000 - val_false_positives: 12674211.0000 - val_true_negatives: 48147576.0000 - val_false_negatives: 5103174.0000 - val_precision: 0.7596 - val_recall: 0.8870\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0813 - accuracy: 0.8676 - binary_iou: 0.7596 - true_positives: 108523808.0000 - false_positives: 19610268.0000 - true_negatives: 168706416.0000 - false_negatives: 22680374.0000 - precision: 0.8470 - recall: 0.8271 - val_loss: 0.0870 - val_accuracy: 0.8546 - val_binary_iou: 0.7357 - val_true_positives: 33240562.0000 - val_false_positives: 3608494.0000 - val_true_negatives: 57325588.0000 - val_false_negatives: 11797062.0000 - val_precision: 0.9021 - val_recall: 0.7381\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 132s 330ms/step - loss: 0.0808 - accuracy: 0.8688 - binary_iou: 0.7614 - true_positives: 108646064.0000 - false_positives: 19449168.0000 - true_negatives: 168965888.0000 - false_negatives: 22459632.0000 - precision: 0.8482 - recall: 0.8287 - val_loss: 0.0867 - val_accuracy: 0.8618 - val_binary_iou: 0.7540 - val_true_positives: 38839240.0000 - val_false_positives: 8306769.0000 - val_true_negatives: 52484908.0000 - val_false_negatives: 6340797.0000 - val_precision: 0.8238 - val_recall: 0.8597\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0805 - accuracy: 0.8692 - binary_iou: 0.7619 - true_positives: 108503840.0000 - false_positives: 19143860.0000 - true_negatives: 169210224.0000 - false_negatives: 22662762.0000 - precision: 0.8500 - recall: 0.8272 - val_loss: 0.0967 - val_accuracy: 0.8472 - val_binary_iou: 0.7338 - val_true_positives: 40768900.0000 - val_false_positives: 11939663.0000 - val_true_negatives: 49015408.0000 - val_false_negatives: 4247704.0000 - val_precision: 0.7735 - val_recall: 0.9056\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 132s 333ms/step - loss: 0.0795 - accuracy: 0.8707 - binary_iou: 0.7643 - true_positives: 108716080.0000 - false_positives: 18938558.0000 - true_negatives: 169478768.0000 - false_negatives: 22387304.0000 - precision: 0.8516 - recall: 0.8292 - val_loss: 0.1078 - val_accuracy: 0.8230 - val_binary_iou: 0.6988 - val_true_positives: 41153548.0000 - val_false_positives: 14788690.0000 - val_true_negatives: 46060360.0000 - val_false_negatives: 3969113.0000 - val_precision: 0.7356 - val_recall: 0.9120\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0801 - accuracy: 0.8702 - binary_iou: 0.7636 - true_positives: 108823816.0000 - false_positives: 19210666.0000 - true_negatives: 169220608.0000 - false_negatives: 22265680.0000 - precision: 0.8500 - recall: 0.8301 - val_loss: 0.0927 - val_accuracy: 0.8444 - val_binary_iou: 0.7203 - val_true_positives: 32952966.0000 - val_false_positives: 4359997.0000 - val_true_negatives: 56526712.0000 - val_false_negatives: 12132058.0000 - val_precision: 0.8832 - val_recall: 0.7309\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0790 - accuracy: 0.8721 - binary_iou: 0.7667 - true_positives: 109167728.0000 - false_positives: 18871536.0000 - true_negatives: 169501680.0000 - false_negatives: 21979664.0000 - precision: 0.8526 - recall: 0.8324 - val_loss: 0.0850 - val_accuracy: 0.8600 - val_binary_iou: 0.7507 - val_true_positives: 38290392.0000 - val_false_positives: 8004973.0000 - val_true_negatives: 52842848.0000 - val_false_negatives: 6833502.0000 - val_precision: 0.8271 - val_recall: 0.8486\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0791 - accuracy: 0.8710 - binary_iou: 0.7649 - true_positives: 108841576.0000 - false_positives: 18948360.0000 - true_negatives: 169474752.0000 - false_negatives: 22256104.0000 - precision: 0.8517 - recall: 0.8302 - val_loss: 0.0908 - val_accuracy: 0.8506 - val_binary_iou: 0.7392 - val_true_positives: 41490552.0000 - val_false_positives: 12217507.0000 - val_true_negatives: 48650728.0000 - val_false_negatives: 3612923.0000 - val_precision: 0.7725 - val_recall: 0.9199\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.8688 - val_binary_iou: 0.7620 - val_true_positives: 36486688.0000 - val_false_positives: 5333113.0000 - val_true_negatives: 55582152.0000 - val_false_negatives: 8569759.0000 - val_precision: 0.8725 - val_recall: 0.8098\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.8727 - val_binary_iou: 0.7702 - val_true_positives: 38349988.0000 - val_false_positives: 6743923.0000 - val_true_negatives: 54133528.0000 - val_false_negatives: 6744254.0000 - val_precision: 0.8504 - val_recall: 0.8504\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348 - val_loss: 0.0788 - val_accuracy: 0.8748 - val_binary_iou: 0.7732 - val_true_positives: 38262152.0000 - val_false_positives: 6452901.0000 - val_true_negatives: 54439296.0000 - val_false_negatives: 6817371.0000 - val_precision: 0.8557 - val_recall: 0.8488\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0770 - accuracy: 0.8750 - binary_iou: 0.7714 - true_positives: 109860424.0000 - false_positives: 18651358.0000 - true_negatives: 169709808.0000 - false_negatives: 21299248.0000 - precision: 0.8549 - recall: 0.8376 - val_loss: 0.1144 - val_accuracy: 0.8331 - val_binary_iou: 0.7128 - val_true_positives: 40152272.0000 - val_false_positives: 12796243.0000 - val_true_negatives: 48135368.0000 - val_false_negatives: 4887845.0000 - val_precision: 0.7583 - val_recall: 0.8915\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351 - val_loss: 0.0760 - val_accuracy: 0.8774 - val_binary_iou: 0.7753 - val_true_positives: 36616788.0000 - val_false_positives: 4558136.0000 - val_true_negatives: 56358976.0000 - val_false_negatives: 8437822.0000 - val_precision: 0.8893 - val_recall: 0.8127\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0768 - accuracy: 0.8754 - binary_iou: 0.7720 - true_positives: 109704112.0000 - false_positives: 18303342.0000 - true_negatives: 170015376.0000 - false_negatives: 21497948.0000 - precision: 0.8570 - recall: 0.8361 - val_loss: 0.0893 - val_accuracy: 0.8511 - val_binary_iou: 0.7392 - val_true_positives: 40275688.0000 - val_false_positives: 11033940.0000 - val_true_negatives: 49917440.0000 - val_false_negatives: 4744650.0000 - val_precision: 0.7850 - val_recall: 0.8946\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0759 - accuracy: 0.8769 - binary_iou: 0.7744 - true_positives: 109680688.0000 - false_positives: 17862716.0000 - true_negatives: 170521232.0000 - false_negatives: 21456152.0000 - precision: 0.8599 - recall: 0.8364 - val_loss: 0.1278 - val_accuracy: 0.7639 - val_binary_iou: 0.5848 - val_true_positives: 21954286.0000 - val_false_positives: 1845093.0000 - val_true_negatives: 58996816.0000 - val_false_negatives: 23175526.0000 - val_precision: 0.9225 - val_recall: 0.4865\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0763 - accuracy: 0.8771 - binary_iou: 0.7746 - true_positives: 109722248.0000 - false_positives: 17865852.0000 - true_negatives: 170533120.0000 - false_negatives: 21399564.0000 - precision: 0.8600 - recall: 0.8368 - val_loss: 0.0804 - val_accuracy: 0.8689 - val_binary_iou: 0.7605 - val_true_positives: 35240620.0000 - val_false_positives: 4020838.0000 - val_true_negatives: 56843064.0000 - val_false_negatives: 9867173.0000 - val_precision: 0.8976 - val_recall: 0.7813\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0752 - accuracy: 0.8781 - binary_iou: 0.7763 - true_positives: 109918400.0000 - false_positives: 17765496.0000 - true_negatives: 170650224.0000 - false_negatives: 21186664.0000 - precision: 0.8609 - recall: 0.8384 - val_loss: 0.0844 - val_accuracy: 0.8658 - val_binary_iou: 0.7554 - val_true_positives: 35053628.0000 - val_false_positives: 4161809.0000 - val_true_negatives: 56692608.0000 - val_false_negatives: 10063672.0000 - val_precision: 0.8939 - val_recall: 0.7769\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0756 - accuracy: 0.8780 - binary_iou: 0.7762 - true_positives: 109991488.0000 - false_positives: 17822768.0000 - true_negatives: 170557728.0000 - false_negatives: 21148782.0000 - precision: 0.8606 - recall: 0.8387 - val_loss: 0.0847 - val_accuracy: 0.8642 - val_binary_iou: 0.7593 - val_true_positives: 40863752.0000 - val_false_positives: 10137314.0000 - val_true_negatives: 50722208.0000 - val_false_negatives: 4248468.0000 - val_precision: 0.8012 - val_recall: 0.9058\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0755 - accuracy: 0.8783 - binary_iou: 0.7766 - true_positives: 110056080.0000 - false_positives: 17851890.0000 - true_negatives: 170569152.0000 - false_negatives: 21043648.0000 - precision: 0.8604 - recall: 0.8395 - val_loss: 0.0940 - val_accuracy: 0.8438 - val_binary_iou: 0.7149 - val_true_positives: 30703540.0000 - val_false_positives: 2279773.0000 - val_true_negatives: 58713400.0000 - val_false_negatives: 14274987.0000 - val_precision: 0.9309 - val_recall: 0.6826\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0748 - accuracy: 0.8801 - binary_iou: 0.7794 - true_positives: 110202584.0000 - false_positives: 17466404.0000 - true_negatives: 170994736.0000 - false_negatives: 20856996.0000 - precision: 0.8632 - recall: 0.8409 - val_loss: 0.0782 - val_accuracy: 0.8715 - val_binary_iou: 0.7644 - val_true_positives: 35198112.0000 - val_false_positives: 3698824.0000 - val_true_negatives: 57161548.0000 - val_false_negatives: 9913227.0000 - val_precision: 0.9049 - val_recall: 0.7802\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0746 - accuracy: 0.8794 - binary_iou: 0.7784 - true_positives: 110242680.0000 - false_positives: 17726232.0000 - true_negatives: 170747120.0000 - false_negatives: 20804768.0000 - precision: 0.8615 - recall: 0.8412 - val_loss: 0.0825 - val_accuracy: 0.8634 - val_binary_iou: 0.7571 - val_true_positives: 39490388.0000 - val_false_positives: 8987308.0000 - val_true_negatives: 52010136.0000 - val_false_negatives: 5483891.0000 - val_precision: 0.8146 - val_recall: 0.8781\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0738 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110744256.0000 - false_positives: 17311324.0000 - true_negatives: 171002512.0000 - false_negatives: 20462732.0000 - precision: 0.8648 - recall: 0.8440 - val_loss: 0.0911 - val_accuracy: 0.8514 - val_binary_iou: 0.7390 - val_true_positives: 39461084.0000 - val_false_positives: 10119243.0000 - val_true_negatives: 50764184.0000 - val_false_negatives: 5627177.0000 - val_precision: 0.7959 - val_recall: 0.8752\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0740 - accuracy: 0.8811 - binary_iou: 0.7813 - true_positives: 110620672.0000 - false_positives: 17410712.0000 - true_negatives: 170911776.0000 - false_negatives: 20577528.0000 - precision: 0.8640 - recall: 0.8432 - val_loss: 0.0893 - val_accuracy: 0.8568 - val_binary_iou: 0.7480 - val_true_positives: 40675372.0000 - val_false_positives: 10765509.0000 - val_true_negatives: 50123008.0000 - val_false_negatives: 4407833.0000 - val_precision: 0.7907 - val_recall: 0.9022\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0741 - accuracy: 0.8810 - binary_iou: 0.7810 - true_positives: 110477176.0000 - false_positives: 17368754.0000 - true_negatives: 171013616.0000 - false_negatives: 20661116.0000 - precision: 0.8641 - recall: 0.8424 - val_loss: 0.0915 - val_accuracy: 0.8609 - val_binary_iou: 0.7545 - val_true_positives: 41110948.0000 - val_false_positives: 10759448.0000 - val_true_negatives: 50124624.0000 - val_false_negatives: 3976692.0000 - val_precision: 0.7926 - val_recall: 0.9118\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110759184.0000 - false_positives: 17434206.0000 - true_negatives: 170991264.0000 - false_negatives: 20336120.0000 - precision: 0.8640 - recall: 0.8449 - val_loss: 0.0767 - val_accuracy: 0.8763 - val_binary_iou: 0.7738 - val_true_positives: 36665456.0000 - val_false_positives: 4793163.0000 - val_true_negatives: 56202104.0000 - val_false_negatives: 8311005.0000 - val_precision: 0.8844 - val_recall: 0.8152\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0732 - accuracy: 0.8824 - binary_iou: 0.7833 - true_positives: 110589928.0000 - false_positives: 17049368.0000 - true_negatives: 171352096.0000 - false_negatives: 20529470.0000 - precision: 0.8664 - recall: 0.8434 - val_loss: 0.3467 - val_accuracy: 0.6217 - val_binary_iou: 0.3609 - val_true_positives: 5513703.0000 - val_false_positives: 492476.0000 - val_true_negatives: 60369508.0000 - val_false_negatives: 39596012.0000 - val_precision: 0.9180 - val_recall: 0.1222\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0728 - accuracy: 0.8823 - binary_iou: 0.7831 - true_positives: 110610448.0000 - false_positives: 17153838.0000 - true_negatives: 171295808.0000 - false_negatives: 20460704.0000 - precision: 0.8657 - recall: 0.8439 - val_loss: 0.1083 - val_accuracy: 0.8334 - val_binary_iou: 0.7133 - val_true_positives: 40344744.0000 - val_false_positives: 12932603.0000 - val_true_negatives: 47975588.0000 - val_false_negatives: 4718782.0000 - val_precision: 0.7573 - val_recall: 0.8953\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448 - val_loss: 0.0720 - val_accuracy: 0.8834 - val_binary_iou: 0.7860 - val_true_positives: 37677948.0000 - val_false_positives: 4890033.0000 - val_true_negatives: 55932928.0000 - val_false_negatives: 7470800.0000 - val_precision: 0.8851 - val_recall: 0.8345\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7851 - true_positives: 110872664.0000 - false_positives: 16952142.0000 - true_negatives: 171421840.0000 - false_negatives: 20274174.0000 - precision: 0.8674 - recall: 0.8454 - val_loss: 0.0791 - val_accuracy: 0.8718 - val_binary_iou: 0.7701 - val_true_positives: 39755304.0000 - val_false_positives: 8201396.0000 - val_true_negatives: 52630668.0000 - val_false_negatives: 5384339.0000 - val_precision: 0.8290 - val_recall: 0.8807\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0720 - accuracy: 0.8844 - binary_iou: 0.7866 - true_positives: 111036360.0000 - false_positives: 16833284.0000 - true_negatives: 171542160.0000 - false_negatives: 20108824.0000 - precision: 0.8684 - recall: 0.8467 - val_loss: 0.0752 - val_accuracy: 0.8761 - val_binary_iou: 0.7749 - val_true_positives: 37911000.0000 - val_false_positives: 6057223.0000 - val_true_negatives: 54926472.0000 - val_false_negatives: 7077021.0000 - val_precision: 0.8622 - val_recall: 0.8427\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473 - val_loss: 0.0718 - val_accuracy: 0.8838 - val_binary_iou: 0.7886 - val_true_positives: 39486004.0000 - val_false_positives: 6718828.0000 - val_true_negatives: 54175552.0000 - val_false_negatives: 5591349.0000 - val_precision: 0.8546 - val_recall: 0.8760\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0711 - accuracy: 0.8859 - binary_iou: 0.7891 - true_positives: 111437792.0000 - false_positives: 16779652.0000 - true_negatives: 171621232.0000 - false_negatives: 19682034.0000 - precision: 0.8691 - recall: 0.8499 - val_loss: 0.0789 - val_accuracy: 0.8750 - val_binary_iou: 0.7750 - val_true_positives: 39677440.0000 - val_false_positives: 7832372.0000 - val_true_negatives: 53050432.0000 - val_false_negatives: 5411455.0000 - val_precision: 0.8351 - val_recall: 0.8800\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0723 - accuracy: 0.8840 - binary_iou: 0.7860 - true_positives: 110917688.0000 - false_positives: 16858026.0000 - true_negatives: 171550656.0000 - false_negatives: 20194422.0000 - precision: 0.8681 - recall: 0.8460 - val_loss: 0.0761 - val_accuracy: 0.8785 - val_binary_iou: 0.7793 - val_true_positives: 38523632.0000 - val_false_positives: 6267567.0000 - val_true_negatives: 54571044.0000 - val_false_negatives: 6609449.0000 - val_precision: 0.8601 - val_recall: 0.8536\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.0713 - accuracy: 0.8857 - binary_iou: 0.7888 - true_positives: 111161040.0000 - false_positives: 16627165.0000 - true_negatives: 171846624.0000 - false_negatives: 19886010.0000 - precision: 0.8699 - recall: 0.8483 - val_loss: 0.0784 - val_accuracy: 0.8712 - val_binary_iou: 0.7654 - val_true_positives: 36260056.0000 - val_false_positives: 4831201.0000 - val_true_negatives: 56061988.0000 - val_false_negatives: 8818443.0000 - val_precision: 0.8824 - val_recall: 0.8044\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0713 - accuracy: 0.8850 - binary_iou: 0.7875 - true_positives: 110992376.0000 - false_positives: 16666216.0000 - true_negatives: 171785184.0000 - false_negatives: 20076980.0000 - precision: 0.8694 - recall: 0.8468 - val_loss: 0.0749 - val_accuracy: 0.8792 - val_binary_iou: 0.7783 - val_true_positives: 36636472.0000 - val_false_positives: 4348723.0000 - val_true_negatives: 56539000.0000 - val_false_negatives: 8447519.0000 - val_precision: 0.8939 - val_recall: 0.8126\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0712 - accuracy: 0.8865 - binary_iou: 0.7901 - true_positives: 111404088.0000 - false_positives: 16538362.0000 - true_negatives: 171853856.0000 - false_negatives: 19724452.0000 - precision: 0.8707 - recall: 0.8496 - val_loss: 0.0919 - val_accuracy: 0.8460 - val_binary_iou: 0.7183 - val_true_positives: 30782204.0000 - val_false_positives: 1975765.0000 - val_true_negatives: 58874352.0000 - val_false_negatives: 14339410.0000 - val_precision: 0.9397 - val_recall: 0.6822\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0705 - accuracy: 0.8877 - binary_iou: 0.7921 - true_positives: 111597744.0000 - false_positives: 16313104.0000 - true_negatives: 172038480.0000 - false_negatives: 19571406.0000 - precision: 0.8725 - recall: 0.8508 - val_loss: 0.0778 - val_accuracy: 0.8731 - val_binary_iou: 0.7718 - val_true_positives: 39438596.0000 - val_false_positives: 7786716.0000 - val_true_negatives: 53084064.0000 - val_false_negatives: 5662343.0000 - val_precision: 0.8351 - val_recall: 0.8745\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0707 - accuracy: 0.8871 - binary_iou: 0.7910 - true_positives: 111379944.0000 - false_positives: 16308250.0000 - true_negatives: 172061968.0000 - false_negatives: 19770506.0000 - precision: 0.8723 - recall: 0.8493 - val_loss: 0.0848 - val_accuracy: 0.8574 - val_binary_iou: 0.7399 - val_true_positives: 33218982.0000 - val_false_positives: 3312352.0000 - val_true_negatives: 57644400.0000 - val_false_negatives: 11795967.0000 - val_precision: 0.9093 - val_recall: 0.7380\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0705 - accuracy: 0.8872 - binary_iou: 0.7912 - true_positives: 111304640.0000 - false_positives: 16271008.0000 - true_negatives: 172181952.0000 - false_negatives: 19763074.0000 - precision: 0.8725 - recall: 0.8492 - val_loss: 0.0780 - val_accuracy: 0.8788 - val_binary_iou: 0.7815 - val_true_positives: 40363296.0000 - val_false_positives: 8102494.0000 - val_true_negatives: 52768896.0000 - val_false_negatives: 4737019.0000 - val_precision: 0.8328 - val_recall: 0.8950\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0703 - accuracy: 0.8879 - binary_iou: 0.7923 - true_positives: 111497272.0000 - false_positives: 16185796.0000 - true_negatives: 172192080.0000 - false_negatives: 19645634.0000 - precision: 0.8732 - recall: 0.8502 - val_loss: 0.0729 - val_accuracy: 0.8834 - val_binary_iou: 0.7850 - val_true_positives: 36861128.0000 - val_false_positives: 4175830.0000 - val_true_negatives: 56752168.0000 - val_false_negatives: 8182607.0000 - val_precision: 0.8982 - val_recall: 0.8183\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0702 - accuracy: 0.8878 - binary_iou: 0.7922 - true_positives: 111428296.0000 - false_positives: 16189002.0000 - true_negatives: 172243248.0000 - false_negatives: 19660228.0000 - precision: 0.8731 - recall: 0.8500 - val_loss: 0.0748 - val_accuracy: 0.8787 - val_binary_iou: 0.7808 - val_true_positives: 39858764.0000 - val_false_positives: 7576542.0000 - val_true_negatives: 53255492.0000 - val_false_negatives: 5280936.0000 - val_precision: 0.8403 - val_recall: 0.8830\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0699 - accuracy: 0.8884 - binary_iou: 0.7932 - true_positives: 111605032.0000 - false_positives: 16211818.0000 - true_negatives: 172253808.0000 - false_negatives: 19450116.0000 - precision: 0.8732 - recall: 0.8516 - val_loss: 0.0724 - val_accuracy: 0.8823 - val_binary_iou: 0.7848 - val_true_positives: 38025824.0000 - val_false_positives: 5357245.0000 - val_true_negatives: 55475288.0000 - val_false_negatives: 7113354.0000 - val_precision: 0.8765 - val_recall: 0.8424\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514 - val_loss: 0.0719 - val_accuracy: 0.8857 - val_binary_iou: 0.7920 - val_true_positives: 40008660.0000 - val_false_positives: 6950614.0000 - val_true_negatives: 53851884.0000 - val_false_negatives: 5160537.0000 - val_precision: 0.8520 - val_recall: 0.8858\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111832104.0000 - false_positives: 16087610.0000 - true_negatives: 172342992.0000 - false_negatives: 19257988.0000 - precision: 0.8742 - recall: 0.8531 - val_loss: 0.0860 - val_accuracy: 0.8592 - val_binary_iou: 0.7425 - val_true_positives: 33238404.0000 - val_false_positives: 3034032.0000 - val_true_negatives: 57809696.0000 - val_false_negatives: 11889571.0000 - val_precision: 0.9164 - val_recall: 0.7365\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111810888.0000 - false_positives: 16032721.0000 - true_negatives: 172367728.0000 - false_negatives: 19309438.0000 - precision: 0.8746 - recall: 0.8527 - val_loss: 0.0795 - val_accuracy: 0.8735 - val_binary_iou: 0.7676 - val_true_positives: 35400352.0000 - val_false_positives: 3689432.0000 - val_true_negatives: 57161040.0000 - val_false_negatives: 9720906.0000 - val_precision: 0.9056 - val_recall: 0.7846\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0695 - accuracy: 0.8884 - binary_iou: 0.7933 - true_positives: 111689736.0000 - false_positives: 16202075.0000 - true_negatives: 172186048.0000 - false_negatives: 19442862.0000 - precision: 0.8733 - recall: 0.8517 - val_loss: 0.0758 - val_accuracy: 0.8776 - val_binary_iou: 0.7791 - val_true_positives: 39693812.0000 - val_false_positives: 7559088.0000 - val_true_negatives: 53310804.0000 - val_false_negatives: 5407998.0000 - val_precision: 0.8400 - val_recall: 0.8801\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0689 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 111939024.0000 - false_positives: 15899358.0000 - true_negatives: 172475312.0000 - false_negatives: 19207072.0000 - precision: 0.8756 - recall: 0.8535 - val_loss: 0.1359 - val_accuracy: 0.7880 - val_binary_iou: 0.6222 - val_true_positives: 24266056.0000 - val_false_positives: 1582781.0000 - val_true_negatives: 59243448.0000 - val_false_negatives: 20879408.0000 - val_precision: 0.9388 - val_recall: 0.5375\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 428ms/step - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537 - val_loss: 0.0701 - val_accuracy: 0.8880 - val_binary_iou: 0.7950 - val_true_positives: 39279140.0000 - val_false_positives: 6042733.0000 - val_true_negatives: 54825964.0000 - val_false_negatives: 5823879.0000 - val_precision: 0.8667 - val_recall: 0.8709\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0688 - accuracy: 0.8901 - binary_iou: 0.7960 - true_positives: 111865480.0000 - false_positives: 15830442.0000 - true_negatives: 172532208.0000 - false_negatives: 19292612.0000 - precision: 0.8760 - recall: 0.8529 - val_loss: 0.0774 - val_accuracy: 0.8784 - val_binary_iou: 0.7808 - val_true_positives: 40402348.0000 - val_false_positives: 8221260.0000 - val_true_negatives: 52680000.0000 - val_false_negatives: 4668108.0000 - val_precision: 0.8309 - val_recall: 0.8964\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0690 - accuracy: 0.8891 - binary_iou: 0.7944 - true_positives: 111709696.0000 - false_positives: 15976760.0000 - true_negatives: 172388368.0000 - false_negatives: 19445922.0000 - precision: 0.8749 - recall: 0.8517 - val_loss: 0.0803 - val_accuracy: 0.8730 - val_binary_iou: 0.7725 - val_true_positives: 40478668.0000 - val_false_positives: 8900463.0000 - val_true_negatives: 52034368.0000 - val_false_negatives: 4558195.0000 - val_precision: 0.8198 - val_recall: 0.8988\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0688 - accuracy: 0.8902 - binary_iou: 0.7962 - true_positives: 111886672.0000 - false_positives: 15776121.0000 - true_negatives: 172563696.0000 - false_negatives: 19294172.0000 - precision: 0.8764 - recall: 0.8529 - val_loss: 0.0752 - val_accuracy: 0.8810 - val_binary_iou: 0.7845 - val_true_positives: 39947648.0000 - val_false_positives: 7431002.0000 - val_true_negatives: 53413960.0000 - val_false_negatives: 5179119.0000 - val_precision: 0.8432 - val_recall: 0.8852\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0691 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111791048.0000 - false_positives: 16044969.0000 - true_negatives: 172387392.0000 - false_negatives: 19297388.0000 - precision: 0.8745 - recall: 0.8528 - val_loss: 0.0951 - val_accuracy: 0.8679 - val_binary_iou: 0.7649 - val_true_positives: 40768648.0000 - val_false_positives: 9800652.0000 - val_true_negatives: 51205848.0000 - val_false_negatives: 4196562.0000 - val_precision: 0.8062 - val_recall: 0.9067\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0686 - accuracy: 0.8903 - binary_iou: 0.7963 - true_positives: 112000912.0000 - false_positives: 15904758.0000 - true_negatives: 172459744.0000 - false_negatives: 19155282.0000 - precision: 0.8757 - recall: 0.8540 - val_loss: 0.0771 - val_accuracy: 0.8741 - val_binary_iou: 0.7688 - val_true_positives: 35527912.0000 - val_false_positives: 3736203.0000 - val_true_negatives: 57103272.0000 - val_false_negatives: 9604338.0000 - val_precision: 0.9048 - val_recall: 0.7872\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0678 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112179992.0000 - false_positives: 15409854.0000 - true_negatives: 173029520.0000 - false_negatives: 18901586.0000 - precision: 0.8792 - recall: 0.8558 - val_loss: 0.0724 - val_accuracy: 0.8848 - val_binary_iou: 0.7907 - val_true_positives: 40174352.0000 - val_false_positives: 7346762.0000 - val_true_negatives: 53591184.0000 - val_false_negatives: 4859408.0000 - val_precision: 0.8454 - val_recall: 0.8921\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 171s 429ms/step - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540 - val_loss: 0.0689 - val_accuracy: 0.8901 - val_binary_iou: 0.7975 - val_true_positives: 38453356.0000 - val_false_positives: 4979271.0000 - val_true_negatives: 55869972.0000 - val_false_negatives: 6669114.0000 - val_precision: 0.8854 - val_recall: 0.8522\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 160s 402ms/step - loss: 0.0682 - accuracy: 0.8911 - binary_iou: 0.7976 - true_positives: 112027632.0000 - false_positives: 15746636.0000 - true_negatives: 172694192.0000 - false_negatives: 19052250.0000 - precision: 0.8768 - recall: 0.8547 - val_loss: 0.0703 - val_accuracy: 0.8876 - val_binary_iou: 0.7944 - val_true_positives: 39253120.0000 - val_false_positives: 6203339.0000 - val_true_negatives: 54812624.0000 - val_false_negatives: 5702634.0000 - val_precision: 0.8635 - val_recall: 0.8732\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0678 - accuracy: 0.8924 - binary_iou: 0.7998 - true_positives: 112174480.0000 - false_positives: 15427345.0000 - true_negatives: 172958144.0000 - false_negatives: 18960760.0000 - precision: 0.8791 - recall: 0.8554 - val_loss: 0.0714 - val_accuracy: 0.8860 - val_binary_iou: 0.7922 - val_true_positives: 39661624.0000 - val_false_positives: 6618287.0000 - val_true_negatives: 54230892.0000 - val_false_negatives: 5460903.0000 - val_precision: 0.8570 - val_recall: 0.8790\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0676 - accuracy: 0.8918 - binary_iou: 0.7988 - true_positives: 112268576.0000 - false_positives: 15669733.0000 - true_negatives: 172670096.0000 - false_negatives: 18912436.0000 - precision: 0.8775 - recall: 0.8558 - val_loss: 0.0768 - val_accuracy: 0.8799 - val_binary_iou: 0.7831 - val_true_positives: 40321992.0000 - val_false_positives: 7994599.0000 - val_true_negatives: 52923220.0000 - val_false_negatives: 4731924.0000 - val_precision: 0.8345 - val_recall: 0.8950\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 135s 338ms/step - loss: 0.0672 - accuracy: 0.8930 - binary_iou: 0.8009 - true_positives: 112414688.0000 - false_positives: 15411543.0000 - true_negatives: 172917456.0000 - false_negatives: 18777054.0000 - precision: 0.8794 - recall: 0.8569 - val_loss: 0.1484 - val_accuracy: 0.7818 - val_binary_iou: 0.6113 - val_true_positives: 23371532.0000 - val_false_positives: 1365110.0000 - val_true_negatives: 59475000.0000 - val_false_negatives: 21760066.0000 - val_precision: 0.9448 - val_recall: 0.5179\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0670 - accuracy: 0.8930 - binary_iou: 0.8007 - true_positives: 112071688.0000 - false_positives: 15228398.0000 - true_negatives: 173257568.0000 - false_negatives: 18963102.0000 - precision: 0.8804 - recall: 0.8553 - val_loss: 0.0730 - val_accuracy: 0.8837 - val_binary_iou: 0.7859 - val_true_positives: 37128412.0000 - val_false_positives: 4391111.0000 - val_true_negatives: 56520536.0000 - val_false_negatives: 7931644.0000 - val_precision: 0.8942 - val_recall: 0.8240\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 427ms/step - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554 - val_loss: 0.0678 - val_accuracy: 0.8915 - val_binary_iou: 0.7994 - val_true_positives: 38122228.0000 - val_false_positives: 4515762.0000 - val_true_negatives: 56352220.0000 - val_false_negatives: 6981488.0000 - val_precision: 0.8941 - val_recall: 0.8452\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 133s 333ms/step - loss: 0.0669 - accuracy: 0.8936 - binary_iou: 0.8018 - true_positives: 112442640.0000 - false_positives: 15260840.0000 - true_negatives: 173075456.0000 - false_negatives: 18741888.0000 - precision: 0.8805 - recall: 0.8571 - val_loss: 0.0707 - val_accuracy: 0.8882 - val_binary_iou: 0.7955 - val_true_positives: 39381688.0000 - val_false_positives: 6069700.0000 - val_true_negatives: 54746240.0000 - val_false_negatives: 5774078.0000 - val_precision: 0.8665 - val_recall: 0.8721\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0668 - accuracy: 0.8932 - binary_iou: 0.8013 - true_positives: 112449040.0000 - false_positives: 15470578.0000 - true_negatives: 172959840.0000 - false_negatives: 18641352.0000 - precision: 0.8791 - recall: 0.8578 - val_loss: 0.0734 - val_accuracy: 0.8809 - val_binary_iou: 0.7799 - val_true_positives: 35980932.0000 - val_false_positives: 3395829.0000 - val_true_negatives: 57365376.0000 - val_false_negatives: 9229588.0000 - val_precision: 0.9138 - val_recall: 0.7959\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8015 - true_positives: 112170456.0000 - false_positives: 15109560.0000 - true_negatives: 173310432.0000 - false_negatives: 18930238.0000 - precision: 0.8813 - recall: 0.8556 - val_loss: 0.0687 - val_accuracy: 0.8896 - val_binary_iou: 0.7965 - val_true_positives: 38277924.0000 - val_false_positives: 4777362.0000 - val_true_negatives: 55992768.0000 - val_false_negatives: 6923645.0000 - val_precision: 0.8890 - val_recall: 0.8468\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0665 - accuracy: 0.8945 - binary_iou: 0.8033 - true_positives: 112567264.0000 - false_positives: 15171494.0000 - true_negatives: 173237200.0000 - false_negatives: 18544780.0000 - precision: 0.8812 - recall: 0.8586 - val_loss: 0.1019 - val_accuracy: 0.8186 - val_binary_iou: 0.6723 - val_true_positives: 27651104.0000 - val_false_positives: 1777387.0000 - val_true_negatives: 59099132.0000 - val_false_negatives: 17444088.0000 - val_precision: 0.9396 - val_recall: 0.6132\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0674 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112299664.0000 - false_positives: 15546087.0000 - true_negatives: 172895488.0000 - false_negatives: 18779640.0000 - precision: 0.8784 - recall: 0.8567 - val_loss: 0.0816 - val_accuracy: 0.8774 - val_binary_iou: 0.7792 - val_true_positives: 40354892.0000 - val_false_positives: 8312571.0000 - val_true_negatives: 52624612.0000 - val_false_negatives: 4679636.0000 - val_precision: 0.8292 - val_recall: 0.8961\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0667 - accuracy: 0.8937 - binary_iou: 0.8020 - true_positives: 112282648.0000 - false_positives: 15109516.0000 - true_negatives: 173280112.0000 - false_negatives: 18848368.0000 - precision: 0.8814 - recall: 0.8563 - val_loss: 0.0783 - val_accuracy: 0.8691 - val_binary_iou: 0.7659 - val_true_positives: 39678192.0000 - val_false_positives: 8383734.0000 - val_true_negatives: 52426100.0000 - val_false_negatives: 5483700.0000 - val_precision: 0.8256 - val_recall: 0.8786\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8018 - true_positives: 112706776.0000 - false_positives: 15555337.0000 - true_negatives: 172791440.0000 - false_negatives: 18467180.0000 - precision: 0.8787 - recall: 0.8592 - val_loss: 0.0741 - val_accuracy: 0.8826 - val_binary_iou: 0.7877 - val_true_positives: 40878036.0000 - val_false_positives: 8097197.0000 - val_true_negatives: 52650636.0000 - val_false_negatives: 4345838.0000 - val_precision: 0.8347 - val_recall: 0.9039\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8952 - binary_iou: 0.8046 - true_positives: 112822448.0000 - false_positives: 15160487.0000 - true_negatives: 173219936.0000 - false_negatives: 18317834.0000 - precision: 0.8815 - recall: 0.8603 - val_loss: 0.0712 - val_accuracy: 0.8861 - val_binary_iou: 0.7889 - val_true_positives: 36594128.0000 - val_false_positives: 3547294.0000 - val_true_negatives: 57302372.0000 - val_false_negatives: 8527889.0000 - val_precision: 0.9116 - val_recall: 0.8110\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0661 - accuracy: 0.8949 - binary_iou: 0.8041 - true_positives: 112634032.0000 - false_positives: 15075881.0000 - true_negatives: 173317312.0000 - false_negatives: 18493656.0000 - precision: 0.8820 - recall: 0.8590 - val_loss: 0.1567 - val_accuracy: 0.7551 - val_binary_iou: 0.5705 - val_true_positives: 20908572.0000 - val_false_positives: 1721498.0000 - val_true_negatives: 59106516.0000 - val_false_negatives: 24235132.0000 - val_precision: 0.9239 - val_recall: 0.4632\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8953 - binary_iou: 0.8046 - true_positives: 112573032.0000 - false_positives: 14919423.0000 - true_negatives: 173497088.0000 - false_negatives: 18531148.0000 - precision: 0.8830 - recall: 0.8587 - val_loss: 0.0721 - val_accuracy: 0.8864 - val_binary_iou: 0.7910 - val_true_positives: 37871184.0000 - val_false_positives: 4839935.0000 - val_true_negatives: 56064496.0000 - val_false_negatives: 7196119.0000 - val_precision: 0.8867 - val_recall: 0.8403\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0654 - accuracy: 0.8963 - binary_iou: 0.8064 - true_positives: 112841192.0000 - false_positives: 14810634.0000 - true_negatives: 173555312.0000 - false_negatives: 18313536.0000 - precision: 0.8840 - recall: 0.8604 - val_loss: 0.0810 - val_accuracy: 0.8655 - val_binary_iou: 0.7549 - val_true_positives: 35077924.0000 - val_false_positives: 4263421.0000 - val_true_negatives: 56635472.0000 - val_false_negatives: 9994884.0000 - val_precision: 0.8916 - val_recall: 0.7783\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0652 - accuracy: 0.8962 - binary_iou: 0.8062 - true_positives: 112972344.0000 - false_positives: 15045884.0000 - true_negatives: 173367568.0000 - false_negatives: 18134990.0000 - precision: 0.8825 - recall: 0.8617 - val_loss: 0.0913 - val_accuracy: 0.8630 - val_binary_iou: 0.7575 - val_true_positives: 40925680.0000 - val_false_positives: 10408766.0000 - val_true_negatives: 50531900.0000 - val_false_negatives: 4105355.0000 - val_precision: 0.7972 - val_recall: 0.9088\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0655 - accuracy: 0.8956 - binary_iou: 0.8053 - true_positives: 112770296.0000 - false_positives: 14935553.0000 - true_negatives: 173408240.0000 - false_negatives: 18406754.0000 - precision: 0.8830 - recall: 0.8597 - val_loss: 0.0681 - val_accuracy: 0.8916 - val_binary_iou: 0.7991 - val_true_positives: 37650052.0000 - val_false_positives: 4016793.0000 - val_true_negatives: 56835504.0000 - val_false_negatives: 7469375.0000 - val_precision: 0.9036 - val_recall: 0.8345\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8965 - binary_iou: 0.8066 - true_positives: 112672744.0000 - false_positives: 14632333.0000 - true_negatives: 173781648.0000 - false_negatives: 18434098.0000 - precision: 0.8851 - recall: 0.8594 - val_loss: 0.0741 - val_accuracy: 0.8843 - val_binary_iou: 0.7891 - val_true_positives: 39229924.0000 - val_false_positives: 6452676.0000 - val_true_negatives: 54484932.0000 - val_false_negatives: 5804178.0000 - val_precision: 0.8587 - val_recall: 0.8711\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0654 - accuracy: 0.8961 - binary_iou: 0.8061 - true_positives: 112790800.0000 - false_positives: 14832199.0000 - true_negatives: 173542400.0000 - false_negatives: 18355386.0000 - precision: 0.8838 - recall: 0.8600 - val_loss: 0.0749 - val_accuracy: 0.8854 - val_binary_iou: 0.7920 - val_true_positives: 40681160.0000 - val_false_positives: 7715254.0000 - val_true_negatives: 53141616.0000 - val_false_negatives: 4433672.0000 - val_precision: 0.8406 - val_recall: 0.9017\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0653 - accuracy: 0.8962 - binary_iou: 0.8061 - true_positives: 112847560.0000 - false_positives: 14876293.0000 - true_negatives: 173496784.0000 - false_negatives: 18300084.0000 - precision: 0.8835 - recall: 0.8605 - val_loss: 0.0764 - val_accuracy: 0.8787 - val_binary_iou: 0.7810 - val_true_positives: 40074776.0000 - val_false_positives: 7857041.0000 - val_true_negatives: 53039168.0000 - val_false_negatives: 5000726.0000 - val_precision: 0.8361 - val_recall: 0.8891\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598 - val_loss: 0.0676 - val_accuracy: 0.8920 - val_binary_iou: 0.8012 - val_true_positives: 39038164.0000 - val_false_positives: 5411304.0000 - val_true_negatives: 55491768.0000 - val_false_negatives: 6030472.0000 - val_precision: 0.8783 - val_recall: 0.8662\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 133s 334ms/step - loss: 0.0649 - accuracy: 0.8968 - binary_iou: 0.8072 - true_positives: 112836920.0000 - false_positives: 14683751.0000 - true_negatives: 173715984.0000 - false_negatives: 18284156.0000 - precision: 0.8849 - recall: 0.8606 - val_loss: 0.0736 - val_accuracy: 0.8828 - val_binary_iou: 0.7850 - val_true_positives: 37599728.0000 - val_false_positives: 4910598.0000 - val_true_negatives: 55953576.0000 - val_false_negatives: 7507811.0000 - val_precision: 0.8845 - val_recall: 0.8336\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0644 - accuracy: 0.8975 - binary_iou: 0.8083 - true_positives: 113073528.0000 - false_positives: 14661790.0000 - true_negatives: 173689344.0000 - false_negatives: 18096160.0000 - precision: 0.8852 - recall: 0.8620 - val_loss: 0.0808 - val_accuracy: 0.8723 - val_binary_iou: 0.7642 - val_true_positives: 34353932.0000 - val_false_positives: 2753126.0000 - val_true_negatives: 58084044.0000 - val_false_negatives: 10780616.0000 - val_precision: 0.9258 - val_recall: 0.7611\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8971 - binary_iou: 0.8076 - true_positives: 112894736.0000 - false_positives: 14678940.0000 - true_negatives: 173739488.0000 - false_negatives: 18207648.0000 - precision: 0.8849 - recall: 0.8611 - val_loss: 0.0691 - val_accuracy: 0.8917 - val_binary_iou: 0.8007 - val_true_positives: 39146796.0000 - val_false_positives: 5586695.0000 - val_true_negatives: 55345212.0000 - val_false_negatives: 5892998.0000 - val_precision: 0.8751 - val_recall: 0.8692\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0648 - accuracy: 0.8970 - binary_iou: 0.8074 - true_positives: 112868432.0000 - false_positives: 14630436.0000 - true_negatives: 173732256.0000 - false_negatives: 18289650.0000 - precision: 0.8853 - recall: 0.8606 - val_loss: 0.0872 - val_accuracy: 0.8663 - val_binary_iou: 0.7620 - val_true_positives: 40245384.0000 - val_false_positives: 9343865.0000 - val_true_negatives: 51557684.0000 - val_false_negatives: 4824793.0000 - val_precision: 0.8116 - val_recall: 0.8929\n",
      "132/132 [==============================] - 45s 317ms/step - loss: 212.9752 - accuracy: 0.8897 - binary_iou: 0.7965 - true_positives: 38099952.0000 - false_positives: 5604668.0000 - true_negatives: 56180072.0000 - false_negatives: 6087014.0000 - precision: 0.8718 - recall: 0.8622\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 185s 442ms/step - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509 - val_loss: 0.1105 - val_accuracy: 0.8061 - val_binary_iou: 0.6605 - val_true_positives: 29558962.0000 - val_false_positives: 5074877.0000 - val_true_negatives: 55861256.0000 - val_false_negatives: 15476612.0000 - val_precision: 0.8535 - val_recall: 0.6563\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0969 - accuracy: 0.8330 - binary_iou: 0.7067 - true_positives: 103866728.0000 - false_positives: 26122214.0000 - true_negatives: 162309504.0000 - false_negatives: 27222196.0000 - precision: 0.7990 - recall: 0.7923 - val_loss: 0.1090 - val_accuracy: 0.7971 - val_binary_iou: 0.6466 - val_true_positives: 28650442.0000 - val_false_positives: 5022378.0000 - val_true_negatives: 55819924.0000 - val_false_negatives: 16478962.0000 - val_precision: 0.8508 - val_recall: 0.6349\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946 - val_loss: 0.1040 - val_accuracy: 0.8304 - val_binary_iou: 0.7052 - val_true_positives: 36088200.0000 - val_false_positives: 8909478.0000 - val_true_negatives: 51910856.0000 - val_false_negatives: 9063180.0000 - val_precision: 0.8020 - val_recall: 0.7993\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036 - val_loss: 0.0947 - val_accuracy: 0.8398 - val_binary_iou: 0.7195 - val_true_positives: 36842232.0000 - val_false_positives: 8677888.0000 - val_true_negatives: 52152584.0000 - val_false_negatives: 8299018.0000 - val_precision: 0.8094 - val_recall: 0.8162\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0914 - accuracy: 0.8468 - binary_iou: 0.7275 - true_positives: 106150000.0000 - false_positives: 23878964.0000 - true_negatives: 164412704.0000 - false_negatives: 25079016.0000 - precision: 0.8164 - recall: 0.8089 - val_loss: 0.1028 - val_accuracy: 0.8082 - val_binary_iou: 0.6639 - val_true_positives: 29808732.0000 - val_false_positives: 5023932.0000 - val_true_negatives: 55838920.0000 - val_false_negatives: 15300131.0000 - val_precision: 0.8558 - val_recall: 0.6608\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109 - val_loss: 0.0844 - val_accuracy: 0.8593 - val_binary_iou: 0.7474 - val_true_positives: 36334244.0000 - val_false_positives: 6082476.0000 - val_true_negatives: 54722900.0000 - val_false_negatives: 8832084.0000 - val_precision: 0.8566 - val_recall: 0.8045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0889 - accuracy: 0.8510 - binary_iou: 0.7339 - true_positives: 106864624.0000 - false_positives: 23327616.0000 - true_negatives: 165044144.0000 - false_negatives: 24284384.0000 - precision: 0.8208 - recall: 0.8148 - val_loss: 0.1001 - val_accuracy: 0.8204 - val_binary_iou: 0.6782 - val_true_positives: 29000756.0000 - val_false_positives: 3039177.0000 - val_true_negatives: 57938184.0000 - val_false_negatives: 15993596.0000 - val_precision: 0.9051 - val_recall: 0.6445\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0877 - accuracy: 0.8533 - binary_iou: 0.7374 - true_positives: 107015776.0000 - false_positives: 22760176.0000 - true_negatives: 165621696.0000 - false_negatives: 24123068.0000 - precision: 0.8246 - recall: 0.8160 - val_loss: 0.0992 - val_accuracy: 0.8232 - val_binary_iou: 0.6827 - val_true_positives: 29234104.0000 - val_false_positives: 2876097.0000 - val_true_negatives: 58006276.0000 - val_false_negatives: 15855237.0000 - val_precision: 0.9104 - val_recall: 0.6484\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0868 - accuracy: 0.8551 - binary_iou: 0.7402 - true_positives: 107298048.0000 - false_positives: 22419816.0000 - true_negatives: 165917520.0000 - false_negatives: 23885356.0000 - precision: 0.8272 - recall: 0.8179 - val_loss: 0.0907 - val_accuracy: 0.8447 - val_binary_iou: 0.7263 - val_true_positives: 36638376.0000 - val_false_positives: 7956607.0000 - val_true_negatives: 52870960.0000 - val_false_negatives: 8505777.0000 - val_precision: 0.8216 - val_recall: 0.8116\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0860 - accuracy: 0.8567 - binary_iou: 0.7427 - true_positives: 107560656.0000 - false_positives: 22263318.0000 - true_negatives: 166169616.0000 - false_negatives: 23527152.0000 - precision: 0.8285 - recall: 0.8205 - val_loss: 0.0871 - val_accuracy: 0.8539 - val_binary_iou: 0.7427 - val_true_positives: 39383768.0000 - val_false_positives: 9782407.0000 - val_true_negatives: 51109704.0000 - val_false_negatives: 5695821.0000 - val_precision: 0.8010 - val_recall: 0.8736\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0840 - accuracy: 0.8601 - binary_iou: 0.7481 - true_positives: 108232024.0000 - false_positives: 21758164.0000 - true_negatives: 166597248.0000 - false_negatives: 22933332.0000 - precision: 0.8326 - recall: 0.8252 - val_loss: 0.0899 - val_accuracy: 0.8479 - val_binary_iou: 0.7261 - val_true_positives: 33317968.0000 - val_false_positives: 4355052.0000 - val_true_negatives: 56538512.0000 - val_false_negatives: 11760183.0000 - val_precision: 0.8844 - val_recall: 0.7391\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262 - val_loss: 0.0843 - val_accuracy: 0.8626 - val_binary_iou: 0.7532 - val_true_positives: 36904740.0000 - val_false_positives: 6333535.0000 - val_true_negatives: 54509848.0000 - val_false_negatives: 8223592.0000 - val_precision: 0.8535 - val_recall: 0.8178\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0827 - accuracy: 0.8639 - binary_iou: 0.7537 - true_positives: 108190992.0000 - false_positives: 20585124.0000 - true_negatives: 167837744.0000 - false_negatives: 22906836.0000 - precision: 0.8401 - recall: 0.8253 - val_loss: 0.0861 - val_accuracy: 0.8567 - val_binary_iou: 0.7439 - val_true_positives: 36617192.0000 - val_false_positives: 6830996.0000 - val_true_negatives: 54164012.0000 - val_false_negatives: 8359509.0000 - val_precision: 0.8428 - val_recall: 0.8141\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304 - val_loss: 0.0832 - val_accuracy: 0.8657 - val_binary_iou: 0.7568 - val_true_positives: 36133160.0000 - val_false_positives: 5289682.0000 - val_true_negatives: 55606572.0000 - val_false_negatives: 8942304.0000 - val_precision: 0.8723 - val_recall: 0.8016\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0805 - accuracy: 0.8679 - binary_iou: 0.7603 - true_positives: 109205312.0000 - false_positives: 20384652.0000 - true_negatives: 168115712.0000 - false_negatives: 21815188.0000 - precision: 0.8427 - recall: 0.8335 - val_loss: 0.0826 - val_accuracy: 0.8640 - val_binary_iou: 0.7537 - val_true_positives: 35741368.0000 - val_false_positives: 5012108.0000 - val_true_negatives: 55818184.0000 - val_false_negatives: 9400030.0000 - val_precision: 0.8770 - val_recall: 0.7918\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0796 - accuracy: 0.8695 - binary_iou: 0.7628 - true_positives: 109519336.0000 - false_positives: 20095204.0000 - true_negatives: 168288400.0000 - false_negatives: 21617852.0000 - precision: 0.8450 - recall: 0.8352 - val_loss: 0.0904 - val_accuracy: 0.8553 - val_binary_iou: 0.7370 - val_true_positives: 33358712.0000 - val_false_positives: 3548969.0000 - val_true_negatives: 57280136.0000 - val_false_negatives: 11783893.0000 - val_precision: 0.9038 - val_recall: 0.7390\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0802 - accuracy: 0.8684 - binary_iou: 0.7611 - true_positives: 109389072.0000 - false_positives: 20335696.0000 - true_negatives: 168089696.0000 - false_negatives: 21706340.0000 - precision: 0.8432 - recall: 0.8344 - val_loss: 0.0819 - val_accuracy: 0.8643 - val_binary_iou: 0.7543 - val_true_positives: 35849168.0000 - val_false_positives: 5100314.0000 - val_true_negatives: 55738372.0000 - val_false_negatives: 9283861.0000 - val_precision: 0.8754 - val_recall: 0.7943\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0787 - accuracy: 0.8711 - binary_iou: 0.7654 - true_positives: 109737320.0000 - false_positives: 19834218.0000 - true_negatives: 168589664.0000 - false_negatives: 21359514.0000 - precision: 0.8469 - recall: 0.8371 - val_loss: 0.0840 - val_accuracy: 0.8606 - val_binary_iou: 0.7474 - val_true_positives: 34968736.0000 - val_false_positives: 4551350.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 10224023.0000 - val_precision: 0.8848 - val_recall: 0.7738\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404 - val_loss: 0.0795 - val_accuracy: 0.8686 - val_binary_iou: 0.7619 - val_true_positives: 36683320.0000 - val_false_positives: 5540348.0000 - val_true_negatives: 55363864.0000 - val_false_negatives: 8384161.0000 - val_precision: 0.8688 - val_recall: 0.8140\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0776 - accuracy: 0.8728 - binary_iou: 0.7680 - true_positives: 109780352.0000 - false_positives: 19325732.0000 - true_negatives: 169090848.0000 - false_negatives: 21323936.0000 - precision: 0.8503 - recall: 0.8374 - val_loss: 0.0809 - val_accuracy: 0.8656 - val_binary_iou: 0.7602 - val_true_positives: 39312376.0000 - val_false_positives: 8557187.0000 - val_true_negatives: 52416080.0000 - val_false_negatives: 5686077.0000 - val_precision: 0.8212 - val_recall: 0.8736\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410 - val_loss: 0.0794 - val_accuracy: 0.8732 - val_binary_iou: 0.7725 - val_true_positives: 40125432.0000 - val_false_positives: 8428567.0000 - val_true_negatives: 52404920.0000 - val_false_negatives: 5012805.0000 - val_precision: 0.8264 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0762 - accuracy: 0.8764 - binary_iou: 0.7739 - true_positives: 110538152.0000 - false_positives: 18913164.0000 - true_negatives: 169494592.0000 - false_negatives: 20574936.0000 - precision: 0.8539 - recall: 0.8431 - val_loss: 0.0951 - val_accuracy: 0.8363 - val_binary_iou: 0.7062 - val_true_positives: 31574824.0000 - val_false_positives: 3741021.0000 - val_true_negatives: 57054612.0000 - val_false_negatives: 13601249.0000 - val_precision: 0.8941 - val_recall: 0.6989\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442 - val_loss: 0.0744 - val_accuracy: 0.8783 - val_binary_iou: 0.7776 - val_true_positives: 37268520.0000 - val_false_positives: 5039199.0000 - val_true_negatives: 55808504.0000 - val_false_negatives: 7855478.0000 - val_precision: 0.8809 - val_recall: 0.8259\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0753 - accuracy: 0.8775 - binary_iou: 0.7757 - true_positives: 110844512.0000 - false_positives: 18808940.0000 - true_negatives: 169537376.0000 - false_negatives: 20330032.0000 - precision: 0.8549 - recall: 0.8450 - val_loss: 0.0757 - val_accuracy: 0.8756 - val_binary_iou: 0.7748 - val_true_positives: 38605216.0000 - val_false_positives: 6663971.0000 - val_true_negatives: 54178532.0000 - val_false_negatives: 6523988.0000 - val_precision: 0.8528 - val_recall: 0.8554\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0744 - accuracy: 0.8792 - binary_iou: 0.7784 - true_positives: 110836560.0000 - false_positives: 18290544.0000 - true_negatives: 170090624.0000 - false_negatives: 20303034.0000 - precision: 0.8584 - recall: 0.8452 - val_loss: 0.0838 - val_accuracy: 0.8686 - val_binary_iou: 0.7643 - val_true_positives: 38808680.0000 - val_false_positives: 7733552.0000 - val_true_negatives: 53238424.0000 - val_false_negatives: 6191043.0000 - val_precision: 0.8338 - val_recall: 0.8624\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455 - val_loss: 0.0743 - val_accuracy: 0.8803 - val_binary_iou: 0.7815 - val_true_positives: 37964788.0000 - val_false_positives: 5535672.0000 - val_true_negatives: 55320728.0000 - val_false_negatives: 7150529.0000 - val_precision: 0.8727 - val_recall: 0.8415\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8807 - binary_iou: 0.7808 - true_positives: 110972968.0000 - false_positives: 17974036.0000 - true_negatives: 170442016.0000 - false_negatives: 20131872.0000 - precision: 0.8606 - recall: 0.8464 - val_loss: 0.0780 - val_accuracy: 0.8706 - val_binary_iou: 0.7684 - val_true_positives: 39906784.0000 - val_false_positives: 8499998.0000 - val_true_negatives: 52356132.0000 - val_false_negatives: 5208790.0000 - val_precision: 0.8244 - val_recall: 0.8845\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0728 - accuracy: 0.8829 - binary_iou: 0.7843 - true_positives: 111373168.0000 - false_positives: 17715180.0000 - true_negatives: 170722176.0000 - false_negatives: 19710296.0000 - precision: 0.8628 - recall: 0.8496 - val_loss: 0.0770 - val_accuracy: 0.8757 - val_binary_iou: 0.7717 - val_true_positives: 35798568.0000 - val_false_positives: 3818787.0000 - val_true_negatives: 57002196.0000 - val_false_negatives: 9352164.0000 - val_precision: 0.9036 - val_recall: 0.7929\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0726 - accuracy: 0.8827 - binary_iou: 0.7841 - true_positives: 111452024.0000 - false_positives: 17798892.0000 - true_negatives: 170586352.0000 - false_negatives: 19683584.0000 - precision: 0.8623 - recall: 0.8499 - val_loss: 0.0810 - val_accuracy: 0.8639 - val_binary_iou: 0.7540 - val_true_positives: 36116544.0000 - val_false_positives: 5372076.0000 - val_true_negatives: 55429736.0000 - val_false_negatives: 9053340.0000 - val_precision: 0.8705 - val_recall: 0.7996\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505 - val_loss: 0.0704 - val_accuracy: 0.8863 - val_binary_iou: 0.7915 - val_true_positives: 38513900.0000 - val_false_positives: 5352287.0000 - val_true_negatives: 55406376.0000 - val_false_negatives: 6699139.0000 - val_precision: 0.8780 - val_recall: 0.8518\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0720 - accuracy: 0.8833 - binary_iou: 0.7852 - true_positives: 111675440.0000 - false_positives: 17808288.0000 - true_negatives: 170566208.0000 - false_negatives: 19470846.0000 - precision: 0.8625 - recall: 0.8515 - val_loss: 0.0821 - val_accuracy: 0.8666 - val_binary_iou: 0.7624 - val_true_positives: 40110328.0000 - val_false_positives: 9223599.0000 - val_true_negatives: 51725288.0000 - val_false_negatives: 4912495.0000 - val_precision: 0.8130 - val_recall: 0.8909\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0706 - accuracy: 0.8862 - binary_iou: 0.7899 - true_positives: 111930336.0000 - false_positives: 17126412.0000 - true_negatives: 171239056.0000 - false_negatives: 19225072.0000 - precision: 0.8673 - recall: 0.8534 - val_loss: 0.0739 - val_accuracy: 0.8792 - val_binary_iou: 0.7784 - val_true_positives: 36755232.0000 - val_false_positives: 4481793.0000 - val_true_negatives: 56420288.0000 - val_false_negatives: 8314384.0000 - val_precision: 0.8913 - val_recall: 0.8155\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0708 - accuracy: 0.8861 - binary_iou: 0.7896 - true_positives: 111675448.0000 - false_positives: 17012134.0000 - true_negatives: 171463120.0000 - false_negatives: 19370032.0000 - precision: 0.8678 - recall: 0.8522 - val_loss: 0.0725 - val_accuracy: 0.8842 - val_binary_iou: 0.7874 - val_true_positives: 37718920.0000 - val_false_positives: 4882348.0000 - val_true_negatives: 55984972.0000 - val_false_negatives: 7385472.0000 - val_precision: 0.8854 - val_recall: 0.8363\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0706 - accuracy: 0.8864 - binary_iou: 0.7901 - true_positives: 112083648.0000 - false_positives: 17320000.0000 - true_negatives: 171126784.0000 - false_negatives: 18990262.0000 - precision: 0.8662 - recall: 0.8551 - val_loss: 0.0778 - val_accuracy: 0.8782 - val_binary_iou: 0.7759 - val_true_positives: 36081004.0000 - val_false_positives: 3847325.0000 - val_true_negatives: 56984628.0000 - val_false_negatives: 9058767.0000 - val_precision: 0.9036 - val_recall: 0.7993\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0708 - accuracy: 0.8855 - binary_iou: 0.7886 - true_positives: 111719080.0000 - false_positives: 17155256.0000 - true_negatives: 171213584.0000 - false_negatives: 19432856.0000 - precision: 0.8669 - recall: 0.8518 - val_loss: 0.0713 - val_accuracy: 0.8854 - val_binary_iou: 0.7898 - val_true_positives: 38198888.0000 - val_false_positives: 5231896.0000 - val_true_negatives: 55629572.0000 - val_false_negatives: 6911343.0000 - val_precision: 0.8795 - val_recall: 0.8468\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 437ms/step - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573 - val_loss: 0.0690 - val_accuracy: 0.8875 - val_binary_iou: 0.7944 - val_true_positives: 39463176.0000 - val_false_positives: 6336379.0000 - val_true_negatives: 54590884.0000 - val_false_negatives: 5581280.0000 - val_precision: 0.8616 - val_recall: 0.8761\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0696 - accuracy: 0.8883 - binary_iou: 0.7932 - true_positives: 112009744.0000 - false_positives: 16654082.0000 - true_negatives: 171826960.0000 - false_negatives: 19029884.0000 - precision: 0.8706 - recall: 0.8548 - val_loss: 0.0782 - val_accuracy: 0.8673 - val_binary_iou: 0.7644 - val_true_positives: 41361104.0000 - val_false_positives: 10324735.0000 - val_true_negatives: 50551800.0000 - val_false_negatives: 3734080.0000 - val_precision: 0.8002 - val_recall: 0.9172\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569 - val_loss: 0.0699 - val_accuracy: 0.8879 - val_binary_iou: 0.7946 - val_true_positives: 38986240.0000 - val_false_positives: 5839663.0000 - val_true_negatives: 55106392.0000 - val_false_negatives: 6039420.0000 - val_precision: 0.8697 - val_recall: 0.8659\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0682 - accuracy: 0.8907 - binary_iou: 0.7971 - true_positives: 112353240.0000 - false_positives: 16102053.0000 - true_negatives: 172235680.0000 - false_negatives: 18829746.0000 - precision: 0.8746 - recall: 0.8565 - val_loss: 0.0704 - val_accuracy: 0.8881 - val_binary_iou: 0.7939 - val_true_positives: 38109872.0000 - val_false_positives: 4901732.0000 - val_true_negatives: 55998932.0000 - val_false_negatives: 6961182.0000 - val_precision: 0.8860 - val_recall: 0.8456\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568 - val_loss: 0.0682 - val_accuracy: 0.8908 - val_binary_iou: 0.7980 - val_true_positives: 37943940.0000 - val_false_positives: 4332921.0000 - val_true_negatives: 56451604.0000 - val_false_negatives: 7243249.0000 - val_precision: 0.8975 - val_recall: 0.8397\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0678 - accuracy: 0.8911 - binary_iou: 0.7979 - true_positives: 112549024.0000 - false_positives: 16229167.0000 - true_negatives: 172190704.0000 - false_negatives: 18551880.0000 - precision: 0.8740 - recall: 0.8585 - val_loss: 0.0777 - val_accuracy: 0.8769 - val_binary_iou: 0.7724 - val_true_positives: 34971264.0000 - val_false_positives: 2822913.0000 - val_true_negatives: 57959224.0000 - val_false_negatives: 10218323.0000 - val_precision: 0.9253 - val_recall: 0.7739\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557 - val_loss: 0.0680 - val_accuracy: 0.8908 - val_binary_iou: 0.7986 - val_true_positives: 38459688.0000 - val_false_positives: 4965429.0000 - val_true_negatives: 55937692.0000 - val_false_negatives: 6608893.0000 - val_precision: 0.8857 - val_recall: 0.8534\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0672 - accuracy: 0.8924 - binary_iou: 0.8000 - true_positives: 112625344.0000 - false_positives: 15909708.0000 - true_negatives: 172527040.0000 - false_negatives: 18458692.0000 - precision: 0.8762 - recall: 0.8592 - val_loss: 0.0681 - val_accuracy: 0.8911 - val_binary_iou: 0.7985 - val_true_positives: 37945288.0000 - val_false_positives: 4341430.0000 - val_true_negatives: 56481624.0000 - val_false_negatives: 7203356.0000 - val_precision: 0.8973 - val_recall: 0.8405\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0670 - accuracy: 0.8926 - binary_iou: 0.8004 - true_positives: 112697608.0000 - false_positives: 15912619.0000 - true_negatives: 172519168.0000 - false_negatives: 18391396.0000 - precision: 0.8763 - recall: 0.8597 - val_loss: 0.0695 - val_accuracy: 0.8885 - val_binary_iou: 0.7942 - val_true_positives: 37790920.0000 - val_false_positives: 4531809.0000 - val_true_negatives: 56360128.0000 - val_false_negatives: 7288845.0000 - val_precision: 0.8929 - val_recall: 0.8383\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0677 - accuracy: 0.8915 - binary_iou: 0.7986 - true_positives: 112710072.0000 - false_positives: 16261744.0000 - true_negatives: 172151872.0000 - false_negatives: 18397136.0000 - precision: 0.8739 - recall: 0.8597 - val_loss: 0.0678 - val_accuracy: 0.8902 - val_binary_iou: 0.7985 - val_true_positives: 39367096.0000 - val_false_positives: 5935776.0000 - val_true_negatives: 54966212.0000 - val_false_negatives: 5702605.0000 - val_precision: 0.8690 - val_recall: 0.8735\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 438ms/step - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633 - val_loss: 0.0660 - val_accuracy: 0.8946 - val_binary_iou: 0.8052 - val_true_positives: 39001808.0000 - val_false_positives: 4980377.0000 - val_true_negatives: 55796588.0000 - val_false_negatives: 6192927.0000 - val_precision: 0.8868 - val_recall: 0.8630\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0664 - accuracy: 0.8936 - binary_iou: 0.8020 - true_positives: 112788272.0000 - false_positives: 15639641.0000 - true_negatives: 172750048.0000 - false_negatives: 18342840.0000 - precision: 0.8782 - recall: 0.8601 - val_loss: 0.0699 - val_accuracy: 0.8875 - val_binary_iou: 0.7919 - val_true_positives: 37142420.0000 - val_false_positives: 4069980.0000 - val_true_negatives: 56904784.0000 - val_false_negatives: 7854534.0000 - val_precision: 0.9012 - val_recall: 0.8254\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0655 - accuracy: 0.8950 - binary_iou: 0.8044 - true_positives: 113115328.0000 - false_positives: 15486498.0000 - true_negatives: 172855152.0000 - false_negatives: 18063804.0000 - precision: 0.8796 - recall: 0.8623 - val_loss: 0.0692 - val_accuracy: 0.8888 - val_binary_iou: 0.7959 - val_true_positives: 38962320.0000 - val_false_positives: 5677038.0000 - val_true_negatives: 55221624.0000 - val_false_negatives: 6110758.0000 - val_precision: 0.8728 - val_recall: 0.8644\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0651 - accuracy: 0.8960 - binary_iou: 0.8059 - true_positives: 113075528.0000 - false_positives: 15203770.0000 - true_negatives: 173212272.0000 - false_negatives: 18029176.0000 - precision: 0.8815 - recall: 0.8625 - val_loss: 0.0729 - val_accuracy: 0.8840 - val_binary_iou: 0.7863 - val_true_positives: 37080092.0000 - val_false_positives: 4269862.0000 - val_true_negatives: 56597916.0000 - val_false_negatives: 8023830.0000 - val_precision: 0.8967 - val_recall: 0.8221\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0648 - accuracy: 0.8961 - binary_iou: 0.8062 - true_positives: 113327736.0000 - false_positives: 15474886.0000 - true_negatives: 172995104.0000 - false_negatives: 17722972.0000 - precision: 0.8799 - recall: 0.8648 - val_loss: 0.0675 - val_accuracy: 0.8916 - val_binary_iou: 0.7997 - val_true_positives: 38295708.0000 - val_false_positives: 4763659.0000 - val_true_negatives: 56185512.0000 - val_false_negatives: 6726823.0000 - val_precision: 0.8894 - val_recall: 0.8506\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0644 - accuracy: 0.8971 - binary_iou: 0.8078 - true_positives: 113363456.0000 - false_positives: 15155710.0000 - true_negatives: 173270416.0000 - false_negatives: 17731144.0000 - precision: 0.8821 - recall: 0.8647 - val_loss: 0.0699 - val_accuracy: 0.8883 - val_binary_iou: 0.7926 - val_true_positives: 36737004.0000 - val_false_positives: 3459131.0000 - val_true_negatives: 57393536.0000 - val_false_negatives: 8382044.0000 - val_precision: 0.9139 - val_recall: 0.8142\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0649 - accuracy: 0.8960 - binary_iou: 0.8061 - true_positives: 113351536.0000 - false_positives: 15406054.0000 - true_negatives: 172946240.0000 - false_negatives: 17816920.0000 - precision: 0.8803 - recall: 0.8642 - val_loss: 0.0693 - val_accuracy: 0.8881 - val_binary_iou: 0.7931 - val_true_positives: 37406232.0000 - val_false_positives: 4189810.0000 - val_true_negatives: 56703164.0000 - val_false_negatives: 7672504.0000 - val_precision: 0.8993 - val_recall: 0.8298\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 439ms/step - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635 - val_loss: 0.0644 - val_accuracy: 0.8982 - val_binary_iou: 0.8115 - val_true_positives: 39367752.0000 - val_false_positives: 4995223.0000 - val_true_negatives: 55818860.0000 - val_false_negatives: 5789865.0000 - val_precision: 0.8874 - val_recall: 0.8718\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0637 - accuracy: 0.8982 - binary_iou: 0.8098 - true_positives: 113737680.0000 - false_positives: 15229448.0000 - true_negatives: 173259152.0000 - false_negatives: 17294578.0000 - precision: 0.8819 - recall: 0.8680 - val_loss: 0.0701 - val_accuracy: 0.8890 - val_binary_iou: 0.7959 - val_true_positives: 38609764.0000 - val_false_positives: 5199589.0000 - val_true_negatives: 55594380.0000 - val_false_negatives: 6567994.0000 - val_precision: 0.8813 - val_recall: 0.8546\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0643 - accuracy: 0.8975 - binary_iou: 0.8085 - true_positives: 113463744.0000 - false_positives: 15104503.0000 - true_negatives: 173302384.0000 - false_negatives: 17650162.0000 - precision: 0.8825 - recall: 0.8654 - val_loss: 0.0674 - val_accuracy: 0.8904 - val_binary_iou: 0.7991 - val_true_positives: 39483080.0000 - val_false_positives: 5960064.0000 - val_true_negatives: 54877108.0000 - val_false_negatives: 5651467.0000 - val_precision: 0.8688 - val_recall: 0.8748\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0637 - accuracy: 0.8983 - binary_iou: 0.8098 - true_positives: 113509408.0000 - false_positives: 14836776.0000 - true_negatives: 173506304.0000 - false_negatives: 17668256.0000 - precision: 0.8844 - recall: 0.8653 - val_loss: 0.0679 - val_accuracy: 0.8912 - val_binary_iou: 0.7994 - val_true_positives: 38486376.0000 - val_false_positives: 4910151.0000 - val_true_negatives: 55960840.0000 - val_false_negatives: 6614339.0000 - val_precision: 0.8869 - val_recall: 0.8533\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0631 - accuracy: 0.8992 - binary_iou: 0.8113 - true_positives: 113698048.0000 - false_positives: 14690406.0000 - true_negatives: 173600240.0000 - false_negatives: 17532068.0000 - precision: 0.8856 - recall: 0.8664 - val_loss: 0.0652 - val_accuracy: 0.8966 - val_binary_iou: 0.8095 - val_true_positives: 40043744.0000 - val_false_positives: 5826681.0000 - val_true_negatives: 54969080.0000 - val_false_negatives: 5132186.0000 - val_precision: 0.8730 - val_recall: 0.8864\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0637 - accuracy: 0.8980 - binary_iou: 0.8094 - true_positives: 113588616.0000 - false_positives: 14980239.0000 - true_negatives: 173351664.0000 - false_negatives: 17600292.0000 - precision: 0.8835 - recall: 0.8658 - val_loss: 0.0656 - val_accuracy: 0.8946 - val_binary_iou: 0.8057 - val_true_positives: 39386224.0000 - val_false_positives: 5345324.0000 - val_true_negatives: 55416720.0000 - val_false_negatives: 5823438.0000 - val_precision: 0.8805 - val_recall: 0.8712\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0632 - accuracy: 0.8994 - binary_iou: 0.8117 - true_positives: 113913360.0000 - false_positives: 14901580.0000 - true_negatives: 173453984.0000 - false_negatives: 17251912.0000 - precision: 0.8843 - recall: 0.8685 - val_loss: 0.0677 - val_accuracy: 0.8909 - val_binary_iou: 0.7967 - val_true_positives: 36674312.0000 - val_false_positives: 3143865.0000 - val_true_negatives: 57733296.0000 - val_false_negatives: 8420255.0000 - val_precision: 0.9210 - val_recall: 0.8133\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0628 - accuracy: 0.8998 - binary_iou: 0.8124 - true_positives: 113707192.0000 - false_positives: 14696928.0000 - true_negatives: 173804480.0000 - false_negatives: 17312232.0000 - precision: 0.8855 - recall: 0.8679 - val_loss: 0.0644 - val_accuracy: 0.8966 - val_binary_iou: 0.8081 - val_true_positives: 38568048.0000 - val_false_positives: 4499647.0000 - val_true_negatives: 56449208.0000 - val_false_negatives: 6454799.0000 - val_precision: 0.8955 - val_recall: 0.8566\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0629 - accuracy: 0.8991 - binary_iou: 0.8111 - true_positives: 113587144.0000 - false_positives: 14703208.0000 - true_negatives: 173683136.0000 - false_negatives: 17547360.0000 - precision: 0.8854 - recall: 0.8662 - val_loss: 0.0652 - val_accuracy: 0.8961 - val_binary_iou: 0.8068 - val_true_positives: 38103600.0000 - val_false_positives: 3996850.0000 - val_true_negatives: 56860540.0000 - val_false_negatives: 7010724.0000 - val_precision: 0.9051 - val_recall: 0.8446\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9011 - binary_iou: 0.8147 - true_positives: 114228344.0000 - false_positives: 14679725.0000 - true_negatives: 173688992.0000 - false_negatives: 16923826.0000 - precision: 0.8861 - recall: 0.8710 - val_loss: 0.0670 - val_accuracy: 0.8930 - val_binary_iou: 0.8033 - val_true_positives: 39714736.0000 - val_false_positives: 5934338.0000 - val_true_negatives: 54915616.0000 - val_false_negatives: 5407036.0000 - val_precision: 0.8700 - val_recall: 0.8802\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0620 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114160192.0000 - false_positives: 14541802.0000 - true_negatives: 173797200.0000 - false_negatives: 17021584.0000 - precision: 0.8870 - recall: 0.8702 - val_loss: 0.0660 - val_accuracy: 0.8971 - val_binary_iou: 0.8080 - val_true_positives: 37770996.0000 - val_false_positives: 3567448.0000 - val_true_negatives: 57291268.0000 - val_false_negatives: 7341999.0000 - val_precision: 0.9137 - val_recall: 0.8373\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0617 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114073448.0000 - false_positives: 14479113.0000 - true_negatives: 173890848.0000 - false_negatives: 17077416.0000 - precision: 0.8874 - recall: 0.8698 - val_loss: 0.0689 - val_accuracy: 0.8869 - val_binary_iou: 0.7917 - val_true_positives: 37728168.0000 - val_false_positives: 4620711.0000 - val_true_negatives: 56262276.0000 - val_false_negatives: 7360528.0000 - val_precision: 0.8909 - val_recall: 0.8368\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9012 - binary_iou: 0.8148 - true_positives: 114021800.0000 - false_positives: 14454801.0000 - true_negatives: 173942048.0000 - false_negatives: 17102218.0000 - precision: 0.8875 - recall: 0.8696 - val_loss: 0.0649 - val_accuracy: 0.8959 - val_binary_iou: 0.8076 - val_true_positives: 39236980.0000 - val_false_positives: 5234554.0000 - val_true_negatives: 55702736.0000 - val_false_negatives: 5797450.0000 - val_precision: 0.8823 - val_recall: 0.8713\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0616 - accuracy: 0.9018 - binary_iou: 0.8158 - true_positives: 114294520.0000 - false_positives: 14557606.0000 - true_negatives: 173837216.0000 - false_negatives: 16831460.0000 - precision: 0.8870 - recall: 0.8716 - val_loss: 0.0668 - val_accuracy: 0.8935 - val_binary_iou: 0.8021 - val_true_positives: 37644852.0000 - val_false_positives: 3729698.0000 - val_true_negatives: 57043988.0000 - val_false_negatives: 7553180.0000 - val_precision: 0.9099 - val_recall: 0.8329\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0610 - accuracy: 0.9025 - binary_iou: 0.8171 - true_positives: 114541624.0000 - false_positives: 14579440.0000 - true_negatives: 173826448.0000 - false_negatives: 16573294.0000 - precision: 0.8871 - recall: 0.8736 - val_loss: 0.0697 - val_accuracy: 0.8909 - val_binary_iou: 0.8004 - val_true_positives: 40092472.0000 - val_false_positives: 6589798.0000 - val_true_negatives: 54318728.0000 - val_false_negatives: 4970714.0000 - val_precision: 0.8588 - val_recall: 0.8897\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 436ms/step - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715 - val_loss: 0.0628 - val_accuracy: 0.8995 - val_binary_iou: 0.8142 - val_true_positives: 40126964.0000 - val_false_positives: 5757267.0000 - val_true_negatives: 55192272.0000 - val_false_negatives: 4895184.0000 - val_precision: 0.8745 - val_recall: 0.8913\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0604 - accuracy: 0.9035 - binary_iou: 0.8187 - true_positives: 114372352.0000 - false_positives: 14042377.0000 - true_negatives: 174325200.0000 - false_negatives: 16780868.0000 - precision: 0.8906 - recall: 0.8721 - val_loss: 0.0720 - val_accuracy: 0.8868 - val_binary_iou: 0.7945 - val_true_positives: 40941160.0000 - val_false_positives: 7836965.0000 - val_true_negatives: 53037104.0000 - val_false_negatives: 4156491.0000 - val_precision: 0.8393 - val_recall: 0.9078\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0598 - accuracy: 0.9050 - binary_iou: 0.8213 - true_positives: 114764616.0000 - false_positives: 13977922.0000 - true_negatives: 174412896.0000 - false_negatives: 16365363.0000 - precision: 0.8914 - recall: 0.8752 - val_loss: 0.0632 - val_accuracy: 0.8991 - val_binary_iou: 0.8121 - val_true_positives: 38543120.0000 - val_false_positives: 4116308.0000 - val_true_negatives: 56735084.0000 - val_false_negatives: 6577184.0000 - val_precision: 0.9035 - val_recall: 0.8542\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0602 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114492112.0000 - false_positives: 14097260.0000 - true_negatives: 174293072.0000 - false_negatives: 16638253.0000 - precision: 0.8904 - recall: 0.8731 - val_loss: 0.0649 - val_accuracy: 0.8957 - val_binary_iou: 0.8085 - val_true_positives: 40805296.0000 - val_false_positives: 6699145.0000 - val_true_negatives: 54108424.0000 - val_false_negatives: 4358863.0000 - val_precision: 0.8590 - val_recall: 0.9035\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0605 - accuracy: 0.9037 - binary_iou: 0.8190 - true_positives: 114271792.0000 - false_positives: 13944031.0000 - true_negatives: 174493456.0000 - false_negatives: 16811372.0000 - precision: 0.8912 - recall: 0.8718 - val_loss: 0.0673 - val_accuracy: 0.8897 - val_binary_iou: 0.7995 - val_true_positives: 41579912.0000 - val_false_positives: 8194420.0000 - val_true_negatives: 52699744.0000 - val_false_negatives: 3497623.0000 - val_precision: 0.8354 - val_recall: 0.9224\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0606 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114383448.0000 - false_positives: 13910560.0000 - true_negatives: 174400160.0000 - false_negatives: 16826680.0000 - precision: 0.8916 - recall: 0.8718 - val_loss: 0.0766 - val_accuracy: 0.8862 - val_binary_iou: 0.7928 - val_true_positives: 40028572.0000 - val_false_positives: 7006960.0000 - val_true_negatives: 53881560.0000 - val_false_negatives: 5054641.0000 - val_precision: 0.8510 - val_recall: 0.8879\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739 - val_loss: 0.0630 - val_accuracy: 0.9009 - val_binary_iou: 0.8159 - val_true_positives: 39473896.0000 - val_false_positives: 4852153.0000 - val_true_negatives: 55992092.0000 - val_false_negatives: 5653550.0000 - val_precision: 0.8905 - val_recall: 0.8747\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0598 - accuracy: 0.9053 - binary_iou: 0.8217 - true_positives: 114655032.0000 - false_positives: 13736962.0000 - true_negatives: 174595376.0000 - false_negatives: 16533304.0000 - precision: 0.8930 - recall: 0.8740 - val_loss: 0.0671 - val_accuracy: 0.8912 - val_binary_iou: 0.7983 - val_true_positives: 37558328.0000 - val_false_positives: 3884693.0000 - val_true_negatives: 56883664.0000 - val_false_negatives: 7645055.0000 - val_precision: 0.9063 - val_recall: 0.8309\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750 - val_loss: 0.0613 - val_accuracy: 0.9038 - val_binary_iou: 0.8209 - val_true_positives: 39589588.0000 - val_false_positives: 4649140.0000 - val_true_negatives: 56191696.0000 - val_false_negatives: 5541295.0000 - val_precision: 0.8949 - val_recall: 0.8772\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9066 - binary_iou: 0.8240 - true_positives: 114924592.0000 - false_positives: 13616651.0000 - true_negatives: 174744976.0000 - false_negatives: 16234598.0000 - precision: 0.8941 - recall: 0.8762 - val_loss: 0.0657 - val_accuracy: 0.8950 - val_binary_iou: 0.8070 - val_true_positives: 40115272.0000 - val_false_positives: 6156170.0000 - val_true_negatives: 54733744.0000 - val_false_negatives: 4966526.0000 - val_precision: 0.8670 - val_recall: 0.8898\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0590 - accuracy: 0.9069 - binary_iou: 0.8244 - true_positives: 114822896.0000 - false_positives: 13371130.0000 - true_negatives: 174937648.0000 - false_negatives: 16389186.0000 - precision: 0.8957 - recall: 0.8751 - val_loss: 0.0643 - val_accuracy: 0.8999 - val_binary_iou: 0.8143 - val_true_positives: 39385200.0000 - val_false_positives: 4859034.0000 - val_true_negatives: 55981228.0000 - val_false_negatives: 5746234.0000 - val_precision: 0.8902 - val_recall: 0.8727\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0592 - accuracy: 0.9064 - binary_iou: 0.8238 - true_positives: 115060424.0000 - false_positives: 13745673.0000 - true_negatives: 174567392.0000 - false_negatives: 16147346.0000 - precision: 0.8933 - recall: 0.8769 - val_loss: 0.0611 - val_accuracy: 0.9035 - val_binary_iou: 0.8204 - val_true_positives: 39653136.0000 - val_false_positives: 4728918.0000 - val_true_negatives: 56094144.0000 - val_false_negatives: 5495510.0000 - val_precision: 0.8934 - val_recall: 0.8783\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9059 - binary_iou: 0.8228 - true_positives: 114785464.0000 - false_positives: 13761449.0000 - true_negatives: 174670400.0000 - false_negatives: 16303439.0000 - precision: 0.8929 - recall: 0.8756 - val_loss: 0.0693 - val_accuracy: 0.8904 - val_binary_iou: 0.7999 - val_true_positives: 40398372.0000 - val_false_positives: 6853430.0000 - val_true_negatives: 53963436.0000 - val_false_negatives: 4756454.0000 - val_precision: 0.8550 - val_recall: 0.8947\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0584 - accuracy: 0.9071 - binary_iou: 0.8249 - true_positives: 115098648.0000 - false_positives: 13609404.0000 - true_negatives: 174737072.0000 - false_negatives: 16075616.0000 - precision: 0.8943 - recall: 0.8774 - val_loss: 0.0620 - val_accuracy: 0.9023 - val_binary_iou: 0.8191 - val_true_positives: 40398948.0000 - val_false_positives: 5691739.0000 - val_true_negatives: 55220200.0000 - val_false_negatives: 4660829.0000 - val_precision: 0.8765 - val_recall: 0.8966\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0580 - accuracy: 0.9078 - binary_iou: 0.8260 - true_positives: 115041896.0000 - false_positives: 13368177.0000 - true_negatives: 175011792.0000 - false_negatives: 16098864.0000 - precision: 0.8959 - recall: 0.8772 - val_loss: 0.0618 - val_accuracy: 0.9024 - val_binary_iou: 0.8176 - val_true_positives: 38695004.0000 - val_false_positives: 3913730.0000 - val_true_negatives: 56928672.0000 - val_false_negatives: 6434295.0000 - val_precision: 0.9081 - val_recall: 0.8574\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0586 - accuracy: 0.9073 - binary_iou: 0.8253 - true_positives: 115108880.0000 - false_positives: 13592248.0000 - true_negatives: 174804848.0000 - false_negatives: 16014808.0000 - precision: 0.8944 - recall: 0.8779 - val_loss: 0.0632 - val_accuracy: 0.9009 - val_binary_iou: 0.8162 - val_true_positives: 39746444.0000 - val_false_positives: 5064269.0000 - val_true_negatives: 55720692.0000 - val_false_negatives: 5440308.0000 - val_precision: 0.8870 - val_recall: 0.8796\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783 - val_loss: 0.0609 - val_accuracy: 0.9045 - val_binary_iou: 0.8220 - val_true_positives: 39622044.0000 - val_false_positives: 4580523.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 5541544.0000 - val_precision: 0.8964 - val_recall: 0.8773\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0579 - accuracy: 0.9080 - binary_iou: 0.8265 - true_positives: 115247800.0000 - false_positives: 13446067.0000 - true_negatives: 174880816.0000 - false_negatives: 15946018.0000 - precision: 0.8955 - recall: 0.8785 - val_loss: 0.0743 - val_accuracy: 0.8851 - val_binary_iou: 0.7913 - val_true_positives: 40276164.0000 - val_false_positives: 7452888.0000 - val_true_negatives: 53520128.0000 - val_false_negatives: 4722535.0000 - val_precision: 0.8439 - val_recall: 0.8951\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0573 - accuracy: 0.9089 - binary_iou: 0.8280 - true_positives: 115350232.0000 - false_positives: 13306295.0000 - true_negatives: 175061568.0000 - false_negatives: 15802560.0000 - precision: 0.8966 - recall: 0.8795 - val_loss: 0.0687 - val_accuracy: 0.8928 - val_binary_iou: 0.8045 - val_true_positives: 41609304.0000 - val_false_positives: 7912378.0000 - val_true_negatives: 52998040.0000 - val_false_negatives: 3452000.0000 - val_precision: 0.8402 - val_recall: 0.9234\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0570 - accuracy: 0.9097 - binary_iou: 0.8295 - true_positives: 115566680.0000 - false_positives: 13204775.0000 - true_negatives: 175116896.0000 - false_negatives: 15632293.0000 - precision: 0.8975 - recall: 0.8809 - val_loss: 0.0618 - val_accuracy: 0.9033 - val_binary_iou: 0.8206 - val_true_positives: 40212672.0000 - val_false_positives: 5331110.0000 - val_true_negatives: 55514868.0000 - val_false_negatives: 4913069.0000 - val_precision: 0.8829 - val_recall: 0.8911\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0574 - accuracy: 0.9091 - binary_iou: 0.8283 - true_positives: 115335368.0000 - false_positives: 13241246.0000 - true_negatives: 175149360.0000 - false_negatives: 15794777.0000 - precision: 0.8970 - recall: 0.8795 - val_loss: 0.0619 - val_accuracy: 0.9025 - val_binary_iou: 0.8185 - val_true_positives: 39427960.0000 - val_false_positives: 4689384.0000 - val_true_negatives: 56207648.0000 - val_false_negatives: 5646732.0000 - val_precision: 0.8937 - val_recall: 0.8747\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0572 - accuracy: 0.9092 - binary_iou: 0.8284 - true_positives: 115450496.0000 - false_positives: 13292661.0000 - true_negatives: 175043360.0000 - false_negatives: 15734289.0000 - precision: 0.8968 - recall: 0.8801 - val_loss: 0.0653 - val_accuracy: 0.8978 - val_binary_iou: 0.8097 - val_true_positives: 38248656.0000 - val_false_positives: 3970812.0000 - val_true_negatives: 56891840.0000 - val_false_negatives: 6860412.0000 - val_precision: 0.9059 - val_recall: 0.8479\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0576 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115059888.0000 - false_positives: 13279338.0000 - true_negatives: 175221456.0000 - false_negatives: 15960160.0000 - precision: 0.8965 - recall: 0.8782 - val_loss: 0.0621 - val_accuracy: 0.9005 - val_binary_iou: 0.8159 - val_true_positives: 40226056.0000 - val_false_positives: 5739225.0000 - val_true_negatives: 55198836.0000 - val_false_negatives: 4807608.0000 - val_precision: 0.8751 - val_recall: 0.8932\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0567 - accuracy: 0.9100 - binary_iou: 0.8299 - true_positives: 115410632.0000 - false_positives: 13091224.0000 - true_negatives: 175366784.0000 - false_negatives: 15652111.0000 - precision: 0.8981 - recall: 0.8806 - val_loss: 0.0648 - val_accuracy: 0.8976 - val_binary_iou: 0.8096 - val_true_positives: 38385240.0000 - val_false_positives: 4143129.0000 - val_true_negatives: 56738792.0000 - val_false_negatives: 6704553.0000 - val_precision: 0.9026 - val_recall: 0.8513\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0569 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115559664.0000 - false_positives: 13187510.0000 - true_negatives: 175197328.0000 - false_negatives: 15576244.0000 - precision: 0.8976 - recall: 0.8812 - val_loss: 0.0616 - val_accuracy: 0.9021 - val_binary_iou: 0.8190 - val_true_positives: 40675596.0000 - val_false_positives: 5981493.0000 - val_true_negatives: 54921920.0000 - val_false_negatives: 4392702.0000 - val_precision: 0.8718 - val_recall: 0.9025\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817 - val_loss: 0.0604 - val_accuracy: 0.9043 - val_binary_iou: 0.8220 - val_true_positives: 40136756.0000 - val_false_positives: 5091398.0000 - val_true_negatives: 55688312.0000 - val_false_negatives: 5055239.0000 - val_precision: 0.8874 - val_recall: 0.8881\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0565 - accuracy: 0.9104 - binary_iou: 0.8305 - true_positives: 115524848.0000 - false_positives: 13007364.0000 - true_negatives: 175357504.0000 - false_negatives: 15631114.0000 - precision: 0.8988 - recall: 0.8808 - val_loss: 0.0637 - val_accuracy: 0.8973 - val_binary_iou: 0.8116 - val_true_positives: 41283940.0000 - val_false_positives: 7066725.0000 - val_true_negatives: 53805696.0000 - val_false_negatives: 3815342.0000 - val_precision: 0.8538 - val_recall: 0.9154\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0566 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115418920.0000 - false_positives: 13103144.0000 - true_negatives: 175337664.0000 - false_negatives: 15661151.0000 - precision: 0.8980 - recall: 0.8805 - val_loss: 0.0685 - val_accuracy: 0.8931 - val_binary_iou: 0.8000 - val_true_positives: 36465344.0000 - val_false_positives: 2706221.0000 - val_true_negatives: 58180776.0000 - val_false_negatives: 8619357.0000 - val_precision: 0.9309 - val_recall: 0.8088\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830 - val_loss: 0.0591 - val_accuracy: 0.9071 - val_binary_iou: 0.8267 - val_true_positives: 40077468.0000 - val_false_positives: 4810660.0000 - val_true_negatives: 56051568.0000 - val_false_negatives: 5032024.0000 - val_precision: 0.8928 - val_recall: 0.8884\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0561 - accuracy: 0.9108 - binary_iou: 0.8312 - true_positives: 115485504.0000 - false_positives: 12872387.0000 - true_negatives: 175535872.0000 - false_negatives: 15627070.0000 - precision: 0.8997 - recall: 0.8808 - val_loss: 0.0686 - val_accuracy: 0.8930 - val_binary_iou: 0.8049 - val_true_positives: 41539792.0000 - val_false_positives: 7744004.0000 - val_true_negatives: 53097324.0000 - val_false_negatives: 3590584.0000 - val_precision: 0.8429 - val_recall: 0.9204\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0560 - accuracy: 0.9111 - binary_iou: 0.8318 - true_positives: 115753184.0000 - false_positives: 13009851.0000 - true_negatives: 175361808.0000 - false_negatives: 15395915.0000 - precision: 0.8990 - recall: 0.8826 - val_loss: 0.0621 - val_accuracy: 0.9018 - val_binary_iou: 0.8154 - val_true_positives: 37469948.0000 - val_false_positives: 2734699.0000 - val_true_negatives: 58100136.0000 - val_false_negatives: 7666928.0000 - val_precision: 0.9320 - val_recall: 0.8301\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0557 - accuracy: 0.9119 - binary_iou: 0.8331 - true_positives: 115764048.0000 - false_positives: 12780396.0000 - true_negatives: 175605136.0000 - false_negatives: 15371262.0000 - precision: 0.9006 - recall: 0.8828 - val_loss: 0.0607 - val_accuracy: 0.9049 - val_binary_iou: 0.8227 - val_true_positives: 39667376.0000 - val_false_positives: 4631294.0000 - val_true_negatives: 56222816.0000 - val_false_negatives: 5450231.0000 - val_precision: 0.8955 - val_recall: 0.8792\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0556 - accuracy: 0.9117 - binary_iou: 0.8328 - true_positives: 115600880.0000 - false_positives: 12729907.0000 - true_negatives: 175719568.0000 - false_negatives: 15470327.0000 - precision: 0.9008 - recall: 0.8820 - val_loss: 0.0629 - val_accuracy: 0.8997 - val_binary_iou: 0.8149 - val_true_positives: 40599992.0000 - val_false_positives: 6119560.0000 - val_true_negatives: 54737740.0000 - val_false_negatives: 4514413.0000 - val_precision: 0.8690 - val_recall: 0.8999\n",
      "132/132 [==============================] - 20s 121ms/step - loss: 224.4008 - accuracy: 0.9036 - binary_iou: 0.8199 - true_positives: 38915348.0000 - false_positives: 4943305.0000 - true_negatives: 56841440.0000 - false_negatives: 5271624.0000 - precision: 0.8873 - recall: 0.8807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Durch RegEx kann aus den Layernamen der Index der Convolutional-Layer entnommen werden und diese dann nacheinander eingefroren werden\n",
    "\n",
    "conv_layers = [4, 7, 11, 15, 18, 22, 26, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 64, 68, 72, 75, 79, 83, 86, 90, 94, 95, 98, 102, 106, 110, 114, 118,\n",
    " 121, 125, 129, 132, 136, 140, 141, 144, 148, 152, 156, 160, 164, 167, 171, 175, 176, 179, 183, 190]\n",
    "\n",
    "import gc\n",
    "\n",
    "for number in conv_layers:      \n",
    "\n",
    "    training_split = 0.6\n",
    "\n",
    "    pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "    conf = {\n",
    "        'AVG': 'BN',\n",
    "        'RNDM': 'BN',\n",
    "        'EXTRA_CONV': 'CONV',\n",
    "        'RGB_SPLIT': 'SPLIT'\n",
    "        } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "    lr = 0.001 # Learning rate\n",
    "\n",
    "    rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "    ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "    l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "    l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "    #freeze = True # Trainierbarkeit des Encoders\n",
    "    freeze_from = 'input' # Ab diesem layer wird eingefroren, EXKLUSIVE (wird überschrieben bei SPLIT-Variante)!\n",
    "    train_encoder_layers = number # Anzahl an Layern (int) im Encoder, die trainiert werden. Rückwärts gezählt ab Bottleneck\n",
    "    #freeze_what = 'No1ConvBN' # Beschreibung ob 1. Layer eingefroren oder nicht\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    patch_size = 224 # Maße des inputs\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "\n",
    "    unet = load_model(conf[pretrained_weights])\n",
    "    set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "    set_weight_decay(unet, l1= l1, l2= l2)\n",
    "    set_pretrained_weights(unet, pretrained_weights)\n",
    "    set_encoder_frozen(unet, pretrained_weights, freeze_from= freeze_from, train_encoder_layers= train_encoder_layers)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "\n",
    "    loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "    model_name = f'FT_test_AVG_no_of_frozen_layers_{number}'\n",
    "\n",
    "    checkpoint_path = f'../saved_model_FT_test/{model_name}_e{str(epochs)}'\n",
    "    logger_path = f'../saved_history_FT_test/{model_name}_e{str(epochs)}.log'\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path)\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "\n",
    "\n",
    "    train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/masks'\n",
    "    )\n",
    "\n",
    "    val_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = True,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/masks'\n",
    "    )\n",
    "\n",
    "    test_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = False,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/masks'\n",
    "    )\n",
    "\n",
    "    model_history = unet.fit(train_data_generator, validation_data=val_data_generator, callbacks= [checkpoint_callback, history_logger], epochs=epochs)\n",
    "\n",
    "\n",
    "    # laden des besten models\n",
    "    unet = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "    # Evaluieren & Ergebnisse in Tabelle\n",
    "    eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "    with open('../results/FT_test_eval_output.csv', 'a') as f_object:\n",
    "        row = []\n",
    "        \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)\n",
    "\n",
    "        writer_object = csv.writer(f_object)\n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "    del unet\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob trainable oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfigurationen, Laden & Kompilieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BN',\n",
    "    'RNDM': 'BN',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0.1 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 480\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "model_name = f'Final_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}_e{total_epochs}'\n",
    "\n",
    "# Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren der Data Generator & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.7929 - binary_iou: 0.6547 - true_positives: 111260928.0000 - false_positives: 46485992.0000 - true_negatives: 142090544.0000 - false_negatives: 19683356.0000 - precision: 0.7053 - recall: 0.8497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 101s 451ms/step - loss: 0.2476 - accuracy: 0.7929 - binary_iou: 0.6547 - true_positives: 111260928.0000 - false_positives: 46485992.0000 - true_negatives: 142090544.0000 - false_negatives: 19683356.0000 - precision: 0.7053 - recall: 0.8497 - val_loss: 0.2726 - val_accuracy: 0.7695 - val_binary_iou: 0.6214 - val_true_positives: 34090968.0000 - val_false_positives: 13482520.0000 - val_true_negatives: 47453612.0000 - val_false_negatives: 10944609.0000 - val_precision: 0.7166 - val_recall: 0.7570\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.8479 - binary_iou: 0.7314 - true_positives: 111700480.0000 - false_positives: 29117956.0000 - true_negatives: 159211456.0000 - false_negatives: 19490928.0000 - precision: 0.7932 - recall: 0.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 87s 436ms/step - loss: 0.1815 - accuracy: 0.8479 - binary_iou: 0.7314 - true_positives: 111700480.0000 - false_positives: 29117956.0000 - true_negatives: 159211456.0000 - false_negatives: 19490928.0000 - precision: 0.7932 - recall: 0.8514 - val_loss: 0.1805 - val_accuracy: 0.8325 - val_binary_iou: 0.7123 - val_true_positives: 41063608.0000 - val_false_positives: 13668315.0000 - val_true_negatives: 47152704.0000 - val_false_negatives: 4087099.0000 - val_precision: 0.7503 - val_recall: 0.9095\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.8603 - binary_iou: 0.7501 - true_positives: 112333432.0000 - false_positives: 25853646.0000 - true_negatives: 162550576.0000 - false_negatives: 18783162.0000 - precision: 0.8129 - recall: 0.8567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 439ms/step - loss: 0.1683 - accuracy: 0.8603 - binary_iou: 0.7501 - true_positives: 112333432.0000 - false_positives: 25853646.0000 - true_negatives: 162550576.0000 - false_negatives: 18783162.0000 - precision: 0.8129 - recall: 0.8567 - val_loss: 0.1702 - val_accuracy: 0.8507 - val_binary_iou: 0.7380 - val_true_positives: 39503848.0000 - val_false_positives: 10189637.0000 - val_true_negatives: 50647692.0000 - val_false_negatives: 5630542.0000 - val_precision: 0.7950 - val_recall: 0.8752\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.8714 - binary_iou: 0.7672 - true_positives: 112810608.0000 - false_positives: 22776774.0000 - true_negatives: 165629360.0000 - false_negatives: 18304026.0000 - precision: 0.8320 - recall: 0.8604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 439ms/step - loss: 0.1557 - accuracy: 0.8714 - binary_iou: 0.7672 - true_positives: 112810608.0000 - false_positives: 22776774.0000 - true_negatives: 165629360.0000 - false_negatives: 18304026.0000 - precision: 0.8320 - recall: 0.8604 - val_loss: 0.1633 - val_accuracy: 0.8520 - val_binary_iou: 0.7409 - val_true_positives: 41096576.0000 - val_false_positives: 11621155.0000 - val_true_negatives: 49186404.0000 - val_false_negatives: 4067588.0000 - val_precision: 0.7796 - val_recall: 0.9099\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - 74s 368ms/step - loss: 0.1507 - accuracy: 0.8754 - binary_iou: 0.7736 - true_positives: 113601816.0000 - false_positives: 22206792.0000 - true_negatives: 166120112.0000 - false_negatives: 17592020.0000 - precision: 0.8365 - recall: 0.8659 - val_loss: 0.1884 - val_accuracy: 0.8422 - val_binary_iou: 0.7223 - val_true_positives: 36328112.0000 - val_false_positives: 7921705.0000 - val_true_negatives: 52918032.0000 - val_false_negatives: 8803860.0000 - val_precision: 0.8210 - val_recall: 0.8049\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.8801 - binary_iou: 0.7810 - true_positives: 114101400.0000 - false_positives: 21314652.0000 - true_negatives: 167096400.0000 - false_negatives: 17008404.0000 - precision: 0.8426 - recall: 0.8703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 442ms/step - loss: 0.1458 - accuracy: 0.8801 - binary_iou: 0.7810 - true_positives: 114101400.0000 - false_positives: 21314652.0000 - true_negatives: 167096400.0000 - false_negatives: 17008404.0000 - precision: 0.8426 - recall: 0.8703 - val_loss: 0.1482 - val_accuracy: 0.8786 - val_binary_iou: 0.7788 - val_true_positives: 37914612.0000 - val_false_positives: 5712061.0000 - val_true_negatives: 55189444.0000 - val_false_negatives: 7155610.0000 - val_precision: 0.8691 - val_recall: 0.8412\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.1414 - accuracy: 0.8836 - binary_iou: 0.7867 - true_positives: 114253376.0000 - false_positives: 20262198.0000 - true_negatives: 168085696.0000 - false_negatives: 16919424.0000 - precision: 0.8494 - recall: 0.8710 - val_loss: 0.1652 - val_accuracy: 0.8445 - val_binary_iou: 0.7304 - val_true_positives: 42304068.0000 - val_false_positives: 13733922.0000 - val_true_negatives: 47187204.0000 - val_false_negatives: 2746526.0000 - val_precision: 0.7549 - val_recall: 0.9390\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - 74s 374ms/step - loss: 0.1366 - accuracy: 0.8876 - binary_iou: 0.7931 - true_positives: 114733800.0000 - false_positives: 19606782.0000 - true_negatives: 168872480.0000 - false_negatives: 16307759.0000 - precision: 0.8541 - recall: 0.8756 - val_loss: 0.1433 - val_accuracy: 0.8686 - val_binary_iou: 0.7667 - val_true_positives: 42139888.0000 - val_false_positives: 10993793.0000 - val_true_negatives: 49903256.0000 - val_false_negatives: 2934777.0000 - val_precision: 0.7931 - val_recall: 0.9349\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.8927 - binary_iou: 0.8016 - true_positives: 115382344.0000 - false_positives: 18508448.0000 - true_negatives: 169866496.0000 - false_negatives: 15763460.0000 - precision: 0.8618 - recall: 0.8798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 450ms/step - loss: 0.1310 - accuracy: 0.8927 - binary_iou: 0.8016 - true_positives: 115382344.0000 - false_positives: 18508448.0000 - true_negatives: 169866496.0000 - false_negatives: 15763460.0000 - precision: 0.8618 - recall: 0.8798 - val_loss: 0.1465 - val_accuracy: 0.8812 - val_binary_iou: 0.7824 - val_true_positives: 37443064.0000 - val_false_positives: 5000822.0000 - val_true_negatives: 55941680.0000 - val_false_negatives: 7586141.0000 - val_precision: 0.8822 - val_recall: 0.8315\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.1283 - accuracy: 0.8945 - binary_iou: 0.8046 - true_positives: 115978928.0000 - false_positives: 18511616.0000 - true_negatives: 169835136.0000 - false_negatives: 15195034.0000 - precision: 0.8624 - recall: 0.8842 - val_loss: 0.1414 - val_accuracy: 0.8781 - val_binary_iou: 0.7798 - val_true_positives: 39740800.0000 - val_false_positives: 7632128.0000 - val_true_negatives: 53309612.0000 - val_false_negatives: 5289164.0000 - val_precision: 0.8389 - val_recall: 0.8825\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.1258 - accuracy: 0.8971 - binary_iou: 0.8087 - true_positives: 115813656.0000 - false_positives: 17581886.0000 - true_negatives: 170812832.0000 - false_negatives: 15312439.0000 - precision: 0.8682 - recall: 0.8832 - val_loss: 0.1521 - val_accuracy: 0.8600 - val_binary_iou: 0.7535 - val_true_positives: 41793848.0000 - val_false_positives: 11450709.0000 - val_true_negatives: 49345084.0000 - val_false_negatives: 3382068.0000 - val_precision: 0.7849 - val_recall: 0.9251\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.1234 - accuracy: 0.8992 - binary_iou: 0.8122 - true_positives: 115997280.0000 - false_positives: 17117856.0000 - true_negatives: 171316576.0000 - false_negatives: 15088993.0000 - precision: 0.8714 - recall: 0.8849 - val_loss: 0.1389 - val_accuracy: 0.8781 - val_binary_iou: 0.7806 - val_true_positives: 40734328.0000 - val_false_positives: 8558066.0000 - val_true_negatives: 52321136.0000 - val_false_negatives: 4358183.0000 - val_precision: 0.8264 - val_recall: 0.9034\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.1184 - accuracy: 0.9033 - binary_iou: 0.8192 - true_positives: 116617440.0000 - false_positives: 16399176.0000 - true_negatives: 172012256.0000 - false_negatives: 14491963.0000 - precision: 0.8767 - recall: 0.8895 - val_loss: 0.1510 - val_accuracy: 0.8629 - val_binary_iou: 0.7577 - val_true_positives: 41454472.0000 - val_false_positives: 10869328.0000 - val_true_negatives: 49991760.0000 - val_false_negatives: 3656137.0000 - val_precision: 0.7923 - val_recall: 0.9190\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9038 - binary_iou: 0.8200 - true_positives: 116949304.0000 - false_positives: 16531186.0000 - true_negatives: 171820960.0000 - false_negatives: 14219298.0000 - precision: 0.8762 - recall: 0.8916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1177 - accuracy: 0.9038 - binary_iou: 0.8200 - true_positives: 116949304.0000 - false_positives: 16531186.0000 - true_negatives: 171820960.0000 - false_negatives: 14219298.0000 - precision: 0.8762 - recall: 0.8916 - val_loss: 0.1280 - val_accuracy: 0.8886 - val_binary_iou: 0.7974 - val_true_positives: 41060392.0000 - val_false_positives: 7711964.0000 - val_true_negatives: 53103608.0000 - val_false_negatives: 4095747.0000 - val_precision: 0.8419 - val_recall: 0.9093\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - 74s 368ms/step - loss: 0.1145 - accuracy: 0.9068 - binary_iou: 0.8250 - true_positives: 116898120.0000 - false_positives: 15523648.0000 - true_negatives: 172836912.0000 - false_negatives: 14262132.0000 - precision: 0.8828 - recall: 0.8913 - val_loss: 0.1273 - val_accuracy: 0.8860 - val_binary_iou: 0.7939 - val_true_positives: 41910020.0000 - val_false_positives: 8836130.0000 - val_true_negatives: 51984440.0000 - val_false_negatives: 3241119.0000 - val_precision: 0.8259 - val_recall: 0.9282\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9073 - binary_iou: 0.8259 - true_positives: 117313360.0000 - false_positives: 15781037.0000 - true_negatives: 172574896.0000 - false_negatives: 13851476.0000 - precision: 0.8814 - recall: 0.8944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 441ms/step - loss: 0.1133 - accuracy: 0.9073 - binary_iou: 0.8259 - true_positives: 117313360.0000 - false_positives: 15781037.0000 - true_negatives: 172574896.0000 - false_negatives: 13851476.0000 - precision: 0.8814 - recall: 0.8944 - val_loss: 0.1236 - val_accuracy: 0.8920 - val_binary_iou: 0.8031 - val_true_positives: 41449904.0000 - val_false_positives: 7771152.0000 - val_true_negatives: 53075020.0000 - val_false_negatives: 3675630.0000 - val_precision: 0.8421 - val_recall: 0.9185\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.1121 - accuracy: 0.9085 - binary_iou: 0.8280 - true_positives: 117394632.0000 - false_positives: 15470533.0000 - true_negatives: 172894992.0000 - false_negatives: 13760651.0000 - precision: 0.8836 - recall: 0.8951 - val_loss: 0.1514 - val_accuracy: 0.8716 - val_binary_iou: 0.7688 - val_true_positives: 38732044.0000 - val_false_positives: 7182804.0000 - val_true_negatives: 53630000.0000 - val_false_negatives: 6426857.0000 - val_precision: 0.8436 - val_recall: 0.8577\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - 73s 367ms/step - loss: 0.1099 - accuracy: 0.9104 - binary_iou: 0.8311 - true_positives: 117405296.0000 - false_positives: 14973210.0000 - true_negatives: 173481232.0000 - false_negatives: 13661014.0000 - precision: 0.8869 - recall: 0.8958 - val_loss: 0.1306 - val_accuracy: 0.8878 - val_binary_iou: 0.7956 - val_true_positives: 40243528.0000 - val_false_positives: 7101776.0000 - val_true_negatives: 53842208.0000 - val_false_negatives: 4784201.0000 - val_precision: 0.8500 - val_recall: 0.8937\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - 73s 367ms/step - loss: 0.1072 - accuracy: 0.9128 - binary_iou: 0.8353 - true_positives: 117727168.0000 - false_positives: 14425841.0000 - true_negatives: 173942144.0000 - false_negatives: 13425727.0000 - precision: 0.8908 - recall: 0.8976 - val_loss: 0.1357 - val_accuracy: 0.8782 - val_binary_iou: 0.7816 - val_true_positives: 41903948.0000 - val_false_positives: 9661356.0000 - val_true_negatives: 51162880.0000 - val_false_negatives: 3243534.0000 - val_precision: 0.8126 - val_recall: 0.9282\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - 73s 368ms/step - loss: 0.1044 - accuracy: 0.9150 - binary_iou: 0.8392 - true_positives: 118245896.0000 - false_positives: 14301140.0000 - true_negatives: 174124032.0000 - false_negatives: 12849763.0000 - precision: 0.8921 - recall: 0.9020 - val_loss: 0.1268 - val_accuracy: 0.8890 - val_binary_iou: 0.7980 - val_true_positives: 41045652.0000 - val_false_positives: 7639924.0000 - val_true_negatives: 53162016.0000 - val_false_negatives: 4124114.0000 - val_precision: 0.8431 - val_recall: 0.9087\n",
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 2 trainable: True\n",
      "170 conv5_block1_3_conv trainable weights: 2 trainable: True\n",
      "171 conv5_block1_out trainable weights: 0 trainable: True\n",
      "172 conv5_block2_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: True\n",
      "174 conv5_block2_1_conv trainable weights: 1 trainable: True\n",
      "175 conv5_block2_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: True\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: True\n",
      "178 conv5_block2_2_conv trainable weights: 1 trainable: True\n",
      "179 conv5_block2_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: True\n",
      "181 conv5_block2_3_conv trainable weights: 2 trainable: True\n",
      "182 conv5_block2_out trainable weights: 0 trainable: True\n",
      "183 conv5_block3_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: True\n",
      "185 conv5_block3_1_conv trainable weights: 1 trainable: True\n",
      "186 conv5_block3_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: True\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: True\n",
      "189 conv5_block3_2_conv trainable weights: 1 trainable: True\n",
      "190 conv5_block3_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: True\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2  trainable:  True  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 21/500\n",
      "199/199 [==============================] - 81s 387ms/step - loss: 0.1081 - accuracy: 0.9122 - binary_iou: 0.8342 - true_positives: 117850120.0000 - false_positives: 14786053.0000 - true_negatives: 173604272.0000 - false_negatives: 13280332.0000 - precision: 0.8885 - recall: 0.8987 - val_loss: 0.1291 - val_accuracy: 0.8847 - val_binary_iou: 0.7918 - val_true_positives: 41789412.0000 - val_false_positives: 8968920.0000 - val_true_negatives: 51967956.0000 - val_false_negatives: 3245411.0000 - val_precision: 0.8233 - val_recall: 0.9279\n",
      "Epoch 22/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9222 - binary_iou: 0.8516 - true_positives: 119112944.0000 - false_positives: 12845247.0000 - true_negatives: 175542752.0000 - false_negatives: 12019843.0000 - precision: 0.9027 - recall: 0.9083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0961 - accuracy: 0.9222 - binary_iou: 0.8516 - true_positives: 119112944.0000 - false_positives: 12845247.0000 - true_negatives: 175542752.0000 - false_negatives: 12019843.0000 - precision: 0.9027 - recall: 0.9083 - val_loss: 0.1200 - val_accuracy: 0.8935 - val_binary_iou: 0.8058 - val_true_positives: 41857480.0000 - val_false_positives: 8020901.0000 - val_true_negatives: 52828960.0000 - val_false_negatives: 3264380.0000 - val_precision: 0.8392 - val_recall: 0.9277\n",
      "Epoch 23/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9267 - binary_iou: 0.8596 - true_positives: 119586424.0000 - false_positives: 11906005.0000 - true_negatives: 176525760.0000 - false_negatives: 11502549.0000 - precision: 0.9095 - recall: 0.9123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0904 - accuracy: 0.9267 - binary_iou: 0.8596 - true_positives: 119586424.0000 - false_positives: 11906005.0000 - true_negatives: 176525760.0000 - false_negatives: 11502549.0000 - precision: 0.9095 - recall: 0.9123 - val_loss: 0.1171 - val_accuracy: 0.8969 - val_binary_iou: 0.8113 - val_true_positives: 41730832.0000 - val_false_positives: 7538793.0000 - val_true_negatives: 53318392.0000 - val_false_negatives: 3383695.0000 - val_precision: 0.8470 - val_recall: 0.9250\n",
      "Epoch 24/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9306 - binary_iou: 0.8665 - true_positives: 120151024.0000 - false_positives: 11239283.0000 - true_negatives: 177197824.0000 - false_negatives: 10932585.0000 - precision: 0.9145 - recall: 0.9166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 457ms/step - loss: 0.0861 - accuracy: 0.9306 - binary_iou: 0.8665 - true_positives: 120151024.0000 - false_positives: 11239283.0000 - true_negatives: 177197824.0000 - false_negatives: 10932585.0000 - precision: 0.9145 - recall: 0.9166 - val_loss: 0.1164 - val_accuracy: 0.8985 - val_binary_iou: 0.8137 - val_true_positives: 41472004.0000 - val_false_positives: 7117811.0000 - val_true_negatives: 53747240.0000 - val_false_negatives: 3634661.0000 - val_precision: 0.8535 - val_recall: 0.9194\n",
      "Epoch 25/500\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0824 - accuracy: 0.9333 - binary_iou: 0.8714 - true_positives: 120545552.0000 - false_positives: 10736367.0000 - true_negatives: 177677984.0000 - false_negatives: 10560877.0000 - precision: 0.9182 - recall: 0.9194 - val_loss: 0.1176 - val_accuracy: 0.8973 - val_binary_iou: 0.8117 - val_true_positives: 41456896.0000 - val_false_positives: 7213787.0000 - val_true_negatives: 53635656.0000 - val_false_negatives: 3665359.0000 - val_precision: 0.8518 - val_recall: 0.9188\n",
      "Epoch 26/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9364 - binary_iou: 0.8769 - true_positives: 121107056.0000 - false_positives: 10268451.0000 - true_negatives: 178091936.0000 - false_negatives: 10053417.0000 - precision: 0.9218 - recall: 0.9234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0785 - accuracy: 0.9364 - binary_iou: 0.8769 - true_positives: 121107056.0000 - false_positives: 10268451.0000 - true_negatives: 178091936.0000 - false_negatives: 10053417.0000 - precision: 0.9218 - recall: 0.9234 - val_loss: 0.1160 - val_accuracy: 0.8994 - val_binary_iou: 0.8150 - val_true_positives: 41366944.0000 - val_false_positives: 6905804.0000 - val_true_negatives: 53941880.0000 - val_false_negatives: 3757088.0000 - val_precision: 0.8569 - val_recall: 0.9167\n",
      "Epoch 27/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9379 - binary_iou: 0.8796 - true_positives: 121134128.0000 - false_positives: 9850050.0000 - true_negatives: 178548080.0000 - false_negatives: 9988525.0000 - precision: 0.9248 - recall: 0.9238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0767 - accuracy: 0.9379 - binary_iou: 0.8796 - true_positives: 121134128.0000 - false_positives: 9850050.0000 - true_negatives: 178548080.0000 - false_negatives: 9988525.0000 - precision: 0.9248 - recall: 0.9238 - val_loss: 0.1144 - val_accuracy: 0.9006 - val_binary_iou: 0.8170 - val_true_positives: 41402260.0000 - val_false_positives: 6780974.0000 - val_true_negatives: 54031972.0000 - val_false_negatives: 3756494.0000 - val_precision: 0.8593 - val_recall: 0.9168\n",
      "Epoch 28/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9407 - binary_iou: 0.8847 - true_positives: 121629464.0000 - false_positives: 9419130.0000 - true_negatives: 178941776.0000 - false_negatives: 9530286.0000 - precision: 0.9281 - recall: 0.9273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0736 - accuracy: 0.9407 - binary_iou: 0.8847 - true_positives: 121629464.0000 - false_positives: 9419130.0000 - true_negatives: 178941776.0000 - false_negatives: 9530286.0000 - precision: 0.9281 - recall: 0.9273 - val_loss: 0.1106 - val_accuracy: 0.9042 - val_binary_iou: 0.8229 - val_true_positives: 41346764.0000 - val_false_positives: 6457563.0000 - val_true_negatives: 54474728.0000 - val_false_negatives: 3692663.0000 - val_precision: 0.8649 - val_recall: 0.9180\n",
      "Epoch 29/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0709 - accuracy: 0.9428 - binary_iou: 0.8886 - true_positives: 121824640.0000 - false_positives: 8983829.0000 - true_negatives: 179428128.0000 - false_negatives: 9284122.0000 - precision: 0.9313 - recall: 0.9292 - val_loss: 0.1158 - val_accuracy: 0.8975 - val_binary_iou: 0.8124 - val_true_positives: 41969660.0000 - val_false_positives: 7710790.0000 - val_true_negatives: 53143024.0000 - val_false_negatives: 3148224.0000 - val_precision: 0.8448 - val_recall: 0.9302\n",
      "Epoch 30/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0698 - accuracy: 0.9439 - binary_iou: 0.8905 - true_positives: 122074528.0000 - false_positives: 8822882.0000 - true_negatives: 179507072.0000 - false_negatives: 9116265.0000 - precision: 0.9326 - recall: 0.9305 - val_loss: 0.1108 - val_accuracy: 0.9037 - val_binary_iou: 0.8222 - val_true_positives: 41520372.0000 - val_false_positives: 6585072.0000 - val_true_negatives: 54244624.0000 - val_false_negatives: 3621662.0000 - val_precision: 0.8631 - val_recall: 0.9198\n",
      "Epoch 31/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9452 - binary_iou: 0.8929 - true_positives: 122246008.0000 - false_positives: 8696081.0000 - true_negatives: 179758704.0000 - false_negatives: 8819988.0000 - precision: 0.9336 - recall: 0.9327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0680 - accuracy: 0.9452 - binary_iou: 0.8929 - true_positives: 122246008.0000 - false_positives: 8696081.0000 - true_negatives: 179758704.0000 - false_negatives: 8819988.0000 - precision: 0.9336 - recall: 0.9327 - val_loss: 0.1107 - val_accuracy: 0.9048 - val_binary_iou: 0.8239 - val_true_positives: 41366736.0000 - val_false_positives: 6371371.0000 - val_true_negatives: 54514608.0000 - val_false_negatives: 3719001.0000 - val_precision: 0.8665 - val_recall: 0.9175\n",
      "Epoch 32/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9463 - binary_iou: 0.8950 - true_positives: 122459560.0000 - false_positives: 8501329.0000 - true_negatives: 179895552.0000 - false_negatives: 8664366.0000 - precision: 0.9351 - recall: 0.9339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0667 - accuracy: 0.9463 - binary_iou: 0.8950 - true_positives: 122459560.0000 - false_positives: 8501329.0000 - true_negatives: 179895552.0000 - false_negatives: 8664366.0000 - precision: 0.9351 - recall: 0.9339 - val_loss: 0.1080 - val_accuracy: 0.9075 - val_binary_iou: 0.8282 - val_true_positives: 41189148.0000 - val_false_positives: 5871088.0000 - val_true_negatives: 54977536.0000 - val_false_negatives: 3933963.0000 - val_precision: 0.8752 - val_recall: 0.9128\n",
      "Epoch 33/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0642 - accuracy: 0.9483 - binary_iou: 0.8986 - true_positives: 122704432.0000 - false_positives: 8130237.0000 - true_negatives: 180283616.0000 - false_negatives: 8402519.0000 - precision: 0.9379 - recall: 0.9359 - val_loss: 0.1111 - val_accuracy: 0.9039 - val_binary_iou: 0.8226 - val_true_positives: 41505060.0000 - val_false_positives: 6576379.0000 - val_true_negatives: 54285964.0000 - val_false_negatives: 3604308.0000 - val_precision: 0.8632 - val_recall: 0.9201\n",
      "Epoch 34/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0637 - accuracy: 0.9485 - binary_iou: 0.8991 - true_positives: 122836368.0000 - false_positives: 8162767.0000 - true_negatives: 180231856.0000 - false_negatives: 8289794.0000 - precision: 0.9377 - recall: 0.9368 - val_loss: 0.1088 - val_accuracy: 0.9068 - val_binary_iou: 0.8270 - val_true_positives: 41034112.0000 - val_false_positives: 5874400.0000 - val_true_negatives: 55060912.0000 - val_false_negatives: 4002278.0000 - val_precision: 0.8748 - val_recall: 0.9111\n",
      "Epoch 35/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0623 - accuracy: 0.9499 - binary_iou: 0.9016 - true_positives: 122877104.0000 - false_positives: 7775228.0000 - true_negatives: 180631648.0000 - false_negatives: 8236784.0000 - precision: 0.9405 - recall: 0.9372 - val_loss: 0.1079 - val_accuracy: 0.9062 - val_binary_iou: 0.8263 - val_true_positives: 41386064.0000 - val_false_positives: 6251065.0000 - val_true_negatives: 54647864.0000 - val_false_negatives: 3686709.0000 - val_precision: 0.8688 - val_recall: 0.9182\n",
      "Epoch 36/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0619 - accuracy: 0.9503 - binary_iou: 0.9024 - true_positives: 123098480.0000 - false_positives: 7823664.0000 - true_negatives: 180529968.0000 - false_negatives: 8068657.0000 - precision: 0.9402 - recall: 0.9385 - val_loss: 0.1093 - val_accuracy: 0.9058 - val_binary_iou: 0.8256 - val_true_positives: 41413880.0000 - val_false_positives: 6309975.0000 - val_true_negatives: 54579296.0000 - val_false_negatives: 3668563.0000 - val_precision: 0.8678 - val_recall: 0.9186\n",
      "Epoch 37/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9514 - binary_iou: 0.9044 - true_positives: 123126048.0000 - false_positives: 7580683.0000 - true_negatives: 180857072.0000 - false_negatives: 7957029.0000 - precision: 0.9420 - recall: 0.9393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0605 - accuracy: 0.9514 - binary_iou: 0.9044 - true_positives: 123126048.0000 - false_positives: 7580683.0000 - true_negatives: 180857072.0000 - false_negatives: 7957029.0000 - precision: 0.9420 - recall: 0.9393 - val_loss: 0.1074 - val_accuracy: 0.9080 - val_binary_iou: 0.8291 - val_true_positives: 41263636.0000 - val_false_positives: 5992664.0000 - val_true_negatives: 54959180.0000 - val_false_negatives: 3756226.0000 - val_precision: 0.8732 - val_recall: 0.9166\n",
      "Epoch 38/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0586 - accuracy: 0.9526 - binary_iou: 0.9068 - true_positives: 123404456.0000 - false_positives: 7423683.0000 - true_negatives: 180986224.0000 - false_negatives: 7706406.0000 - precision: 0.9433 - recall: 0.9412 - val_loss: 0.1125 - val_accuracy: 0.9021 - val_binary_iou: 0.8196 - val_true_positives: 41663792.0000 - val_false_positives: 6876702.0000 - val_true_negatives: 53930800.0000 - val_false_negatives: 3500410.0000 - val_precision: 0.8583 - val_recall: 0.9225\n",
      "Epoch 39/500\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0578 - accuracy: 0.9535 - binary_iou: 0.9084 - true_positives: 123564240.0000 - false_positives: 7340500.0000 - true_negatives: 181089264.0000 - false_negatives: 7526749.0000 - precision: 0.9439 - recall: 0.9426 - val_loss: 0.1126 - val_accuracy: 0.9013 - val_binary_iou: 0.8185 - val_true_positives: 41749744.0000 - val_false_positives: 7085891.0000 - val_true_negatives: 53766576.0000 - val_false_negatives: 3369502.0000 - val_precision: 0.8549 - val_recall: 0.9253\n",
      "Epoch 40/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123602496.0000 - false_positives: 7287404.0000 - true_negatives: 181191328.0000 - false_negatives: 7439513.0000 - precision: 0.9443 - recall: 0.9432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0572 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123602496.0000 - false_positives: 7287404.0000 - true_negatives: 181191328.0000 - false_negatives: 7439513.0000 - precision: 0.9443 - recall: 0.9432 - val_loss: 0.1054 - val_accuracy: 0.9095 - val_binary_iou: 0.8318 - val_true_positives: 41398276.0000 - val_false_positives: 5876676.0000 - val_true_negatives: 54986948.0000 - val_false_negatives: 3709816.0000 - val_precision: 0.8757 - val_recall: 0.9178\n",
      "Epoch 41/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0561 - accuracy: 0.9548 - binary_iou: 0.9109 - true_positives: 123804928.0000 - false_positives: 7124760.0000 - true_negatives: 181271520.0000 - false_negatives: 7319598.0000 - precision: 0.9456 - recall: 0.9442 - val_loss: 0.1121 - val_accuracy: 0.9033 - val_binary_iou: 0.8216 - val_true_positives: 41566292.0000 - val_false_positives: 6664851.0000 - val_true_negatives: 54157560.0000 - val_false_negatives: 3583003.0000 - val_precision: 0.8618 - val_recall: 0.9206\n",
      "Epoch 42/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0547 - accuracy: 0.9558 - binary_iou: 0.9127 - true_positives: 123971304.0000 - false_positives: 6992559.0000 - true_negatives: 181414176.0000 - false_negatives: 7142685.0000 - precision: 0.9466 - recall: 0.9455 - val_loss: 0.1095 - val_accuracy: 0.9058 - val_binary_iou: 0.8255 - val_true_positives: 41422632.0000 - val_false_positives: 6199970.0000 - val_true_negatives: 54561732.0000 - val_false_negatives: 3787388.0000 - val_precision: 0.8698 - val_recall: 0.9162\n",
      "Epoch 43/500\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0550 - accuracy: 0.9558 - binary_iou: 0.9128 - true_positives: 124005488.0000 - false_positives: 6928833.0000 - true_negatives: 181392720.0000 - false_negatives: 7193724.0000 - precision: 0.9471 - recall: 0.9452 - val_loss: 0.1129 - val_accuracy: 0.9020 - val_binary_iou: 0.8195 - val_true_positives: 41697916.0000 - val_false_positives: 6906239.0000 - val_true_negatives: 53889064.0000 - val_false_negatives: 3478492.0000 - val_precision: 0.8579 - val_recall: 0.9230\n",
      "Epoch 44/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0535 - accuracy: 0.9569 - binary_iou: 0.9149 - true_positives: 124191848.0000 - false_positives: 6810624.0000 - true_negatives: 181567216.0000 - false_negatives: 6951036.0000 - precision: 0.9480 - recall: 0.9470 - val_loss: 0.1134 - val_accuracy: 0.9018 - val_binary_iou: 0.8189 - val_true_positives: 41318476.0000 - val_false_positives: 6627975.0000 - val_true_negatives: 54244464.0000 - val_false_negatives: 3780805.0000 - val_precision: 0.8618 - val_recall: 0.9162\n",
      "Epoch 45/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0526 - accuracy: 0.9576 - binary_iou: 0.9162 - true_positives: 124375200.0000 - false_positives: 6751220.0000 - true_negatives: 181603856.0000 - false_negatives: 6790461.0000 - precision: 0.9485 - recall: 0.9482 - val_loss: 0.1091 - val_accuracy: 0.9049 - val_binary_iou: 0.8242 - val_true_positives: 41596024.0000 - val_false_positives: 6536557.0000 - val_true_negatives: 54299700.0000 - val_false_negatives: 3539445.0000 - val_precision: 0.8642 - val_recall: 0.9216\n",
      "Epoch 46/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0515 - accuracy: 0.9585 - binary_iou: 0.9179 - true_positives: 124426368.0000 - false_positives: 6564516.0000 - true_negatives: 181839264.0000 - false_negatives: 6690560.0000 - precision: 0.9499 - recall: 0.9490 - val_loss: 0.1064 - val_accuracy: 0.9081 - val_binary_iou: 0.8294 - val_true_positives: 41566264.0000 - val_false_positives: 6116515.0000 - val_true_negatives: 54664480.0000 - val_false_negatives: 3624465.0000 - val_precision: 0.8717 - val_recall: 0.9198\n",
      "Epoch 47/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0514 - accuracy: 0.9584 - binary_iou: 0.9177 - true_positives: 124492912.0000 - false_positives: 6580101.0000 - true_negatives: 181742416.0000 - false_negatives: 6705329.0000 - precision: 0.9498 - recall: 0.9489 - val_loss: 0.1110 - val_accuracy: 0.9043 - val_binary_iou: 0.8232 - val_true_positives: 41465352.0000 - val_false_positives: 6519350.0000 - val_true_negatives: 54367408.0000 - val_false_negatives: 3619594.0000 - val_precision: 0.8641 - val_recall: 0.9197\n",
      "Epoch 48/500\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0510 - accuracy: 0.9588 - binary_iou: 0.9184 - true_positives: 124409312.0000 - false_positives: 6475144.0000 - true_negatives: 181947056.0000 - false_negatives: 6689278.0000 - precision: 0.9505 - recall: 0.9490 - val_loss: 0.1100 - val_accuracy: 0.9050 - val_binary_iou: 0.8242 - val_true_positives: 41333896.0000 - val_false_positives: 6288059.0000 - val_true_negatives: 54568976.0000 - val_false_negatives: 3780789.0000 - val_precision: 0.8680 - val_recall: 0.9162\n",
      "Epoch 49/500\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0507 - accuracy: 0.9591 - binary_iou: 0.9190 - true_positives: 124547552.0000 - false_positives: 6435187.0000 - true_negatives: 181906592.0000 - false_negatives: 6631471.0000 - precision: 0.9509 - recall: 0.9494 - val_loss: 0.1107 - val_accuracy: 0.9043 - val_binary_iou: 0.8231 - val_true_positives: 41383324.0000 - val_false_positives: 6403466.0000 - val_true_negatives: 54449304.0000 - val_false_negatives: 3735618.0000 - val_precision: 0.8660 - val_recall: 0.9172\n",
      "Epoch 50/500\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0495 - accuracy: 0.9601 - binary_iou: 0.9209 - true_positives: 124698568.0000 - false_positives: 6266918.0000 - true_negatives: 182072704.0000 - false_negatives: 6482547.0000 - precision: 0.9521 - recall: 0.9506 - val_loss: 0.1087 - val_accuracy: 0.9070 - val_binary_iou: 0.8274 - val_true_positives: 41279428.0000 - val_false_positives: 6102821.0000 - val_true_negatives: 54834692.0000 - val_false_negatives: 3754759.0000 - val_precision: 0.8712 - val_recall: 0.9166\n",
      "Epoch 51/500\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0487 - accuracy: 0.9606 - binary_iou: 0.9218 - true_positives: 124799696.0000 - false_positives: 6195769.0000 - true_negatives: 182127680.0000 - false_negatives: 6397641.0000 - precision: 0.9527 - recall: 0.9512 - val_loss: 0.1100 - val_accuracy: 0.9065 - val_binary_iou: 0.8266 - val_true_positives: 41179796.0000 - val_false_positives: 5941245.0000 - val_true_negatives: 54883800.0000 - val_false_negatives: 3966863.0000 - val_precision: 0.8739 - val_recall: 0.9121\n",
      "Epoch 52/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0489 - accuracy: 0.9607 - binary_iou: 0.9220 - true_positives: 124848408.0000 - false_positives: 6192958.0000 - true_negatives: 182103408.0000 - false_negatives: 6375960.0000 - precision: 0.9527 - recall: 0.9514 - val_loss: 0.1108 - val_accuracy: 0.9041 - val_binary_iou: 0.8227 - val_true_positives: 41302508.0000 - val_false_positives: 6362762.0000 - val_true_negatives: 54508640.0000 - val_false_negatives: 3797790.0000 - val_precision: 0.8665 - val_recall: 0.9158\n",
      "Epoch 53/500\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.0478 - accuracy: 0.9614 - binary_iou: 0.9234 - true_positives: 124781768.0000 - false_positives: 6028229.0000 - true_negatives: 182410896.0000 - false_negatives: 6299778.0000 - precision: 0.9539 - recall: 0.9519 - val_loss: 0.1079 - val_accuracy: 0.9069 - val_binary_iou: 0.8274 - val_true_positives: 41515208.0000 - val_false_positives: 6251940.0000 - val_true_negatives: 54587232.0000 - val_false_negatives: 3617330.0000 - val_precision: 0.8691 - val_recall: 0.9199\n",
      "Epoch 54/500\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0476 - accuracy: 0.9616 - binary_iou: 0.9238 - true_positives: 124924176.0000 - false_positives: 6050305.0000 - true_negatives: 182336448.0000 - false_negatives: 6209887.0000 - precision: 0.9538 - recall: 0.9526 - val_loss: 0.1069 - val_accuracy: 0.9090 - val_binary_iou: 0.8305 - val_true_positives: 40783484.0000 - val_false_positives: 5325065.0000 - val_true_negatives: 55547240.0000 - val_false_negatives: 4315930.0000 - val_precision: 0.8845 - val_recall: 0.9043\n",
      "Epoch 55/500\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.0474 - accuracy: 0.9618 - binary_iou: 0.9241 - true_positives: 124931184.0000 - false_positives: 6065452.0000 - true_negatives: 182377440.0000 - false_negatives: 6146674.0000 - precision: 0.9537 - recall: 0.9531 - val_loss: 0.1083 - val_accuracy: 0.9060 - val_binary_iou: 0.8260 - val_true_positives: 41516108.0000 - val_false_positives: 6385700.0000 - val_true_negatives: 54493864.0000 - val_false_negatives: 3576046.0000 - val_precision: 0.8667 - val_recall: 0.9207\n",
      "Epoch 56/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0468 - accuracy: 0.9622 - binary_iou: 0.9249 - true_positives: 125006560.0000 - false_positives: 5895238.0000 - true_negatives: 182434656.0000 - false_negatives: 6184300.0000 - precision: 0.9550 - recall: 0.9529 - val_loss: 0.1058 - val_accuracy: 0.9088 - val_binary_iou: 0.8306 - val_true_positives: 41418924.0000 - val_false_positives: 5956019.0000 - val_true_negatives: 54893120.0000 - val_false_negatives: 3703639.0000 - val_precision: 0.8743 - val_recall: 0.9179\n",
      "Epoch 57/500\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0460 - accuracy: 0.9628 - binary_iou: 0.9261 - true_positives: 125134560.0000 - false_positives: 5834666.0000 - true_negatives: 182503616.0000 - false_negatives: 6047937.0000 - precision: 0.9555 - recall: 0.9539 - val_loss: 0.1100 - val_accuracy: 0.9057 - val_binary_iou: 0.8250 - val_true_positives: 40947492.0000 - val_false_positives: 5964129.0000 - val_true_negatives: 55026784.0000 - val_false_negatives: 4033299.0000 - val_precision: 0.8729 - val_recall: 0.9103\n",
      "Epoch 58/500\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0456 - accuracy: 0.9631 - binary_iou: 0.9266 - true_positives: 125021288.0000 - false_positives: 5758220.0000 - true_negatives: 182708032.0000 - false_negatives: 6033271.0000 - precision: 0.9560 - recall: 0.9540 - val_loss: 0.1086 - val_accuracy: 0.9067 - val_binary_iou: 0.8269 - val_true_positives: 41338920.0000 - val_false_positives: 6183337.0000 - val_true_negatives: 54740844.0000 - val_false_negatives: 3708604.0000 - val_precision: 0.8699 - val_recall: 0.9177\n",
      "Epoch 59/500\n",
      "199/199 [==============================] - 74s 374ms/step - loss: 0.0452 - accuracy: 0.9634 - binary_iou: 0.9273 - true_positives: 125218720.0000 - false_positives: 5719782.0000 - true_negatives: 182622896.0000 - false_negatives: 5959422.0000 - precision: 0.9563 - recall: 0.9546 - val_loss: 0.1081 - val_accuracy: 0.9083 - val_binary_iou: 0.8295 - val_true_positives: 40997964.0000 - val_false_positives: 5605584.0000 - val_true_negatives: 55260952.0000 - val_false_negatives: 4107200.0000 - val_precision: 0.8797 - val_recall: 0.9089\n",
      "Epoch 60/500\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0447 - accuracy: 0.9639 - binary_iou: 0.9281 - true_positives: 125302328.0000 - false_positives: 5706902.0000 - true_negatives: 182681568.0000 - false_negatives: 5829934.0000 - precision: 0.9564 - recall: 0.9555 - val_loss: 0.1086 - val_accuracy: 0.9061 - val_binary_iou: 0.8262 - val_true_positives: 41582604.0000 - val_false_positives: 6432560.0000 - val_true_negatives: 54440996.0000 - val_false_negatives: 3515558.0000 - val_precision: 0.8660 - val_recall: 0.9220\n",
      "Epoch 61/500\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0444 - accuracy: 0.9642 - binary_iou: 0.9288 - true_positives: 125401352.0000 - false_positives: 5623130.0000 - true_negatives: 182683456.0000 - false_negatives: 5812745.0000 - precision: 0.9571 - recall: 0.9557 - val_loss: 0.1076 - val_accuracy: 0.9063 - val_binary_iou: 0.8266 - val_true_positives: 41687512.0000 - val_false_positives: 6413896.0000 - val_true_negatives: 54358464.0000 - val_false_negatives: 3511849.0000 - val_precision: 0.8667 - val_recall: 0.9223\n",
      "Epoch 62/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9645 - binary_iou: 0.9293 - true_positives: 125412112.0000 - false_positives: 5581734.0000 - true_negatives: 182763360.0000 - false_negatives: 5763558.0000 - precision: 0.9574 - recall: 0.9561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 444ms/step - loss: 0.0439 - accuracy: 0.9645 - binary_iou: 0.9293 - true_positives: 125412112.0000 - false_positives: 5581734.0000 - true_negatives: 182763360.0000 - false_negatives: 5763558.0000 - precision: 0.9574 - recall: 0.9561 - val_loss: 0.1041 - val_accuracy: 0.9116 - val_binary_iou: 0.8349 - val_true_positives: 40990592.0000 - val_false_positives: 5214776.0000 - val_true_negatives: 55613848.0000 - val_false_negatives: 4152491.0000 - val_precision: 0.8871 - val_recall: 0.9080\n",
      "Epoch 63/500\n",
      "199/199 [==============================] - 76s 379ms/step - loss: 0.0436 - accuracy: 0.9647 - binary_iou: 0.9298 - true_positives: 125395712.0000 - false_positives: 5555321.0000 - true_negatives: 182857008.0000 - false_negatives: 5712772.0000 - precision: 0.9576 - recall: 0.9564 - val_loss: 0.1047 - val_accuracy: 0.9102 - val_binary_iou: 0.8329 - val_true_positives: 41543160.0000 - val_false_positives: 5942691.0000 - val_true_negatives: 54909252.0000 - val_false_negatives: 3576612.0000 - val_precision: 0.8749 - val_recall: 0.9207\n",
      "Epoch 64/500\n",
      "199/199 [==============================] - 76s 379ms/step - loss: 0.0432 - accuracy: 0.9652 - binary_iou: 0.9307 - true_positives: 125417376.0000 - false_positives: 5471927.0000 - true_negatives: 182989856.0000 - false_negatives: 5641631.0000 - precision: 0.9582 - recall: 0.9570 - val_loss: 0.1049 - val_accuracy: 0.9095 - val_binary_iou: 0.8318 - val_true_positives: 41534372.0000 - val_false_positives: 5988759.0000 - val_true_negatives: 54850736.0000 - val_false_negatives: 3597841.0000 - val_precision: 0.8740 - val_recall: 0.9203\n",
      "Epoch 65/500\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.0424 - accuracy: 0.9659 - binary_iou: 0.9319 - true_positives: 125597424.0000 - false_positives: 5351283.0000 - true_negatives: 183014016.0000 - false_negatives: 5558061.0000 - precision: 0.9591 - recall: 0.9576 - val_loss: 0.1072 - val_accuracy: 0.9074 - val_binary_iou: 0.8281 - val_true_positives: 41319208.0000 - val_false_positives: 6099372.0000 - val_true_negatives: 54835660.0000 - val_false_negatives: 3717462.0000 - val_precision: 0.8714 - val_recall: 0.9175\n",
      "Epoch 66/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0425 - accuracy: 0.9658 - binary_iou: 0.9317 - true_positives: 125558464.0000 - false_positives: 5380410.0000 - true_negatives: 183020192.0000 - false_negatives: 5561696.0000 - precision: 0.9589 - recall: 0.9576 - val_loss: 0.1069 - val_accuracy: 0.9084 - val_binary_iou: 0.8297 - val_true_positives: 41097676.0000 - val_false_positives: 5756508.0000 - val_true_negatives: 55167096.0000 - val_false_negatives: 3950424.0000 - val_precision: 0.8771 - val_recall: 0.9123\n",
      "Epoch 67/500\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0421 - accuracy: 0.9660 - binary_iou: 0.9323 - true_positives: 125603832.0000 - false_positives: 5326552.0000 - true_negatives: 183066768.0000 - false_negatives: 5523626.0000 - precision: 0.9593 - recall: 0.9579 - val_loss: 0.1080 - val_accuracy: 0.9067 - val_binary_iou: 0.8272 - val_true_positives: 41502168.0000 - val_false_positives: 6359238.0000 - val_true_negatives: 54584880.0000 - val_false_negatives: 3525431.0000 - val_precision: 0.8671 - val_recall: 0.9217\n",
      "Epoch 68/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0415 - accuracy: 0.9665 - binary_iou: 0.9331 - true_positives: 125695280.0000 - false_positives: 5315564.0000 - true_negatives: 183114032.0000 - false_negatives: 5395918.0000 - precision: 0.9594 - recall: 0.9588 - val_loss: 0.1059 - val_accuracy: 0.9094 - val_binary_iou: 0.8314 - val_true_positives: 41194600.0000 - val_false_positives: 5623063.0000 - val_true_negatives: 55178732.0000 - val_false_negatives: 3975313.0000 - val_precision: 0.8799 - val_recall: 0.9120\n",
      "Epoch 69/500\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.0412 - accuracy: 0.9666 - binary_iou: 0.9334 - true_positives: 125716008.0000 - false_positives: 5247825.0000 - true_negatives: 183141184.0000 - false_negatives: 5415760.0000 - precision: 0.9599 - recall: 0.9587 - val_loss: 0.1068 - val_accuracy: 0.9076 - val_binary_iou: 0.8287 - val_true_positives: 41553492.0000 - val_false_positives: 6282379.0000 - val_true_negatives: 54628404.0000 - val_false_negatives: 3507447.0000 - val_precision: 0.8687 - val_recall: 0.9222\n",
      "Epoch 70/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0410 - accuracy: 0.9670 - binary_iou: 0.9340 - true_positives: 125786560.0000 - false_positives: 5176259.0000 - true_negatives: 183177168.0000 - false_negatives: 5380774.0000 - precision: 0.9605 - recall: 0.9590 - val_loss: 0.1077 - val_accuracy: 0.9068 - val_binary_iou: 0.8273 - val_true_positives: 41470272.0000 - val_false_positives: 6259233.0000 - val_true_negatives: 54629512.0000 - val_false_negatives: 3612710.0000 - val_precision: 0.8689 - val_recall: 0.9199\n",
      "Epoch 71/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0409 - accuracy: 0.9670 - binary_iou: 0.9341 - true_positives: 125765904.0000 - false_positives: 5207153.0000 - true_negatives: 183204592.0000 - false_negatives: 5343129.0000 - precision: 0.9602 - recall: 0.9592 - val_loss: 0.1065 - val_accuracy: 0.9085 - val_binary_iou: 0.8301 - val_true_positives: 41520256.0000 - val_false_positives: 6076881.0000 - val_true_negatives: 54754800.0000 - val_false_negatives: 3619776.0000 - val_precision: 0.8723 - val_recall: 0.9198\n",
      "Epoch 72/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9673 - binary_iou: 0.9348 - true_positives: 125934744.0000 - false_positives: 5186942.0000 - true_negatives: 183152336.0000 - false_negatives: 5246755.0000 - precision: 0.9604 - recall: 0.9600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0404 - accuracy: 0.9673 - binary_iou: 0.9348 - true_positives: 125934744.0000 - false_positives: 5186942.0000 - true_negatives: 183152336.0000 - false_negatives: 5246755.0000 - precision: 0.9604 - recall: 0.9600 - val_loss: 0.1033 - val_accuracy: 0.9124 - val_binary_iou: 0.8363 - val_true_positives: 41081652.0000 - val_false_positives: 5331349.0000 - val_true_negatives: 55605584.0000 - val_false_negatives: 3953113.0000 - val_precision: 0.8851 - val_recall: 0.9122\n",
      "Epoch 73/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0405 - accuracy: 0.9674 - binary_iou: 0.9348 - true_positives: 125901416.0000 - false_positives: 5144780.0000 - true_negatives: 183190800.0000 - false_negatives: 5283764.0000 - precision: 0.9607 - recall: 0.9597 - val_loss: 0.1058 - val_accuracy: 0.9090 - val_binary_iou: 0.8309 - val_true_positives: 41501748.0000 - val_false_positives: 6057415.0000 - val_true_negatives: 54823968.0000 - val_false_negatives: 3588561.0000 - val_precision: 0.8726 - val_recall: 0.9204\n",
      "Epoch 74/500\n",
      "199/199 [==============================] - 75s 378ms/step - loss: 0.0402 - accuracy: 0.9676 - binary_iou: 0.9352 - true_positives: 125931264.0000 - false_positives: 5119492.0000 - true_negatives: 183226784.0000 - false_negatives: 5243258.0000 - precision: 0.9609 - recall: 0.9600 - val_loss: 0.1043 - val_accuracy: 0.9100 - val_binary_iou: 0.8326 - val_true_positives: 41458928.0000 - val_false_positives: 5964031.0000 - val_true_negatives: 54975240.0000 - val_false_negatives: 3573506.0000 - val_precision: 0.8742 - val_recall: 0.9206\n",
      "Epoch 75/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0393 - accuracy: 0.9682 - binary_iou: 0.9364 - true_positives: 125958312.0000 - false_positives: 5022191.0000 - true_negatives: 183391376.0000 - false_negatives: 5148927.0000 - precision: 0.9617 - recall: 0.9607 - val_loss: 0.1043 - val_accuracy: 0.9105 - val_binary_iou: 0.8334 - val_true_positives: 41512344.0000 - val_false_positives: 5917994.0000 - val_true_negatives: 54969852.0000 - val_false_negatives: 3571529.0000 - val_precision: 0.8752 - val_recall: 0.9208\n",
      "Epoch 76/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0392 - accuracy: 0.9683 - binary_iou: 0.9366 - true_positives: 125964816.0000 - false_positives: 4985518.0000 - true_negatives: 183429056.0000 - false_negatives: 5141457.0000 - precision: 0.9619 - recall: 0.9608 - val_loss: 0.1037 - val_accuracy: 0.9121 - val_binary_iou: 0.8358 - val_true_positives: 41075088.0000 - val_false_positives: 5364364.0000 - val_true_negatives: 55580376.0000 - val_false_negatives: 3951883.0000 - val_precision: 0.8845 - val_recall: 0.9122\n",
      "Epoch 77/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0393 - accuracy: 0.9683 - binary_iou: 0.9367 - true_positives: 125993288.0000 - false_positives: 4980488.0000 - true_negatives: 183412368.0000 - false_negatives: 5134623.0000 - precision: 0.9620 - recall: 0.9608 - val_loss: 0.1037 - val_accuracy: 0.9103 - val_binary_iou: 0.8332 - val_true_positives: 41679664.0000 - val_false_positives: 6072287.0000 - val_true_negatives: 54786744.0000 - val_false_negatives: 3433005.0000 - val_precision: 0.8728 - val_recall: 0.9239\n",
      "Epoch 78/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0386 - accuracy: 0.9689 - binary_iou: 0.9377 - true_positives: 126103096.0000 - false_positives: 4880350.0000 - true_negatives: 183467840.0000 - false_negatives: 5069554.0000 - precision: 0.9627 - recall: 0.9614 - val_loss: 0.1052 - val_accuracy: 0.9089 - val_binary_iou: 0.8310 - val_true_positives: 41771936.0000 - val_false_positives: 6237061.0000 - val_true_negatives: 54548716.0000 - val_false_negatives: 3414001.0000 - val_precision: 0.8701 - val_recall: 0.9244\n",
      "Epoch 79/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0379 - accuracy: 0.9693 - binary_iou: 0.9387 - true_positives: 126121960.0000 - false_positives: 4900962.0000 - true_negatives: 183605376.0000 - false_negatives: 4892442.0000 - precision: 0.9626 - recall: 0.9627 - val_loss: 0.1048 - val_accuracy: 0.9097 - val_binary_iou: 0.8321 - val_true_positives: 41549416.0000 - val_false_positives: 5993168.0000 - val_true_negatives: 54852504.0000 - val_false_negatives: 3576628.0000 - val_precision: 0.8739 - val_recall: 0.9207\n",
      "Epoch 80/500\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0378 - accuracy: 0.9695 - binary_iou: 0.9389 - true_positives: 126182208.0000 - false_positives: 4799659.0000 - true_negatives: 183584816.0000 - false_negatives: 4954133.0000 - precision: 0.9634 - recall: 0.9622 - val_loss: 0.1043 - val_accuracy: 0.9109 - val_binary_iou: 0.8339 - val_true_positives: 41172584.0000 - val_false_positives: 5453862.0000 - val_true_negatives: 55359736.0000 - val_false_negatives: 3985533.0000 - val_precision: 0.8830 - val_recall: 0.9117\n",
      "Epoch 81/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0375 - accuracy: 0.9697 - binary_iou: 0.9393 - true_positives: 126310736.0000 - false_positives: 4810448.0000 - true_negatives: 183518000.0000 - false_negatives: 4881601.0000 - precision: 0.9633 - recall: 0.9628 - val_loss: 0.1044 - val_accuracy: 0.9097 - val_binary_iou: 0.8321 - val_true_positives: 41527200.0000 - val_false_positives: 5978914.0000 - val_true_negatives: 54872464.0000 - val_false_negatives: 3593121.0000 - val_precision: 0.8741 - val_recall: 0.9204\n",
      "Epoch 82/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0378 - accuracy: 0.9696 - binary_iou: 0.9391 - true_positives: 126281280.0000 - false_positives: 4796988.0000 - true_negatives: 183520928.0000 - false_negatives: 4921543.0000 - precision: 0.9634 - recall: 0.9625 - val_loss: 0.1058 - val_accuracy: 0.9090 - val_binary_iou: 0.8308 - val_true_positives: 41429080.0000 - val_false_positives: 5963414.0000 - val_true_negatives: 54896840.0000 - val_false_negatives: 3682373.0000 - val_precision: 0.8742 - val_recall: 0.9184\n",
      "Epoch 83/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0375 - accuracy: 0.9697 - binary_iou: 0.9393 - true_positives: 126181632.0000 - false_positives: 4766943.0000 - true_negatives: 183658624.0000 - false_negatives: 4913628.0000 - precision: 0.9636 - recall: 0.9625 - val_loss: 0.1040 - val_accuracy: 0.9103 - val_binary_iou: 0.8330 - val_true_positives: 41429056.0000 - val_false_positives: 5860020.0000 - val_true_negatives: 55036544.0000 - val_false_negatives: 3646094.0000 - val_precision: 0.8761 - val_recall: 0.9191\n",
      "Epoch 84/500\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0367 - accuracy: 0.9704 - binary_iou: 0.9407 - true_positives: 126377984.0000 - false_positives: 4673528.0000 - true_negatives: 183683792.0000 - false_negatives: 4785489.0000 - precision: 0.9643 - recall: 0.9635 - val_loss: 0.1071 - val_accuracy: 0.9078 - val_binary_iou: 0.8289 - val_true_positives: 41437388.0000 - val_false_positives: 6123517.0000 - val_true_negatives: 54766680.0000 - val_false_negatives: 3644137.0000 - val_precision: 0.8712 - val_recall: 0.9192\n",
      "Epoch 85/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0365 - accuracy: 0.9705 - binary_iou: 0.9409 - true_positives: 126327288.0000 - false_positives: 4664834.0000 - true_negatives: 183767152.0000 - false_negatives: 4761551.0000 - precision: 0.9644 - recall: 0.9637 - val_loss: 0.1035 - val_accuracy: 0.9106 - val_binary_iou: 0.8337 - val_true_positives: 41563608.0000 - val_false_positives: 5979124.0000 - val_true_negatives: 54937628.0000 - val_false_negatives: 3491363.0000 - val_precision: 0.8742 - val_recall: 0.9225\n",
      "Epoch 86/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0366 - accuracy: 0.9705 - binary_iou: 0.9409 - true_positives: 126435104.0000 - false_positives: 4721525.0000 - true_negatives: 183660064.0000 - false_negatives: 4704139.0000 - precision: 0.9640 - recall: 0.9641 - val_loss: 0.1065 - val_accuracy: 0.9074 - val_binary_iou: 0.8284 - val_true_positives: 41557396.0000 - val_false_positives: 6311928.0000 - val_true_negatives: 54605712.0000 - val_false_negatives: 3496694.0000 - val_precision: 0.8681 - val_recall: 0.9224\n",
      "Epoch 87/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0361 - accuracy: 0.9709 - binary_iou: 0.9416 - true_positives: 126376208.0000 - false_positives: 4581300.0000 - true_negatives: 183844048.0000 - false_negatives: 4719310.0000 - precision: 0.9650 - recall: 0.9640 - val_loss: 0.1045 - val_accuracy: 0.9105 - val_binary_iou: 0.8333 - val_true_positives: 41255212.0000 - val_false_positives: 5592069.0000 - val_true_negatives: 55236004.0000 - val_false_negatives: 3888439.0000 - val_precision: 0.8806 - val_recall: 0.9139\n",
      "Epoch 88/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0358 - accuracy: 0.9711 - binary_iou: 0.9420 - true_positives: 126510832.0000 - false_positives: 4583161.0000 - true_negatives: 183761600.0000 - false_negatives: 4665203.0000 - precision: 0.9650 - recall: 0.9644 - val_loss: 0.1076 - val_accuracy: 0.9063 - val_binary_iou: 0.8267 - val_true_positives: 41759288.0000 - val_false_positives: 6598459.0000 - val_true_negatives: 54287184.0000 - val_false_negatives: 3326791.0000 - val_precision: 0.8635 - val_recall: 0.9262\n",
      "Epoch 89/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0356 - accuracy: 0.9712 - binary_iou: 0.9423 - true_positives: 126490064.0000 - false_positives: 4568261.0000 - true_negatives: 183830400.0000 - false_negatives: 4632022.0000 - precision: 0.9651 - recall: 0.9647 - val_loss: 0.1050 - val_accuracy: 0.9082 - val_binary_iou: 0.8299 - val_true_positives: 41907228.0000 - val_false_positives: 6464519.0000 - val_true_negatives: 54336892.0000 - val_false_negatives: 3263079.0000 - val_precision: 0.8664 - val_recall: 0.9278\n",
      "Epoch 90/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0357 - accuracy: 0.9713 - binary_iou: 0.9424 - true_positives: 126413552.0000 - false_positives: 4506756.0000 - true_negatives: 183937536.0000 - false_negatives: 4662913.0000 - precision: 0.9656 - recall: 0.9644 - val_loss: 0.1047 - val_accuracy: 0.9098 - val_binary_iou: 0.8322 - val_true_positives: 41364052.0000 - val_false_positives: 5847442.0000 - val_true_negatives: 55051200.0000 - val_false_negatives: 3709027.0000 - val_precision: 0.8761 - val_recall: 0.9177\n",
      "Epoch 91/500\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0350 - accuracy: 0.9717 - binary_iou: 0.9432 - true_positives: 126599144.0000 - false_positives: 4511326.0000 - true_negatives: 183870416.0000 - false_negatives: 4539939.0000 - precision: 0.9656 - recall: 0.9654 - val_loss: 0.1033 - val_accuracy: 0.9120 - val_binary_iou: 0.8356 - val_true_positives: 41120136.0000 - val_false_positives: 5342837.0000 - val_true_negatives: 55524368.0000 - val_false_negatives: 3984349.0000 - val_precision: 0.8850 - val_recall: 0.9117\n",
      "Epoch 92/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0347 - accuracy: 0.9719 - binary_iou: 0.9437 - true_positives: 126579416.0000 - false_positives: 4423904.0000 - true_negatives: 183978176.0000 - false_negatives: 4539208.0000 - precision: 0.9662 - recall: 0.9654 - val_loss: 0.1055 - val_accuracy: 0.9090 - val_binary_iou: 0.8310 - val_true_positives: 41539848.0000 - val_false_positives: 6119937.0000 - val_true_negatives: 54790072.0000 - val_false_negatives: 3521855.0000 - val_precision: 0.8716 - val_recall: 0.9218\n",
      "Epoch 93/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0349 - accuracy: 0.9719 - binary_iou: 0.9436 - true_positives: 126555928.0000 - false_positives: 4490578.0000 - true_negatives: 183980432.0000 - false_negatives: 4493778.0000 - precision: 0.9657 - recall: 0.9657 - val_loss: 0.1053 - val_accuracy: 0.9097 - val_binary_iou: 0.8321 - val_true_positives: 41368392.0000 - val_false_positives: 5822870.0000 - val_true_negatives: 55036888.0000 - val_false_negatives: 3743554.0000 - val_precision: 0.8766 - val_recall: 0.9170\n",
      "Epoch 94/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9721 - binary_iou: 0.9439 - true_positives: 126726912.0000 - false_positives: 4441520.0000 - true_negatives: 183863808.0000 - false_negatives: 4488545.0000 - precision: 0.9661 - recall: 0.9658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 455ms/step - loss: 0.0345 - accuracy: 0.9721 - binary_iou: 0.9439 - true_positives: 126726912.0000 - false_positives: 4441520.0000 - true_negatives: 183863808.0000 - false_negatives: 4488545.0000 - precision: 0.9661 - recall: 0.9658 - val_loss: 0.1021 - val_accuracy: 0.9125 - val_binary_iou: 0.8367 - val_true_positives: 41501480.0000 - val_false_positives: 5688305.0000 - val_true_negatives: 55193332.0000 - val_false_negatives: 3588616.0000 - val_precision: 0.8795 - val_recall: 0.9204\n",
      "Epoch 95/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0346 - accuracy: 0.9721 - binary_iou: 0.9440 - true_positives: 126586688.0000 - false_positives: 4430150.0000 - true_negatives: 184013264.0000 - false_negatives: 4490698.0000 - precision: 0.9662 - recall: 0.9657 - val_loss: 0.1022 - val_accuracy: 0.9121 - val_binary_iou: 0.8360 - val_true_positives: 41437312.0000 - val_false_positives: 5694959.0000 - val_true_negatives: 55216344.0000 - val_false_negatives: 3623102.0000 - val_precision: 0.8792 - val_recall: 0.9196\n",
      "Epoch 96/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0349 - accuracy: 0.9718 - binary_iou: 0.9434 - true_positives: 126567528.0000 - false_positives: 4462385.0000 - true_negatives: 183945632.0000 - false_negatives: 4545169.0000 - precision: 0.9659 - recall: 0.9653 - val_loss: 0.1107 - val_accuracy: 0.9034 - val_binary_iou: 0.8218 - val_true_positives: 41685492.0000 - val_false_positives: 6833373.0000 - val_true_negatives: 54050928.0000 - val_false_negatives: 3401928.0000 - val_precision: 0.8592 - val_recall: 0.9245\n",
      "Epoch 97/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0339 - accuracy: 0.9726 - binary_iou: 0.9450 - true_positives: 126655368.0000 - false_positives: 4370648.0000 - true_negatives: 184111168.0000 - false_negatives: 4383608.0000 - precision: 0.9666 - recall: 0.9665 - val_loss: 0.1041 - val_accuracy: 0.9118 - val_binary_iou: 0.8353 - val_true_positives: 41156672.0000 - val_false_positives: 5431161.0000 - val_true_negatives: 55464784.0000 - val_false_negatives: 3919096.0000 - val_precision: 0.8834 - val_recall: 0.9131\n",
      "Epoch 98/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0339 - accuracy: 0.9726 - binary_iou: 0.9450 - true_positives: 126812952.0000 - false_positives: 4357777.0000 - true_negatives: 183958848.0000 - false_negatives: 4391178.0000 - precision: 0.9668 - recall: 0.9665 - val_loss: 0.1056 - val_accuracy: 0.9087 - val_binary_iou: 0.8306 - val_true_positives: 41558364.0000 - val_false_positives: 6173087.0000 - val_true_negatives: 54743060.0000 - val_false_negatives: 3497203.0000 - val_precision: 0.8707 - val_recall: 0.9224\n",
      "Epoch 99/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0334 - accuracy: 0.9729 - binary_iou: 0.9456 - true_positives: 126744088.0000 - false_positives: 4286621.0000 - true_negatives: 184117728.0000 - false_negatives: 4372303.0000 - precision: 0.9673 - recall: 0.9667 - val_loss: 0.1073 - val_accuracy: 0.9090 - val_binary_iou: 0.8308 - val_true_positives: 41293384.0000 - val_false_positives: 5945658.0000 - val_true_negatives: 55034324.0000 - val_false_negatives: 3698335.0000 - val_precision: 0.8741 - val_recall: 0.9178\n",
      "Epoch 100/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0332 - accuracy: 0.9732 - binary_iou: 0.9461 - true_positives: 126790672.0000 - false_positives: 4269153.0000 - true_negatives: 184152368.0000 - false_negatives: 4308574.0000 - precision: 0.9674 - recall: 0.9671 - val_loss: 0.1071 - val_accuracy: 0.9072 - val_binary_iou: 0.8280 - val_true_positives: 41568468.0000 - val_false_positives: 6290230.0000 - val_true_negatives: 54571340.0000 - val_false_negatives: 3541676.0000 - val_precision: 0.8686 - val_recall: 0.9215\n",
      "Epoch 101/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0333 - accuracy: 0.9731 - binary_iou: 0.9460 - true_positives: 126807328.0000 - false_positives: 4267194.0000 - true_negatives: 184121232.0000 - false_negatives: 4324945.0000 - precision: 0.9674 - recall: 0.9670 - val_loss: 0.1034 - val_accuracy: 0.9111 - val_binary_iou: 0.8344 - val_true_positives: 41474212.0000 - val_false_positives: 5788980.0000 - val_true_negatives: 55078084.0000 - val_false_negatives: 3630438.0000 - val_precision: 0.8775 - val_recall: 0.9195\n",
      "Epoch 102/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0334 - accuracy: 0.9730 - binary_iou: 0.9458 - true_positives: 126849584.0000 - false_positives: 4284648.0000 - true_negatives: 184050656.0000 - false_negatives: 4335807.0000 - precision: 0.9673 - recall: 0.9669 - val_loss: 0.1065 - val_accuracy: 0.9090 - val_binary_iou: 0.8310 - val_true_positives: 41429668.0000 - val_false_positives: 5948481.0000 - val_true_negatives: 54903200.0000 - val_false_negatives: 3690355.0000 - val_precision: 0.8744 - val_recall: 0.9182\n",
      "Epoch 103/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0327 - accuracy: 0.9735 - binary_iou: 0.9467 - true_positives: 126887040.0000 - false_positives: 4235165.0000 - true_negatives: 184158192.0000 - false_negatives: 4240374.0000 - precision: 0.9677 - recall: 0.9677 - val_loss: 0.1045 - val_accuracy: 0.9116 - val_binary_iou: 0.8349 - val_true_positives: 40846636.0000 - val_false_positives: 5035076.0000 - val_true_negatives: 55761868.0000 - val_false_negatives: 4328117.0000 - val_precision: 0.8903 - val_recall: 0.9042\n",
      "Epoch 104/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0327 - accuracy: 0.9735 - binary_iou: 0.9468 - true_positives: 126936128.0000 - false_positives: 4188499.0000 - true_negatives: 184131888.0000 - false_negatives: 4264212.0000 - precision: 0.9681 - recall: 0.9675 - val_loss: 0.1059 - val_accuracy: 0.9084 - val_binary_iou: 0.8301 - val_true_positives: 41583804.0000 - val_false_positives: 6161256.0000 - val_true_negatives: 54685292.0000 - val_false_negatives: 3541355.0000 - val_precision: 0.8710 - val_recall: 0.9215\n",
      "Epoch 105/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0317 - accuracy: 0.9743 - binary_iou: 0.9484 - true_positives: 127044960.0000 - false_positives: 4096464.0000 - true_negatives: 184274608.0000 - false_negatives: 4104682.0000 - precision: 0.9688 - recall: 0.9687 - val_loss: 0.1060 - val_accuracy: 0.9096 - val_binary_iou: 0.8317 - val_true_positives: 41211240.0000 - val_false_positives: 5645100.0000 - val_true_negatives: 55181056.0000 - val_false_negatives: 3934315.0000 - val_precision: 0.8795 - val_recall: 0.9129\n",
      "Epoch 106/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0322 - accuracy: 0.9740 - binary_iou: 0.9478 - true_positives: 126975096.0000 - false_positives: 4142673.0000 - true_negatives: 184244688.0000 - false_negatives: 4158388.0000 - precision: 0.9684 - recall: 0.9683 - val_loss: 0.1065 - val_accuracy: 0.9088 - val_binary_iou: 0.8305 - val_true_positives: 41510048.0000 - val_false_positives: 6109963.0000 - val_true_negatives: 54792684.0000 - val_false_negatives: 3559004.0000 - val_precision: 0.8717 - val_recall: 0.9210\n",
      "Epoch 107/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0319 - accuracy: 0.9743 - binary_iou: 0.9483 - true_positives: 126949136.0000 - false_positives: 4077252.0000 - true_negatives: 184363872.0000 - false_negatives: 4130524.0000 - precision: 0.9689 - recall: 0.9685 - val_loss: 0.1031 - val_accuracy: 0.9117 - val_binary_iou: 0.8356 - val_true_positives: 41685384.0000 - val_false_positives: 5880779.0000 - val_true_negatives: 54931952.0000 - val_false_negatives: 3473593.0000 - val_precision: 0.8764 - val_recall: 0.9231\n",
      "Epoch 108/500\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0318 - accuracy: 0.9743 - binary_iou: 0.9484 - true_positives: 127012416.0000 - false_positives: 4064859.0000 - true_negatives: 184308736.0000 - false_negatives: 4134734.0000 - precision: 0.9690 - recall: 0.9685 - val_loss: 0.1075 - val_accuracy: 0.9075 - val_binary_iou: 0.8283 - val_true_positives: 41339200.0000 - val_false_positives: 6075614.0000 - val_true_negatives: 54829212.0000 - val_false_negatives: 3727665.0000 - val_precision: 0.8719 - val_recall: 0.9173\n",
      "Epoch 109/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0314 - accuracy: 0.9745 - binary_iou: 0.9488 - true_positives: 127116184.0000 - false_positives: 4055692.0000 - true_negatives: 184269728.0000 - false_negatives: 4079173.0000 - precision: 0.9691 - recall: 0.9689 - val_loss: 0.1034 - val_accuracy: 0.9106 - val_binary_iou: 0.8337 - val_true_positives: 41610536.0000 - val_false_positives: 5941733.0000 - val_true_negatives: 54888820.0000 - val_false_negatives: 3530616.0000 - val_precision: 0.8750 - val_recall: 0.9218\n",
      "Epoch 110/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0318 - accuracy: 0.9743 - binary_iou: 0.9483 - true_positives: 127038624.0000 - false_positives: 4102557.0000 - true_negatives: 184272464.0000 - false_negatives: 4107154.0000 - precision: 0.9687 - recall: 0.9687 - val_loss: 0.1030 - val_accuracy: 0.9109 - val_binary_iou: 0.8342 - val_true_positives: 41671484.0000 - val_false_positives: 6016376.0000 - val_true_negatives: 54855824.0000 - val_false_negatives: 3428008.0000 - val_precision: 0.8738 - val_recall: 0.9240\n",
      "Epoch 111/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0315 - accuracy: 0.9745 - binary_iou: 0.9488 - true_positives: 127136448.0000 - false_positives: 4060762.0000 - true_negatives: 184249760.0000 - false_negatives: 4073715.0000 - precision: 0.9690 - recall: 0.9690 - val_loss: 0.1035 - val_accuracy: 0.9110 - val_binary_iou: 0.8342 - val_true_positives: 41304612.0000 - val_false_positives: 5741758.0000 - val_true_negatives: 55237852.0000 - val_false_negatives: 3687494.0000 - val_precision: 0.8780 - val_recall: 0.9180\n",
      "Epoch 112/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0311 - accuracy: 0.9749 - binary_iou: 0.9495 - true_positives: 127096648.0000 - false_positives: 3988045.0000 - true_negatives: 184399744.0000 - false_negatives: 4036298.0000 - precision: 0.9696 - recall: 0.9692 - val_loss: 0.1058 - val_accuracy: 0.9079 - val_binary_iou: 0.8293 - val_true_positives: 41892632.0000 - val_false_positives: 6553203.0000 - val_true_negatives: 54315828.0000 - val_false_negatives: 3210045.0000 - val_precision: 0.8647 - val_recall: 0.9288\n",
      "Epoch 113/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0309 - accuracy: 0.9750 - binary_iou: 0.9498 - true_positives: 127089480.0000 - false_positives: 3976812.0000 - true_negatives: 184459072.0000 - false_negatives: 3995383.0000 - precision: 0.9697 - recall: 0.9695 - val_loss: 0.1052 - val_accuracy: 0.9099 - val_binary_iou: 0.8324 - val_true_positives: 41467212.0000 - val_false_positives: 5920349.0000 - val_true_negatives: 54957732.0000 - val_false_negatives: 3626428.0000 - val_precision: 0.8751 - val_recall: 0.9196\n",
      "Epoch 114/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0309 - accuracy: 0.9750 - binary_iou: 0.9497 - true_positives: 127125168.0000 - false_positives: 3982420.0000 - true_negatives: 184409744.0000 - false_negatives: 4003455.0000 - precision: 0.9696 - recall: 0.9695 - val_loss: 0.1043 - val_accuracy: 0.9103 - val_binary_iou: 0.8332 - val_true_positives: 41549280.0000 - val_false_positives: 5966026.0000 - val_true_negatives: 54921160.0000 - val_false_negatives: 3535246.0000 - val_precision: 0.8744 - val_recall: 0.9216\n",
      "Epoch 115/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0309 - accuracy: 0.9750 - binary_iou: 0.9497 - true_positives: 127104848.0000 - false_positives: 3962090.0000 - true_negatives: 184429280.0000 - false_negatives: 4024508.0000 - precision: 0.9698 - recall: 0.9693 - val_loss: 0.1065 - val_accuracy: 0.9083 - val_binary_iou: 0.8298 - val_true_positives: 41548896.0000 - val_false_positives: 6191114.0000 - val_true_negatives: 54705752.0000 - val_false_negatives: 3525958.0000 - val_precision: 0.8703 - val_recall: 0.9218\n",
      "Epoch 116/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0306 - accuracy: 0.9752 - binary_iou: 0.9501 - true_positives: 127169728.0000 - false_positives: 3943604.0000 - true_negatives: 184439056.0000 - false_negatives: 3968253.0000 - precision: 0.9699 - recall: 0.9697 - val_loss: 0.1061 - val_accuracy: 0.9085 - val_binary_iou: 0.8302 - val_true_positives: 41618708.0000 - val_false_positives: 6284048.0000 - val_true_negatives: 54654612.0000 - val_false_negatives: 3414341.0000 - val_precision: 0.8688 - val_recall: 0.9242\n",
      "Epoch 117/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0307 - accuracy: 0.9752 - binary_iou: 0.9501 - true_positives: 127189696.0000 - false_positives: 3920819.0000 - true_negatives: 184408160.0000 - false_negatives: 4002052.0000 - precision: 0.9701 - recall: 0.9695 - val_loss: 0.1077 - val_accuracy: 0.9067 - val_binary_iou: 0.8273 - val_true_positives: 41856512.0000 - val_false_positives: 6576026.0000 - val_true_negatives: 54226152.0000 - val_false_negatives: 3313026.0000 - val_precision: 0.8642 - val_recall: 0.9267\n",
      "Epoch 118/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0304 - accuracy: 0.9754 - binary_iou: 0.9506 - true_positives: 127190304.0000 - false_positives: 3930900.0000 - true_negatives: 184485472.0000 - false_negatives: 3914083.0000 - precision: 0.9700 - recall: 0.9701 - val_loss: 0.1046 - val_accuracy: 0.9097 - val_binary_iou: 0.8320 - val_true_positives: 41508284.0000 - val_false_positives: 5942169.0000 - val_true_negatives: 54889316.0000 - val_false_negatives: 3631940.0000 - val_precision: 0.8748 - val_recall: 0.9195\n",
      "Epoch 119/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0298 - accuracy: 0.9759 - binary_iou: 0.9515 - true_positives: 127273016.0000 - false_positives: 3840036.0000 - true_negatives: 184547840.0000 - false_negatives: 3859860.0000 - precision: 0.9707 - recall: 0.9706 - val_loss: 0.1039 - val_accuracy: 0.9111 - val_binary_iou: 0.8344 - val_true_positives: 41366376.0000 - val_false_positives: 5687819.0000 - val_true_negatives: 55188916.0000 - val_false_negatives: 3728589.0000 - val_precision: 0.8791 - val_recall: 0.9173\n",
      "Epoch 120/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0297 - accuracy: 0.9759 - binary_iou: 0.9515 - true_positives: 127261360.0000 - false_positives: 3851654.0000 - true_negatives: 184568400.0000 - false_negatives: 3839303.0000 - precision: 0.9706 - recall: 0.9707 - val_loss: 0.1030 - val_accuracy: 0.9121 - val_binary_iou: 0.8359 - val_true_positives: 41287084.0000 - val_false_positives: 5463565.0000 - val_true_negatives: 55367844.0000 - val_false_negatives: 3853218.0000 - val_precision: 0.8831 - val_recall: 0.9146\n",
      "Epoch 121/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0295 - accuracy: 0.9762 - binary_iou: 0.9519 - true_positives: 127284376.0000 - false_positives: 3777763.0000 - true_negatives: 184616224.0000 - false_negatives: 3842431.0000 - precision: 0.9712 - recall: 0.9707 - val_loss: 0.1033 - val_accuracy: 0.9116 - val_binary_iou: 0.8351 - val_true_positives: 41303840.0000 - val_false_positives: 5578388.0000 - val_true_negatives: 55298960.0000 - val_false_negatives: 3790513.0000 - val_precision: 0.8810 - val_recall: 0.9159\n",
      "Epoch 122/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9764 - binary_iou: 0.9525 - true_positives: 127334976.0000 - false_positives: 3744993.0000 - true_negatives: 184655920.0000 - false_negatives: 3784887.0000 - precision: 0.9714 - recall: 0.9711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0292 - accuracy: 0.9764 - binary_iou: 0.9525 - true_positives: 127334976.0000 - false_positives: 3744993.0000 - true_negatives: 184655920.0000 - false_negatives: 3784887.0000 - precision: 0.9714 - recall: 0.9711 - val_loss: 0.1027 - val_accuracy: 0.9131 - val_binary_iou: 0.8376 - val_true_positives: 41328432.0000 - val_false_positives: 5500009.0000 - val_true_negatives: 55432808.0000 - val_false_negatives: 3710454.0000 - val_precision: 0.8825 - val_recall: 0.9176\n",
      "Epoch 123/500\n",
      "199/199 [==============================] - 77s 383ms/step - loss: 0.0293 - accuracy: 0.9763 - binary_iou: 0.9523 - true_positives: 127346800.0000 - false_positives: 3781083.0000 - true_negatives: 184610320.0000 - false_negatives: 3782547.0000 - precision: 0.9712 - recall: 0.9712 - val_loss: 0.1031 - val_accuracy: 0.9116 - val_binary_iou: 0.8353 - val_true_positives: 41547616.0000 - val_false_positives: 5799042.0000 - val_true_negatives: 55056240.0000 - val_false_negatives: 3568806.0000 - val_precision: 0.8775 - val_recall: 0.9209\n",
      "Epoch 124/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0290 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127323616.0000 - false_positives: 3734150.0000 - true_negatives: 184723296.0000 - false_negatives: 3739694.0000 - precision: 0.9715 - recall: 0.9715 - val_loss: 0.1042 - val_accuracy: 0.9099 - val_binary_iou: 0.8325 - val_true_positives: 41561664.0000 - val_false_positives: 6039500.0000 - val_true_negatives: 54865280.0000 - val_false_negatives: 3505274.0000 - val_precision: 0.8731 - val_recall: 0.9222\n",
      "Epoch 125/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0294 - accuracy: 0.9762 - binary_iou: 0.9521 - true_positives: 127287552.0000 - false_positives: 3798898.0000 - true_negatives: 184637696.0000 - false_negatives: 3796625.0000 - precision: 0.9710 - recall: 0.9710 - val_loss: 0.1026 - val_accuracy: 0.9124 - val_binary_iou: 0.8365 - val_true_positives: 41261472.0000 - val_false_positives: 5460794.0000 - val_true_negatives: 55430808.0000 - val_false_negatives: 3818639.0000 - val_precision: 0.8831 - val_recall: 0.9153\n",
      "Epoch 126/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0291 - accuracy: 0.9765 - binary_iou: 0.9526 - true_positives: 127336984.0000 - false_positives: 3762403.0000 - true_negatives: 184671168.0000 - false_negatives: 3750250.0000 - precision: 0.9713 - recall: 0.9714 - val_loss: 0.1036 - val_accuracy: 0.9109 - val_binary_iou: 0.8342 - val_true_positives: 41505540.0000 - val_false_positives: 5832101.0000 - val_true_negatives: 55028840.0000 - val_false_negatives: 3605230.0000 - val_precision: 0.8768 - val_recall: 0.9201\n",
      "Epoch 127/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0289 - accuracy: 0.9767 - binary_iou: 0.9529 - true_positives: 127362176.0000 - false_positives: 3687196.0000 - true_negatives: 184701040.0000 - false_negatives: 3770367.0000 - precision: 0.9719 - recall: 0.9712 - val_loss: 0.1041 - val_accuracy: 0.9100 - val_binary_iou: 0.8326 - val_true_positives: 41681392.0000 - val_false_positives: 6091824.0000 - val_true_negatives: 54748276.0000 - val_false_negatives: 3450201.0000 - val_precision: 0.8725 - val_recall: 0.9236\n",
      "Epoch 128/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0287 - accuracy: 0.9768 - binary_iou: 0.9532 - true_positives: 127442032.0000 - false_positives: 3727298.0000 - true_negatives: 184664736.0000 - false_negatives: 3686727.0000 - precision: 0.9716 - recall: 0.9719 - val_loss: 0.1074 - val_accuracy: 0.9065 - val_binary_iou: 0.8270 - val_true_positives: 41801684.0000 - val_false_positives: 6586438.0000 - val_true_negatives: 54265328.0000 - val_false_negatives: 3318267.0000 - val_precision: 0.8639 - val_recall: 0.9265\n",
      "Epoch 129/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0285 - accuracy: 0.9770 - binary_iou: 0.9537 - true_positives: 127497640.0000 - false_positives: 3669848.0000 - true_negatives: 184683232.0000 - false_negatives: 3670016.0000 - precision: 0.9720 - recall: 0.9720 - val_loss: 0.1057 - val_accuracy: 0.9090 - val_binary_iou: 0.8309 - val_true_positives: 41561240.0000 - val_false_positives: 6140225.0000 - val_true_negatives: 54762500.0000 - val_false_negatives: 3507740.0000 - val_precision: 0.8713 - val_recall: 0.9222\n",
      "Epoch 130/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0282 - accuracy: 0.9772 - binary_iou: 0.9540 - true_positives: 127475216.0000 - false_positives: 3617340.0000 - true_negatives: 184755744.0000 - false_negatives: 3672418.0000 - precision: 0.9724 - recall: 0.9720 - val_loss: 0.1041 - val_accuracy: 0.9099 - val_binary_iou: 0.8324 - val_true_positives: 41404944.0000 - val_false_positives: 5898103.0000 - val_true_negatives: 55021124.0000 - val_false_negatives: 3647552.0000 - val_precision: 0.8753 - val_recall: 0.9190\n",
      "Epoch 131/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0284 - accuracy: 0.9770 - binary_iou: 0.9536 - true_positives: 127424712.0000 - false_positives: 3652478.0000 - true_negatives: 184753744.0000 - false_negatives: 3689911.0000 - precision: 0.9721 - recall: 0.9719 - val_loss: 0.1025 - val_accuracy: 0.9125 - val_binary_iou: 0.8367 - val_true_positives: 41460468.0000 - val_false_positives: 5588820.0000 - val_true_negatives: 55236944.0000 - val_false_negatives: 3685462.0000 - val_precision: 0.8812 - val_recall: 0.9184\n",
      "Epoch 132/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0280 - accuracy: 0.9773 - binary_iou: 0.9542 - true_positives: 127489376.0000 - false_positives: 3628683.0000 - true_negatives: 184772608.0000 - false_negatives: 3630054.0000 - precision: 0.9723 - recall: 0.9723 - val_loss: 0.1023 - val_accuracy: 0.9128 - val_binary_iou: 0.8373 - val_true_positives: 41463072.0000 - val_false_positives: 5540619.0000 - val_true_negatives: 55271904.0000 - val_false_negatives: 3696110.0000 - val_precision: 0.8821 - val_recall: 0.9182\n",
      "Epoch 133/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0279 - accuracy: 0.9774 - binary_iou: 0.9544 - true_positives: 127432984.0000 - false_positives: 3614373.0000 - true_negatives: 184865200.0000 - false_negatives: 3608207.0000 - precision: 0.9724 - recall: 0.9725 - val_loss: 0.1021 - val_accuracy: 0.9127 - val_binary_iou: 0.8368 - val_true_positives: 41139040.0000 - val_false_positives: 5264332.0000 - val_true_negatives: 55577480.0000 - val_false_negatives: 3990860.0000 - val_precision: 0.8866 - val_recall: 0.9116\n",
      "Epoch 134/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0276 - accuracy: 0.9776 - binary_iou: 0.9548 - true_positives: 127579952.0000 - false_positives: 3586845.0000 - true_negatives: 184786656.0000 - false_negatives: 3567334.0000 - precision: 0.9727 - recall: 0.9728 - val_loss: 0.1036 - val_accuracy: 0.9114 - val_binary_iou: 0.8349 - val_true_positives: 41359628.0000 - val_false_positives: 5663032.0000 - val_true_negatives: 55224452.0000 - val_false_negatives: 3724611.0000 - val_precision: 0.8796 - val_recall: 0.9174\n",
      "Epoch 135/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9550 - true_positives: 127485624.0000 - false_positives: 3530118.0000 - true_negatives: 184920000.0000 - false_negatives: 3585019.0000 - precision: 0.9731 - recall: 0.9726 - val_loss: 0.1025 - val_accuracy: 0.9118 - val_binary_iou: 0.8356 - val_true_positives: 41490332.0000 - val_false_positives: 5710156.0000 - val_true_negatives: 55135728.0000 - val_false_negatives: 3635490.0000 - val_precision: 0.8790 - val_recall: 0.9194\n",
      "Epoch 136/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9550 - true_positives: 127575192.0000 - false_positives: 3558876.0000 - true_negatives: 184821360.0000 - false_negatives: 3565218.0000 - precision: 0.9729 - recall: 0.9728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 454ms/step - loss: 0.0276 - accuracy: 0.9777 - binary_iou: 0.9550 - true_positives: 127575192.0000 - false_positives: 3558876.0000 - true_negatives: 184821360.0000 - false_negatives: 3565218.0000 - precision: 0.9729 - recall: 0.9728 - val_loss: 0.1012 - val_accuracy: 0.9144 - val_binary_iou: 0.8396 - val_true_positives: 40980824.0000 - val_false_positives: 4910239.0000 - val_true_negatives: 55918768.0000 - val_false_negatives: 4161878.0000 - val_precision: 0.8930 - val_recall: 0.9078\n",
      "Epoch 137/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0275 - accuracy: 0.9778 - binary_iou: 0.9551 - true_positives: 127654360.0000 - false_positives: 3563195.0000 - true_negatives: 184759872.0000 - false_negatives: 3543320.0000 - precision: 0.9728 - recall: 0.9730 - val_loss: 0.1033 - val_accuracy: 0.9113 - val_binary_iou: 0.8347 - val_true_positives: 41497392.0000 - val_false_positives: 5781140.0000 - val_true_negatives: 55070744.0000 - val_false_negatives: 3622406.0000 - val_precision: 0.8777 - val_recall: 0.9197\n",
      "Epoch 138/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0271 - accuracy: 0.9781 - binary_iou: 0.9557 - true_positives: 127628872.0000 - false_positives: 3498730.0000 - true_negatives: 184883040.0000 - false_negatives: 3510187.0000 - precision: 0.9733 - recall: 0.9732 - val_loss: 0.1034 - val_accuracy: 0.9110 - val_binary_iou: 0.8343 - val_true_positives: 41506780.0000 - val_false_positives: 5796357.0000 - val_true_negatives: 55036712.0000 - val_false_negatives: 3631860.0000 - val_precision: 0.8775 - val_recall: 0.9195\n",
      "Epoch 139/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0273 - accuracy: 0.9779 - binary_iou: 0.9553 - true_positives: 127570104.0000 - false_positives: 3536287.0000 - true_negatives: 184874192.0000 - false_negatives: 3540174.0000 - precision: 0.9730 - recall: 0.9730 - val_loss: 0.1022 - val_accuracy: 0.9123 - val_binary_iou: 0.8365 - val_true_positives: 41511400.0000 - val_false_positives: 5582250.0000 - val_true_negatives: 55170736.0000 - val_false_negatives: 3707324.0000 - val_precision: 0.8815 - val_recall: 0.9180\n",
      "Epoch 140/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0270 - accuracy: 0.9781 - binary_iou: 0.9557 - true_positives: 127600264.0000 - false_positives: 3509353.0000 - true_negatives: 184914240.0000 - false_negatives: 3496920.0000 - precision: 0.9732 - recall: 0.9733 - val_loss: 0.1034 - val_accuracy: 0.9106 - val_binary_iou: 0.8337 - val_true_positives: 41678288.0000 - val_false_positives: 6065841.0000 - val_true_negatives: 54815928.0000 - val_false_negatives: 3411645.0000 - val_precision: 0.8730 - val_recall: 0.9243\n",
      "Epoch 141/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0273 - accuracy: 0.9780 - binary_iou: 0.9555 - true_positives: 127541568.0000 - false_positives: 3492286.0000 - true_negatives: 184945584.0000 - false_negatives: 3541335.0000 - precision: 0.9733 - recall: 0.9730 - val_loss: 0.1029 - val_accuracy: 0.9122 - val_binary_iou: 0.8364 - val_true_positives: 41592552.0000 - val_false_positives: 5738170.0000 - val_true_negatives: 55079584.0000 - val_false_negatives: 3561402.0000 - val_precision: 0.8788 - val_recall: 0.9211\n",
      "Epoch 142/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0269 - accuracy: 0.9782 - binary_iou: 0.9560 - true_positives: 127695824.0000 - false_positives: 3499051.0000 - true_negatives: 184858880.0000 - false_negatives: 3466921.0000 - precision: 0.9733 - recall: 0.9736 - val_loss: 0.1022 - val_accuracy: 0.9128 - val_binary_iou: 0.8371 - val_true_positives: 41320872.0000 - val_false_positives: 5455991.0000 - val_true_negatives: 55407016.0000 - val_false_negatives: 3787827.0000 - val_precision: 0.8834 - val_recall: 0.9160\n",
      "Epoch 143/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0272 - accuracy: 0.9780 - binary_iou: 0.9556 - true_positives: 127689240.0000 - false_positives: 3500439.0000 - true_negatives: 184809264.0000 - false_negatives: 3521866.0000 - precision: 0.9733 - recall: 0.9732 - val_loss: 0.1067 - val_accuracy: 0.9075 - val_binary_iou: 0.8284 - val_true_positives: 41532960.0000 - val_false_positives: 6241029.0000 - val_true_negatives: 54633452.0000 - val_false_negatives: 3564264.0000 - val_precision: 0.8694 - val_recall: 0.9210\n",
      "Epoch 144/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0270 - accuracy: 0.9783 - binary_iou: 0.9561 - true_positives: 127606464.0000 - false_positives: 3467543.0000 - true_negatives: 184974224.0000 - false_negatives: 3472451.0000 - precision: 0.9735 - recall: 0.9735 - val_loss: 0.1061 - val_accuracy: 0.9087 - val_binary_iou: 0.8306 - val_true_positives: 41663320.0000 - val_false_positives: 6253793.0000 - val_true_negatives: 54633768.0000 - val_false_negatives: 3420822.0000 - val_precision: 0.8695 - val_recall: 0.9241\n",
      "Epoch 145/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0264 - accuracy: 0.9786 - binary_iou: 0.9567 - true_positives: 127721568.0000 - false_positives: 3421260.0000 - true_negatives: 184957408.0000 - false_negatives: 3420513.0000 - precision: 0.9739 - recall: 0.9739 - val_loss: 0.1049 - val_accuracy: 0.9098 - val_binary_iou: 0.8322 - val_true_positives: 41348288.0000 - val_false_positives: 5845752.0000 - val_true_negatives: 55067424.0000 - val_false_negatives: 3710255.0000 - val_precision: 0.8761 - val_recall: 0.9177\n",
      "Epoch 146/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0263 - accuracy: 0.9788 - binary_iou: 0.9572 - true_positives: 127714680.0000 - false_positives: 3406853.0000 - true_negatives: 185037888.0000 - false_negatives: 3361324.0000 - precision: 0.9740 - recall: 0.9744 - val_loss: 0.1021 - val_accuracy: 0.9124 - val_binary_iou: 0.8367 - val_true_positives: 41510040.0000 - val_false_positives: 5603334.0000 - val_true_negatives: 55181240.0000 - val_false_negatives: 3677109.0000 - val_precision: 0.8811 - val_recall: 0.9186\n",
      "Epoch 147/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0260 - accuracy: 0.9789 - binary_iou: 0.9573 - true_positives: 127780576.0000 - false_positives: 3394300.0000 - true_negatives: 184992048.0000 - false_negatives: 3353802.0000 - precision: 0.9741 - recall: 0.9744 - val_loss: 0.1034 - val_accuracy: 0.9107 - val_binary_iou: 0.8338 - val_true_positives: 41563232.0000 - val_false_positives: 5824478.0000 - val_true_negatives: 54947716.0000 - val_false_negatives: 3636284.0000 - val_precision: 0.8771 - val_recall: 0.9196\n",
      "Epoch 148/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0258 - accuracy: 0.9791 - binary_iou: 0.9577 - true_positives: 127799456.0000 - false_positives: 3322590.0000 - true_negatives: 185034112.0000 - false_negatives: 3364652.0000 - precision: 0.9747 - recall: 0.9743 - val_loss: 0.1022 - val_accuracy: 0.9126 - val_binary_iou: 0.8367 - val_true_positives: 41272416.0000 - val_false_positives: 5464201.0000 - val_true_negatives: 55434912.0000 - val_false_negatives: 3800184.0000 - val_precision: 0.8831 - val_recall: 0.9157\n",
      "Epoch 149/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0260 - accuracy: 0.9790 - binary_iou: 0.9576 - true_positives: 127817248.0000 - false_positives: 3377873.0000 - true_negatives: 184999248.0000 - false_negatives: 3326385.0000 - precision: 0.9743 - recall: 0.9746 - val_loss: 0.1030 - val_accuracy: 0.9113 - val_binary_iou: 0.8347 - val_true_positives: 41413260.0000 - val_false_positives: 5702153.0000 - val_true_negatives: 55159012.0000 - val_false_negatives: 3697286.0000 - val_precision: 0.8790 - val_recall: 0.9180\n",
      "Epoch 150/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0261 - accuracy: 0.9789 - binary_iou: 0.9573 - true_positives: 127754680.0000 - false_positives: 3363988.0000 - true_negatives: 185018560.0000 - false_negatives: 3383559.0000 - precision: 0.9743 - recall: 0.9742 - val_loss: 0.1022 - val_accuracy: 0.9126 - val_binary_iou: 0.8369 - val_true_positives: 41365100.0000 - val_false_positives: 5478238.0000 - val_true_negatives: 55346592.0000 - val_false_negatives: 3781788.0000 - val_precision: 0.8831 - val_recall: 0.9162\n",
      "Epoch 151/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9791 - binary_iou: 0.9578 - true_positives: 127743048.0000 - false_positives: 3334157.0000 - true_negatives: 185103264.0000 - false_negatives: 3340365.0000 - precision: 0.9746 - recall: 0.9745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0258 - accuracy: 0.9791 - binary_iou: 0.9578 - true_positives: 127743048.0000 - false_positives: 3334157.0000 - true_negatives: 185103264.0000 - false_negatives: 3340365.0000 - precision: 0.9746 - recall: 0.9745 - val_loss: 0.0997 - val_accuracy: 0.9142 - val_binary_iou: 0.8398 - val_true_positives: 41673444.0000 - val_false_positives: 5686378.0000 - val_true_negatives: 55207512.0000 - val_false_negatives: 3404385.0000 - val_precision: 0.8799 - val_recall: 0.9245\n",
      "Epoch 152/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0257 - accuracy: 0.9793 - binary_iou: 0.9581 - true_positives: 127789592.0000 - false_positives: 3310976.0000 - true_negatives: 185106864.0000 - false_negatives: 3313237.0000 - precision: 0.9747 - recall: 0.9747 - val_loss: 0.1027 - val_accuracy: 0.9117 - val_binary_iou: 0.8353 - val_true_positives: 41363684.0000 - val_false_positives: 5637099.0000 - val_true_negatives: 55251216.0000 - val_false_negatives: 3719708.0000 - val_precision: 0.8801 - val_recall: 0.9175\n",
      "Epoch 153/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0256 - accuracy: 0.9794 - binary_iou: 0.9583 - true_positives: 127823552.0000 - false_positives: 3296209.0000 - true_negatives: 185111328.0000 - false_negatives: 3289682.0000 - precision: 0.9749 - recall: 0.9749 - val_loss: 0.1027 - val_accuracy: 0.9120 - val_binary_iou: 0.8359 - val_true_positives: 41427472.0000 - val_false_positives: 5625258.0000 - val_true_negatives: 55220464.0000 - val_false_negatives: 3698520.0000 - val_precision: 0.8804 - val_recall: 0.9180\n",
      "Epoch 154/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0254 - accuracy: 0.9794 - binary_iou: 0.9584 - true_positives: 127865976.0000 - false_positives: 3279614.0000 - true_negatives: 185078352.0000 - false_negatives: 3296843.0000 - precision: 0.9750 - recall: 0.9749 - val_loss: 0.1040 - val_accuracy: 0.9102 - val_binary_iou: 0.8331 - val_true_positives: 41651868.0000 - val_false_positives: 6068614.0000 - val_true_negatives: 54808140.0000 - val_false_negatives: 3443091.0000 - val_precision: 0.8728 - val_recall: 0.9236\n",
      "Epoch 155/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0255 - accuracy: 0.9795 - binary_iou: 0.9585 - true_positives: 127837944.0000 - false_positives: 3265543.0000 - true_negatives: 185128320.0000 - false_negatives: 3288965.0000 - precision: 0.9751 - recall: 0.9749 - val_loss: 0.1036 - val_accuracy: 0.9107 - val_binary_iou: 0.8336 - val_true_positives: 41350060.0000 - val_false_positives: 5758067.0000 - val_true_negatives: 55156056.0000 - val_false_negatives: 3707521.0000 - val_precision: 0.8778 - val_recall: 0.9177\n",
      "Epoch 156/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0254 - accuracy: 0.9795 - binary_iou: 0.9585 - true_positives: 127870352.0000 - false_positives: 3289567.0000 - true_negatives: 185088128.0000 - false_negatives: 3272660.0000 - precision: 0.9749 - recall: 0.9750 - val_loss: 0.1047 - val_accuracy: 0.9091 - val_binary_iou: 0.8312 - val_true_positives: 41657768.0000 - val_false_positives: 6089736.0000 - val_true_negatives: 54680800.0000 - val_false_negatives: 3543404.0000 - val_precision: 0.8725 - val_recall: 0.9216\n",
      "Epoch 157/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0252 - accuracy: 0.9796 - binary_iou: 0.9588 - true_positives: 127881176.0000 - false_positives: 3269889.0000 - true_negatives: 185122976.0000 - false_negatives: 3246726.0000 - precision: 0.9751 - recall: 0.9752 - val_loss: 0.1044 - val_accuracy: 0.9104 - val_binary_iou: 0.8332 - val_true_positives: 41299592.0000 - val_false_positives: 5728804.0000 - val_true_negatives: 55180456.0000 - val_false_negatives: 3762857.0000 - val_precision: 0.8782 - val_recall: 0.9165\n",
      "Epoch 158/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0252 - accuracy: 0.9796 - binary_iou: 0.9588 - true_positives: 127878680.0000 - false_positives: 3240788.0000 - true_negatives: 185136304.0000 - false_negatives: 3264968.0000 - precision: 0.9753 - recall: 0.9751 - val_loss: 0.1061 - val_accuracy: 0.9090 - val_binary_iou: 0.8309 - val_true_positives: 41378176.0000 - val_false_positives: 5947070.0000 - val_true_negatives: 54951848.0000 - val_false_negatives: 3694624.0000 - val_precision: 0.8743 - val_recall: 0.9180\n",
      "Epoch 159/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0252 - accuracy: 0.9796 - binary_iou: 0.9587 - true_positives: 127915632.0000 - false_positives: 3265405.0000 - true_negatives: 185084592.0000 - false_negatives: 3255109.0000 - precision: 0.9751 - recall: 0.9752 - val_loss: 0.1060 - val_accuracy: 0.9080 - val_binary_iou: 0.8295 - val_true_positives: 41784596.0000 - val_false_positives: 6423645.0000 - val_true_negatives: 54440076.0000 - val_false_negatives: 3323394.0000 - val_precision: 0.8668 - val_recall: 0.9263\n",
      "Epoch 160/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0249 - accuracy: 0.9799 - binary_iou: 0.9592 - true_positives: 127921832.0000 - false_positives: 3213564.0000 - true_negatives: 185161280.0000 - false_negatives: 3224138.0000 - precision: 0.9755 - recall: 0.9754 - val_loss: 0.1033 - val_accuracy: 0.9118 - val_binary_iou: 0.8354 - val_true_positives: 41258504.0000 - val_false_positives: 5500114.0000 - val_true_negatives: 55362600.0000 - val_false_negatives: 3850487.0000 - val_precision: 0.8824 - val_recall: 0.9146\n",
      "Epoch 161/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0245 - accuracy: 0.9802 - binary_iou: 0.9599 - true_positives: 127974048.0000 - false_positives: 3150404.0000 - true_negatives: 185212720.0000 - false_negatives: 3183546.0000 - precision: 0.9760 - recall: 0.9757 - val_loss: 0.1016 - val_accuracy: 0.9135 - val_binary_iou: 0.8382 - val_true_positives: 41281228.0000 - val_false_positives: 5452141.0000 - val_true_negatives: 55520632.0000 - val_false_negatives: 3717705.0000 - val_precision: 0.8833 - val_recall: 0.9174\n",
      "Epoch 162/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0246 - accuracy: 0.9801 - binary_iou: 0.9597 - true_positives: 128014744.0000 - false_positives: 3173421.0000 - true_negatives: 185146688.0000 - false_negatives: 3185968.0000 - precision: 0.9758 - recall: 0.9757 - val_loss: 0.1029 - val_accuracy: 0.9117 - val_binary_iou: 0.8354 - val_true_positives: 41509068.0000 - val_false_positives: 5790725.0000 - val_true_negatives: 55102240.0000 - val_false_negatives: 3569693.0000 - val_precision: 0.8776 - val_recall: 0.9208\n",
      "Epoch 163/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9601 - true_positives: 128087272.0000 - false_positives: 3152159.0000 - true_negatives: 185129312.0000 - false_negatives: 3151936.0000 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.1023 - val_accuracy: 0.9124 - val_binary_iou: 0.8366 - val_true_positives: 41528364.0000 - val_false_positives: 5689374.0000 - val_true_negatives: 55158960.0000 - val_false_negatives: 3595018.0000 - val_precision: 0.8795 - val_recall: 0.9203\n",
      "Epoch 164/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9601 - true_positives: 127980192.0000 - false_positives: 3139638.0000 - true_negatives: 185248896.0000 - false_negatives: 3152098.0000 - precision: 0.9761 - recall: 0.9760 - val_loss: 0.1041 - val_accuracy: 0.9104 - val_binary_iou: 0.8333 - val_true_positives: 41454728.0000 - val_false_positives: 5827240.0000 - val_true_negatives: 55023808.0000 - val_false_negatives: 3665944.0000 - val_precision: 0.8768 - val_recall: 0.9188\n",
      "Epoch 165/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0242 - accuracy: 0.9804 - binary_iou: 0.9603 - true_positives: 128013408.0000 - false_positives: 3146686.0000 - true_negatives: 185235904.0000 - false_negatives: 3124740.0000 - precision: 0.9760 - recall: 0.9762 - val_loss: 0.1052 - val_accuracy: 0.9093 - val_binary_iou: 0.8315 - val_true_positives: 41471740.0000 - val_false_positives: 6024409.0000 - val_true_negatives: 54891200.0000 - val_false_negatives: 3584374.0000 - val_precision: 0.8732 - val_recall: 0.9204\n",
      "Epoch 166/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0243 - accuracy: 0.9804 - binary_iou: 0.9603 - true_positives: 127967744.0000 - false_positives: 3137469.0000 - true_negatives: 185281936.0000 - false_negatives: 3133627.0000 - precision: 0.9761 - recall: 0.9761 - val_loss: 0.1032 - val_accuracy: 0.9116 - val_binary_iou: 0.8352 - val_true_positives: 41379240.0000 - val_false_positives: 5621261.0000 - val_true_negatives: 55226304.0000 - val_false_negatives: 3744908.0000 - val_precision: 0.8804 - val_recall: 0.9170\n",
      "Epoch 167/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0240 - accuracy: 0.9805 - binary_iou: 0.9606 - true_positives: 127984152.0000 - false_positives: 3098166.0000 - true_negatives: 185320608.0000 - false_negatives: 3117807.0000 - precision: 0.9764 - recall: 0.9762 - val_loss: 0.1011 - val_accuracy: 0.9137 - val_binary_iou: 0.8385 - val_true_positives: 41168756.0000 - val_false_positives: 5192847.0000 - val_true_negatives: 55657264.0000 - val_false_negatives: 3952858.0000 - val_precision: 0.8880 - val_recall: 0.9124\n",
      "Epoch 168/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0238 - accuracy: 0.9807 - binary_iou: 0.9610 - true_positives: 128014992.0000 - false_positives: 3102235.0000 - true_negatives: 185348480.0000 - false_negatives: 3055141.0000 - precision: 0.9763 - recall: 0.9767 - val_loss: 0.1027 - val_accuracy: 0.9121 - val_binary_iou: 0.8359 - val_true_positives: 41280856.0000 - val_false_positives: 5500792.0000 - val_true_negatives: 55372700.0000 - val_false_negatives: 3817356.0000 - val_precision: 0.8824 - val_recall: 0.9154\n",
      "Epoch 169/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0239 - accuracy: 0.9806 - binary_iou: 0.9607 - true_positives: 128040984.0000 - false_positives: 3098827.0000 - true_negatives: 185282688.0000 - false_negatives: 3098221.0000 - precision: 0.9764 - recall: 0.9764 - val_loss: 0.1044 - val_accuracy: 0.9105 - val_binary_iou: 0.8335 - val_true_positives: 41492304.0000 - val_false_positives: 5968840.0000 - val_true_negatives: 55000168.0000 - val_false_negatives: 3510404.0000 - val_precision: 0.8742 - val_recall: 0.9220\n",
      "Epoch 170/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0237 - accuracy: 0.9809 - binary_iou: 0.9612 - true_positives: 128058880.0000 - false_positives: 3049991.0000 - true_negatives: 185345488.0000 - false_negatives: 3066411.0000 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.1029 - val_accuracy: 0.9132 - val_binary_iou: 0.8377 - val_true_positives: 40979648.0000 - val_false_positives: 5162008.0000 - val_true_negatives: 55798728.0000 - val_false_negatives: 4031317.0000 - val_precision: 0.8881 - val_recall: 0.9104\n",
      "Epoch 171/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9616 - true_positives: 128180136.0000 - false_positives: 3036087.0000 - true_negatives: 185278304.0000 - false_negatives: 3026205.0000 - precision: 0.9769 - recall: 0.9769 - val_loss: 0.1020 - val_accuracy: 0.9129 - val_binary_iou: 0.8374 - val_true_positives: 41416740.0000 - val_false_positives: 5583920.0000 - val_true_negatives: 55325640.0000 - val_false_negatives: 3645416.0000 - val_precision: 0.8812 - val_recall: 0.9191\n",
      "Epoch 172/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0235 - accuracy: 0.9809 - binary_iou: 0.9614 - true_positives: 128148680.0000 - false_positives: 3029693.0000 - true_negatives: 185280096.0000 - false_negatives: 3062312.0000 - precision: 0.9769 - recall: 0.9767 - val_loss: 0.1017 - val_accuracy: 0.9132 - val_binary_iou: 0.8378 - val_true_positives: 41272516.0000 - val_false_positives: 5370075.0000 - val_true_negatives: 55502852.0000 - val_false_negatives: 3826265.0000 - val_precision: 0.8849 - val_recall: 0.9152\n",
      "Epoch 173/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9616 - true_positives: 128059008.0000 - false_positives: 3046352.0000 - true_negatives: 185396560.0000 - false_negatives: 3018792.0000 - precision: 0.9768 - recall: 0.9770 - val_loss: 0.1019 - val_accuracy: 0.9118 - val_binary_iou: 0.8358 - val_true_positives: 41741072.0000 - val_false_positives: 5937163.0000 - val_true_negatives: 54886896.0000 - val_false_negatives: 3406581.0000 - val_precision: 0.8755 - val_recall: 0.9245\n",
      "Epoch 174/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0236 - accuracy: 0.9810 - binary_iou: 0.9615 - true_positives: 128075792.0000 - false_positives: 3023642.0000 - true_negatives: 185372944.0000 - false_negatives: 3048409.0000 - precision: 0.9769 - recall: 0.9768 - val_loss: 0.1033 - val_accuracy: 0.9122 - val_binary_iou: 0.8360 - val_true_positives: 41137900.0000 - val_false_positives: 5335700.0000 - val_true_negatives: 55528648.0000 - val_false_negatives: 3969478.0000 - val_precision: 0.8852 - val_recall: 0.9120\n",
      "Epoch 175/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9617 - true_positives: 128039480.0000 - false_positives: 3027095.0000 - true_negatives: 185443184.0000 - false_negatives: 3010986.0000 - precision: 0.9769 - recall: 0.9770 - val_loss: 0.1017 - val_accuracy: 0.9123 - val_binary_iou: 0.8365 - val_true_positives: 41545472.0000 - val_false_positives: 5740711.0000 - val_true_negatives: 55135496.0000 - val_false_negatives: 3550030.0000 - val_precision: 0.8786 - val_recall: 0.9213\n",
      "Epoch 176/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9616 - true_positives: 128129392.0000 - false_positives: 3037819.0000 - true_negatives: 185337856.0000 - false_negatives: 3015690.0000 - precision: 0.9768 - recall: 0.9770 - val_loss: 0.1025 - val_accuracy: 0.9117 - val_binary_iou: 0.8355 - val_true_positives: 41598376.0000 - val_false_positives: 5818806.0000 - val_true_negatives: 55018284.0000 - val_false_negatives: 3536235.0000 - val_precision: 0.8773 - val_recall: 0.9217\n",
      "Epoch 177/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9617 - true_positives: 128066704.0000 - false_positives: 3038421.0000 - true_negatives: 185415344.0000 - false_negatives: 3000307.0000 - precision: 0.9768 - recall: 0.9771 - val_loss: 0.1035 - val_accuracy: 0.9119 - val_binary_iou: 0.8356 - val_true_positives: 41226188.0000 - val_false_positives: 5539718.0000 - val_true_negatives: 55411376.0000 - val_false_negatives: 3794441.0000 - val_precision: 0.8815 - val_recall: 0.9157\n",
      "Epoch 178/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0231 - accuracy: 0.9813 - binary_iou: 0.9621 - true_positives: 128126064.0000 - false_positives: 2995779.0000 - true_negatives: 185412752.0000 - false_negatives: 2986175.0000 - precision: 0.9772 - recall: 0.9772 - val_loss: 0.1034 - val_accuracy: 0.9119 - val_binary_iou: 0.8356 - val_true_positives: 41209184.0000 - val_false_positives: 5499057.0000 - val_true_negatives: 55428784.0000 - val_false_negatives: 3834689.0000 - val_precision: 0.8823 - val_recall: 0.9149\n",
      "Epoch 179/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0231 - accuracy: 0.9814 - binary_iou: 0.9622 - true_positives: 128140832.0000 - false_positives: 2995720.0000 - true_negatives: 185426960.0000 - false_negatives: 2957376.0000 - precision: 0.9772 - recall: 0.9774 - val_loss: 0.1025 - val_accuracy: 0.9113 - val_binary_iou: 0.8348 - val_true_positives: 41541160.0000 - val_false_positives: 5893169.0000 - val_true_negatives: 55033608.0000 - val_false_negatives: 3503785.0000 - val_precision: 0.8758 - val_recall: 0.9222\n",
      "Epoch 180/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0228 - accuracy: 0.9816 - binary_iou: 0.9627 - true_positives: 128145744.0000 - false_positives: 2935147.0000 - true_negatives: 185493040.0000 - false_negatives: 2946812.0000 - precision: 0.9776 - recall: 0.9775 - val_loss: 0.1021 - val_accuracy: 0.9123 - val_binary_iou: 0.8363 - val_true_positives: 41302620.0000 - val_false_positives: 5470590.0000 - val_true_negatives: 55377448.0000 - val_false_negatives: 3821045.0000 - val_precision: 0.8830 - val_recall: 0.9153\n",
      "Epoch 181/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0229 - accuracy: 0.9816 - binary_iou: 0.9626 - true_positives: 128139584.0000 - false_positives: 2949874.0000 - true_negatives: 185490640.0000 - false_negatives: 2940661.0000 - precision: 0.9775 - recall: 0.9776 - val_loss: 0.1037 - val_accuracy: 0.9111 - val_binary_iou: 0.8344 - val_true_positives: 41463108.0000 - val_false_positives: 5784476.0000 - val_true_negatives: 55089276.0000 - val_false_negatives: 3634850.0000 - val_precision: 0.8776 - val_recall: 0.9194\n",
      "Epoch 182/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9817 - binary_iou: 0.9630 - true_positives: 128119264.0000 - false_positives: 2922460.0000 - true_negatives: 185564624.0000 - false_negatives: 2914332.0000 - precision: 0.9777 - recall: 0.9778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 454ms/step - loss: 0.0226 - accuracy: 0.9817 - binary_iou: 0.9630 - true_positives: 128119264.0000 - false_positives: 2922460.0000 - true_negatives: 185564624.0000 - false_negatives: 2914332.0000 - precision: 0.9777 - recall: 0.9778 - val_loss: 0.1009 - val_accuracy: 0.9147 - val_binary_iou: 0.8402 - val_true_positives: 41219812.0000 - val_false_positives: 5263139.0000 - val_true_negatives: 55709380.0000 - val_false_negatives: 3779386.0000 - val_precision: 0.8868 - val_recall: 0.9160\n",
      "Epoch 183/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9629 - true_positives: 128174704.0000 - false_positives: 2929632.0000 - true_negatives: 185492736.0000 - false_negatives: 2923666.0000 - precision: 0.9777 - recall: 0.9777 - val_loss: 0.1035 - val_accuracy: 0.9108 - val_binary_iou: 0.8340 - val_true_positives: 41661984.0000 - val_false_positives: 5952627.0000 - val_true_negatives: 54855712.0000 - val_false_negatives: 3501381.0000 - val_precision: 0.8750 - val_recall: 0.9225\n",
      "Epoch 184/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0224 - accuracy: 0.9819 - binary_iou: 0.9632 - true_positives: 128230584.0000 - false_positives: 2889092.0000 - true_negatives: 185491328.0000 - false_negatives: 2909804.0000 - precision: 0.9780 - recall: 0.9778 - val_loss: 0.1026 - val_accuracy: 0.9115 - val_binary_iou: 0.8351 - val_true_positives: 41456424.0000 - val_false_positives: 5716552.0000 - val_true_negatives: 55135788.0000 - val_false_negatives: 3662925.0000 - val_precision: 0.8788 - val_recall: 0.9188\n",
      "Epoch 185/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0223 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128252848.0000 - false_positives: 2896520.0000 - true_negatives: 185483904.0000 - false_negatives: 2887471.0000 - precision: 0.9779 - recall: 0.9780 - val_loss: 0.1019 - val_accuracy: 0.9125 - val_binary_iou: 0.8368 - val_true_positives: 41511548.0000 - val_false_positives: 5659597.0000 - val_true_negatives: 55189164.0000 - val_false_negatives: 3611396.0000 - val_precision: 0.8800 - val_recall: 0.9200\n",
      "Epoch 186/500\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0224 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128197040.0000 - false_positives: 2875213.0000 - true_negatives: 185537376.0000 - false_negatives: 2911186.0000 - precision: 0.9781 - recall: 0.9778 - val_loss: 0.1014 - val_accuracy: 0.9130 - val_binary_iou: 0.8376 - val_true_positives: 41458748.0000 - val_false_positives: 5516421.0000 - val_true_negatives: 55292224.0000 - val_false_negatives: 3704317.0000 - val_precision: 0.8826 - val_recall: 0.9180\n",
      "Epoch 187/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0224 - accuracy: 0.9819 - binary_iou: 0.9634 - true_positives: 128236632.0000 - false_positives: 2888153.0000 - true_negatives: 185513280.0000 - false_negatives: 2882678.0000 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.1032 - val_accuracy: 0.9117 - val_binary_iou: 0.8354 - val_true_positives: 41422972.0000 - val_false_positives: 5646177.0000 - val_true_negatives: 55194144.0000 - val_false_negatives: 3708422.0000 - val_precision: 0.8800 - val_recall: 0.9178\n",
      "Epoch 188/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9629 - true_positives: 128126440.0000 - false_positives: 2934068.0000 - true_negatives: 185545856.0000 - false_negatives: 2914420.0000 - precision: 0.9776 - recall: 0.9778 - val_loss: 0.1029 - val_accuracy: 0.9106 - val_binary_iou: 0.8338 - val_true_positives: 41775976.0000 - val_false_positives: 6073710.0000 - val_true_negatives: 54722400.0000 - val_false_negatives: 3399619.0000 - val_precision: 0.8731 - val_recall: 0.9247\n",
      "Epoch 189/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0223 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128269832.0000 - false_positives: 2892459.0000 - true_negatives: 185471808.0000 - false_negatives: 2886655.0000 - precision: 0.9779 - recall: 0.9780 - val_loss: 0.1029 - val_accuracy: 0.9128 - val_binary_iou: 0.8371 - val_true_positives: 41173120.0000 - val_false_positives: 5362120.0000 - val_true_negatives: 55560944.0000 - val_false_negatives: 3875530.0000 - val_precision: 0.8848 - val_recall: 0.9140\n",
      "Epoch 190/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0224 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128243592.0000 - false_positives: 2895888.0000 - true_negatives: 185488320.0000 - false_negatives: 2892956.0000 - precision: 0.9779 - recall: 0.9779 - val_loss: 0.1039 - val_accuracy: 0.9100 - val_binary_iou: 0.8328 - val_true_positives: 41728328.0000 - val_false_positives: 6167078.0000 - val_true_negatives: 54706500.0000 - val_false_negatives: 3369820.0000 - val_precision: 0.8712 - val_recall: 0.9253\n",
      "Epoch 191/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0222 - accuracy: 0.9820 - binary_iou: 0.9635 - true_positives: 128254440.0000 - false_positives: 2894141.0000 - true_negatives: 185510416.0000 - false_negatives: 2861740.0000 - precision: 0.9779 - recall: 0.9782 - val_loss: 0.1010 - val_accuracy: 0.9128 - val_binary_iou: 0.8373 - val_true_positives: 41554656.0000 - val_false_positives: 5626181.0000 - val_true_negatives: 55172760.0000 - val_false_negatives: 3618103.0000 - val_precision: 0.8808 - val_recall: 0.9199\n",
      "Epoch 192/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0221 - accuracy: 0.9821 - binary_iou: 0.9637 - true_positives: 128240856.0000 - false_positives: 2841149.0000 - true_negatives: 185565952.0000 - false_negatives: 2872832.0000 - precision: 0.9783 - recall: 0.9781 - val_loss: 0.1039 - val_accuracy: 0.9120 - val_binary_iou: 0.8357 - val_true_positives: 41279256.0000 - val_false_positives: 5599361.0000 - val_true_negatives: 55363456.0000 - val_false_negatives: 3729647.0000 - val_precision: 0.8806 - val_recall: 0.9171\n",
      "Epoch 193/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0218 - accuracy: 0.9823 - binary_iou: 0.9642 - true_positives: 128236928.0000 - false_positives: 2822660.0000 - true_negatives: 185642752.0000 - false_negatives: 2818470.0000 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.1018 - val_accuracy: 0.9123 - val_binary_iou: 0.8366 - val_true_positives: 41683960.0000 - val_false_positives: 5792899.0000 - val_true_negatives: 54995528.0000 - val_false_negatives: 3499329.0000 - val_precision: 0.8780 - val_recall: 0.9226\n",
      "Epoch 194/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0218 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128262928.0000 - false_positives: 2817614.0000 - true_negatives: 185634448.0000 - false_negatives: 2805800.0000 - precision: 0.9785 - recall: 0.9786 - val_loss: 0.1028 - val_accuracy: 0.9110 - val_binary_iou: 0.8343 - val_true_positives: 41673848.0000 - val_false_positives: 5991168.0000 - val_true_negatives: 54862324.0000 - val_false_negatives: 3444385.0000 - val_precision: 0.8743 - val_recall: 0.9237\n",
      "Epoch 195/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0216 - accuracy: 0.9826 - binary_iou: 0.9646 - true_positives: 128254520.0000 - false_positives: 2780398.0000 - true_negatives: 185696432.0000 - false_negatives: 2789408.0000 - precision: 0.9788 - recall: 0.9787 - val_loss: 0.1032 - val_accuracy: 0.9111 - val_binary_iou: 0.8346 - val_true_positives: 41663700.0000 - val_false_positives: 6029403.0000 - val_true_negatives: 54888344.0000 - val_false_negatives: 3390264.0000 - val_precision: 0.8736 - val_recall: 0.9248\n",
      "Epoch 196/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0217 - accuracy: 0.9824 - binary_iou: 0.9644 - true_positives: 128292000.0000 - false_positives: 2807227.0000 - true_negatives: 185620800.0000 - false_negatives: 2800744.0000 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.1020 - val_accuracy: 0.9125 - val_binary_iou: 0.8368 - val_true_positives: 41495944.0000 - val_false_positives: 5608851.0000 - val_true_negatives: 55207948.0000 - val_false_negatives: 3658963.0000 - val_precision: 0.8809 - val_recall: 0.9190\n",
      "Epoch 197/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0214 - accuracy: 0.9827 - binary_iou: 0.9648 - true_positives: 128307136.0000 - false_positives: 2780711.0000 - true_negatives: 185677392.0000 - false_negatives: 2755501.0000 - precision: 0.9788 - recall: 0.9790 - val_loss: 0.1010 - val_accuracy: 0.9133 - val_binary_iou: 0.8380 - val_true_positives: 41362952.0000 - val_false_positives: 5399165.0000 - val_true_negatives: 55419176.0000 - val_false_negatives: 3790431.0000 - val_precision: 0.8845 - val_recall: 0.9161\n",
      "Epoch 198/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0212 - accuracy: 0.9828 - binary_iou: 0.9651 - true_positives: 128402000.0000 - false_positives: 2753990.0000 - true_negatives: 185630144.0000 - false_negatives: 2734602.0000 - precision: 0.9790 - recall: 0.9791 - val_loss: 0.1024 - val_accuracy: 0.9113 - val_binary_iou: 0.8348 - val_true_positives: 41506016.0000 - val_false_positives: 5760154.0000 - val_true_negatives: 55068768.0000 - val_false_negatives: 3636793.0000 - val_precision: 0.8781 - val_recall: 0.9194\n",
      "Epoch 199/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0216 - accuracy: 0.9826 - binary_iou: 0.9647 - true_positives: 128304376.0000 - false_positives: 2778731.0000 - true_negatives: 185655472.0000 - false_negatives: 2782190.0000 - precision: 0.9788 - recall: 0.9788 - val_loss: 0.1011 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41248288.0000 - val_false_positives: 5164599.0000 - val_true_negatives: 55633260.0000 - val_false_negatives: 3925561.0000 - val_precision: 0.8887 - val_recall: 0.9131\n",
      "Epoch 200/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0214 - accuracy: 0.9826 - binary_iou: 0.9648 - true_positives: 128301080.0000 - false_positives: 2778434.0000 - true_negatives: 185673456.0000 - false_negatives: 2767799.0000 - precision: 0.9788 - recall: 0.9789 - val_loss: 0.1025 - val_accuracy: 0.9123 - val_binary_iou: 0.8363 - val_true_positives: 41357464.0000 - val_false_positives: 5504022.0000 - val_true_negatives: 55320144.0000 - val_false_negatives: 3790078.0000 - val_precision: 0.8825 - val_recall: 0.9161\n",
      "Epoch 201/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0212 - accuracy: 0.9828 - binary_iou: 0.9651 - true_positives: 128396056.0000 - false_positives: 2747079.0000 - true_negatives: 185629616.0000 - false_negatives: 2748045.0000 - precision: 0.9791 - recall: 0.9790 - val_loss: 0.1018 - val_accuracy: 0.9127 - val_binary_iou: 0.8371 - val_true_positives: 41385792.0000 - val_false_positives: 5527647.0000 - val_true_negatives: 55337972.0000 - val_false_negatives: 3720296.0000 - val_precision: 0.8822 - val_recall: 0.9175\n",
      "Epoch 202/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0211 - accuracy: 0.9830 - binary_iou: 0.9654 - true_positives: 128470432.0000 - false_positives: 2720100.0000 - true_negatives: 185608688.0000 - false_negatives: 2721564.0000 - precision: 0.9793 - recall: 0.9793 - val_loss: 0.1023 - val_accuracy: 0.9123 - val_binary_iou: 0.8365 - val_true_positives: 41467088.0000 - val_false_positives: 5712166.0000 - val_true_negatives: 55213696.0000 - val_false_negatives: 3578769.0000 - val_precision: 0.8789 - val_recall: 0.9206\n",
      "Epoch 203/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0212 - accuracy: 0.9829 - binary_iou: 0.9652 - true_positives: 128380384.0000 - false_positives: 2744622.0000 - true_negatives: 185667136.0000 - false_negatives: 2728616.0000 - precision: 0.9791 - recall: 0.9792 - val_loss: 0.1025 - val_accuracy: 0.9138 - val_binary_iou: 0.8386 - val_true_positives: 41065140.0000 - val_false_positives: 5090175.0000 - val_true_negatives: 55767148.0000 - val_false_negatives: 4049256.0000 - val_precision: 0.8897 - val_recall: 0.9102\n",
      "Epoch 204/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0212 - accuracy: 0.9828 - binary_iou: 0.9651 - true_positives: 128333312.0000 - false_positives: 2747583.0000 - true_negatives: 185700016.0000 - false_negatives: 2739928.0000 - precision: 0.9790 - recall: 0.9791 - val_loss: 0.1007 - val_accuracy: 0.9140 - val_binary_iou: 0.8391 - val_true_positives: 41351696.0000 - val_false_positives: 5356221.0000 - val_true_negatives: 55501988.0000 - val_false_negatives: 3761812.0000 - val_precision: 0.8853 - val_recall: 0.9166\n",
      "Epoch 205/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9655 - true_positives: 128472080.0000 - false_positives: 2719093.0000 - true_negatives: 185615968.0000 - false_negatives: 2713581.0000 - precision: 0.9793 - recall: 0.9793 - val_loss: 0.1028 - val_accuracy: 0.9117 - val_binary_iou: 0.8354 - val_true_positives: 41430684.0000 - val_false_positives: 5667013.0000 - val_true_negatives: 55187248.0000 - val_false_negatives: 3686767.0000 - val_precision: 0.8797 - val_recall: 0.9183\n",
      "Epoch 206/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0208 - accuracy: 0.9832 - binary_iou: 0.9659 - true_positives: 128475064.0000 - false_positives: 2687541.0000 - true_negatives: 185677776.0000 - false_negatives: 2680328.0000 - precision: 0.9795 - recall: 0.9796 - val_loss: 0.1024 - val_accuracy: 0.9118 - val_binary_iou: 0.8357 - val_true_positives: 41590524.0000 - val_false_positives: 5812931.0000 - val_true_negatives: 55036688.0000 - val_false_negatives: 3531589.0000 - val_precision: 0.8774 - val_recall: 0.9217\n",
      "Epoch 207/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0207 - accuracy: 0.9832 - binary_iou: 0.9659 - true_positives: 128540064.0000 - false_positives: 2707133.0000 - true_negatives: 185607808.0000 - false_negatives: 2665702.0000 - precision: 0.9794 - recall: 0.9797 - val_loss: 0.1033 - val_accuracy: 0.9108 - val_binary_iou: 0.8340 - val_true_positives: 41641112.0000 - val_false_positives: 6007404.0000 - val_true_negatives: 54878540.0000 - val_false_negatives: 3444658.0000 - val_precision: 0.8739 - val_recall: 0.9236\n",
      "Epoch 208/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0208 - accuracy: 0.9832 - binary_iou: 0.9658 - true_positives: 128441640.0000 - false_positives: 2685218.0000 - true_negatives: 185702480.0000 - false_negatives: 2691440.0000 - precision: 0.9795 - recall: 0.9795 - val_loss: 0.1021 - val_accuracy: 0.9131 - val_binary_iou: 0.8376 - val_true_positives: 41268128.0000 - val_false_positives: 5352802.0000 - val_true_negatives: 55496352.0000 - val_false_negatives: 3854428.0000 - val_precision: 0.8852 - val_recall: 0.9146\n",
      "Epoch 209/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0205 - accuracy: 0.9834 - binary_iou: 0.9662 - true_positives: 128491736.0000 - false_positives: 2663365.0000 - true_negatives: 185713152.0000 - false_negatives: 2652471.0000 - precision: 0.9797 - recall: 0.9798 - val_loss: 0.1010 - val_accuracy: 0.9136 - val_binary_iou: 0.8386 - val_true_positives: 41399104.0000 - val_false_positives: 5426937.0000 - val_true_negatives: 55416776.0000 - val_false_negatives: 3728890.0000 - val_precision: 0.8841 - val_recall: 0.9174\n",
      "Epoch 210/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9666 - true_positives: 128543904.0000 - false_positives: 2629263.0000 - true_negatives: 185725536.0000 - false_negatives: 2622070.0000 - precision: 0.9800 - recall: 0.9800 - val_loss: 0.1037 - val_accuracy: 0.9110 - val_binary_iou: 0.8341 - val_true_positives: 41158328.0000 - val_false_positives: 5501041.0000 - val_true_negatives: 55386700.0000 - val_false_negatives: 3925644.0000 - val_precision: 0.8821 - val_recall: 0.9129\n",
      "Epoch 211/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9666 - true_positives: 128571136.0000 - false_positives: 2632692.0000 - true_negatives: 185694464.0000 - false_negatives: 2622429.0000 - precision: 0.9799 - recall: 0.9800 - val_loss: 0.1042 - val_accuracy: 0.9105 - val_binary_iou: 0.8334 - val_true_positives: 41408328.0000 - val_false_positives: 5947668.0000 - val_true_negatives: 55079016.0000 - val_false_negatives: 3536698.0000 - val_precision: 0.8744 - val_recall: 0.9213\n",
      "Epoch 212/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128402592.0000 - false_positives: 2618282.0000 - true_negatives: 185886016.0000 - false_negatives: 2613785.0000 - precision: 0.9800 - recall: 0.9800 - val_loss: 0.1022 - val_accuracy: 0.9123 - val_binary_iou: 0.8362 - val_true_positives: 41214676.0000 - val_false_positives: 5466732.0000 - val_true_negatives: 55458656.0000 - val_false_negatives: 3831653.0000 - val_precision: 0.8829 - val_recall: 0.9149\n",
      "Epoch 213/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128489376.0000 - false_positives: 2623069.0000 - true_negatives: 185770448.0000 - false_negatives: 2637933.0000 - precision: 0.9800 - recall: 0.9799 - val_loss: 0.1012 - val_accuracy: 0.9141 - val_binary_iou: 0.8392 - val_true_positives: 41203804.0000 - val_false_positives: 5294358.0000 - val_true_negatives: 55660988.0000 - val_false_negatives: 3812563.0000 - val_precision: 0.8861 - val_recall: 0.9153\n",
      "Epoch 214/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9668 - true_positives: 128449160.0000 - false_positives: 2599581.0000 - true_negatives: 185842976.0000 - false_negatives: 2628990.0000 - precision: 0.9802 - recall: 0.9799 - val_loss: 0.1008 - val_accuracy: 0.9135 - val_binary_iou: 0.8384 - val_true_positives: 41326732.0000 - val_false_positives: 5390419.0000 - val_true_negatives: 55483104.0000 - val_false_negatives: 3771468.0000 - val_precision: 0.8846 - val_recall: 0.9164\n",
      "Epoch 215/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128550928.0000 - false_positives: 2631837.0000 - true_negatives: 185725040.0000 - false_negatives: 2612982.0000 - precision: 0.9799 - recall: 0.9801 - val_loss: 0.1033 - val_accuracy: 0.9112 - val_binary_iou: 0.8346 - val_true_positives: 41513760.0000 - val_false_positives: 5737814.0000 - val_true_negatives: 55045248.0000 - val_false_negatives: 3674893.0000 - val_precision: 0.8786 - val_recall: 0.9187\n",
      "Epoch 216/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0205 - accuracy: 0.9834 - binary_iou: 0.9664 - true_positives: 128470696.0000 - false_positives: 2648372.0000 - true_negatives: 185757648.0000 - false_negatives: 2644064.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.1028 - val_accuracy: 0.9121 - val_binary_iou: 0.8359 - val_true_positives: 41218524.0000 - val_false_positives: 5544053.0000 - val_true_negatives: 55440756.0000 - val_false_negatives: 3768374.0000 - val_precision: 0.8814 - val_recall: 0.9162\n",
      "Epoch 217/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0203 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128465112.0000 - false_positives: 2620372.0000 - true_negatives: 185796640.0000 - false_negatives: 2638619.0000 - precision: 0.9800 - recall: 0.9799 - val_loss: 0.1024 - val_accuracy: 0.9123 - val_binary_iou: 0.8363 - val_true_positives: 41361392.0000 - val_false_positives: 5522411.0000 - val_true_negatives: 55315012.0000 - val_false_negatives: 3772905.0000 - val_precision: 0.8822 - val_recall: 0.9164\n",
      "Epoch 218/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0203 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128479840.0000 - false_positives: 2635068.0000 - true_negatives: 185783072.0000 - false_negatives: 2622780.0000 - precision: 0.9799 - recall: 0.9800 - val_loss: 0.1033 - val_accuracy: 0.9113 - val_binary_iou: 0.8348 - val_true_positives: 41509704.0000 - val_false_positives: 5787747.0000 - val_true_negatives: 55066768.0000 - val_false_negatives: 3607482.0000 - val_precision: 0.8776 - val_recall: 0.9200\n",
      "Epoch 219/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0201 - accuracy: 0.9837 - binary_iou: 0.9669 - true_positives: 128579736.0000 - false_positives: 2604618.0000 - true_negatives: 185738688.0000 - false_negatives: 2597775.0000 - precision: 0.9801 - recall: 0.9802 - val_loss: 0.1022 - val_accuracy: 0.9120 - val_binary_iou: 0.8360 - val_true_positives: 41457252.0000 - val_false_positives: 5675270.0000 - val_true_negatives: 55191896.0000 - val_false_negatives: 3647293.0000 - val_precision: 0.8796 - val_recall: 0.9191\n",
      "Epoch 220/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0200 - accuracy: 0.9838 - binary_iou: 0.9671 - true_positives: 128563896.0000 - false_positives: 2587344.0000 - true_negatives: 185784784.0000 - false_negatives: 2584704.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.1013 - val_accuracy: 0.9135 - val_binary_iou: 0.8382 - val_true_positives: 41249776.0000 - val_false_positives: 5289607.0000 - val_true_negatives: 55553312.0000 - val_false_negatives: 3879030.0000 - val_precision: 0.8863 - val_recall: 0.9140\n",
      "Epoch 221/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0198 - accuracy: 0.9839 - binary_iou: 0.9673 - true_positives: 128509488.0000 - false_positives: 2575216.0000 - true_negatives: 185873120.0000 - false_negatives: 2562929.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.1043 - val_accuracy: 0.9106 - val_binary_iou: 0.8334 - val_true_positives: 41321312.0000 - val_false_positives: 5723901.0000 - val_true_negatives: 55173960.0000 - val_false_negatives: 3752535.0000 - val_precision: 0.8783 - val_recall: 0.9167\n",
      "Epoch 222/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0197 - accuracy: 0.9840 - binary_iou: 0.9675 - true_positives: 128550272.0000 - false_positives: 2558432.0000 - true_negatives: 185859648.0000 - false_negatives: 2552318.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.1014 - val_accuracy: 0.9134 - val_binary_iou: 0.8381 - val_true_positives: 41287508.0000 - val_false_positives: 5371067.0000 - val_true_negatives: 55504832.0000 - val_false_negatives: 3808312.0000 - val_precision: 0.8849 - val_recall: 0.9156\n",
      "Epoch 223/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0197 - accuracy: 0.9841 - binary_iou: 0.9677 - true_positives: 128590120.0000 - false_positives: 2545465.0000 - true_negatives: 185847136.0000 - false_negatives: 2537970.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.1021 - val_accuracy: 0.9125 - val_binary_iou: 0.8367 - val_true_positives: 41421476.0000 - val_false_positives: 5574767.0000 - val_true_negatives: 55277408.0000 - val_false_negatives: 3698052.0000 - val_precision: 0.8814 - val_recall: 0.9180\n",
      "Epoch 224/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128546520.0000 - false_positives: 2546200.0000 - true_negatives: 185903744.0000 - false_negatives: 2524274.0000 - precision: 0.9806 - recall: 0.9807 - val_loss: 0.1022 - val_accuracy: 0.9122 - val_binary_iou: 0.8363 - val_true_positives: 41433192.0000 - val_false_positives: 5575581.0000 - val_true_negatives: 55236064.0000 - val_false_negatives: 3726878.0000 - val_precision: 0.8814 - val_recall: 0.9175\n",
      "Epoch 225/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0195 - accuracy: 0.9842 - binary_iou: 0.9679 - true_positives: 128622952.0000 - false_positives: 2514045.0000 - true_negatives: 185852272.0000 - false_negatives: 2531518.0000 - precision: 0.9808 - recall: 0.9807 - val_loss: 0.1049 - val_accuracy: 0.9104 - val_binary_iou: 0.8331 - val_true_positives: 41383896.0000 - val_false_positives: 5877653.0000 - val_true_negatives: 55087820.0000 - val_false_negatives: 3622336.0000 - val_precision: 0.8756 - val_recall: 0.9195\n",
      "Epoch 226/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0195 - accuracy: 0.9842 - binary_iou: 0.9679 - true_positives: 128535720.0000 - false_positives: 2529618.0000 - true_negatives: 185942784.0000 - false_negatives: 2512592.0000 - precision: 0.9807 - recall: 0.9808 - val_loss: 0.1015 - val_accuracy: 0.9128 - val_binary_iou: 0.8372 - val_true_positives: 41448760.0000 - val_false_positives: 5568790.0000 - val_true_negatives: 55278656.0000 - val_false_negatives: 3675498.0000 - val_precision: 0.8816 - val_recall: 0.9185\n",
      "Epoch 227/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0195 - accuracy: 0.9843 - binary_iou: 0.9681 - true_positives: 128582712.0000 - false_positives: 2508395.0000 - true_negatives: 185918768.0000 - false_negatives: 2510908.0000 - precision: 0.9809 - recall: 0.9808 - val_loss: 0.1027 - val_accuracy: 0.9122 - val_binary_iou: 0.8361 - val_true_positives: 41286960.0000 - val_false_positives: 5464834.0000 - val_true_negatives: 55380288.0000 - val_false_negatives: 3839632.0000 - val_precision: 0.8831 - val_recall: 0.9149\n",
      "Epoch 228/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0196 - accuracy: 0.9842 - binary_iou: 0.9678 - true_positives: 128645032.0000 - false_positives: 2548512.0000 - true_negatives: 185814944.0000 - false_negatives: 2512268.0000 - precision: 0.9806 - recall: 0.9808 - val_loss: 0.1031 - val_accuracy: 0.9113 - val_binary_iou: 0.8348 - val_true_positives: 41474728.0000 - val_false_positives: 5740760.0000 - val_true_negatives: 55098896.0000 - val_false_negatives: 3657319.0000 - val_precision: 0.8784 - val_recall: 0.9190\n",
      "Epoch 229/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9682 - true_positives: 128644520.0000 - false_positives: 2515824.0000 - true_negatives: 185873504.0000 - false_negatives: 2486933.0000 - precision: 0.9808 - recall: 0.9810 - val_loss: 0.1007 - val_accuracy: 0.9138 - val_binary_iou: 0.8388 - val_true_positives: 41368028.0000 - val_false_positives: 5365533.0000 - val_true_negatives: 55465328.0000 - val_false_negatives: 3772808.0000 - val_precision: 0.8852 - val_recall: 0.9164\n",
      "Epoch 230/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0192 - accuracy: 0.9844 - binary_iou: 0.9684 - true_positives: 128652328.0000 - false_positives: 2496639.0000 - true_negatives: 185896224.0000 - false_negatives: 2475623.0000 - precision: 0.9810 - recall: 0.9811 - val_loss: 0.1022 - val_accuracy: 0.9121 - val_binary_iou: 0.8361 - val_true_positives: 41543264.0000 - val_false_positives: 5716208.0000 - val_true_negatives: 55114372.0000 - val_false_negatives: 3597861.0000 - val_precision: 0.8790 - val_recall: 0.9203\n",
      "Epoch 231/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9681 - true_positives: 128645520.0000 - false_positives: 2518083.0000 - true_negatives: 185864144.0000 - false_negatives: 2493037.0000 - precision: 0.9808 - recall: 0.9810 - val_loss: 0.1017 - val_accuracy: 0.9132 - val_binary_iou: 0.8379 - val_true_positives: 41333820.0000 - val_false_positives: 5313048.0000 - val_true_negatives: 55442452.0000 - val_false_negatives: 3882385.0000 - val_precision: 0.8861 - val_recall: 0.9141\n",
      "Epoch 232/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0193 - accuracy: 0.9844 - binary_iou: 0.9683 - true_positives: 128645024.0000 - false_positives: 2495960.0000 - true_negatives: 185885760.0000 - false_negatives: 2494047.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.1022 - val_accuracy: 0.9116 - val_binary_iou: 0.8352 - val_true_positives: 41427908.0000 - val_false_positives: 5678283.0000 - val_true_negatives: 55177720.0000 - val_false_negatives: 3687793.0000 - val_precision: 0.8795 - val_recall: 0.9183\n",
      "Epoch 233/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9686 - true_positives: 128624848.0000 - false_positives: 2479784.0000 - true_negatives: 185955312.0000 - false_negatives: 2460872.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1039 - val_accuracy: 0.9100 - val_binary_iou: 0.8326 - val_true_positives: 41555136.0000 - val_false_positives: 5968678.0000 - val_true_negatives: 54878144.0000 - val_false_negatives: 3569747.0000 - val_precision: 0.8744 - val_recall: 0.9209\n",
      "Epoch 234/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0192 - accuracy: 0.9845 - binary_iou: 0.9684 - true_positives: 128646768.0000 - false_positives: 2462048.0000 - true_negatives: 185910912.0000 - false_negatives: 2501128.0000 - precision: 0.9812 - recall: 0.9809 - val_loss: 0.1025 - val_accuracy: 0.9129 - val_binary_iou: 0.8372 - val_true_positives: 41065924.0000 - val_false_positives: 5241848.0000 - val_true_negatives: 55680276.0000 - val_false_negatives: 3983659.0000 - val_precision: 0.8868 - val_recall: 0.9116\n",
      "Epoch 235/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0189 - accuracy: 0.9846 - binary_iou: 0.9687 - true_positives: 128684016.0000 - false_positives: 2478186.0000 - true_negatives: 185924384.0000 - false_negatives: 2434081.0000 - precision: 0.9811 - recall: 0.9814 - val_loss: 0.1040 - val_accuracy: 0.9116 - val_binary_iou: 0.8350 - val_true_positives: 41178016.0000 - val_false_positives: 5474546.0000 - val_true_negatives: 55426216.0000 - val_false_negatives: 3892931.0000 - val_precision: 0.8827 - val_recall: 0.9136\n",
      "Epoch 236/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128618896.0000 - false_positives: 2443590.0000 - true_negatives: 186013824.0000 - false_negatives: 2444423.0000 - precision: 0.9814 - recall: 0.9813 - val_loss: 0.1036 - val_accuracy: 0.9118 - val_binary_iou: 0.8355 - val_true_positives: 41378344.0000 - val_false_positives: 5697653.0000 - val_true_negatives: 55246336.0000 - val_false_negatives: 3649372.0000 - val_precision: 0.8790 - val_recall: 0.9190\n",
      "Epoch 237/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128643072.0000 - false_positives: 2465883.0000 - true_negatives: 185984480.0000 - false_negatives: 2427407.0000 - precision: 0.9812 - recall: 0.9815 - val_loss: 0.1051 - val_accuracy: 0.9098 - val_binary_iou: 0.8323 - val_true_positives: 41563916.0000 - val_false_positives: 6018190.0000 - val_true_negatives: 54851008.0000 - val_false_negatives: 3538599.0000 - val_precision: 0.8735 - val_recall: 0.9215\n",
      "Epoch 238/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0190 - accuracy: 0.9847 - binary_iou: 0.9688 - true_positives: 128671040.0000 - false_positives: 2458651.0000 - true_negatives: 185948000.0000 - false_negatives: 2442957.0000 - precision: 0.9813 - recall: 0.9814 - val_loss: 0.1035 - val_accuracy: 0.9118 - val_binary_iou: 0.8354 - val_true_positives: 41181188.0000 - val_false_positives: 5420206.0000 - val_true_negatives: 55446804.0000 - val_false_negatives: 3923515.0000 - val_precision: 0.8837 - val_recall: 0.9130\n",
      "Epoch 239/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128701312.0000 - false_positives: 2440572.0000 - true_negatives: 185927728.0000 - false_negatives: 2451111.0000 - precision: 0.9814 - recall: 0.9813 - val_loss: 0.1016 - val_accuracy: 0.9126 - val_binary_iou: 0.8369 - val_true_positives: 41278368.0000 - val_false_positives: 5523011.0000 - val_true_negatives: 55435608.0000 - val_false_negatives: 3734738.0000 - val_precision: 0.8820 - val_recall: 0.9170\n",
      "Epoch 240/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9688 - true_positives: 128718672.0000 - false_positives: 2472362.0000 - true_negatives: 185904864.0000 - false_negatives: 2424822.0000 - precision: 0.9812 - recall: 0.9815 - val_loss: 0.1023 - val_accuracy: 0.9122 - val_binary_iou: 0.8362 - val_true_positives: 41323400.0000 - val_false_positives: 5454626.0000 - val_true_negatives: 55346240.0000 - val_false_negatives: 3847452.0000 - val_precision: 0.8834 - val_recall: 0.9148\n",
      "Epoch 241/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128697272.0000 - false_positives: 2444978.0000 - true_negatives: 185943344.0000 - false_negatives: 2435225.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.1017 - val_accuracy: 0.9127 - val_binary_iou: 0.8370 - val_true_positives: 41407488.0000 - val_false_positives: 5530421.0000 - val_true_negatives: 55310788.0000 - val_false_negatives: 3723016.0000 - val_precision: 0.8822 - val_recall: 0.9175\n",
      "Epoch 242/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0186 - accuracy: 0.9849 - binary_iou: 0.9693 - true_positives: 128730752.0000 - false_positives: 2411736.0000 - true_negatives: 185971136.0000 - false_negatives: 2407208.0000 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.1035 - val_accuracy: 0.9121 - val_binary_iou: 0.8357 - val_true_positives: 41076448.0000 - val_false_positives: 5334527.0000 - val_true_negatives: 55575504.0000 - val_false_negatives: 3985230.0000 - val_precision: 0.8851 - val_recall: 0.9116\n",
      "Epoch 243/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0184 - accuracy: 0.9851 - binary_iou: 0.9697 - true_positives: 128722880.0000 - false_positives: 2381391.0000 - true_negatives: 186036736.0000 - false_negatives: 2379748.0000 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.1033 - val_accuracy: 0.9118 - val_binary_iou: 0.8355 - val_true_positives: 41307936.0000 - val_false_positives: 5550597.0000 - val_true_negatives: 55315984.0000 - val_false_negatives: 3797190.0000 - val_precision: 0.8815 - val_recall: 0.9158\n",
      "Epoch 244/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0186 - accuracy: 0.9849 - binary_iou: 0.9694 - true_positives: 128750104.0000 - false_positives: 2402750.0000 - true_negatives: 185958128.0000 - false_negatives: 2409808.0000 - precision: 0.9817 - recall: 0.9816 - val_loss: 0.1024 - val_accuracy: 0.9127 - val_binary_iou: 0.8369 - val_true_positives: 41152660.0000 - val_false_positives: 5264955.0000 - val_true_negatives: 55571288.0000 - val_false_negatives: 3982825.0000 - val_precision: 0.8866 - val_recall: 0.9118\n",
      "Epoch 245/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0186 - accuracy: 0.9849 - binary_iou: 0.9693 - true_positives: 128787520.0000 - false_positives: 2417707.0000 - true_negatives: 185915792.0000 - false_negatives: 2399728.0000 - precision: 0.9816 - recall: 0.9817 - val_loss: 0.1012 - val_accuracy: 0.9141 - val_binary_iou: 0.8392 - val_true_positives: 41134480.0000 - val_false_positives: 5165190.0000 - val_true_negatives: 55735584.0000 - val_false_negatives: 3936468.0000 - val_precision: 0.8884 - val_recall: 0.9127\n",
      "Epoch 246/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0183 - accuracy: 0.9851 - binary_iou: 0.9698 - true_positives: 128733760.0000 - false_positives: 2390682.0000 - true_negatives: 186036128.0000 - false_negatives: 2360195.0000 - precision: 0.9818 - recall: 0.9820 - val_loss: 0.1004 - val_accuracy: 0.9139 - val_binary_iou: 0.8391 - val_true_positives: 41347056.0000 - val_false_positives: 5255884.0000 - val_true_negatives: 55504584.0000 - val_false_negatives: 3864194.0000 - val_precision: 0.8872 - val_recall: 0.9145\n",
      "Epoch 247/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0184 - accuracy: 0.9850 - binary_iou: 0.9696 - true_positives: 128804664.0000 - false_positives: 2387558.0000 - true_negatives: 185937920.0000 - false_negatives: 2390672.0000 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.1021 - val_accuracy: 0.9124 - val_binary_iou: 0.8365 - val_true_positives: 41339176.0000 - val_false_positives: 5576841.0000 - val_true_negatives: 55352088.0000 - val_false_negatives: 3703616.0000 - val_precision: 0.8811 - val_recall: 0.9178\n",
      "Epoch 248/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128713496.0000 - false_positives: 2369420.0000 - true_negatives: 186072064.0000 - false_negatives: 2365762.0000 - precision: 0.9819 - recall: 0.9820 - val_loss: 0.1025 - val_accuracy: 0.9122 - val_binary_iou: 0.8360 - val_true_positives: 41221808.0000 - val_false_positives: 5379291.0000 - val_true_negatives: 55441424.0000 - val_false_negatives: 3929185.0000 - val_precision: 0.8846 - val_recall: 0.9130\n",
      "Epoch 249/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0184 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128845376.0000 - false_positives: 2376510.0000 - true_negatives: 185939824.0000 - false_negatives: 2359084.0000 - precision: 0.9819 - recall: 0.9820 - val_loss: 0.1008 - val_accuracy: 0.9136 - val_binary_iou: 0.8386 - val_true_positives: 41382984.0000 - val_false_positives: 5436228.0000 - val_true_negatives: 55434020.0000 - val_false_negatives: 3718468.0000 - val_precision: 0.8839 - val_recall: 0.9176\n",
      "Epoch 250/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0181 - accuracy: 0.9853 - binary_iou: 0.9701 - true_positives: 128839592.0000 - false_positives: 2366909.0000 - true_negatives: 185979264.0000 - false_negatives: 2334922.0000 - precision: 0.9820 - recall: 0.9822 - val_loss: 0.1021 - val_accuracy: 0.9129 - val_binary_iou: 0.8373 - val_true_positives: 41259492.0000 - val_false_positives: 5373843.0000 - val_true_negatives: 55485364.0000 - val_false_negatives: 3853007.0000 - val_precision: 0.8848 - val_recall: 0.9146\n",
      "Epoch 251/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0182 - accuracy: 0.9853 - binary_iou: 0.9701 - true_positives: 128808592.0000 - false_positives: 2354251.0000 - true_negatives: 186009024.0000 - false_negatives: 2348866.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1012 - val_accuracy: 0.9133 - val_binary_iou: 0.8379 - val_true_positives: 41212132.0000 - val_false_positives: 5313743.0000 - val_true_negatives: 55569548.0000 - val_false_negatives: 3876293.0000 - val_precision: 0.8858 - val_recall: 0.9140\n",
      "Epoch 252/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9702 - true_positives: 128824832.0000 - false_positives: 2342550.0000 - true_negatives: 186019552.0000 - false_negatives: 2333860.0000 - precision: 0.9821 - recall: 0.9822 - val_loss: 0.1012 - val_accuracy: 0.9136 - val_binary_iou: 0.8384 - val_true_positives: 41168880.0000 - val_false_positives: 5278496.0000 - val_true_negatives: 55648328.0000 - val_false_negatives: 3876021.0000 - val_precision: 0.8864 - val_recall: 0.9140\n",
      "Epoch 253/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0182 - accuracy: 0.9853 - binary_iou: 0.9701 - true_positives: 128831608.0000 - false_positives: 2347438.0000 - true_negatives: 185992032.0000 - false_negatives: 2349605.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1030 - val_accuracy: 0.9131 - val_binary_iou: 0.8376 - val_true_positives: 41345424.0000 - val_false_positives: 5422205.0000 - val_true_negatives: 55414896.0000 - val_false_negatives: 3789176.0000 - val_precision: 0.8841 - val_recall: 0.9160\n",
      "Epoch 254/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0182 - accuracy: 0.9853 - binary_iou: 0.9702 - true_positives: 128835280.0000 - false_positives: 2346162.0000 - true_negatives: 185997984.0000 - false_negatives: 2341314.0000 - precision: 0.9821 - recall: 0.9822 - val_loss: 0.1000 - val_accuracy: 0.9137 - val_binary_iou: 0.8388 - val_true_positives: 41558456.0000 - val_false_positives: 5612171.0000 - val_true_negatives: 55267864.0000 - val_false_negatives: 3533231.0000 - val_precision: 0.8810 - val_recall: 0.9216\n",
      "Epoch 255/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0180 - accuracy: 0.9854 - binary_iou: 0.9703 - true_positives: 128819480.0000 - false_positives: 2335887.0000 - true_negatives: 186039744.0000 - false_negatives: 2325649.0000 - precision: 0.9822 - recall: 0.9823 - val_loss: 0.1025 - val_accuracy: 0.9125 - val_binary_iou: 0.8364 - val_true_positives: 40985924.0000 - val_false_positives: 5158704.0000 - val_true_negatives: 55711396.0000 - val_false_negatives: 4115681.0000 - val_precision: 0.8882 - val_recall: 0.9087\n",
      "Epoch 256/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9699 - true_positives: 128746704.0000 - false_positives: 2361026.0000 - true_negatives: 186046096.0000 - false_negatives: 2367037.0000 - precision: 0.9820 - recall: 0.9819 - val_loss: 0.1042 - val_accuracy: 0.9108 - val_binary_iou: 0.8339 - val_true_positives: 41429272.0000 - val_false_positives: 5717670.0000 - val_true_negatives: 55093248.0000 - val_false_negatives: 3731512.0000 - val_precision: 0.8787 - val_recall: 0.9174\n",
      "Epoch 257/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9703 - true_positives: 128822544.0000 - false_positives: 2334346.0000 - true_negatives: 186027072.0000 - false_negatives: 2336896.0000 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1036 - val_accuracy: 0.9117 - val_binary_iou: 0.8353 - val_true_positives: 41258740.0000 - val_false_positives: 5564592.0000 - val_true_negatives: 55355640.0000 - val_false_negatives: 3792730.0000 - val_precision: 0.8812 - val_recall: 0.9158\n",
      "Epoch 258/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0181 - accuracy: 0.9854 - binary_iou: 0.9702 - true_positives: 128824040.0000 - false_positives: 2339183.0000 - true_negatives: 186019200.0000 - false_negatives: 2338353.0000 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1019 - val_accuracy: 0.9139 - val_binary_iou: 0.8387 - val_true_positives: 40863924.0000 - val_false_positives: 4908626.0000 - val_true_negatives: 55986960.0000 - val_false_negatives: 4212208.0000 - val_precision: 0.8928 - val_recall: 0.9066\n",
      "Epoch 259/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0178 - accuracy: 0.9856 - binary_iou: 0.9708 - true_positives: 128816712.0000 - false_positives: 2306100.0000 - true_negatives: 186113088.0000 - false_negatives: 2284908.0000 - precision: 0.9824 - recall: 0.9826 - val_loss: 0.1024 - val_accuracy: 0.9130 - val_binary_iou: 0.8373 - val_true_positives: 40980780.0000 - val_false_positives: 5098702.0000 - val_true_negatives: 55773096.0000 - val_false_negatives: 4119152.0000 - val_precision: 0.8893 - val_recall: 0.9087\n",
      "Epoch 260/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0179 - accuracy: 0.9856 - binary_iou: 0.9706 - true_positives: 128814880.0000 - false_positives: 2312651.0000 - true_negatives: 186090976.0000 - false_negatives: 2302253.0000 - precision: 0.9824 - recall: 0.9824 - val_loss: 0.1045 - val_accuracy: 0.9100 - val_binary_iou: 0.8325 - val_true_positives: 41394496.0000 - val_false_positives: 5901831.0000 - val_true_negatives: 55038992.0000 - val_false_negatives: 3636391.0000 - val_precision: 0.8752 - val_recall: 0.9192\n",
      "Epoch 261/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0178 - accuracy: 0.9856 - binary_iou: 0.9707 - true_positives: 128847008.0000 - false_positives: 2303257.0000 - true_negatives: 186076800.0000 - false_negatives: 2293678.0000 - precision: 0.9824 - recall: 0.9825 - val_loss: 0.1026 - val_accuracy: 0.9124 - val_binary_iou: 0.8364 - val_true_positives: 41227856.0000 - val_false_positives: 5439340.0000 - val_true_negatives: 55458048.0000 - val_false_negatives: 3846476.0000 - val_precision: 0.8834 - val_recall: 0.9147\n",
      "Epoch 262/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0177 - accuracy: 0.9857 - binary_iou: 0.9708 - true_positives: 128868848.0000 - false_positives: 2307245.0000 - true_negatives: 186070912.0000 - false_negatives: 2273777.0000 - precision: 0.9824 - recall: 0.9827 - val_loss: 0.1031 - val_accuracy: 0.9115 - val_binary_iou: 0.8352 - val_true_positives: 41532200.0000 - val_false_positives: 5814909.0000 - val_true_negatives: 55063456.0000 - val_false_negatives: 3561162.0000 - val_precision: 0.8772 - val_recall: 0.9210\n",
      "Epoch 263/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0176 - accuracy: 0.9858 - binary_iou: 0.9711 - true_positives: 128855776.0000 - false_positives: 2267141.0000 - true_negatives: 186123680.0000 - false_negatives: 2274211.0000 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.1026 - val_accuracy: 0.9121 - val_binary_iou: 0.8359 - val_true_positives: 41109948.0000 - val_false_positives: 5326599.0000 - val_true_negatives: 55549224.0000 - val_false_negatives: 3985932.0000 - val_precision: 0.8853 - val_recall: 0.9116\n",
      "Epoch 264/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0175 - accuracy: 0.9858 - binary_iou: 0.9712 - true_positives: 128914920.0000 - false_positives: 2261745.0000 - true_negatives: 186081408.0000 - false_negatives: 2262678.0000 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.1031 - val_accuracy: 0.9121 - val_binary_iou: 0.8360 - val_true_positives: 41472400.0000 - val_false_positives: 5623789.0000 - val_true_negatives: 55181692.0000 - val_false_negatives: 3693831.0000 - val_precision: 0.8806 - val_recall: 0.9182\n",
      "Epoch 265/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0175 - accuracy: 0.9858 - binary_iou: 0.9711 - true_positives: 128874000.0000 - false_positives: 2277383.0000 - true_negatives: 186109808.0000 - false_negatives: 2259619.0000 - precision: 0.9826 - recall: 0.9828 - val_loss: 0.1031 - val_accuracy: 0.9122 - val_binary_iou: 0.8362 - val_true_positives: 41331496.0000 - val_false_positives: 5543985.0000 - val_true_negatives: 55340580.0000 - val_false_negatives: 3755648.0000 - val_precision: 0.8817 - val_recall: 0.9167\n",
      "Epoch 266/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0174 - accuracy: 0.9859 - binary_iou: 0.9714 - true_positives: 128850368.0000 - false_positives: 2239056.0000 - true_negatives: 186174912.0000 - false_negatives: 2256404.0000 - precision: 0.9829 - recall: 0.9828 - val_loss: 0.1030 - val_accuracy: 0.9121 - val_binary_iou: 0.8360 - val_true_positives: 41277456.0000 - val_false_positives: 5591826.0000 - val_true_negatives: 55380752.0000 - val_false_negatives: 3721699.0000 - val_precision: 0.8807 - val_recall: 0.9173\n",
      "Epoch 267/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0174 - accuracy: 0.9859 - binary_iou: 0.9714 - true_positives: 128863824.0000 - false_positives: 2240423.0000 - true_negatives: 186163312.0000 - false_negatives: 2253182.0000 - precision: 0.9829 - recall: 0.9828 - val_loss: 0.1039 - val_accuracy: 0.9106 - val_binary_iou: 0.8336 - val_true_positives: 41438132.0000 - val_false_positives: 5882904.0000 - val_true_negatives: 55063520.0000 - val_false_negatives: 3587170.0000 - val_precision: 0.8757 - val_recall: 0.9203\n",
      "Epoch 268/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0173 - accuracy: 0.9860 - binary_iou: 0.9715 - true_positives: 128920864.0000 - false_positives: 2242538.0000 - true_negatives: 186128368.0000 - false_negatives: 2228907.0000 - precision: 0.9829 - recall: 0.9830 - val_loss: 0.1011 - val_accuracy: 0.9144 - val_binary_iou: 0.8396 - val_true_positives: 41026884.0000 - val_false_positives: 5118902.0000 - val_true_negatives: 55870460.0000 - val_false_negatives: 3955473.0000 - val_precision: 0.8891 - val_recall: 0.9121\n",
      "Epoch 269/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0173 - accuracy: 0.9861 - binary_iou: 0.9716 - true_positives: 128903576.0000 - false_positives: 2203503.0000 - true_negatives: 186161376.0000 - false_negatives: 2252321.0000 - precision: 0.9832 - recall: 0.9828 - val_loss: 0.1008 - val_accuracy: 0.9137 - val_binary_iou: 0.8385 - val_true_positives: 41227180.0000 - val_false_positives: 5324417.0000 - val_true_negatives: 55595432.0000 - val_false_negatives: 3824683.0000 - val_precision: 0.8856 - val_recall: 0.9151\n",
      "Epoch 270/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0172 - accuracy: 0.9861 - binary_iou: 0.9717 - true_positives: 128838088.0000 - false_positives: 2233524.0000 - true_negatives: 186241120.0000 - false_negatives: 2208000.0000 - precision: 0.9830 - recall: 0.9832 - val_loss: 0.1037 - val_accuracy: 0.9111 - val_binary_iou: 0.8343 - val_true_positives: 41232100.0000 - val_false_positives: 5516522.0000 - val_true_negatives: 55322272.0000 - val_false_negatives: 3900816.0000 - val_precision: 0.8820 - val_recall: 0.9136\n",
      "Epoch 271/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0172 - accuracy: 0.9861 - binary_iou: 0.9718 - true_positives: 128870152.0000 - false_positives: 2199481.0000 - true_negatives: 186219664.0000 - false_negatives: 2231422.0000 - precision: 0.9832 - recall: 0.9830 - val_loss: 0.1043 - val_accuracy: 0.9105 - val_binary_iou: 0.8334 - val_true_positives: 41338464.0000 - val_false_positives: 5709255.0000 - val_true_negatives: 55151136.0000 - val_false_negatives: 3772874.0000 - val_precision: 0.8786 - val_recall: 0.9164\n",
      "Epoch 272/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0170 - accuracy: 0.9862 - binary_iou: 0.9719 - true_positives: 128965576.0000 - false_positives: 2190733.0000 - true_negatives: 186152080.0000 - false_negatives: 2212349.0000 - precision: 0.9833 - recall: 0.9831 - val_loss: 0.1032 - val_accuracy: 0.9116 - val_binary_iou: 0.8351 - val_true_positives: 41210652.0000 - val_false_positives: 5486837.0000 - val_true_negatives: 55394956.0000 - val_false_negatives: 3879256.0000 - val_precision: 0.8825 - val_recall: 0.9140\n",
      "Epoch 273/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0173 - accuracy: 0.9860 - binary_iou: 0.9715 - true_positives: 128881480.0000 - false_positives: 2243875.0000 - true_negatives: 186164544.0000 - false_negatives: 2230859.0000 - precision: 0.9829 - recall: 0.9830 - val_loss: 0.1027 - val_accuracy: 0.9117 - val_binary_iou: 0.8351 - val_true_positives: 41089552.0000 - val_false_positives: 5365814.0000 - val_true_negatives: 55522336.0000 - val_false_negatives: 3994009.0000 - val_precision: 0.8845 - val_recall: 0.9114\n",
      "Epoch 274/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0173 - accuracy: 0.9860 - binary_iou: 0.9715 - true_positives: 128905936.0000 - false_positives: 2228326.0000 - true_negatives: 186142768.0000 - false_negatives: 2243780.0000 - precision: 0.9830 - recall: 0.9829 - val_loss: 0.1057 - val_accuracy: 0.9094 - val_binary_iou: 0.8315 - val_true_positives: 41251760.0000 - val_false_positives: 5687318.0000 - val_true_negatives: 55122448.0000 - val_false_negatives: 3910187.0000 - val_precision: 0.8788 - val_recall: 0.9134\n",
      "Epoch 275/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0171 - accuracy: 0.9862 - binary_iou: 0.9718 - true_positives: 128851648.0000 - false_positives: 2216678.0000 - true_negatives: 186251408.0000 - false_negatives: 2200980.0000 - precision: 0.9831 - recall: 0.9832 - val_loss: 0.1041 - val_accuracy: 0.9106 - val_binary_iou: 0.8334 - val_true_positives: 41352004.0000 - val_false_positives: 5705858.0000 - val_true_negatives: 55141264.0000 - val_false_negatives: 3772581.0000 - val_precision: 0.8787 - val_recall: 0.9164\n",
      "Epoch 276/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0169 - accuracy: 0.9863 - binary_iou: 0.9721 - true_positives: 128912576.0000 - false_positives: 2185884.0000 - true_negatives: 186238176.0000 - false_negatives: 2184099.0000 - precision: 0.9833 - recall: 0.9833 - val_loss: 0.1028 - val_accuracy: 0.9119 - val_binary_iou: 0.8356 - val_true_positives: 41206864.0000 - val_false_positives: 5395916.0000 - val_true_negatives: 55429992.0000 - val_false_negatives: 3938935.0000 - val_precision: 0.8842 - val_recall: 0.9128\n",
      "Epoch 277/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0170 - accuracy: 0.9862 - binary_iou: 0.9720 - true_positives: 128961880.0000 - false_positives: 2209789.0000 - true_negatives: 186158576.0000 - false_negatives: 2190582.0000 - precision: 0.9832 - recall: 0.9833 - val_loss: 0.1044 - val_accuracy: 0.9107 - val_binary_iou: 0.8336 - val_true_positives: 41308928.0000 - val_false_positives: 5713575.0000 - val_true_negatives: 55198408.0000 - val_false_negatives: 3750798.0000 - val_precision: 0.8785 - val_recall: 0.9168\n",
      "Epoch 278/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0169 - accuracy: 0.9864 - binary_iou: 0.9722 - true_positives: 128898192.0000 - false_positives: 2186204.0000 - true_negatives: 186265104.0000 - false_negatives: 2171243.0000 - precision: 0.9833 - recall: 0.9834 - val_loss: 0.1030 - val_accuracy: 0.9124 - val_binary_iou: 0.8363 - val_true_positives: 41045072.0000 - val_false_positives: 5296046.0000 - val_true_negatives: 55646476.0000 - val_false_negatives: 3984132.0000 - val_precision: 0.8857 - val_recall: 0.9115\n",
      "Epoch 279/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0168 - accuracy: 0.9864 - binary_iou: 0.9723 - true_positives: 128867056.0000 - false_positives: 2177057.0000 - true_negatives: 186303360.0000 - false_negatives: 2173380.0000 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.1025 - val_accuracy: 0.9124 - val_binary_iou: 0.8363 - val_true_positives: 41088288.0000 - val_false_positives: 5338820.0000 - val_true_negatives: 55600048.0000 - val_false_negatives: 3944550.0000 - val_precision: 0.8850 - val_recall: 0.9124\n",
      "Epoch 280/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0168 - accuracy: 0.9864 - binary_iou: 0.9723 - true_positives: 128952000.0000 - false_positives: 2180714.0000 - true_negatives: 186219984.0000 - false_negatives: 2168057.0000 - precision: 0.9834 - recall: 0.9835 - val_loss: 0.1021 - val_accuracy: 0.9129 - val_binary_iou: 0.8375 - val_true_positives: 41433532.0000 - val_false_positives: 5476479.0000 - val_true_negatives: 55311532.0000 - val_false_negatives: 3750181.0000 - val_precision: 0.8833 - val_recall: 0.9170\n",
      "Epoch 281/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0167 - accuracy: 0.9865 - binary_iou: 0.9724 - true_positives: 128911280.0000 - false_positives: 2171501.0000 - true_negatives: 186281264.0000 - false_negatives: 2156706.0000 - precision: 0.9834 - recall: 0.9835 - val_loss: 0.1050 - val_accuracy: 0.9107 - val_binary_iou: 0.8335 - val_true_positives: 41204292.0000 - val_false_positives: 5651177.0000 - val_true_negatives: 55300400.0000 - val_false_negatives: 3815819.0000 - val_precision: 0.8794 - val_recall: 0.9152\n",
      "Epoch 282/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0167 - accuracy: 0.9865 - binary_iou: 0.9724 - true_positives: 128875480.0000 - false_positives: 2142287.0000 - true_negatives: 186322816.0000 - false_negatives: 2180238.0000 - precision: 0.9836 - recall: 0.9834 - val_loss: 0.1019 - val_accuracy: 0.9132 - val_binary_iou: 0.8378 - val_true_positives: 41143792.0000 - val_false_positives: 5285944.0000 - val_true_negatives: 55632976.0000 - val_false_negatives: 3908993.0000 - val_precision: 0.8862 - val_recall: 0.9132\n",
      "Epoch 283/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0165 - accuracy: 0.9866 - binary_iou: 0.9728 - true_positives: 129030032.0000 - false_positives: 2153209.0000 - true_negatives: 186221248.0000 - false_negatives: 2116367.0000 - precision: 0.9836 - recall: 0.9839 - val_loss: 0.1031 - val_accuracy: 0.9113 - val_binary_iou: 0.8346 - val_true_positives: 41432144.0000 - val_false_positives: 5759065.0000 - val_true_negatives: 55135048.0000 - val_false_negatives: 3645453.0000 - val_precision: 0.8780 - val_recall: 0.9191\n",
      "Epoch 284/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0166 - accuracy: 0.9866 - binary_iou: 0.9727 - true_positives: 128972784.0000 - false_positives: 2139742.0000 - true_negatives: 186258544.0000 - false_negatives: 2149728.0000 - precision: 0.9837 - recall: 0.9836 - val_loss: 0.1036 - val_accuracy: 0.9105 - val_binary_iou: 0.8334 - val_true_positives: 41601040.0000 - val_false_positives: 5943569.0000 - val_true_negatives: 54881828.0000 - val_false_negatives: 3545273.0000 - val_precision: 0.8750 - val_recall: 0.9215\n",
      "Epoch 285/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0165 - accuracy: 0.9866 - binary_iou: 0.9727 - true_positives: 128969920.0000 - false_positives: 2138626.0000 - true_negatives: 186275168.0000 - false_negatives: 2137023.0000 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.1033 - val_accuracy: 0.9112 - val_binary_iou: 0.8346 - val_true_positives: 41528100.0000 - val_false_positives: 5805299.0000 - val_true_negatives: 55034008.0000 - val_false_negatives: 3604300.0000 - val_precision: 0.8774 - val_recall: 0.9201\n",
      "Epoch 286/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0166 - accuracy: 0.9866 - binary_iou: 0.9727 - true_positives: 128948728.0000 - false_positives: 2148515.0000 - true_negatives: 186291760.0000 - false_negatives: 2131748.0000 - precision: 0.9836 - recall: 0.9837 - val_loss: 0.1010 - val_accuracy: 0.9134 - val_binary_iou: 0.8382 - val_true_positives: 41382016.0000 - val_false_positives: 5416679.0000 - val_true_negatives: 55411428.0000 - val_false_negatives: 3761597.0000 - val_precision: 0.8843 - val_recall: 0.9167\n",
      "Epoch 287/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0166 - accuracy: 0.9866 - binary_iou: 0.9727 - true_positives: 129049248.0000 - false_positives: 2140774.0000 - true_negatives: 186186736.0000 - false_negatives: 2143977.0000 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.1038 - val_accuracy: 0.9118 - val_binary_iou: 0.8354 - val_true_positives: 41239436.0000 - val_false_positives: 5486440.0000 - val_true_negatives: 55384752.0000 - val_false_negatives: 3861077.0000 - val_precision: 0.8826 - val_recall: 0.9144\n",
      "Epoch 288/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0166 - accuracy: 0.9865 - binary_iou: 0.9726 - true_positives: 129027704.0000 - false_positives: 2160723.0000 - true_negatives: 186193664.0000 - false_negatives: 2138736.0000 - precision: 0.9835 - recall: 0.9837 - val_loss: 0.1056 - val_accuracy: 0.9104 - val_binary_iou: 0.8330 - val_true_positives: 41239256.0000 - val_false_positives: 5797634.0000 - val_true_negatives: 55235032.0000 - val_false_negatives: 3699775.0000 - val_precision: 0.8767 - val_recall: 0.9177\n",
      "Epoch 289/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0165 - accuracy: 0.9867 - binary_iou: 0.9728 - true_positives: 128993200.0000 - false_positives: 2127593.0000 - true_negatives: 186262144.0000 - false_negatives: 2137788.0000 - precision: 0.9838 - recall: 0.9837 - val_loss: 0.1031 - val_accuracy: 0.9116 - val_binary_iou: 0.8349 - val_true_positives: 41072876.0000 - val_false_positives: 5403154.0000 - val_true_negatives: 55526012.0000 - val_false_negatives: 3969671.0000 - val_precision: 0.8837 - val_recall: 0.9119\n",
      "Epoch 290/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0165 - accuracy: 0.9867 - binary_iou: 0.9728 - true_positives: 128981448.0000 - false_positives: 2134820.0000 - true_negatives: 186274960.0000 - false_negatives: 2129579.0000 - precision: 0.9837 - recall: 0.9838 - val_loss: 0.1046 - val_accuracy: 0.9093 - val_binary_iou: 0.8315 - val_true_positives: 41495928.0000 - val_false_positives: 6011614.0000 - val_true_negatives: 54867552.0000 - val_false_negatives: 3596648.0000 - val_precision: 0.8735 - val_recall: 0.9202\n",
      "Epoch 291/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0162 - accuracy: 0.9868 - binary_iou: 0.9732 - true_positives: 129068272.0000 - false_positives: 2108586.0000 - true_negatives: 186242896.0000 - false_negatives: 2100963.0000 - precision: 0.9839 - recall: 0.9840 - val_loss: 0.1020 - val_accuracy: 0.9129 - val_binary_iou: 0.8371 - val_true_positives: 41097168.0000 - val_false_positives: 5313236.0000 - val_true_negatives: 55643092.0000 - val_false_negatives: 3918206.0000 - val_precision: 0.8855 - val_recall: 0.9130\n",
      "Epoch 292/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0162 - accuracy: 0.9868 - binary_iou: 0.9732 - true_positives: 129142400.0000 - false_positives: 2109084.0000 - true_negatives: 186167536.0000 - false_negatives: 2101733.0000 - precision: 0.9839 - recall: 0.9840 - val_loss: 0.1039 - val_accuracy: 0.9111 - val_binary_iou: 0.8344 - val_true_positives: 41528660.0000 - val_false_positives: 5847876.0000 - val_true_negatives: 55017744.0000 - val_false_negatives: 3577435.0000 - val_precision: 0.8766 - val_recall: 0.9207\n",
      "Epoch 293/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0162 - accuracy: 0.9869 - binary_iou: 0.9733 - true_positives: 128999688.0000 - false_positives: 2093246.0000 - true_negatives: 186338496.0000 - false_negatives: 2089404.0000 - precision: 0.9840 - recall: 0.9841 - val_loss: 0.1046 - val_accuracy: 0.9100 - val_binary_iou: 0.8326 - val_true_positives: 41598292.0000 - val_false_positives: 6030396.0000 - val_true_negatives: 54834164.0000 - val_false_negatives: 3508861.0000 - val_precision: 0.8734 - val_recall: 0.9222\n",
      "Epoch 294/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0162 - accuracy: 0.9869 - binary_iou: 0.9733 - true_positives: 129050744.0000 - false_positives: 2097421.0000 - true_negatives: 186289888.0000 - false_negatives: 2082686.0000 - precision: 0.9840 - recall: 0.9841 - val_loss: 0.1008 - val_accuracy: 0.9132 - val_binary_iou: 0.8378 - val_true_positives: 41394884.0000 - val_false_positives: 5402161.0000 - val_true_negatives: 55376448.0000 - val_false_negatives: 3798227.0000 - val_precision: 0.8846 - val_recall: 0.9160\n",
      "Epoch 295/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0161 - accuracy: 0.9869 - binary_iou: 0.9734 - true_positives: 129037136.0000 - false_positives: 2083081.0000 - true_negatives: 186308048.0000 - false_negatives: 2092610.0000 - precision: 0.9841 - recall: 0.9840 - val_loss: 0.1035 - val_accuracy: 0.9112 - val_binary_iou: 0.8344 - val_true_positives: 41301692.0000 - val_false_positives: 5612006.0000 - val_true_negatives: 55258080.0000 - val_false_negatives: 3799923.0000 - val_precision: 0.8804 - val_recall: 0.9157\n",
      "Epoch 296/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0162 - accuracy: 0.9869 - binary_iou: 0.9732 - true_positives: 129033504.0000 - false_positives: 2115259.0000 - true_negatives: 186287488.0000 - false_negatives: 2084493.0000 - precision: 0.9839 - recall: 0.9841 - val_loss: 0.1019 - val_accuracy: 0.9136 - val_binary_iou: 0.8385 - val_true_positives: 41295516.0000 - val_false_positives: 5362499.0000 - val_true_negatives: 55519864.0000 - val_false_negatives: 3793844.0000 - val_precision: 0.8851 - val_recall: 0.9159\n",
      "Epoch 297/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0161 - accuracy: 0.9869 - binary_iou: 0.9734 - true_positives: 128990032.0000 - false_positives: 2075810.0000 - true_negatives: 186357760.0000 - false_negatives: 2097108.0000 - precision: 0.9842 - recall: 0.9840 - val_loss: 0.1033 - val_accuracy: 0.9118 - val_binary_iou: 0.8356 - val_true_positives: 41375980.0000 - val_false_positives: 5631209.0000 - val_true_negatives: 55251800.0000 - val_false_negatives: 3712716.0000 - val_precision: 0.8802 - val_recall: 0.9177\n",
      "Epoch 298/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0162 - accuracy: 0.9869 - binary_iou: 0.9733 - true_positives: 128985752.0000 - false_positives: 2093869.0000 - true_negatives: 186352560.0000 - false_negatives: 2088583.0000 - precision: 0.9840 - recall: 0.9841 - val_loss: 0.1016 - val_accuracy: 0.9140 - val_binary_iou: 0.8389 - val_true_positives: 40989720.0000 - val_false_positives: 5099157.0000 - val_true_negatives: 55868928.0000 - val_false_negatives: 4013909.0000 - val_precision: 0.8894 - val_recall: 0.9108\n",
      "Epoch 299/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0160 - accuracy: 0.9870 - binary_iou: 0.9736 - true_positives: 129132840.0000 - false_positives: 2067463.0000 - true_negatives: 186241184.0000 - false_negatives: 2079301.0000 - precision: 0.9842 - recall: 0.9842 - val_loss: 0.1010 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41309160.0000 - val_false_positives: 5349180.0000 - val_true_negatives: 55519552.0000 - val_false_negatives: 3793821.0000 - val_precision: 0.8854 - val_recall: 0.9159\n",
      "Epoch 300/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0161 - accuracy: 0.9870 - binary_iou: 0.9735 - true_positives: 128967304.0000 - false_positives: 2061204.0000 - true_negatives: 186401760.0000 - false_negatives: 2090464.0000 - precision: 0.9843 - recall: 0.9840 - val_loss: 0.1032 - val_accuracy: 0.9118 - val_binary_iou: 0.8355 - val_true_positives: 41205972.0000 - val_false_positives: 5433634.0000 - val_true_negatives: 55424128.0000 - val_false_negatives: 3907984.0000 - val_precision: 0.8835 - val_recall: 0.9134\n",
      "Epoch 301/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0160 - accuracy: 0.9870 - binary_iou: 0.9735 - true_positives: 129034160.0000 - false_positives: 2062859.0000 - true_negatives: 186338848.0000 - false_negatives: 2084921.0000 - precision: 0.9843 - recall: 0.9841 - val_loss: 0.1025 - val_accuracy: 0.9120 - val_binary_iou: 0.8359 - val_true_positives: 41482232.0000 - val_false_positives: 5644470.0000 - val_true_negatives: 55162976.0000 - val_false_negatives: 3682026.0000 - val_precision: 0.8802 - val_recall: 0.9185\n",
      "Epoch 302/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0164 - accuracy: 0.9868 - binary_iou: 0.9730 - true_positives: 129012176.0000 - false_positives: 2137223.0000 - true_negatives: 186281776.0000 - false_negatives: 2089647.0000 - precision: 0.9837 - recall: 0.9841 - val_loss: 0.1034 - val_accuracy: 0.9120 - val_binary_iou: 0.8360 - val_true_positives: 41478840.0000 - val_false_positives: 5672206.0000 - val_true_negatives: 55170692.0000 - val_false_negatives: 3649964.0000 - val_precision: 0.8797 - val_recall: 0.9191\n",
      "Epoch 303/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0160 - accuracy: 0.9870 - binary_iou: 0.9736 - true_positives: 129097168.0000 - false_positives: 2075285.0000 - true_negatives: 186285904.0000 - false_negatives: 2062490.0000 - precision: 0.9842 - recall: 0.9843 - val_loss: 0.1032 - val_accuracy: 0.9117 - val_binary_iou: 0.8353 - val_true_positives: 41407952.0000 - val_false_positives: 5688653.0000 - val_true_negatives: 55204500.0000 - val_false_negatives: 3670599.0000 - val_precision: 0.8792 - val_recall: 0.9186\n",
      "Epoch 304/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0160 - accuracy: 0.9871 - binary_iou: 0.9737 - true_positives: 129041992.0000 - false_positives: 2066136.0000 - true_negatives: 186362784.0000 - false_negatives: 2049791.0000 - precision: 0.9842 - recall: 0.9844 - val_loss: 0.1023 - val_accuracy: 0.9130 - val_binary_iou: 0.8374 - val_true_positives: 41296316.0000 - val_false_positives: 5405021.0000 - val_true_negatives: 55451008.0000 - val_false_negatives: 3819362.0000 - val_precision: 0.8843 - val_recall: 0.9153\n",
      "Epoch 305/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0158 - accuracy: 0.9872 - binary_iou: 0.9740 - true_positives: 129032608.0000 - false_positives: 2039581.0000 - true_negatives: 186408816.0000 - false_negatives: 2039738.0000 - precision: 0.9844 - recall: 0.9844 - val_loss: 0.1019 - val_accuracy: 0.9129 - val_binary_iou: 0.8373 - val_true_positives: 41313616.0000 - val_false_positives: 5493113.0000 - val_true_negatives: 55425788.0000 - val_false_negatives: 3739204.0000 - val_precision: 0.8826 - val_recall: 0.9170\n",
      "Epoch 306/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0160 - accuracy: 0.9871 - binary_iou: 0.9737 - true_positives: 129026136.0000 - false_positives: 2061730.0000 - true_negatives: 186370544.0000 - false_negatives: 2062426.0000 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.1009 - val_accuracy: 0.9141 - val_binary_iou: 0.8392 - val_true_positives: 41117096.0000 - val_false_positives: 5081017.0000 - val_true_negatives: 55755276.0000 - val_false_negatives: 4018319.0000 - val_precision: 0.8900 - val_recall: 0.9110\n",
      "Epoch 307/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0158 - accuracy: 0.9873 - binary_iou: 0.9740 - true_positives: 129091240.0000 - false_positives: 2014632.0000 - true_negatives: 186361232.0000 - false_negatives: 2053639.0000 - precision: 0.9846 - recall: 0.9843 - val_loss: 0.1016 - val_accuracy: 0.9130 - val_binary_iou: 0.8376 - val_true_positives: 41546576.0000 - val_false_positives: 5615246.0000 - val_true_negatives: 55201560.0000 - val_false_negatives: 3608333.0000 - val_precision: 0.8809 - val_recall: 0.9201\n",
      "Epoch 308/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0157 - accuracy: 0.9873 - binary_iou: 0.9741 - true_positives: 129128720.0000 - false_positives: 2027529.0000 - true_negatives: 186335408.0000 - false_negatives: 2029154.0000 - precision: 0.9845 - recall: 0.9845 - val_loss: 0.1019 - val_accuracy: 0.9128 - val_binary_iou: 0.8372 - val_true_positives: 41423016.0000 - val_false_positives: 5532034.0000 - val_true_negatives: 55303568.0000 - val_false_negatives: 3713090.0000 - val_precision: 0.8822 - val_recall: 0.9177\n",
      "Epoch 309/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9874 - binary_iou: 0.9744 - true_positives: 129156024.0000 - false_positives: 2001185.0000 - true_negatives: 186348192.0000 - false_negatives: 2015235.0000 - precision: 0.9847 - recall: 0.9846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0155 - accuracy: 0.9874 - binary_iou: 0.9744 - true_positives: 129156024.0000 - false_positives: 2001185.0000 - true_negatives: 186348192.0000 - false_negatives: 2015235.0000 - precision: 0.9847 - recall: 0.9846 - val_loss: 0.0996 - val_accuracy: 0.9149 - val_binary_iou: 0.8405 - val_true_positives: 41139384.0000 - val_false_positives: 5103132.0000 - val_true_negatives: 55810500.0000 - val_false_negatives: 3918704.0000 - val_precision: 0.8896 - val_recall: 0.9130\n",
      "Epoch 310/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0156 - accuracy: 0.9874 - binary_iou: 0.9743 - true_positives: 129104832.0000 - false_positives: 2016778.0000 - true_negatives: 186389984.0000 - false_negatives: 2009150.0000 - precision: 0.9846 - recall: 0.9847 - val_loss: 0.1025 - val_accuracy: 0.9126 - val_binary_iou: 0.8368 - val_true_positives: 41314492.0000 - val_false_positives: 5486952.0000 - val_true_negatives: 55397384.0000 - val_false_negatives: 3772896.0000 - val_precision: 0.8828 - val_recall: 0.9163\n",
      "Epoch 311/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0155 - accuracy: 0.9874 - binary_iou: 0.9743 - true_positives: 129115168.0000 - false_positives: 2019409.0000 - true_negatives: 186372624.0000 - false_negatives: 2013554.0000 - precision: 0.9846 - recall: 0.9846 - val_loss: 0.1028 - val_accuracy: 0.9123 - val_binary_iou: 0.8364 - val_true_positives: 41319176.0000 - val_false_positives: 5539425.0000 - val_true_negatives: 55363976.0000 - val_false_negatives: 3749147.0000 - val_precision: 0.8818 - val_recall: 0.9168\n",
      "Epoch 312/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0155 - accuracy: 0.9875 - binary_iou: 0.9744 - true_positives: 129117496.0000 - false_positives: 1997062.0000 - true_negatives: 186395184.0000 - false_negatives: 2011057.0000 - precision: 0.9848 - recall: 0.9847 - val_loss: 0.1006 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41410064.0000 - val_false_positives: 5331153.0000 - val_true_negatives: 55488948.0000 - val_false_negatives: 3741548.0000 - val_precision: 0.8859 - val_recall: 0.9171\n",
      "Epoch 313/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0156 - accuracy: 0.9874 - binary_iou: 0.9744 - true_positives: 129146440.0000 - false_positives: 2012833.0000 - true_negatives: 186357008.0000 - false_negatives: 2004486.0000 - precision: 0.9847 - recall: 0.9847 - val_loss: 0.1012 - val_accuracy: 0.9133 - val_binary_iou: 0.8381 - val_true_positives: 41475440.0000 - val_false_positives: 5551537.0000 - val_true_negatives: 55305860.0000 - val_false_negatives: 3638883.0000 - val_precision: 0.8819 - val_recall: 0.9193\n",
      "Epoch 314/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9875 - binary_iou: 0.9745 - true_positives: 129089960.0000 - false_positives: 1994715.0000 - true_negatives: 186433312.0000 - false_negatives: 2002756.0000 - precision: 0.9848 - recall: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 457ms/step - loss: 0.0155 - accuracy: 0.9875 - binary_iou: 0.9745 - true_positives: 129089960.0000 - false_positives: 1994715.0000 - true_negatives: 186433312.0000 - false_negatives: 2002756.0000 - precision: 0.9848 - recall: 0.9847 - val_loss: 0.1001 - val_accuracy: 0.9150 - val_binary_iou: 0.8408 - val_true_positives: 41256684.0000 - val_false_positives: 5139006.0000 - val_true_negatives: 55706004.0000 - val_false_negatives: 3870024.0000 - val_precision: 0.8892 - val_recall: 0.9142\n",
      "Epoch 315/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0154 - accuracy: 0.9875 - binary_iou: 0.9745 - true_positives: 129195280.0000 - false_positives: 1997097.0000 - true_negatives: 186333152.0000 - false_negatives: 1995262.0000 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.1009 - val_accuracy: 0.9136 - val_binary_iou: 0.8385 - val_true_positives: 41496720.0000 - val_false_positives: 5457018.0000 - val_true_negatives: 55313888.0000 - val_false_negatives: 3704080.0000 - val_precision: 0.8838 - val_recall: 0.9181\n",
      "Epoch 316/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0154 - accuracy: 0.9876 - binary_iou: 0.9747 - true_positives: 129186144.0000 - false_positives: 1971560.0000 - true_negatives: 186364800.0000 - false_negatives: 1998275.0000 - precision: 0.9850 - recall: 0.9848 - val_loss: 0.1028 - val_accuracy: 0.9117 - val_binary_iou: 0.8354 - val_true_positives: 41451512.0000 - val_false_positives: 5768214.0000 - val_true_negatives: 55164668.0000 - val_false_negatives: 3587325.0000 - val_precision: 0.8778 - val_recall: 0.9204\n",
      "Epoch 317/500\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0154 - accuracy: 0.9876 - binary_iou: 0.9746 - true_positives: 129145840.0000 - false_positives: 1990831.0000 - true_negatives: 186403120.0000 - false_negatives: 1981004.0000 - precision: 0.9848 - recall: 0.9849 - val_loss: 0.1029 - val_accuracy: 0.9121 - val_binary_iou: 0.8361 - val_true_positives: 41499060.0000 - val_false_positives: 5705377.0000 - val_true_negatives: 55158400.0000 - val_false_negatives: 3608864.0000 - val_precision: 0.8791 - val_recall: 0.9200\n",
      "Epoch 318/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9874 - binary_iou: 0.9744 - true_positives: 129073304.0000 - false_positives: 2019985.0000 - true_negatives: 186431056.0000 - false_negatives: 1996437.0000 - precision: 0.9846 - recall: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0155 - accuracy: 0.9874 - binary_iou: 0.9744 - true_positives: 129073304.0000 - false_positives: 2019985.0000 - true_negatives: 186431056.0000 - false_negatives: 1996437.0000 - precision: 0.9846 - recall: 0.9848 - val_loss: 0.0997 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41325996.0000 - val_false_positives: 5222807.0000 - val_true_negatives: 55650240.0000 - val_false_negatives: 3772665.0000 - val_precision: 0.8878 - val_recall: 0.9163\n",
      "Epoch 319/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0154 - accuracy: 0.9875 - binary_iou: 0.9746 - true_positives: 129134952.0000 - false_positives: 1988521.0000 - true_negatives: 186406080.0000 - false_negatives: 1991171.0000 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.1019 - val_accuracy: 0.9139 - val_binary_iou: 0.8390 - val_true_positives: 41277516.0000 - val_false_positives: 5282199.0000 - val_true_negatives: 55573384.0000 - val_false_negatives: 3838605.0000 - val_precision: 0.8866 - val_recall: 0.9149\n",
      "Epoch 320/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0153 - accuracy: 0.9876 - binary_iou: 0.9746 - true_positives: 129204688.0000 - false_positives: 1979624.0000 - true_negatives: 186340304.0000 - false_negatives: 1996118.0000 - precision: 0.9849 - recall: 0.9848 - val_loss: 0.1025 - val_accuracy: 0.9128 - val_binary_iou: 0.8372 - val_true_positives: 41363816.0000 - val_false_positives: 5536410.0000 - val_true_negatives: 55365212.0000 - val_false_negatives: 3706278.0000 - val_precision: 0.8820 - val_recall: 0.9178\n",
      "Epoch 321/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0153 - accuracy: 0.9876 - binary_iou: 0.9748 - true_positives: 129194912.0000 - false_positives: 1986771.0000 - true_negatives: 186371488.0000 - false_negatives: 1967562.0000 - precision: 0.9849 - recall: 0.9850 - val_loss: 0.1030 - val_accuracy: 0.9121 - val_binary_iou: 0.8360 - val_true_positives: 41345308.0000 - val_false_positives: 5547634.0000 - val_true_negatives: 55314088.0000 - val_false_negatives: 3764675.0000 - val_precision: 0.8817 - val_recall: 0.9165\n",
      "Epoch 322/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0152 - accuracy: 0.9877 - binary_iou: 0.9749 - true_positives: 129132800.0000 - false_positives: 1973955.0000 - true_negatives: 186451264.0000 - false_negatives: 1962727.0000 - precision: 0.9849 - recall: 0.9850 - val_loss: 0.1001 - val_accuracy: 0.9146 - val_binary_iou: 0.8401 - val_true_positives: 41261772.0000 - val_false_positives: 5280461.0000 - val_true_negatives: 55654896.0000 - val_false_negatives: 3774584.0000 - val_precision: 0.8865 - val_recall: 0.9162\n",
      "Epoch 323/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0150 - accuracy: 0.9878 - binary_iou: 0.9752 - true_positives: 129220096.0000 - false_positives: 1942764.0000 - true_negatives: 186410640.0000 - false_negatives: 1947304.0000 - precision: 0.9852 - recall: 0.9852 - val_loss: 0.1017 - val_accuracy: 0.9135 - val_binary_iou: 0.8384 - val_true_positives: 41450860.0000 - val_false_positives: 5475692.0000 - val_true_negatives: 55353352.0000 - val_false_negatives: 3691804.0000 - val_precision: 0.8833 - val_recall: 0.9182\n",
      "Epoch 324/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9879 - binary_iou: 0.9752 - true_positives: 129148232.0000 - false_positives: 1955364.0000 - true_negatives: 186491024.0000 - false_negatives: 1926121.0000 - precision: 0.9851 - recall: 0.9853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 455ms/step - loss: 0.0150 - accuracy: 0.9879 - binary_iou: 0.9752 - true_positives: 129148232.0000 - false_positives: 1955364.0000 - true_negatives: 186491024.0000 - false_negatives: 1926121.0000 - precision: 0.9851 - recall: 0.9853 - val_loss: 0.0999 - val_accuracy: 0.9156 - val_binary_iou: 0.8418 - val_true_positives: 41096284.0000 - val_false_positives: 4954029.0000 - val_true_negatives: 55936160.0000 - val_false_negatives: 3985234.0000 - val_precision: 0.8924 - val_recall: 0.9116\n",
      "Epoch 325/500\n",
      "199/199 [==============================] - 77s 383ms/step - loss: 0.0150 - accuracy: 0.9878 - binary_iou: 0.9752 - true_positives: 129251688.0000 - false_positives: 1938845.0000 - true_negatives: 186382976.0000 - false_negatives: 1947297.0000 - precision: 0.9852 - recall: 0.9852 - val_loss: 0.1025 - val_accuracy: 0.9119 - val_binary_iou: 0.8357 - val_true_positives: 41485284.0000 - val_false_positives: 5669430.0000 - val_true_negatives: 55145096.0000 - val_false_negatives: 3671893.0000 - val_precision: 0.8798 - val_recall: 0.9187\n",
      "Epoch 326/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0151 - accuracy: 0.9877 - binary_iou: 0.9750 - true_positives: 129196488.0000 - false_positives: 1963435.0000 - true_negatives: 186402384.0000 - false_negatives: 1958474.0000 - precision: 0.9850 - recall: 0.9851 - val_loss: 0.1009 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41395240.0000 - val_false_positives: 5355707.0000 - val_true_negatives: 55505432.0000 - val_false_negatives: 3715338.0000 - val_precision: 0.8854 - val_recall: 0.9176\n",
      "Epoch 327/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9875 - binary_iou: 0.9745 - true_positives: 129151864.0000 - false_positives: 1987512.0000 - true_negatives: 186377776.0000 - false_negatives: 2003532.0000 - precision: 0.9848 - recall: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0155 - accuracy: 0.9875 - binary_iou: 0.9745 - true_positives: 129151864.0000 - false_positives: 1987512.0000 - true_negatives: 186377776.0000 - false_negatives: 2003532.0000 - precision: 0.9848 - recall: 0.9847 - val_loss: 0.0984 - val_accuracy: 0.9159 - val_binary_iou: 0.8424 - val_true_positives: 41380052.0000 - val_false_positives: 5133671.0000 - val_true_negatives: 55678484.0000 - val_false_negatives: 3779508.0000 - val_precision: 0.8896 - val_recall: 0.9163\n",
      "Epoch 328/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0156 - accuracy: 0.9874 - binary_iou: 0.9743 - true_positives: 129201368.0000 - false_positives: 2021815.0000 - true_negatives: 186284016.0000 - false_negatives: 2013487.0000 - precision: 0.9846 - recall: 0.9847 - val_loss: 0.0994 - val_accuracy: 0.9155 - val_binary_iou: 0.8416 - val_true_positives: 41026640.0000 - val_false_positives: 4935435.0000 - val_true_negatives: 55995700.0000 - val_false_negatives: 4013931.0000 - val_precision: 0.8926 - val_recall: 0.9109\n",
      "Epoch 329/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0151 - accuracy: 0.9877 - binary_iou: 0.9750 - true_positives: 129164856.0000 - false_positives: 1973110.0000 - true_negatives: 186434944.0000 - false_negatives: 1947873.0000 - precision: 0.9850 - recall: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9123 - val_binary_iou: 0.8364 - val_true_positives: 41482948.0000 - val_false_positives: 5663328.0000 - val_true_negatives: 55192912.0000 - val_false_negatives: 3632540.0000 - val_precision: 0.8799 - val_recall: 0.9195\n",
      "Epoch 330/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0152 - accuracy: 0.9877 - binary_iou: 0.9749 - true_positives: 129205280.0000 - false_positives: 1970074.0000 - true_negatives: 186383072.0000 - false_negatives: 1962238.0000 - precision: 0.9850 - recall: 0.9850 - val_loss: 0.1011 - val_accuracy: 0.9137 - val_binary_iou: 0.8386 - val_true_positives: 41276972.0000 - val_false_positives: 5330862.0000 - val_true_negatives: 55544248.0000 - val_false_negatives: 3819622.0000 - val_precision: 0.8856 - val_recall: 0.9153\n",
      "Epoch 331/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0150 - accuracy: 0.9878 - binary_iou: 0.9752 - true_positives: 129181424.0000 - false_positives: 1946851.0000 - true_negatives: 186452944.0000 - false_negatives: 1939493.0000 - precision: 0.9852 - recall: 0.9852 - val_loss: 0.1000 - val_accuracy: 0.9148 - val_binary_iou: 0.8406 - val_true_positives: 41322688.0000 - val_false_positives: 5123997.0000 - val_true_negatives: 55624984.0000 - val_false_negatives: 3900037.0000 - val_precision: 0.8897 - val_recall: 0.9138\n",
      "Epoch 332/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0149 - accuracy: 0.9879 - binary_iou: 0.9754 - true_positives: 129225056.0000 - false_positives: 1927095.0000 - true_negatives: 186439888.0000 - false_negatives: 1928717.0000 - precision: 0.9853 - recall: 0.9853 - val_loss: 0.1002 - val_accuracy: 0.9138 - val_binary_iou: 0.8389 - val_true_positives: 41522408.0000 - val_false_positives: 5588118.0000 - val_true_negatives: 55311044.0000 - val_false_negatives: 3550129.0000 - val_precision: 0.8814 - val_recall: 0.9212\n",
      "Epoch 333/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0148 - accuracy: 0.9880 - binary_iou: 0.9755 - true_positives: 129261496.0000 - false_positives: 1918341.0000 - true_negatives: 186425008.0000 - false_negatives: 1915874.0000 - precision: 0.9854 - recall: 0.9854 - val_loss: 0.1001 - val_accuracy: 0.9146 - val_binary_iou: 0.8402 - val_true_positives: 41414820.0000 - val_false_positives: 5314910.0000 - val_true_negatives: 55504460.0000 - val_false_negatives: 3737512.0000 - val_precision: 0.8863 - val_recall: 0.9172\n",
      "Epoch 334/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0149 - accuracy: 0.9881 - binary_iou: 0.9756 - true_positives: 129180776.0000 - false_positives: 1908142.0000 - true_negatives: 186525024.0000 - false_negatives: 1906774.0000 - precision: 0.9854 - recall: 0.9855 - val_loss: 0.1010 - val_accuracy: 0.9133 - val_binary_iou: 0.8381 - val_true_positives: 41470020.0000 - val_false_positives: 5466201.0000 - val_true_negatives: 55317096.0000 - val_false_negatives: 3718401.0000 - val_precision: 0.8835 - val_recall: 0.9177\n",
      "Epoch 335/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0148 - accuracy: 0.9880 - binary_iou: 0.9756 - true_positives: 129307856.0000 - false_positives: 1919534.0000 - true_negatives: 186389440.0000 - false_negatives: 1903888.0000 - precision: 0.9854 - recall: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9159 - val_binary_iou: 0.8422 - val_true_positives: 41022232.0000 - val_false_positives: 4874487.0000 - val_true_negatives: 56038488.0000 - val_false_negatives: 4036498.0000 - val_precision: 0.8938 - val_recall: 0.9104\n",
      "Epoch 336/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0148 - accuracy: 0.9880 - binary_iou: 0.9756 - true_positives: 129198520.0000 - false_positives: 1908406.0000 - true_negatives: 186493792.0000 - false_negatives: 1920006.0000 - precision: 0.9854 - recall: 0.9854 - val_loss: 0.1001 - val_accuracy: 0.9140 - val_binary_iou: 0.8392 - val_true_positives: 41259760.0000 - val_false_positives: 5241922.0000 - val_true_negatives: 55600916.0000 - val_false_negatives: 3869112.0000 - val_precision: 0.8873 - val_recall: 0.9143\n",
      "Epoch 337/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0146 - accuracy: 0.9882 - binary_iou: 0.9759 - true_positives: 129287256.0000 - false_positives: 1896338.0000 - true_negatives: 186466528.0000 - false_negatives: 1870646.0000 - precision: 0.9855 - recall: 0.9857 - val_loss: 0.1003 - val_accuracy: 0.9150 - val_binary_iou: 0.8408 - val_true_positives: 41209376.0000 - val_false_positives: 5168518.0000 - val_true_negatives: 55754208.0000 - val_false_negatives: 3839611.0000 - val_precision: 0.8886 - val_recall: 0.9148\n",
      "Epoch 338/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0148 - accuracy: 0.9881 - binary_iou: 0.9757 - true_positives: 129159368.0000 - false_positives: 1890928.0000 - true_negatives: 186549600.0000 - false_negatives: 1920799.0000 - precision: 0.9856 - recall: 0.9853 - val_loss: 0.0996 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41305508.0000 - val_false_positives: 5182698.0000 - val_true_negatives: 55670856.0000 - val_false_negatives: 3812658.0000 - val_precision: 0.8885 - val_recall: 0.9155\n",
      "Epoch 339/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0147 - accuracy: 0.9881 - binary_iou: 0.9758 - true_positives: 129250448.0000 - false_positives: 1900479.0000 - true_negatives: 186482352.0000 - false_negatives: 1887370.0000 - precision: 0.9855 - recall: 0.9856 - val_loss: 0.1010 - val_accuracy: 0.9140 - val_binary_iou: 0.8390 - val_true_positives: 41113612.0000 - val_false_positives: 5164374.0000 - val_true_negatives: 55741080.0000 - val_false_negatives: 3952641.0000 - val_precision: 0.8884 - val_recall: 0.9123\n",
      "Epoch 340/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0147 - accuracy: 0.9881 - binary_iou: 0.9757 - true_positives: 129258112.0000 - false_positives: 1899909.0000 - true_negatives: 186464192.0000 - false_negatives: 1898561.0000 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.1009 - val_accuracy: 0.9133 - val_binary_iou: 0.8382 - val_true_positives: 41545720.0000 - val_false_positives: 5562631.0000 - val_true_negatives: 55240528.0000 - val_false_negatives: 3622821.0000 - val_precision: 0.8819 - val_recall: 0.9198\n",
      "Epoch 341/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0148 - accuracy: 0.9880 - binary_iou: 0.9755 - true_positives: 129278328.0000 - false_positives: 1925439.0000 - true_negatives: 186404144.0000 - false_negatives: 1912821.0000 - precision: 0.9853 - recall: 0.9854 - val_loss: 0.0996 - val_accuracy: 0.9147 - val_binary_iou: 0.8403 - val_true_positives: 41225896.0000 - val_false_positives: 5135337.0000 - val_true_negatives: 55705892.0000 - val_false_negatives: 3904586.0000 - val_precision: 0.8892 - val_recall: 0.9135\n",
      "Epoch 342/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0147 - accuracy: 0.9881 - binary_iou: 0.9758 - true_positives: 129163936.0000 - false_positives: 1899956.0000 - true_negatives: 186561168.0000 - false_negatives: 1895716.0000 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.1002 - val_accuracy: 0.9149 - val_binary_iou: 0.8405 - val_true_positives: 41147716.0000 - val_false_positives: 5140474.0000 - val_true_negatives: 55802320.0000 - val_false_negatives: 3881197.0000 - val_precision: 0.8889 - val_recall: 0.9138\n",
      "Epoch 343/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0148 - accuracy: 0.9881 - binary_iou: 0.9757 - true_positives: 129218864.0000 - false_positives: 1891493.0000 - true_negatives: 186493232.0000 - false_negatives: 1917169.0000 - precision: 0.9856 - recall: 0.9854 - val_loss: 0.1006 - val_accuracy: 0.9152 - val_binary_iou: 0.8410 - val_true_positives: 40904148.0000 - val_false_positives: 4807915.0000 - val_true_negatives: 56085580.0000 - val_false_negatives: 4174073.0000 - val_precision: 0.8948 - val_recall: 0.9074\n",
      "Epoch 344/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0146 - accuracy: 0.9882 - binary_iou: 0.9759 - true_positives: 129250832.0000 - false_positives: 1899202.0000 - true_negatives: 186490144.0000 - false_negatives: 1880651.0000 - precision: 0.9855 - recall: 0.9857 - val_loss: 0.0993 - val_accuracy: 0.9152 - val_binary_iou: 0.8412 - val_true_positives: 41222208.0000 - val_false_positives: 5152969.0000 - val_true_negatives: 55766156.0000 - val_false_negatives: 3830372.0000 - val_precision: 0.8889 - val_recall: 0.9150\n",
      "Epoch 345/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0144 - accuracy: 0.9883 - binary_iou: 0.9761 - true_positives: 129235608.0000 - false_positives: 1864658.0000 - true_negatives: 186538800.0000 - false_negatives: 1881702.0000 - precision: 0.9858 - recall: 0.9856 - val_loss: 0.1014 - val_accuracy: 0.9135 - val_binary_iou: 0.8383 - val_true_positives: 41201476.0000 - val_false_positives: 5197741.0000 - val_true_negatives: 55607944.0000 - val_false_negatives: 3964547.0000 - val_precision: 0.8880 - val_recall: 0.9122\n",
      "Epoch 346/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0144 - accuracy: 0.9883 - binary_iou: 0.9761 - true_positives: 129254704.0000 - false_positives: 1876127.0000 - true_negatives: 186530496.0000 - false_negatives: 1859449.0000 - precision: 0.9857 - recall: 0.9858 - val_loss: 0.1016 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41378916.0000 - val_false_positives: 5352850.0000 - val_true_negatives: 55446040.0000 - val_false_negatives: 3793893.0000 - val_precision: 0.8855 - val_recall: 0.9160\n",
      "Epoch 347/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0143 - accuracy: 0.9884 - binary_iou: 0.9763 - true_positives: 129274624.0000 - false_positives: 1860259.0000 - true_negatives: 186543184.0000 - false_negatives: 1842611.0000 - precision: 0.9858 - recall: 0.9859 - val_loss: 0.1006 - val_accuracy: 0.9139 - val_binary_iou: 0.8391 - val_true_positives: 41405112.0000 - val_false_positives: 5431966.0000 - val_true_negatives: 55443460.0000 - val_false_negatives: 3691168.0000 - val_precision: 0.8840 - val_recall: 0.9181\n",
      "Epoch 348/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0144 - accuracy: 0.9884 - binary_iou: 0.9762 - true_positives: 129266544.0000 - false_positives: 1850850.0000 - true_negatives: 186533824.0000 - false_negatives: 1869510.0000 - precision: 0.9859 - recall: 0.9857 - val_loss: 0.1011 - val_accuracy: 0.9138 - val_binary_iou: 0.8389 - val_true_positives: 41331004.0000 - val_false_positives: 5239572.0000 - val_true_negatives: 55509944.0000 - val_false_negatives: 3891198.0000 - val_precision: 0.8875 - val_recall: 0.9140\n",
      "Epoch 349/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0144 - accuracy: 0.9884 - binary_iou: 0.9763 - true_positives: 129243504.0000 - false_positives: 1855114.0000 - true_negatives: 186574048.0000 - false_negatives: 1848067.0000 - precision: 0.9858 - recall: 0.9859 - val_loss: 0.0993 - val_accuracy: 0.9147 - val_binary_iou: 0.8404 - val_true_positives: 41438824.0000 - val_false_positives: 5380071.0000 - val_true_negatives: 55489556.0000 - val_false_negatives: 3663261.0000 - val_precision: 0.8851 - val_recall: 0.9188\n",
      "Epoch 350/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0142 - accuracy: 0.9885 - binary_iou: 0.9765 - true_positives: 129314120.0000 - false_positives: 1846494.0000 - true_negatives: 186529600.0000 - false_negatives: 1830433.0000 - precision: 0.9859 - recall: 0.9860 - val_loss: 0.0994 - val_accuracy: 0.9147 - val_binary_iou: 0.8403 - val_true_positives: 41330472.0000 - val_false_positives: 5337687.0000 - val_true_negatives: 55601436.0000 - val_false_negatives: 3702119.0000 - val_precision: 0.8856 - val_recall: 0.9178\n",
      "Epoch 351/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0143 - accuracy: 0.9884 - binary_iou: 0.9764 - true_positives: 129315608.0000 - false_positives: 1858513.0000 - true_negatives: 186505632.0000 - false_negatives: 1840929.0000 - precision: 0.9858 - recall: 0.9860 - val_loss: 0.1001 - val_accuracy: 0.9147 - val_binary_iou: 0.8401 - val_true_positives: 41137356.0000 - val_false_positives: 5082917.0000 - val_true_negatives: 55790168.0000 - val_false_negatives: 3961263.0000 - val_precision: 0.8900 - val_recall: 0.9122\n",
      "Epoch 352/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0144 - accuracy: 0.9883 - binary_iou: 0.9761 - true_positives: 129359376.0000 - false_positives: 1873918.0000 - true_negatives: 186426224.0000 - false_negatives: 1861227.0000 - precision: 0.9857 - recall: 0.9858 - val_loss: 0.1002 - val_accuracy: 0.9145 - val_binary_iou: 0.8400 - val_true_positives: 41370872.0000 - val_false_positives: 5252211.0000 - val_true_negatives: 55538024.0000 - val_false_negatives: 3810614.0000 - val_precision: 0.8873 - val_recall: 0.9157\n",
      "Epoch 353/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0143 - accuracy: 0.9884 - binary_iou: 0.9764 - true_positives: 129303352.0000 - false_positives: 1864616.0000 - true_negatives: 186522208.0000 - false_negatives: 1830615.0000 - precision: 0.9858 - recall: 0.9860 - val_loss: 0.0990 - val_accuracy: 0.9150 - val_binary_iou: 0.8410 - val_true_positives: 41424344.0000 - val_false_positives: 5237892.0000 - val_true_negatives: 55544176.0000 - val_false_negatives: 3765300.0000 - val_precision: 0.8877 - val_recall: 0.9167\n",
      "Epoch 354/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0143 - accuracy: 0.9885 - binary_iou: 0.9764 - true_positives: 129286752.0000 - false_positives: 1845373.0000 - true_negatives: 186546224.0000 - false_negatives: 1842458.0000 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.0996 - val_accuracy: 0.9157 - val_binary_iou: 0.8418 - val_true_positives: 41108364.0000 - val_false_positives: 4875492.0000 - val_true_negatives: 55928024.0000 - val_false_negatives: 4059835.0000 - val_precision: 0.8940 - val_recall: 0.9101\n",
      "Epoch 355/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0144 - accuracy: 0.9884 - binary_iou: 0.9763 - true_positives: 129225480.0000 - false_positives: 1864977.0000 - true_negatives: 186592224.0000 - false_negatives: 1838004.0000 - precision: 0.9858 - recall: 0.9860 - val_loss: 0.0997 - val_accuracy: 0.9152 - val_binary_iou: 0.8412 - val_true_positives: 41404832.0000 - val_false_positives: 5275530.0000 - val_true_negatives: 55579700.0000 - val_false_negatives: 3711645.0000 - val_precision: 0.8870 - val_recall: 0.9177\n",
      "Epoch 356/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0146 - accuracy: 0.9882 - binary_iou: 0.9758 - true_positives: 129228040.0000 - false_positives: 1880252.0000 - true_negatives: 186508640.0000 - false_negatives: 1903882.0000 - precision: 0.9857 - recall: 0.9855 - val_loss: 0.1014 - val_accuracy: 0.9143 - val_binary_iou: 0.8395 - val_true_positives: 41000280.0000 - val_false_positives: 5026402.0000 - val_true_negatives: 55894520.0000 - val_false_negatives: 4050506.0000 - val_precision: 0.8908 - val_recall: 0.9101\n",
      "Epoch 357/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0142 - accuracy: 0.9885 - binary_iou: 0.9764 - true_positives: 129280184.0000 - false_positives: 1847194.0000 - true_negatives: 186551856.0000 - false_negatives: 1841507.0000 - precision: 0.9859 - recall: 0.9860 - val_loss: 0.0998 - val_accuracy: 0.9152 - val_binary_iou: 0.8412 - val_true_positives: 41323816.0000 - val_false_positives: 5206616.0000 - val_true_negatives: 55663980.0000 - val_false_negatives: 3777300.0000 - val_precision: 0.8881 - val_recall: 0.9162\n",
      "Epoch 358/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0144 - accuracy: 0.9884 - binary_iou: 0.9762 - true_positives: 129283072.0000 - false_positives: 1856642.0000 - true_negatives: 186518608.0000 - false_negatives: 1862491.0000 - precision: 0.9858 - recall: 0.9858 - val_loss: 0.1018 - val_accuracy: 0.9128 - val_binary_iou: 0.8372 - val_true_positives: 41341432.0000 - val_false_positives: 5450740.0000 - val_true_negatives: 55393528.0000 - val_false_negatives: 3786006.0000 - val_precision: 0.8835 - val_recall: 0.9161\n",
      "Epoch 359/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0143 - accuracy: 0.9885 - binary_iou: 0.9765 - true_positives: 129239064.0000 - false_positives: 1855057.0000 - true_negatives: 186607408.0000 - false_negatives: 1819196.0000 - precision: 0.9858 - recall: 0.9861 - val_loss: 0.1005 - val_accuracy: 0.9146 - val_binary_iou: 0.8403 - val_true_positives: 41496188.0000 - val_false_positives: 5420035.0000 - val_true_negatives: 55426688.0000 - val_false_negatives: 3628825.0000 - val_precision: 0.8845 - val_recall: 0.9196\n",
      "Epoch 360/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0142 - accuracy: 0.9885 - binary_iou: 0.9766 - true_positives: 129378640.0000 - false_positives: 1857699.0000 - true_negatives: 186475920.0000 - false_negatives: 1808501.0000 - precision: 0.9858 - recall: 0.9862 - val_loss: 0.1010 - val_accuracy: 0.9134 - val_binary_iou: 0.8383 - val_true_positives: 41543352.0000 - val_false_positives: 5506775.0000 - val_true_negatives: 55252576.0000 - val_false_negatives: 3669011.0000 - val_precision: 0.8830 - val_recall: 0.9188\n",
      "Epoch 361/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0140 - accuracy: 0.9886 - binary_iou: 0.9768 - true_positives: 129328416.0000 - false_positives: 1818593.0000 - true_negatives: 186558096.0000 - false_negatives: 1815674.0000 - precision: 0.9861 - recall: 0.9862 - val_loss: 0.1001 - val_accuracy: 0.9143 - val_binary_iou: 0.8398 - val_true_positives: 41519492.0000 - val_false_positives: 5490970.0000 - val_true_negatives: 55373032.0000 - val_false_negatives: 3588214.0000 - val_precision: 0.8832 - val_recall: 0.9205\n",
      "Epoch 362/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0141 - accuracy: 0.9886 - binary_iou: 0.9767 - true_positives: 129214696.0000 - false_positives: 1818056.0000 - true_negatives: 186665472.0000 - false_negatives: 1822537.0000 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.0999 - val_accuracy: 0.9143 - val_binary_iou: 0.8397 - val_true_positives: 41461960.0000 - val_false_positives: 5456456.0000 - val_true_negatives: 55423540.0000 - val_false_negatives: 3629766.0000 - val_precision: 0.8837 - val_recall: 0.9195\n",
      "Epoch 363/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0141 - accuracy: 0.9886 - binary_iou: 0.9767 - true_positives: 129326896.0000 - false_positives: 1823414.0000 - true_negatives: 186552528.0000 - false_negatives: 1817949.0000 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.1023 - val_accuracy: 0.9122 - val_binary_iou: 0.8364 - val_true_positives: 41591616.0000 - val_false_positives: 5827955.0000 - val_true_negatives: 55078496.0000 - val_false_negatives: 3473636.0000 - val_precision: 0.8771 - val_recall: 0.9229\n",
      "Epoch 364/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9889 - binary_iou: 0.9773 - true_positives: 129312592.0000 - false_positives: 1785750.0000 - true_negatives: 186652272.0000 - false_negatives: 1770168.0000 - precision: 0.9864 - recall: 0.9865 - val_loss: 0.0993 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41414952.0000 - val_false_positives: 5359371.0000 - val_true_negatives: 55486072.0000 - val_false_negatives: 3711316.0000 - val_precision: 0.8854 - val_recall: 0.9178\n",
      "Epoch 365/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9771 - true_positives: 129339280.0000 - false_positives: 1786699.0000 - true_negatives: 186605360.0000 - false_negatives: 1789462.0000 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.0994 - val_accuracy: 0.9148 - val_binary_iou: 0.8405 - val_true_positives: 41269032.0000 - val_false_positives: 5283357.0000 - val_true_negatives: 55673568.0000 - val_false_negatives: 3745766.0000 - val_precision: 0.8865 - val_recall: 0.9168\n",
      "Epoch 366/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9771 - true_positives: 129366968.0000 - false_positives: 1785920.0000 - true_negatives: 186577168.0000 - false_negatives: 1790727.0000 - precision: 0.9864 - recall: 0.9863 - val_loss: 0.0993 - val_accuracy: 0.9147 - val_binary_iou: 0.8404 - val_true_positives: 41483584.0000 - val_false_positives: 5378053.0000 - val_true_negatives: 55445900.0000 - val_false_negatives: 3664154.0000 - val_precision: 0.8852 - val_recall: 0.9188\n",
      "Epoch 367/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9772 - true_positives: 129320776.0000 - false_positives: 1787478.0000 - true_negatives: 186626336.0000 - false_negatives: 1786178.0000 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.1011 - val_accuracy: 0.9136 - val_binary_iou: 0.8386 - val_true_positives: 41491664.0000 - val_false_positives: 5570204.0000 - val_true_negatives: 55321444.0000 - val_false_negatives: 3588407.0000 - val_precision: 0.8816 - val_recall: 0.9204\n",
      "Epoch 368/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9772 - true_positives: 129387824.0000 - false_positives: 1791750.0000 - true_negatives: 186567648.0000 - false_negatives: 1773537.0000 - precision: 0.9863 - recall: 0.9865 - val_loss: 0.1012 - val_accuracy: 0.9129 - val_binary_iou: 0.8375 - val_true_positives: 41519424.0000 - val_false_positives: 5637746.0000 - val_true_negatives: 55225184.0000 - val_false_negatives: 3589347.0000 - val_precision: 0.8804 - val_recall: 0.9204\n",
      "Epoch 369/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0138 - accuracy: 0.9889 - binary_iou: 0.9773 - true_positives: 129256976.0000 - false_positives: 1784112.0000 - true_negatives: 186708064.0000 - false_negatives: 1771603.0000 - precision: 0.9864 - recall: 0.9865 - val_loss: 0.0999 - val_accuracy: 0.9148 - val_binary_iou: 0.8406 - val_true_positives: 41411244.0000 - val_false_positives: 5321003.0000 - val_true_negatives: 55532780.0000 - val_false_negatives: 3706684.0000 - val_precision: 0.8861 - val_recall: 0.9178\n",
      "Epoch 370/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0137 - accuracy: 0.9890 - binary_iou: 0.9774 - true_positives: 129368744.0000 - false_positives: 1773171.0000 - true_negatives: 186622704.0000 - false_negatives: 1756138.0000 - precision: 0.9865 - recall: 0.9866 - val_loss: 0.1001 - val_accuracy: 0.9146 - val_binary_iou: 0.8401 - val_true_positives: 41326280.0000 - val_false_positives: 5253371.0000 - val_true_negatives: 55593324.0000 - val_false_negatives: 3798731.0000 - val_precision: 0.8872 - val_recall: 0.9158\n",
      "Epoch 371/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0137 - accuracy: 0.9889 - binary_iou: 0.9773 - true_positives: 129365136.0000 - false_positives: 1773968.0000 - true_negatives: 186610880.0000 - false_negatives: 1770796.0000 - precision: 0.9865 - recall: 0.9865 - val_loss: 0.1021 - val_accuracy: 0.9129 - val_binary_iou: 0.8373 - val_true_positives: 41353944.0000 - val_false_positives: 5494813.0000 - val_true_negatives: 55383920.0000 - val_false_negatives: 3739049.0000 - val_precision: 0.8827 - val_recall: 0.9171\n",
      "Epoch 372/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9889 - binary_iou: 0.9773 - true_positives: 129374128.0000 - false_positives: 1774044.0000 - true_negatives: 186588848.0000 - false_negatives: 1783779.0000 - precision: 0.9865 - recall: 0.9864 - val_loss: 0.1010 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41144512.0000 - val_false_positives: 5195775.0000 - val_true_negatives: 55760488.0000 - val_false_negatives: 3870941.0000 - val_precision: 0.8879 - val_recall: 0.9140\n",
      "Epoch 373/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0136 - accuracy: 0.9890 - binary_iou: 0.9775 - true_positives: 129372192.0000 - false_positives: 1770948.0000 - true_negatives: 186624576.0000 - false_negatives: 1753028.0000 - precision: 0.9865 - recall: 0.9866 - val_loss: 0.1015 - val_accuracy: 0.9126 - val_binary_iou: 0.8369 - val_true_positives: 41438988.0000 - val_false_positives: 5629248.0000 - val_true_negatives: 55269068.0000 - val_false_negatives: 3634412.0000 - val_precision: 0.8804 - val_recall: 0.9194\n",
      "Epoch 374/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9772 - true_positives: 129384048.0000 - false_positives: 1779584.0000 - true_negatives: 186562912.0000 - false_negatives: 1794324.0000 - precision: 0.9864 - recall: 0.9863 - val_loss: 0.1002 - val_accuracy: 0.9145 - val_binary_iou: 0.8400 - val_true_positives: 41299288.0000 - val_false_positives: 5289057.0000 - val_true_negatives: 55613808.0000 - val_false_negatives: 3769543.0000 - val_precision: 0.8865 - val_recall: 0.9164\n",
      "Epoch 375/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9771 - true_positives: 129415360.0000 - false_positives: 1790796.0000 - true_negatives: 186525024.0000 - false_negatives: 1789564.0000 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.0997 - val_accuracy: 0.9152 - val_binary_iou: 0.8412 - val_true_positives: 41371768.0000 - val_false_positives: 5231316.0000 - val_true_negatives: 55611072.0000 - val_false_negatives: 3757558.0000 - val_precision: 0.8877 - val_recall: 0.9167\n",
      "Epoch 376/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0137 - accuracy: 0.9889 - binary_iou: 0.9774 - true_positives: 129383080.0000 - false_positives: 1779261.0000 - true_negatives: 186594464.0000 - false_negatives: 1764013.0000 - precision: 0.9864 - recall: 0.9865 - val_loss: 0.1015 - val_accuracy: 0.9143 - val_binary_iou: 0.8396 - val_true_positives: 41304972.0000 - val_false_positives: 5282152.0000 - val_true_negatives: 55581736.0000 - val_false_negatives: 3802856.0000 - val_precision: 0.8866 - val_recall: 0.9157\n",
      "Epoch 377/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0137 - accuracy: 0.9890 - binary_iou: 0.9775 - true_positives: 129309016.0000 - false_positives: 1759170.0000 - true_negatives: 186687536.0000 - false_negatives: 1764951.0000 - precision: 0.9866 - recall: 0.9865 - val_loss: 0.1019 - val_accuracy: 0.9125 - val_binary_iou: 0.8367 - val_true_positives: 41431280.0000 - val_false_positives: 5611833.0000 - val_true_negatives: 55265420.0000 - val_false_negatives: 3663175.0000 - val_precision: 0.8807 - val_recall: 0.9188\n",
      "Epoch 378/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0138 - accuracy: 0.9888 - binary_iou: 0.9772 - true_positives: 129329512.0000 - false_positives: 1801200.0000 - true_negatives: 186616000.0000 - false_negatives: 1774120.0000 - precision: 0.9863 - recall: 0.9865 - val_loss: 0.1016 - val_accuracy: 0.9133 - val_binary_iou: 0.8381 - val_true_positives: 41360224.0000 - val_false_positives: 5428284.0000 - val_true_negatives: 55428280.0000 - val_false_negatives: 3754913.0000 - val_precision: 0.8840 - val_recall: 0.9168\n",
      "Epoch 379/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0137 - accuracy: 0.9889 - binary_iou: 0.9773 - true_positives: 129413472.0000 - false_positives: 1778363.0000 - true_negatives: 186562944.0000 - false_negatives: 1765967.0000 - precision: 0.9864 - recall: 0.9865 - val_loss: 0.1014 - val_accuracy: 0.9140 - val_binary_iou: 0.8391 - val_true_positives: 41316792.0000 - val_false_positives: 5240321.0000 - val_true_negatives: 55538204.0000 - val_false_negatives: 3876389.0000 - val_precision: 0.8874 - val_recall: 0.9142\n",
      "Epoch 380/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0136 - accuracy: 0.9890 - binary_iou: 0.9776 - true_positives: 129460656.0000 - false_positives: 1762132.0000 - true_negatives: 186548912.0000 - false_negatives: 1749000.0000 - precision: 0.9866 - recall: 0.9867 - val_loss: 0.1000 - val_accuracy: 0.9149 - val_binary_iou: 0.8406 - val_true_positives: 41273640.0000 - val_false_positives: 5232126.0000 - val_true_negatives: 55679060.0000 - val_false_negatives: 3786882.0000 - val_precision: 0.8875 - val_recall: 0.9160\n",
      "Epoch 381/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0136 - accuracy: 0.9890 - binary_iou: 0.9776 - true_positives: 129425120.0000 - false_positives: 1757639.0000 - true_negatives: 186588288.0000 - false_negatives: 1749735.0000 - precision: 0.9866 - recall: 0.9867 - val_loss: 0.1016 - val_accuracy: 0.9135 - val_binary_iou: 0.8383 - val_true_positives: 41266304.0000 - val_false_positives: 5340477.0000 - val_true_negatives: 55537344.0000 - val_false_negatives: 3827595.0000 - val_precision: 0.8854 - val_recall: 0.9151\n",
      "Epoch 382/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0136 - accuracy: 0.9890 - binary_iou: 0.9776 - true_positives: 129389280.0000 - false_positives: 1757904.0000 - true_negatives: 186627056.0000 - false_negatives: 1746441.0000 - precision: 0.9866 - recall: 0.9867 - val_loss: 0.0994 - val_accuracy: 0.9155 - val_binary_iou: 0.8416 - val_true_positives: 41228032.0000 - val_false_positives: 5133915.0000 - val_true_negatives: 55788136.0000 - val_false_negatives: 3821625.0000 - val_precision: 0.8893 - val_recall: 0.9152\n",
      "Epoch 383/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0135 - accuracy: 0.9891 - binary_iou: 0.9777 - true_positives: 129344608.0000 - false_positives: 1747154.0000 - true_negatives: 186682592.0000 - false_negatives: 1746452.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.0998 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41371332.0000 - val_false_positives: 5336509.0000 - val_true_negatives: 55503100.0000 - val_false_negatives: 3760765.0000 - val_precision: 0.8857 - val_recall: 0.9167\n",
      "Epoch 384/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0134 - accuracy: 0.9892 - binary_iou: 0.9778 - true_positives: 129410712.0000 - false_positives: 1749155.0000 - true_negatives: 186643456.0000 - false_negatives: 1717512.0000 - precision: 0.9867 - recall: 0.9869 - val_loss: 0.1007 - val_accuracy: 0.9139 - val_binary_iou: 0.8392 - val_true_positives: 41529552.0000 - val_false_positives: 5481904.0000 - val_true_negatives: 55320452.0000 - val_false_negatives: 3639805.0000 - val_precision: 0.8834 - val_recall: 0.9194\n",
      "Epoch 385/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0134 - accuracy: 0.9892 - binary_iou: 0.9779 - true_positives: 129466600.0000 - false_positives: 1732744.0000 - true_negatives: 186596736.0000 - false_negatives: 1724699.0000 - precision: 0.9868 - recall: 0.9869 - val_loss: 0.1009 - val_accuracy: 0.9137 - val_binary_iou: 0.8388 - val_true_positives: 41478284.0000 - val_false_positives: 5544009.0000 - val_true_negatives: 55348008.0000 - val_false_negatives: 3601408.0000 - val_precision: 0.8821 - val_recall: 0.9201\n",
      "Epoch 386/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0135 - accuracy: 0.9891 - binary_iou: 0.9778 - true_positives: 129364320.0000 - false_positives: 1737541.0000 - true_negatives: 186677120.0000 - false_negatives: 1741864.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.0997 - val_accuracy: 0.9155 - val_binary_iou: 0.8418 - val_true_positives: 41369428.0000 - val_false_positives: 5188009.0000 - val_true_negatives: 55649876.0000 - val_false_negatives: 3764387.0000 - val_precision: 0.8886 - val_recall: 0.9166\n",
      "Epoch 387/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0133 - accuracy: 0.9892 - binary_iou: 0.9779 - true_positives: 129407672.0000 - false_positives: 1733462.0000 - true_negatives: 186662304.0000 - false_negatives: 1717447.0000 - precision: 0.9868 - recall: 0.9869 - val_loss: 0.1008 - val_accuracy: 0.9145 - val_binary_iou: 0.8399 - val_true_positives: 41246708.0000 - val_false_positives: 5269647.0000 - val_true_negatives: 55661616.0000 - val_false_negatives: 3793728.0000 - val_precision: 0.8867 - val_recall: 0.9158\n",
      "Epoch 388/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0134 - accuracy: 0.9892 - binary_iou: 0.9779 - true_positives: 129382472.0000 - false_positives: 1741096.0000 - true_negatives: 186684176.0000 - false_negatives: 1712966.0000 - precision: 0.9867 - recall: 0.9869 - val_loss: 0.1016 - val_accuracy: 0.9135 - val_binary_iou: 0.8382 - val_true_positives: 41143812.0000 - val_false_positives: 5178061.0000 - val_true_negatives: 55662180.0000 - val_false_negatives: 3987665.0000 - val_precision: 0.8882 - val_recall: 0.9116\n",
      "Epoch 389/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0133 - accuracy: 0.9892 - binary_iou: 0.9779 - true_positives: 129410760.0000 - false_positives: 1733878.0000 - true_negatives: 186660704.0000 - false_negatives: 1715356.0000 - precision: 0.9868 - recall: 0.9869 - val_loss: 0.1001 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41458172.0000 - val_false_positives: 5477530.0000 - val_true_negatives: 55417136.0000 - val_false_negatives: 3618879.0000 - val_precision: 0.8833 - val_recall: 0.9197\n",
      "Epoch 390/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0135 - accuracy: 0.9890 - binary_iou: 0.9776 - true_positives: 129382072.0000 - false_positives: 1763241.0000 - true_negatives: 186639232.0000 - false_negatives: 1736242.0000 - precision: 0.9866 - recall: 0.9868 - val_loss: 0.1011 - val_accuracy: 0.9145 - val_binary_iou: 0.8400 - val_true_positives: 41305600.0000 - val_false_positives: 5219115.0000 - val_true_negatives: 55605968.0000 - val_false_negatives: 3841017.0000 - val_precision: 0.8878 - val_recall: 0.9149\n",
      "Epoch 391/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0133 - accuracy: 0.9893 - binary_iou: 0.9781 - true_positives: 129423872.0000 - false_positives: 1727326.0000 - true_negatives: 186664000.0000 - false_negatives: 1705607.0000 - precision: 0.9868 - recall: 0.9870 - val_loss: 0.1004 - val_accuracy: 0.9140 - val_binary_iou: 0.8391 - val_true_positives: 41344004.0000 - val_false_positives: 5369784.0000 - val_true_negatives: 55510280.0000 - val_false_negatives: 3747662.0000 - val_precision: 0.8850 - val_recall: 0.9169\n",
      "Epoch 392/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0133 - accuracy: 0.9892 - binary_iou: 0.9780 - true_positives: 129359632.0000 - false_positives: 1723299.0000 - true_negatives: 186725952.0000 - false_negatives: 1711850.0000 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.1014 - val_accuracy: 0.9136 - val_binary_iou: 0.8386 - val_true_positives: 41435060.0000 - val_false_positives: 5407201.0000 - val_true_negatives: 55382252.0000 - val_false_negatives: 3747196.0000 - val_precision: 0.8846 - val_recall: 0.9171\n",
      "Epoch 393/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0132 - accuracy: 0.9893 - binary_iou: 0.9782 - true_positives: 129309568.0000 - false_positives: 1697068.0000 - true_negatives: 186798992.0000 - false_negatives: 1715115.0000 - precision: 0.9870 - recall: 0.9869 - val_loss: 0.1014 - val_accuracy: 0.9132 - val_binary_iou: 0.8379 - val_true_positives: 41517832.0000 - val_false_positives: 5612627.0000 - val_true_negatives: 55251120.0000 - val_false_negatives: 3590140.0000 - val_precision: 0.8809 - val_recall: 0.9204\n",
      "Epoch 394/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0133 - accuracy: 0.9893 - binary_iou: 0.9780 - true_positives: 129444608.0000 - false_positives: 1722481.0000 - true_negatives: 186642032.0000 - false_negatives: 1711671.0000 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.1004 - val_accuracy: 0.9142 - val_binary_iou: 0.8396 - val_true_positives: 41460872.0000 - val_false_positives: 5357692.0000 - val_true_negatives: 55417784.0000 - val_false_negatives: 3735346.0000 - val_precision: 0.8856 - val_recall: 0.9174\n",
      "Epoch 395/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0132 - accuracy: 0.9893 - binary_iou: 0.9782 - true_positives: 129392792.0000 - false_positives: 1717387.0000 - true_negatives: 186711024.0000 - false_negatives: 1699465.0000 - precision: 0.9869 - recall: 0.9870 - val_loss: 0.1005 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41324964.0000 - val_false_positives: 5327514.0000 - val_true_negatives: 55579944.0000 - val_false_negatives: 3739288.0000 - val_precision: 0.8858 - val_recall: 0.9170\n",
      "Epoch 396/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0132 - accuracy: 0.9893 - binary_iou: 0.9780 - true_positives: 129370408.0000 - false_positives: 1723474.0000 - true_negatives: 186717600.0000 - false_negatives: 1709274.0000 - precision: 0.9869 - recall: 0.9870 - val_loss: 0.1008 - val_accuracy: 0.9147 - val_binary_iou: 0.8401 - val_true_positives: 41066376.0000 - val_false_positives: 4993842.0000 - val_true_negatives: 55862248.0000 - val_false_negatives: 4049239.0000 - val_precision: 0.8916 - val_recall: 0.9102\n",
      "Epoch 397/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0133 - accuracy: 0.9892 - binary_iou: 0.9780 - true_positives: 129439504.0000 - false_positives: 1725379.0000 - true_negatives: 186639648.0000 - false_negatives: 1716215.0000 - precision: 0.9868 - recall: 0.9869 - val_loss: 0.1014 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41367784.0000 - val_false_positives: 5470412.0000 - val_true_negatives: 55461776.0000 - val_false_negatives: 3671741.0000 - val_precision: 0.8832 - val_recall: 0.9185\n",
      "Epoch 398/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0133 - accuracy: 0.9892 - binary_iou: 0.9780 - true_positives: 129428656.0000 - false_positives: 1732361.0000 - true_negatives: 186650048.0000 - false_negatives: 1709732.0000 - precision: 0.9868 - recall: 0.9870 - val_loss: 0.1008 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41355084.0000 - val_false_positives: 5396107.0000 - val_true_negatives: 55545008.0000 - val_false_negatives: 3675507.0000 - val_precision: 0.8846 - val_recall: 0.9184\n",
      "Epoch 399/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0132 - accuracy: 0.9893 - binary_iou: 0.9781 - true_positives: 129429440.0000 - false_positives: 1695975.0000 - true_negatives: 186673344.0000 - false_negatives: 1722021.0000 - precision: 0.9871 - recall: 0.9869 - val_loss: 0.1016 - val_accuracy: 0.9124 - val_binary_iou: 0.8367 - val_true_positives: 41595248.0000 - val_false_positives: 5720905.0000 - val_true_negatives: 55097648.0000 - val_false_negatives: 3557905.0000 - val_precision: 0.8791 - val_recall: 0.9212\n",
      "Epoch 400/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0131 - accuracy: 0.9894 - binary_iou: 0.9784 - true_positives: 129462392.0000 - false_positives: 1698363.0000 - true_negatives: 186679664.0000 - false_negatives: 1680259.0000 - precision: 0.9871 - recall: 0.9872 - val_loss: 0.1005 - val_accuracy: 0.9143 - val_binary_iou: 0.8396 - val_true_positives: 41257476.0000 - val_false_positives: 5229790.0000 - val_true_negatives: 55630864.0000 - val_false_negatives: 3853566.0000 - val_precision: 0.8875 - val_recall: 0.9146\n",
      "Epoch 401/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9785 - true_positives: 129432872.0000 - false_positives: 1690617.0000 - true_negatives: 186730304.0000 - false_negatives: 1666930.0000 - precision: 0.9871 - recall: 0.9873 - val_loss: 0.1007 - val_accuracy: 0.9135 - val_binary_iou: 0.8384 - val_true_positives: 41358872.0000 - val_false_positives: 5404788.0000 - val_true_negatives: 55449372.0000 - val_false_negatives: 3758680.0000 - val_precision: 0.8844 - val_recall: 0.9167\n",
      "Epoch 402/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9785 - true_positives: 129367816.0000 - false_positives: 1677325.0000 - true_negatives: 186797216.0000 - false_negatives: 1678486.0000 - precision: 0.9872 - recall: 0.9872 - val_loss: 0.0998 - val_accuracy: 0.9144 - val_binary_iou: 0.8400 - val_true_positives: 41558280.0000 - val_false_positives: 5456427.0000 - val_true_negatives: 55344204.0000 - val_false_negatives: 3612791.0000 - val_precision: 0.8839 - val_recall: 0.9200\n",
      "Epoch 403/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129486320.0000 - false_positives: 1666726.0000 - true_negatives: 186685744.0000 - false_negatives: 1682021.0000 - precision: 0.9873 - recall: 0.9872 - val_loss: 0.1000 - val_accuracy: 0.9150 - val_binary_iou: 0.8408 - val_true_positives: 41349568.0000 - val_false_positives: 5287481.0000 - val_true_negatives: 55609332.0000 - val_false_negatives: 3725326.0000 - val_precision: 0.8866 - val_recall: 0.9174\n",
      "Epoch 404/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9785 - true_positives: 129456800.0000 - false_positives: 1689608.0000 - true_negatives: 186694656.0000 - false_negatives: 1679739.0000 - precision: 0.9871 - recall: 0.9872 - val_loss: 0.1008 - val_accuracy: 0.9132 - val_binary_iou: 0.8381 - val_true_positives: 41536644.0000 - val_false_positives: 5594280.0000 - val_true_negatives: 55241864.0000 - val_false_negatives: 3598936.0000 - val_precision: 0.8813 - val_recall: 0.9203\n",
      "Epoch 405/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129405296.0000 - false_positives: 1683280.0000 - true_negatives: 186772512.0000 - false_negatives: 1659789.0000 - precision: 0.9872 - recall: 0.9873 - val_loss: 0.1000 - val_accuracy: 0.9140 - val_binary_iou: 0.8392 - val_true_positives: 41551220.0000 - val_false_positives: 5474337.0000 - val_true_negatives: 55301908.0000 - val_false_negatives: 3644256.0000 - val_precision: 0.8836 - val_recall: 0.9194\n",
      "Epoch 406/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129468792.0000 - false_positives: 1669015.0000 - true_negatives: 186700480.0000 - false_negatives: 1682498.0000 - precision: 0.9873 - recall: 0.9872 - val_loss: 0.1005 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41199208.0000 - val_false_positives: 5169690.0000 - val_true_negatives: 55705684.0000 - val_false_negatives: 3897145.0000 - val_precision: 0.8885 - val_recall: 0.9136\n",
      "Epoch 407/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0131 - accuracy: 0.9894 - binary_iou: 0.9783 - true_positives: 129464096.0000 - false_positives: 1693958.0000 - true_negatives: 186665456.0000 - false_negatives: 1697212.0000 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.1005 - val_accuracy: 0.9147 - val_binary_iou: 0.8402 - val_true_positives: 41227060.0000 - val_false_positives: 5119256.0000 - val_true_negatives: 55701920.0000 - val_false_negatives: 3923476.0000 - val_precision: 0.8895 - val_recall: 0.9131\n",
      "Epoch 408/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129451616.0000 - false_positives: 1667040.0000 - true_negatives: 186715504.0000 - false_negatives: 1686637.0000 - precision: 0.9873 - recall: 0.9871 - val_loss: 0.1009 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41303920.0000 - val_false_positives: 5303903.0000 - val_true_negatives: 55592112.0000 - val_false_negatives: 3771776.0000 - val_precision: 0.8862 - val_recall: 0.9163\n",
      "Epoch 409/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0130 - accuracy: 0.9895 - binary_iou: 0.9785 - true_positives: 129426600.0000 - false_positives: 1689157.0000 - true_negatives: 186739632.0000 - false_negatives: 1665224.0000 - precision: 0.9871 - recall: 0.9873 - val_loss: 0.1006 - val_accuracy: 0.9141 - val_binary_iou: 0.8393 - val_true_positives: 41413392.0000 - val_false_positives: 5377497.0000 - val_true_negatives: 55450308.0000 - val_false_negatives: 3730515.0000 - val_precision: 0.8851 - val_recall: 0.9174\n",
      "Epoch 410/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0128 - accuracy: 0.9896 - binary_iou: 0.9787 - true_positives: 129458344.0000 - false_positives: 1685867.0000 - true_negatives: 186733984.0000 - false_negatives: 1642552.0000 - precision: 0.9871 - recall: 0.9875 - val_loss: 0.0998 - val_accuracy: 0.9151 - val_binary_iou: 0.8409 - val_true_positives: 41182312.0000 - val_false_positives: 5068432.0000 - val_true_negatives: 55793472.0000 - val_false_negatives: 3927499.0000 - val_precision: 0.8904 - val_recall: 0.9129\n",
      "Epoch 411/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0128 - accuracy: 0.9896 - binary_iou: 0.9787 - true_positives: 129460640.0000 - false_positives: 1670603.0000 - true_negatives: 186731552.0000 - false_negatives: 1658073.0000 - precision: 0.9873 - recall: 0.9874 - val_loss: 0.1003 - val_accuracy: 0.9138 - val_binary_iou: 0.8389 - val_true_positives: 41426296.0000 - val_false_positives: 5418241.0000 - val_true_negatives: 55408344.0000 - val_false_negatives: 3718839.0000 - val_precision: 0.8843 - val_recall: 0.9176\n",
      "Epoch 412/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0127 - accuracy: 0.9897 - binary_iou: 0.9789 - true_positives: 129543776.0000 - false_positives: 1652734.0000 - true_negatives: 186680032.0000 - false_negatives: 1644236.0000 - precision: 0.9874 - recall: 0.9875 - val_loss: 0.0998 - val_accuracy: 0.9150 - val_binary_iou: 0.8409 - val_true_positives: 41375328.0000 - val_false_positives: 5257293.0000 - val_true_negatives: 55589880.0000 - val_false_negatives: 3749230.0000 - val_precision: 0.8873 - val_recall: 0.9169\n",
      "Epoch 413/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0128 - accuracy: 0.9897 - binary_iou: 0.9789 - true_positives: 129474112.0000 - false_positives: 1653270.0000 - true_negatives: 186748432.0000 - false_negatives: 1644826.0000 - precision: 0.9874 - recall: 0.9875 - val_loss: 0.0999 - val_accuracy: 0.9148 - val_binary_iou: 0.8405 - val_true_positives: 41260196.0000 - val_false_positives: 5177006.0000 - val_true_negatives: 55687408.0000 - val_false_negatives: 3847122.0000 - val_precision: 0.8885 - val_recall: 0.9147\n",
      "Epoch 414/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0128 - accuracy: 0.9896 - binary_iou: 0.9788 - true_positives: 129507280.0000 - false_positives: 1661130.0000 - true_negatives: 186697424.0000 - false_negatives: 1655002.0000 - precision: 0.9873 - recall: 0.9874 - val_loss: 0.1002 - val_accuracy: 0.9148 - val_binary_iou: 0.8404 - val_true_positives: 41151876.0000 - val_false_positives: 4996295.0000 - val_true_negatives: 55789076.0000 - val_false_negatives: 4034453.0000 - val_precision: 0.8917 - val_recall: 0.9107\n",
      "Epoch 415/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0131 - accuracy: 0.9894 - binary_iou: 0.9783 - true_positives: 129355376.0000 - false_positives: 1677236.0000 - true_negatives: 186768480.0000 - false_negatives: 1719590.0000 - precision: 0.9872 - recall: 0.9869 - val_loss: 0.1021 - val_accuracy: 0.9129 - val_binary_iou: 0.8376 - val_true_positives: 41637600.0000 - val_false_positives: 5762332.0000 - val_true_negatives: 55106640.0000 - val_false_negatives: 3465145.0000 - val_precision: 0.8784 - val_recall: 0.9232\n",
      "Epoch 416/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129422688.0000 - false_positives: 1661748.0000 - true_negatives: 186755568.0000 - false_negatives: 1680770.0000 - precision: 0.9873 - recall: 0.9872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.1_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0129 - accuracy: 0.9895 - binary_iou: 0.9786 - true_positives: 129422688.0000 - false_positives: 1661748.0000 - true_negatives: 186755568.0000 - false_negatives: 1680770.0000 - precision: 0.9873 - recall: 0.9872 - val_loss: 0.0979 - val_accuracy: 0.9171 - val_binary_iou: 0.8443 - val_true_positives: 41184256.0000 - val_false_positives: 4769223.0000 - val_true_negatives: 56003996.0000 - val_false_negatives: 4014224.0000 - val_precision: 0.8962 - val_recall: 0.9112\n",
      "Epoch 417/500\n",
      "199/199 [==============================] - 77s 383ms/step - loss: 0.0127 - accuracy: 0.9897 - binary_iou: 0.9789 - true_positives: 129535216.0000 - false_positives: 1641008.0000 - true_negatives: 186687328.0000 - false_negatives: 1657286.0000 - precision: 0.9875 - recall: 0.9874 - val_loss: 0.0992 - val_accuracy: 0.9157 - val_binary_iou: 0.8421 - val_true_positives: 41336280.0000 - val_false_positives: 5173583.0000 - val_true_negatives: 55702896.0000 - val_false_negatives: 3758948.0000 - val_precision: 0.8888 - val_recall: 0.9166\n",
      "Epoch 418/500\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0127 - accuracy: 0.9897 - binary_iou: 0.9790 - true_positives: 129504640.0000 - false_positives: 1645148.0000 - true_negatives: 186732192.0000 - false_negatives: 1638745.0000 - precision: 0.9875 - recall: 0.9875 - val_loss: 0.1014 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41364688.0000 - val_false_positives: 5442599.0000 - val_true_negatives: 55460672.0000 - val_false_negatives: 3703747.0000 - val_precision: 0.8837 - val_recall: 0.9178\n",
      "Epoch 419/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0126 - accuracy: 0.9898 - binary_iou: 0.9791 - true_positives: 129557096.0000 - false_positives: 1636598.0000 - true_negatives: 186699008.0000 - false_negatives: 1628083.0000 - precision: 0.9875 - recall: 0.9876 - val_loss: 0.1008 - val_accuracy: 0.9142 - val_binary_iou: 0.8396 - val_true_positives: 41306848.0000 - val_false_positives: 5233246.0000 - val_true_negatives: 55577696.0000 - val_false_negatives: 3853925.0000 - val_precision: 0.8876 - val_recall: 0.9147\n",
      "Epoch 420/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0125 - accuracy: 0.9899 - binary_iou: 0.9793 - true_positives: 129487664.0000 - false_positives: 1623945.0000 - true_negatives: 186792192.0000 - false_negatives: 1616901.0000 - precision: 0.9876 - recall: 0.9877 - val_loss: 0.0995 - val_accuracy: 0.9152 - val_binary_iou: 0.8413 - val_true_positives: 41400916.0000 - val_false_positives: 5269590.0000 - val_true_negatives: 55588744.0000 - val_false_negatives: 3712453.0000 - val_precision: 0.8871 - val_recall: 0.9177\n",
      "Epoch 421/500\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0126 - accuracy: 0.9898 - binary_iou: 0.9791 - true_positives: 129517168.0000 - false_positives: 1635428.0000 - true_negatives: 186735936.0000 - false_negatives: 1632282.0000 - precision: 0.9875 - recall: 0.9876 - val_loss: 0.1010 - val_accuracy: 0.9140 - val_binary_iou: 0.8392 - val_true_positives: 41378336.0000 - val_false_positives: 5406508.0000 - val_true_negatives: 55478076.0000 - val_false_negatives: 3708797.0000 - val_precision: 0.8844 - val_recall: 0.9177\n",
      "Epoch 422/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0126 - accuracy: 0.9898 - binary_iou: 0.9792 - true_positives: 129531912.0000 - false_positives: 1633057.0000 - true_negatives: 186738864.0000 - false_negatives: 1616929.0000 - precision: 0.9875 - recall: 0.9877 - val_loss: 0.1015 - val_accuracy: 0.9129 - val_binary_iou: 0.8376 - val_true_positives: 41646008.0000 - val_false_positives: 5804182.0000 - val_true_negatives: 55098416.0000 - val_false_negatives: 3423100.0000 - val_precision: 0.8777 - val_recall: 0.9240\n",
      "Epoch 423/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9898 - binary_iou: 0.9792 - true_positives: 129530256.0000 - false_positives: 1610807.0000 - true_negatives: 186742368.0000 - false_negatives: 1637272.0000 - precision: 0.9877 - recall: 0.9875 - val_loss: 0.1002 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41342532.0000 - val_false_positives: 5382310.0000 - val_true_negatives: 55555732.0000 - val_false_negatives: 3691132.0000 - val_precision: 0.8848 - val_recall: 0.9180\n",
      "Epoch 424/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9899 - binary_iou: 0.9794 - true_positives: 129531272.0000 - false_positives: 1622815.0000 - true_negatives: 186767968.0000 - false_negatives: 1598710.0000 - precision: 0.9876 - recall: 0.9878 - val_loss: 0.0995 - val_accuracy: 0.9149 - val_binary_iou: 0.8406 - val_true_positives: 41307428.0000 - val_false_positives: 5222793.0000 - val_true_negatives: 55643368.0000 - val_false_negatives: 3798103.0000 - val_precision: 0.8878 - val_recall: 0.9158\n",
      "Epoch 425/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0124 - accuracy: 0.9899 - binary_iou: 0.9794 - true_positives: 129493032.0000 - false_positives: 1617795.0000 - true_negatives: 186811168.0000 - false_negatives: 1598795.0000 - precision: 0.9877 - recall: 0.9878 - val_loss: 0.0993 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41351296.0000 - val_false_positives: 5239513.0000 - val_true_negatives: 55624040.0000 - val_false_negatives: 3756858.0000 - val_precision: 0.8875 - val_recall: 0.9167\n",
      "Epoch 426/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0126 - accuracy: 0.9899 - binary_iou: 0.9793 - true_positives: 129546888.0000 - false_positives: 1627914.0000 - true_negatives: 186732288.0000 - false_negatives: 1613733.0000 - precision: 0.9876 - recall: 0.9877 - val_loss: 0.1003 - val_accuracy: 0.9148 - val_binary_iou: 0.8405 - val_true_positives: 41358032.0000 - val_false_positives: 5300437.0000 - val_true_negatives: 55579872.0000 - val_false_negatives: 3733378.0000 - val_precision: 0.8864 - val_recall: 0.9172\n",
      "Epoch 427/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0124 - accuracy: 0.9899 - binary_iou: 0.9794 - true_positives: 129510568.0000 - false_positives: 1612522.0000 - true_negatives: 186785632.0000 - false_negatives: 1611942.0000 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9136 - val_binary_iou: 0.8387 - val_true_positives: 41563488.0000 - val_false_positives: 5541108.0000 - val_true_negatives: 55257136.0000 - val_false_negatives: 3609992.0000 - val_precision: 0.8824 - val_recall: 0.9201\n",
      "Epoch 428/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0124 - accuracy: 0.9900 - binary_iou: 0.9795 - true_positives: 129602624.0000 - false_positives: 1616621.0000 - true_negatives: 186707984.0000 - false_negatives: 1593538.0000 - precision: 0.9877 - recall: 0.9879 - val_loss: 0.1000 - val_accuracy: 0.9147 - val_binary_iou: 0.8404 - val_true_positives: 41371084.0000 - val_false_positives: 5334969.0000 - val_true_negatives: 55563976.0000 - val_false_negatives: 3701694.0000 - val_precision: 0.8858 - val_recall: 0.9179\n",
      "Epoch 429/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9899 - binary_iou: 0.9793 - true_positives: 129530592.0000 - false_positives: 1608144.0000 - true_negatives: 186751728.0000 - false_negatives: 1630265.0000 - precision: 0.9877 - recall: 0.9876 - val_loss: 0.1013 - val_accuracy: 0.9126 - val_binary_iou: 0.8370 - val_true_positives: 41695424.0000 - val_false_positives: 5812385.0000 - val_true_negatives: 55012476.0000 - val_false_negatives: 3451435.0000 - val_precision: 0.8777 - val_recall: 0.9236\n",
      "Epoch 430/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9899 - binary_iou: 0.9794 - true_positives: 129454496.0000 - false_positives: 1615232.0000 - true_negatives: 186841840.0000 - false_negatives: 1609276.0000 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.1009 - val_accuracy: 0.9139 - val_binary_iou: 0.8390 - val_true_positives: 41277664.0000 - val_false_positives: 5308231.0000 - val_true_negatives: 55573316.0000 - val_false_negatives: 3812501.0000 - val_precision: 0.8861 - val_recall: 0.9154\n",
      "Epoch 431/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9899 - binary_iou: 0.9793 - true_positives: 129455664.0000 - false_positives: 1617403.0000 - true_negatives: 186830320.0000 - false_negatives: 1617317.0000 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.1007 - val_accuracy: 0.9141 - val_binary_iou: 0.8393 - val_true_positives: 41106008.0000 - val_false_positives: 5167377.0000 - val_true_negatives: 55767504.0000 - val_false_negatives: 3930812.0000 - val_precision: 0.8883 - val_recall: 0.9127\n",
      "Epoch 432/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0126 - accuracy: 0.9898 - binary_iou: 0.9791 - true_positives: 129440512.0000 - false_positives: 1623442.0000 - true_negatives: 186820000.0000 - false_negatives: 1636757.0000 - precision: 0.9876 - recall: 0.9875 - val_loss: 0.0995 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41303356.0000 - val_false_positives: 5155247.0000 - val_true_negatives: 55671640.0000 - val_false_negatives: 3841473.0000 - val_precision: 0.8890 - val_recall: 0.9149\n",
      "Epoch 433/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0125 - accuracy: 0.9898 - binary_iou: 0.9792 - true_positives: 129562776.0000 - false_positives: 1621549.0000 - true_negatives: 186713696.0000 - false_negatives: 1622771.0000 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.0997 - val_accuracy: 0.9138 - val_binary_iou: 0.8389 - val_true_positives: 41447100.0000 - val_false_positives: 5502517.0000 - val_true_negatives: 55386880.0000 - val_false_negatives: 3635198.0000 - val_precision: 0.8828 - val_recall: 0.9194\n",
      "Epoch 434/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0124 - accuracy: 0.9900 - binary_iou: 0.9795 - true_positives: 129411064.0000 - false_positives: 1616458.0000 - true_negatives: 186902032.0000 - false_negatives: 1591254.0000 - precision: 0.9877 - recall: 0.9879 - val_loss: 0.1017 - val_accuracy: 0.9137 - val_binary_iou: 0.8386 - val_true_positives: 41279156.0000 - val_false_positives: 5389034.0000 - val_true_negatives: 55545184.0000 - val_false_negatives: 3758344.0000 - val_precision: 0.8845 - val_recall: 0.9166\n",
      "Epoch 435/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0124 - accuracy: 0.9900 - binary_iou: 0.9795 - true_positives: 129511712.0000 - false_positives: 1622817.0000 - true_negatives: 186802992.0000 - false_negatives: 1583218.0000 - precision: 0.9876 - recall: 0.9879 - val_loss: 0.1006 - val_accuracy: 0.9145 - val_binary_iou: 0.8399 - val_true_positives: 41262544.0000 - val_false_positives: 5232300.0000 - val_true_negatives: 55647220.0000 - val_false_negatives: 3829634.0000 - val_precision: 0.8875 - val_recall: 0.9151\n",
      "Epoch 436/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9798 - true_positives: 129506640.0000 - false_positives: 1591557.0000 - true_negatives: 186851168.0000 - false_negatives: 1571465.0000 - precision: 0.9879 - recall: 0.9880 - val_loss: 0.1014 - val_accuracy: 0.9133 - val_binary_iou: 0.8380 - val_true_positives: 41466324.0000 - val_false_positives: 5550636.0000 - val_true_negatives: 55314528.0000 - val_false_negatives: 3640206.0000 - val_precision: 0.8819 - val_recall: 0.9193\n",
      "Epoch 437/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0123 - accuracy: 0.9901 - binary_iou: 0.9797 - true_positives: 129602736.0000 - false_positives: 1587469.0000 - true_negatives: 186746848.0000 - false_negatives: 1583660.0000 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.1001 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41218576.0000 - val_false_positives: 5261616.0000 - val_true_negatives: 55684668.0000 - val_false_negatives: 3806848.0000 - val_precision: 0.8868 - val_recall: 0.9155\n",
      "Epoch 438/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9798 - true_positives: 129558920.0000 - false_positives: 1591503.0000 - true_negatives: 186799808.0000 - false_negatives: 1570489.0000 - precision: 0.9879 - recall: 0.9880 - val_loss: 0.1019 - val_accuracy: 0.9133 - val_binary_iou: 0.8378 - val_true_positives: 41149840.0000 - val_false_positives: 5292567.0000 - val_true_negatives: 55632372.0000 - val_false_negatives: 3896937.0000 - val_precision: 0.8860 - val_recall: 0.9135\n",
      "Epoch 439/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9797 - true_positives: 129611104.0000 - false_positives: 1593744.0000 - true_negatives: 186743424.0000 - false_negatives: 1572491.0000 - precision: 0.9879 - recall: 0.9880 - val_loss: 0.0996 - val_accuracy: 0.9153 - val_binary_iou: 0.8414 - val_true_positives: 41373792.0000 - val_false_positives: 5161046.0000 - val_true_negatives: 55624000.0000 - val_false_negatives: 3812874.0000 - val_precision: 0.8891 - val_recall: 0.9156\n",
      "Epoch 440/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0123 - accuracy: 0.9900 - binary_iou: 0.9796 - true_positives: 129539048.0000 - false_positives: 1586092.0000 - true_negatives: 186800976.0000 - false_negatives: 1594596.0000 - precision: 0.9879 - recall: 0.9878 - val_loss: 0.0996 - val_accuracy: 0.9147 - val_binary_iou: 0.8405 - val_true_positives: 41462808.0000 - val_false_positives: 5296913.0000 - val_true_negatives: 55474592.0000 - val_false_negatives: 3737388.0000 - val_precision: 0.8867 - val_recall: 0.9173\n",
      "Epoch 441/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0123 - accuracy: 0.9900 - binary_iou: 0.9796 - true_positives: 129525456.0000 - false_positives: 1600252.0000 - true_negatives: 186804832.0000 - false_negatives: 1590276.0000 - precision: 0.9878 - recall: 0.9879 - val_loss: 0.1007 - val_accuracy: 0.9139 - val_binary_iou: 0.8392 - val_true_positives: 41500980.0000 - val_false_positives: 5486178.0000 - val_true_negatives: 55348540.0000 - val_false_negatives: 3636010.0000 - val_precision: 0.8832 - val_recall: 0.9194\n",
      "Epoch 442/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9798 - true_positives: 129514632.0000 - false_positives: 1568169.0000 - true_negatives: 186853856.0000 - false_negatives: 1584106.0000 - precision: 0.9880 - recall: 0.9879 - val_loss: 0.1009 - val_accuracy: 0.9141 - val_binary_iou: 0.8393 - val_true_positives: 41282528.0000 - val_false_positives: 5327291.0000 - val_true_negatives: 55584168.0000 - val_false_negatives: 3777734.0000 - val_precision: 0.8857 - val_recall: 0.9162\n",
      "Epoch 443/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9797 - true_positives: 129560104.0000 - false_positives: 1587006.0000 - true_negatives: 186796032.0000 - false_negatives: 1577619.0000 - precision: 0.9879 - recall: 0.9880 - val_loss: 0.1010 - val_accuracy: 0.9137 - val_binary_iou: 0.8388 - val_true_positives: 41677156.0000 - val_false_positives: 5742796.0000 - val_true_negatives: 55144536.0000 - val_false_negatives: 3407222.0000 - val_precision: 0.8789 - val_recall: 0.9244\n",
      "Epoch 444/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0123 - accuracy: 0.9901 - binary_iou: 0.9797 - true_positives: 129579728.0000 - false_positives: 1587793.0000 - true_negatives: 186766016.0000 - false_negatives: 1587188.0000 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.1000 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41390512.0000 - val_false_positives: 5435855.0000 - val_true_negatives: 55434972.0000 - val_false_negatives: 3710376.0000 - val_precision: 0.8839 - val_recall: 0.9177\n",
      "Epoch 445/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0121 - accuracy: 0.9902 - binary_iou: 0.9799 - true_positives: 129552400.0000 - false_positives: 1574700.0000 - true_negatives: 186829408.0000 - false_negatives: 1564279.0000 - precision: 0.9880 - recall: 0.9881 - val_loss: 0.1008 - val_accuracy: 0.9137 - val_binary_iou: 0.8388 - val_true_positives: 41408800.0000 - val_false_positives: 5462229.0000 - val_true_negatives: 55422572.0000 - val_false_negatives: 3678115.0000 - val_precision: 0.8835 - val_recall: 0.9184\n",
      "Epoch 446/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0121 - accuracy: 0.9902 - binary_iou: 0.9800 - true_positives: 129567184.0000 - false_positives: 1567654.0000 - true_negatives: 186824608.0000 - false_negatives: 1561316.0000 - precision: 0.9880 - recall: 0.9881 - val_loss: 0.0999 - val_accuracy: 0.9151 - val_binary_iou: 0.8411 - val_true_positives: 41452480.0000 - val_false_positives: 5302121.0000 - val_true_negatives: 55521368.0000 - val_false_negatives: 3695729.0000 - val_precision: 0.8866 - val_recall: 0.9181\n",
      "Epoch 447/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9902 - binary_iou: 0.9799 - true_positives: 129483760.0000 - false_positives: 1566907.0000 - true_negatives: 186898400.0000 - false_negatives: 1571687.0000 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.1001 - val_accuracy: 0.9140 - val_binary_iou: 0.8393 - val_true_positives: 41553224.0000 - val_false_positives: 5483451.0000 - val_true_negatives: 55303704.0000 - val_false_negatives: 3631317.0000 - val_precision: 0.8834 - val_recall: 0.9196\n",
      "Epoch 448/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0121 - accuracy: 0.9902 - binary_iou: 0.9800 - true_positives: 129537280.0000 - false_positives: 1567144.0000 - true_negatives: 186862368.0000 - false_negatives: 1553994.0000 - precision: 0.9880 - recall: 0.9881 - val_loss: 0.1004 - val_accuracy: 0.9134 - val_binary_iou: 0.8384 - val_true_positives: 41513720.0000 - val_false_positives: 5657556.0000 - val_true_negatives: 55285840.0000 - val_false_negatives: 3514598.0000 - val_precision: 0.8801 - val_recall: 0.9219\n",
      "Epoch 449/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9902 - binary_iou: 0.9799 - true_positives: 129515000.0000 - false_positives: 1568808.0000 - true_negatives: 186865024.0000 - false_negatives: 1571856.0000 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.0992 - val_accuracy: 0.9152 - val_binary_iou: 0.8412 - val_true_positives: 41321592.0000 - val_false_positives: 5242653.0000 - val_true_negatives: 55667580.0000 - val_false_negatives: 3739896.0000 - val_precision: 0.8874 - val_recall: 0.9170\n",
      "Epoch 450/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0123 - accuracy: 0.9900 - binary_iou: 0.9796 - true_positives: 129515256.0000 - false_positives: 1589906.0000 - true_negatives: 186815120.0000 - false_negatives: 1600524.0000 - precision: 0.9879 - recall: 0.9878 - val_loss: 0.1014 - val_accuracy: 0.9130 - val_binary_iou: 0.8376 - val_true_positives: 41483840.0000 - val_false_positives: 5592885.0000 - val_true_negatives: 55265756.0000 - val_false_negatives: 3629226.0000 - val_precision: 0.8812 - val_recall: 0.9196\n",
      "Epoch 451/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0122 - accuracy: 0.9901 - binary_iou: 0.9798 - true_positives: 129487448.0000 - false_positives: 1576512.0000 - true_negatives: 186872736.0000 - false_negatives: 1584013.0000 - precision: 0.9880 - recall: 0.9879 - val_loss: 0.0999 - val_accuracy: 0.9147 - val_binary_iou: 0.8402 - val_true_positives: 41273748.0000 - val_false_positives: 5183804.0000 - val_true_negatives: 55654244.0000 - val_false_negatives: 3859923.0000 - val_precision: 0.8884 - val_recall: 0.9145\n",
      "Epoch 452/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0120 - accuracy: 0.9903 - binary_iou: 0.9801 - true_positives: 129557464.0000 - false_positives: 1564441.0000 - true_negatives: 186848400.0000 - false_negatives: 1550446.0000 - precision: 0.9881 - recall: 0.9882 - val_loss: 0.1009 - val_accuracy: 0.9139 - val_binary_iou: 0.8391 - val_true_positives: 41347576.0000 - val_false_positives: 5354624.0000 - val_true_negatives: 55503500.0000 - val_false_negatives: 3766021.0000 - val_precision: 0.8853 - val_recall: 0.9165\n",
      "Epoch 453/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0120 - accuracy: 0.9903 - binary_iou: 0.9801 - true_positives: 129586800.0000 - false_positives: 1553334.0000 - true_negatives: 186826208.0000 - false_negatives: 1554487.0000 - precision: 0.9882 - recall: 0.9881 - val_loss: 0.1023 - val_accuracy: 0.9123 - val_binary_iou: 0.8363 - val_true_positives: 41445656.0000 - val_false_positives: 5606738.0000 - val_true_negatives: 55228172.0000 - val_false_negatives: 3691142.0000 - val_precision: 0.8808 - val_recall: 0.9182\n",
      "Epoch 454/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0120 - accuracy: 0.9903 - binary_iou: 0.9801 - true_positives: 129574160.0000 - false_positives: 1561632.0000 - true_negatives: 186840144.0000 - false_negatives: 1544847.0000 - precision: 0.9881 - recall: 0.9882 - val_loss: 0.1011 - val_accuracy: 0.9131 - val_binary_iou: 0.8378 - val_true_positives: 41583868.0000 - val_false_positives: 5687608.0000 - val_true_negatives: 55174096.0000 - val_false_negatives: 3526150.0000 - val_precision: 0.8797 - val_recall: 0.9218\n",
      "Epoch 455/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0120 - accuracy: 0.9903 - binary_iou: 0.9802 - true_positives: 129521392.0000 - false_positives: 1549675.0000 - true_negatives: 186898688.0000 - false_negatives: 1550963.0000 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.1009 - val_accuracy: 0.9134 - val_binary_iou: 0.8383 - val_true_positives: 41464940.0000 - val_false_positives: 5448896.0000 - val_true_negatives: 55334004.0000 - val_false_negatives: 3723860.0000 - val_precision: 0.8839 - val_recall: 0.9176\n",
      "Epoch 456/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0119 - accuracy: 0.9904 - binary_iou: 0.9803 - true_positives: 129655864.0000 - false_positives: 1552183.0000 - true_negatives: 186786256.0000 - false_negatives: 1526503.0000 - precision: 0.9882 - recall: 0.9884 - val_loss: 0.0996 - val_accuracy: 0.9153 - val_binary_iou: 0.8411 - val_true_positives: 41141352.0000 - val_false_positives: 5058040.0000 - val_true_negatives: 55849448.0000 - val_false_negatives: 3922880.0000 - val_precision: 0.8905 - val_recall: 0.9129\n",
      "Epoch 457/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129612056.0000 - false_positives: 1526422.0000 - true_negatives: 186872688.0000 - false_negatives: 1509606.0000 - precision: 0.9884 - recall: 0.9885 - val_loss: 0.1001 - val_accuracy: 0.9145 - val_binary_iou: 0.8401 - val_true_positives: 41435296.0000 - val_false_positives: 5384507.0000 - val_true_negatives: 55476896.0000 - val_false_negatives: 3675015.0000 - val_precision: 0.8850 - val_recall: 0.9185\n",
      "Epoch 458/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9905 - binary_iou: 0.9805 - true_positives: 129590960.0000 - false_positives: 1520922.0000 - true_negatives: 186888240.0000 - false_negatives: 1520549.0000 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.1000 - val_accuracy: 0.9140 - val_binary_iou: 0.8394 - val_true_positives: 41537264.0000 - val_false_positives: 5522378.0000 - val_true_negatives: 55325376.0000 - val_false_negatives: 3586700.0000 - val_precision: 0.8827 - val_recall: 0.9205\n",
      "Epoch 459/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9905 - binary_iou: 0.9805 - true_positives: 129577488.0000 - false_positives: 1532112.0000 - true_negatives: 186894880.0000 - false_negatives: 1516316.0000 - precision: 0.9883 - recall: 0.9884 - val_loss: 0.1000 - val_accuracy: 0.9148 - val_binary_iou: 0.8405 - val_true_positives: 41261544.0000 - val_false_positives: 5143543.0000 - val_true_negatives: 55681380.0000 - val_false_negatives: 3885234.0000 - val_precision: 0.8892 - val_recall: 0.9139\n",
      "Epoch 460/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9904 - binary_iou: 0.9804 - true_positives: 129623632.0000 - false_positives: 1534912.0000 - true_negatives: 186841872.0000 - false_negatives: 1520347.0000 - precision: 0.9883 - recall: 0.9884 - val_loss: 0.1015 - val_accuracy: 0.9127 - val_binary_iou: 0.8370 - val_true_positives: 41360080.0000 - val_false_positives: 5458427.0000 - val_true_negatives: 55361236.0000 - val_false_negatives: 3791970.0000 - val_precision: 0.8834 - val_recall: 0.9160\n",
      "Epoch 461/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0119 - accuracy: 0.9904 - binary_iou: 0.9803 - true_positives: 129635152.0000 - false_positives: 1537642.0000 - true_negatives: 186807040.0000 - false_negatives: 1540815.0000 - precision: 0.9883 - recall: 0.9883 - val_loss: 0.0996 - val_accuracy: 0.9147 - val_binary_iou: 0.8404 - val_true_positives: 41368352.0000 - val_false_positives: 5317994.0000 - val_true_negatives: 55564204.0000 - val_false_negatives: 3721160.0000 - val_precision: 0.8861 - val_recall: 0.9175\n",
      "Epoch 462/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0120 - accuracy: 0.9903 - binary_iou: 0.9802 - true_positives: 129492832.0000 - false_positives: 1549314.0000 - true_negatives: 186930576.0000 - false_negatives: 1548015.0000 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.1002 - val_accuracy: 0.9146 - val_binary_iou: 0.8401 - val_true_positives: 41313416.0000 - val_false_positives: 5230026.0000 - val_true_negatives: 55604448.0000 - val_false_negatives: 3823838.0000 - val_precision: 0.8876 - val_recall: 0.9153\n",
      "Epoch 463/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0119 - accuracy: 0.9903 - binary_iou: 0.9802 - true_positives: 129515184.0000 - false_positives: 1543673.0000 - true_negatives: 186918144.0000 - false_negatives: 1543798.0000 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.1008 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41390688.0000 - val_false_positives: 5369179.0000 - val_true_negatives: 55488456.0000 - val_false_negatives: 3723407.0000 - val_precision: 0.8852 - val_recall: 0.9175\n",
      "Epoch 464/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9904 - binary_iou: 0.9804 - true_positives: 129591688.0000 - false_positives: 1540662.0000 - true_negatives: 186871040.0000 - false_negatives: 1517332.0000 - precision: 0.9883 - recall: 0.9884 - val_loss: 0.0989 - val_accuracy: 0.9155 - val_binary_iou: 0.8418 - val_true_positives: 41326376.0000 - val_false_positives: 5134559.0000 - val_true_negatives: 55695072.0000 - val_false_negatives: 3815702.0000 - val_precision: 0.8895 - val_recall: 0.9155\n",
      "Epoch 465/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9905 - binary_iou: 0.9805 - true_positives: 129637712.0000 - false_positives: 1516435.0000 - true_negatives: 186836032.0000 - false_negatives: 1530590.0000 - precision: 0.9884 - recall: 0.9883 - val_loss: 0.1009 - val_accuracy: 0.9145 - val_binary_iou: 0.8399 - val_true_positives: 41150624.0000 - val_false_positives: 5166533.0000 - val_true_negatives: 55764160.0000 - val_false_negatives: 3890412.0000 - val_precision: 0.8885 - val_recall: 0.9136\n",
      "Epoch 466/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9807 - true_positives: 129596640.0000 - false_positives: 1527148.0000 - true_negatives: 186902736.0000 - false_negatives: 1494168.0000 - precision: 0.9884 - recall: 0.9886 - val_loss: 0.0995 - val_accuracy: 0.9149 - val_binary_iou: 0.8406 - val_true_positives: 41325000.0000 - val_false_positives: 5206954.0000 - val_true_negatives: 55624656.0000 - val_false_negatives: 3815088.0000 - val_precision: 0.8881 - val_recall: 0.9155\n",
      "Epoch 467/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129597736.0000 - false_positives: 1515922.0000 - true_negatives: 186896384.0000 - false_negatives: 1510799.0000 - precision: 0.9884 - recall: 0.9885 - val_loss: 0.1000 - val_accuracy: 0.9145 - val_binary_iou: 0.8400 - val_true_positives: 41439128.0000 - val_false_positives: 5412602.0000 - val_true_negatives: 55469448.0000 - val_false_negatives: 3650538.0000 - val_precision: 0.8845 - val_recall: 0.9190\n",
      "Epoch 468/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129622568.0000 - false_positives: 1517614.0000 - true_negatives: 186871888.0000 - false_negatives: 1508683.0000 - precision: 0.9884 - recall: 0.9885 - val_loss: 0.1008 - val_accuracy: 0.9141 - val_binary_iou: 0.8395 - val_true_positives: 41472688.0000 - val_false_positives: 5507433.0000 - val_true_negatives: 55399996.0000 - val_false_negatives: 3591603.0000 - val_precision: 0.8828 - val_recall: 0.9203\n",
      "Epoch 469/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129607800.0000 - false_positives: 1530742.0000 - true_negatives: 186884864.0000 - false_negatives: 1497395.0000 - precision: 0.9883 - recall: 0.9886 - val_loss: 0.0996 - val_accuracy: 0.9153 - val_binary_iou: 0.8413 - val_true_positives: 41189428.0000 - val_false_positives: 5013735.0000 - val_true_negatives: 55808576.0000 - val_false_negatives: 3959965.0000 - val_precision: 0.8915 - val_recall: 0.9123\n",
      "Epoch 470/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9905 - binary_iou: 0.9805 - true_positives: 129580816.0000 - false_positives: 1530754.0000 - true_negatives: 186890560.0000 - false_negatives: 1518685.0000 - precision: 0.9883 - recall: 0.9884 - val_loss: 0.1009 - val_accuracy: 0.9140 - val_binary_iou: 0.8392 - val_true_positives: 41296972.0000 - val_false_positives: 5307958.0000 - val_true_negatives: 55561904.0000 - val_false_negatives: 3804889.0000 - val_precision: 0.8861 - val_recall: 0.9156\n",
      "Epoch 471/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9805 - true_positives: 129650472.0000 - false_positives: 1533351.0000 - true_negatives: 186829376.0000 - false_negatives: 1507555.0000 - precision: 0.9883 - recall: 0.9885 - val_loss: 0.1005 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41460672.0000 - val_false_positives: 5359273.0000 - val_true_negatives: 55434680.0000 - val_false_negatives: 3717086.0000 - val_precision: 0.8855 - val_recall: 0.9177\n",
      "Epoch 472/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0118 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129626568.0000 - false_positives: 1520727.0000 - true_negatives: 186857008.0000 - false_negatives: 1516434.0000 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.1017 - val_accuracy: 0.9130 - val_binary_iou: 0.8375 - val_true_positives: 41479912.0000 - val_false_positives: 5654735.0000 - val_true_negatives: 55268332.0000 - val_false_negatives: 3568730.0000 - val_precision: 0.8800 - val_recall: 0.9208\n",
      "Epoch 473/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129606448.0000 - false_positives: 1524557.0000 - true_negatives: 186897600.0000 - false_negatives: 1492137.0000 - precision: 0.9884 - recall: 0.9886 - val_loss: 0.1019 - val_accuracy: 0.9130 - val_binary_iou: 0.8374 - val_true_positives: 41317668.0000 - val_false_positives: 5506549.0000 - val_true_negatives: 55430708.0000 - val_false_negatives: 3716776.0000 - val_precision: 0.8824 - val_recall: 0.9175\n",
      "Epoch 474/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0117 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129636224.0000 - false_positives: 1502790.0000 - true_negatives: 186874048.0000 - false_negatives: 1507749.0000 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.1015 - val_accuracy: 0.9135 - val_binary_iou: 0.8383 - val_true_positives: 41391244.0000 - val_false_positives: 5485260.0000 - val_true_negatives: 55410912.0000 - val_false_negatives: 3684301.0000 - val_precision: 0.8830 - val_recall: 0.9183\n",
      "Epoch 475/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129564848.0000 - false_positives: 1501537.0000 - true_negatives: 186940512.0000 - false_negatives: 1513882.0000 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.1001 - val_accuracy: 0.9143 - val_binary_iou: 0.8397 - val_true_positives: 41401328.0000 - val_false_positives: 5258781.0000 - val_true_negatives: 55488616.0000 - val_false_negatives: 3822993.0000 - val_precision: 0.8873 - val_recall: 0.9155\n",
      "Epoch 476/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0116 - accuracy: 0.9906 - binary_iou: 0.9808 - true_positives: 129684688.0000 - false_positives: 1501292.0000 - true_negatives: 186838624.0000 - false_negatives: 1496235.0000 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.0991 - val_accuracy: 0.9156 - val_binary_iou: 0.8418 - val_true_positives: 41231556.0000 - val_false_positives: 5027531.0000 - val_true_negatives: 55796268.0000 - val_false_negatives: 3916345.0000 - val_precision: 0.8913 - val_recall: 0.9133\n",
      "Epoch 477/500\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0116 - accuracy: 0.9906 - binary_iou: 0.9808 - true_positives: 129662464.0000 - false_positives: 1501771.0000 - true_negatives: 186859728.0000 - false_negatives: 1496803.0000 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.1004 - val_accuracy: 0.9152 - val_binary_iou: 0.8410 - val_true_positives: 41153760.0000 - val_false_positives: 5044329.0000 - val_true_negatives: 55826388.0000 - val_false_negatives: 3947210.0000 - val_precision: 0.8908 - val_recall: 0.9125\n",
      "Epoch 478/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9905 - binary_iou: 0.9806 - true_positives: 129630376.0000 - false_positives: 1509799.0000 - true_negatives: 186866400.0000 - false_negatives: 1514188.0000 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.0995 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41278544.0000 - val_false_positives: 5244869.0000 - val_true_negatives: 55696528.0000 - val_false_negatives: 3751765.0000 - val_precision: 0.8873 - val_recall: 0.9167\n",
      "Epoch 479/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0116 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129645992.0000 - false_positives: 1515703.0000 - true_negatives: 186867200.0000 - false_negatives: 1491821.0000 - precision: 0.9884 - recall: 0.9886 - val_loss: 0.0988 - val_accuracy: 0.9161 - val_binary_iou: 0.8424 - val_true_positives: 41025676.0000 - val_false_positives: 4788915.0000 - val_true_negatives: 56050648.0000 - val_false_negatives: 4106480.0000 - val_precision: 0.8955 - val_recall: 0.9090\n",
      "Epoch 480/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9906 - binary_iou: 0.9808 - true_positives: 129518184.0000 - false_positives: 1511715.0000 - true_negatives: 186997264.0000 - false_negatives: 1493586.0000 - precision: 0.9885 - recall: 0.9886 - val_loss: 0.1000 - val_accuracy: 0.9144 - val_binary_iou: 0.8399 - val_true_positives: 41395472.0000 - val_false_positives: 5244395.0000 - val_true_negatives: 55505504.0000 - val_false_negatives: 3826323.0000 - val_precision: 0.8876 - val_recall: 0.9154\n",
      "Epoch 481/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0117 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129531048.0000 - false_positives: 1498606.0000 - true_negatives: 186981680.0000 - false_negatives: 1509430.0000 - precision: 0.9886 - recall: 0.9885 - val_loss: 0.0994 - val_accuracy: 0.9162 - val_binary_iou: 0.8426 - val_true_positives: 40992444.0000 - val_false_positives: 4835871.0000 - val_true_negatives: 56097932.0000 - val_false_negatives: 4045463.0000 - val_precision: 0.8945 - val_recall: 0.9102\n",
      "Epoch 482/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0116 - accuracy: 0.9906 - binary_iou: 0.9807 - true_positives: 129608568.0000 - false_positives: 1499619.0000 - true_negatives: 186905200.0000 - false_negatives: 1507424.0000 - precision: 0.9886 - recall: 0.9885 - val_loss: 0.0997 - val_accuracy: 0.9156 - val_binary_iou: 0.8417 - val_true_positives: 41147368.0000 - val_false_positives: 4986933.0000 - val_true_negatives: 55881024.0000 - val_false_negatives: 3956378.0000 - val_precision: 0.8919 - val_recall: 0.9123\n",
      "Epoch 483/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0115 - accuracy: 0.9907 - binary_iou: 0.9809 - true_positives: 129657784.0000 - false_positives: 1491261.0000 - true_negatives: 186879936.0000 - false_negatives: 1491717.0000 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.1001 - val_accuracy: 0.9143 - val_binary_iou: 0.8397 - val_true_positives: 41352856.0000 - val_false_positives: 5330939.0000 - val_true_negatives: 55540136.0000 - val_false_negatives: 3747799.0000 - val_precision: 0.8858 - val_recall: 0.9169\n",
      "Epoch 484/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0115 - accuracy: 0.9907 - binary_iou: 0.9809 - true_positives: 129637088.0000 - false_positives: 1495879.0000 - true_negatives: 186902064.0000 - false_negatives: 1485743.0000 - precision: 0.9886 - recall: 0.9887 - val_loss: 0.1005 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41314532.0000 - val_false_positives: 5244870.0000 - val_true_negatives: 55567800.0000 - val_false_negatives: 3844488.0000 - val_precision: 0.8874 - val_recall: 0.9149\n",
      "Epoch 485/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0116 - accuracy: 0.9907 - binary_iou: 0.9809 - true_positives: 129649008.0000 - false_positives: 1495215.0000 - true_negatives: 186885248.0000 - false_negatives: 1491222.0000 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.0987 - val_accuracy: 0.9163 - val_binary_iou: 0.8429 - val_true_positives: 41133280.0000 - val_false_positives: 4894052.0000 - val_true_negatives: 55970656.0000 - val_false_negatives: 3973730.0000 - val_precision: 0.8937 - val_recall: 0.9119\n",
      "Epoch 486/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0114 - accuracy: 0.9908 - binary_iou: 0.9811 - true_positives: 129627688.0000 - false_positives: 1477195.0000 - true_negatives: 186949440.0000 - false_negatives: 1466454.0000 - precision: 0.9887 - recall: 0.9888 - val_loss: 0.1002 - val_accuracy: 0.9149 - val_binary_iou: 0.8407 - val_true_positives: 41243316.0000 - val_false_positives: 5214964.0000 - val_true_negatives: 55711992.0000 - val_false_negatives: 3801438.0000 - val_precision: 0.8877 - val_recall: 0.9156\n",
      "Epoch 487/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0114 - accuracy: 0.9908 - binary_iou: 0.9812 - true_positives: 129674944.0000 - false_positives: 1473185.0000 - true_negatives: 186911280.0000 - false_negatives: 1461359.0000 - precision: 0.9888 - recall: 0.9889 - val_loss: 0.0998 - val_accuracy: 0.9159 - val_binary_iou: 0.8421 - val_true_positives: 41063592.0000 - val_false_positives: 4954399.0000 - val_true_negatives: 55991768.0000 - val_false_negatives: 3961954.0000 - val_precision: 0.8923 - val_recall: 0.9120\n",
      "Epoch 488/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0116 - accuracy: 0.9907 - binary_iou: 0.9809 - true_positives: 129581368.0000 - false_positives: 1496735.0000 - true_negatives: 186954160.0000 - false_negatives: 1488536.0000 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.1002 - val_accuracy: 0.9144 - val_binary_iou: 0.8398 - val_true_positives: 41280376.0000 - val_false_positives: 5275466.0000 - val_true_negatives: 55622472.0000 - val_false_negatives: 3793392.0000 - val_precision: 0.8867 - val_recall: 0.9158\n",
      "Epoch 489/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0114 - accuracy: 0.9908 - binary_iou: 0.9811 - true_positives: 129716112.0000 - false_positives: 1485087.0000 - true_negatives: 186853664.0000 - false_negatives: 1465962.0000 - precision: 0.9887 - recall: 0.9888 - val_loss: 0.1003 - val_accuracy: 0.9138 - val_binary_iou: 0.8389 - val_true_positives: 41397272.0000 - val_false_positives: 5458556.0000 - val_true_negatives: 55437572.0000 - val_false_negatives: 3678318.0000 - val_precision: 0.8835 - val_recall: 0.9184\n",
      "Epoch 490/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0114 - accuracy: 0.9907 - binary_iou: 0.9811 - true_positives: 129655056.0000 - false_positives: 1481773.0000 - true_negatives: 186908384.0000 - false_negatives: 1475594.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.1002 - val_accuracy: 0.9146 - val_binary_iou: 0.8403 - val_true_positives: 41409052.0000 - val_false_positives: 5397295.0000 - val_true_negatives: 55515592.0000 - val_false_negatives: 3649791.0000 - val_precision: 0.8847 - val_recall: 0.9190\n",
      "Epoch 491/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0114 - accuracy: 0.9908 - binary_iou: 0.9812 - true_positives: 129680744.0000 - false_positives: 1487901.0000 - true_negatives: 186897024.0000 - false_negatives: 1455114.0000 - precision: 0.9887 - recall: 0.9889 - val_loss: 0.1010 - val_accuracy: 0.9142 - val_binary_iou: 0.8395 - val_true_positives: 41364928.0000 - val_false_positives: 5301919.0000 - val_true_negatives: 55513916.0000 - val_false_negatives: 3790947.0000 - val_precision: 0.8864 - val_recall: 0.9160\n",
      "Epoch 492/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129750344.0000 - false_positives: 1467538.0000 - true_negatives: 186858560.0000 - false_negatives: 1444312.0000 - precision: 0.9888 - recall: 0.9890 - val_loss: 0.1001 - val_accuracy: 0.9151 - val_binary_iou: 0.8410 - val_true_positives: 41290496.0000 - val_false_positives: 5204494.0000 - val_true_negatives: 55683408.0000 - val_false_negatives: 3793313.0000 - val_precision: 0.8881 - val_recall: 0.9159\n",
      "Epoch 493/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9813 - true_positives: 129657448.0000 - false_positives: 1475660.0000 - true_negatives: 186947968.0000 - false_negatives: 1439621.0000 - precision: 0.9887 - recall: 0.9890 - val_loss: 0.0994 - val_accuracy: 0.9150 - val_binary_iou: 0.8409 - val_true_positives: 41424792.0000 - val_false_positives: 5338714.0000 - val_true_negatives: 55535144.0000 - val_false_negatives: 3673076.0000 - val_precision: 0.8858 - val_recall: 0.9186\n",
      "Epoch 494/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0112 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129688464.0000 - false_positives: 1468534.0000 - true_negatives: 186928336.0000 - false_negatives: 1435417.0000 - precision: 0.9888 - recall: 0.9891 - val_loss: 0.1005 - val_accuracy: 0.9147 - val_binary_iou: 0.8403 - val_true_positives: 41193632.0000 - val_false_positives: 5190571.0000 - val_true_negatives: 55743348.0000 - val_false_negatives: 3844158.0000 - val_precision: 0.8881 - val_recall: 0.9146\n",
      "Epoch 495/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129675232.0000 - false_positives: 1457888.0000 - true_negatives: 186935264.0000 - false_negatives: 1452424.0000 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0999 - val_accuracy: 0.9145 - val_binary_iou: 0.8400 - val_true_positives: 41358084.0000 - val_false_positives: 5408786.0000 - val_true_negatives: 55552836.0000 - val_false_negatives: 3652008.0000 - val_precision: 0.8843 - val_recall: 0.9189\n",
      "Epoch 496/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129691888.0000 - false_positives: 1457762.0000 - true_negatives: 186921824.0000 - false_negatives: 1449285.0000 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0978 - val_accuracy: 0.9162 - val_binary_iou: 0.8428 - val_true_positives: 41270352.0000 - val_false_positives: 4967185.0000 - val_true_negatives: 55819932.0000 - val_false_negatives: 3914263.0000 - val_precision: 0.8926 - val_recall: 0.9134\n",
      "Epoch 497/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0112 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129617560.0000 - false_positives: 1450112.0000 - true_negatives: 186997968.0000 - false_negatives: 1455122.0000 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0996 - val_accuracy: 0.9149 - val_binary_iou: 0.8407 - val_true_positives: 41494208.0000 - val_false_positives: 5325448.0000 - val_true_negatives: 55454736.0000 - val_false_negatives: 3697325.0000 - val_precision: 0.8863 - val_recall: 0.9182\n",
      "Epoch 498/500\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0112 - accuracy: 0.9909 - binary_iou: 0.9814 - true_positives: 129626824.0000 - false_positives: 1458124.0000 - true_negatives: 186993024.0000 - false_negatives: 1442759.0000 - precision: 0.9889 - recall: 0.9890 - val_loss: 0.0989 - val_accuracy: 0.9156 - val_binary_iou: 0.8418 - val_true_positives: 41328752.0000 - val_false_positives: 5119664.0000 - val_true_negatives: 55697112.0000 - val_false_negatives: 3826174.0000 - val_precision: 0.8898 - val_recall: 0.9153\n",
      "Epoch 499/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9813 - true_positives: 129622832.0000 - false_positives: 1469366.0000 - true_negatives: 186975136.0000 - false_negatives: 1453404.0000 - precision: 0.9888 - recall: 0.9889 - val_loss: 0.1000 - val_accuracy: 0.9142 - val_binary_iou: 0.8396 - val_true_positives: 41401832.0000 - val_false_positives: 5385871.0000 - val_true_negatives: 55477768.0000 - val_false_negatives: 3706241.0000 - val_precision: 0.8849 - val_recall: 0.9178\n",
      "Epoch 500/500\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0113 - accuracy: 0.9909 - binary_iou: 0.9813 - true_positives: 129660792.0000 - false_positives: 1469377.0000 - true_negatives: 186941904.0000 - false_negatives: 1448683.0000 - precision: 0.9888 - recall: 0.9890 - val_loss: 0.0987 - val_accuracy: 0.9158 - val_binary_iou: 0.8422 - val_true_positives: 41211424.0000 - val_false_positives: 4967503.0000 - val_true_negatives: 55839388.0000 - val_false_negatives: 3953386.0000 - val_precision: 0.8924 - val_recall: 0.9125\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix, early_stop)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "# Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\n",
    "shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= initial_epochs)\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 12s 128ms/step - loss: 402.0228 - accuracy: 0.9147 - binary_iou: 0.8395 - true_positives: 40138080.0000 - false_positives: 4989474.0000 - true_negatives: 56795280.0000 - false_negatives: 4048898.0000 - precision: 0.8894 - recall: 0.9084\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_name = 'testlauf_fine_tune_first_layerFalse'\n",
    "#output_folder_prefix = 'final_runs'\n",
    "\n",
    "# Zusammenführen von Training- und Fine-Tuning-History\n",
    "iou = model_history.history['binary_iou']\n",
    "iou += history_fine.history['binary_iou']\n",
    "\n",
    "val_iou = model_history.history['val_binary_iou']\n",
    "val_iou += history_fine.history['val_binary_iou']\n",
    "\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "# Schreiben der Eval-Ergebnisse in csv\n",
    "with open('../output/final_runs.csv', 'a') as f_object:\n",
    "    row = []\n",
    "    \n",
    "    row.append(model_name)\n",
    "\n",
    "    for x in eval_out:\n",
    "        row.append(x)\n",
    "\n",
    "    # Einfügen der Trainingszeit in Minuten\n",
    "    row.append(training_time/60)\n",
    "\n",
    "    # Einfügen der maximalen Val-IoU\n",
    "    row.append(max(val_iou))\n",
    "\n",
    "    # Einfügen des Index der maximalen Val-IoU\n",
    "    row.append(np.argmax(val_iou))\n",
    "\n",
    "    writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "    writer_object.writerow(row)\n",
    "\n",
    "\n",
    "# Plotten\n",
    "epochs = range(1, len(val_iou)+1)\n",
    "\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], iou[0:(len(val_iou) - 1)], 'g', label= 'Training IoU')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_iou[0:(len(val_iou) - 1)], 'b', label= 'Validation IoU')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'../output/plots/IoU/iou_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model_history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = model_history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], loss[0:(len(val_iou) - 1)], 'g', label= 'Training Loss')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_loss[0:(len(val_iou) - 1)], 'b', label= 'Validation Loss')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'../output/plots/Loss/loss_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 120ms/step\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "#unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "#compile_model(unet, learning_rate)\n",
    "\n",
    "# Prognose mit Hilfe des geladenen besten Modells\n",
    "prediction = unet.predict(test_data_generator)\n",
    "\n",
    "# Erstellung einer binären Maske aus den wahrscheinlichkeiten, Schwellwert 0.5\n",
    "out = (prediction > 0.5).astype(np.uint8)\n",
    "\n",
    "# lediglich halbe Batch Size in eine Abbildung wegen Übersichtlichkeit\n",
    "rows = int(batch_size / 2)\n",
    "columns = 3\n",
    "\n",
    "# Anzahl verfügbarer Batches des Data-Generators\n",
    "no_of_batches = test_data_generator.__len__()\n",
    "\n",
    "# Prognose kommt als Tensor mit der Länge der Anzahl der Beispiele\n",
    "out_idx = 0\n",
    "\n",
    "# Erstellen des Prognosen-Ordners\n",
    "if not os.path.isdir(f'../output/predictions/{model_name}'):\n",
    "    os.makedirs(f'../output/predictions/{model_name}')\n",
    "\n",
    "# Input und Masken kommen als Batches, über die iteriert wird\n",
    "for batch_no in range(0, no_of_batches):\n",
    "\n",
    "    # iterieren über erste Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_I.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # iterieren über zweite Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][rows + i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][rows + i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    print(batch_no)\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_II.png', bbox_inches='tight', dpi= 400)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Zusammenführen der .log-Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "combine_log_files(output_folder_prefix, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " split_input (Lambda)           [(None, 224, 224, 1  0           ['input[0][0]']                  \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dropout_r (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_g (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][1]']            \n",
      "                                                                                                  \n",
      " dropout_b (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][2]']            \n",
      "                                                                                                  \n",
      " dropout_ir (Dropout)           (None, 224, 224, 1)  0           ['split_input[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_dropout (Concatena  (None, 224, 224, 4)  0          ['dropout_r[0][0]',              \n",
      " te)                                                              'dropout_g[0][0]',              \n",
      "                                                                  'dropout_b[0][0]',              \n",
      "                                                                  'dropout_ir[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 2048  0           ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 2304  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 256)  5308416     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 14, 256)  1024       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 14, 256)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 256)  589824      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  442368      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  147456      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   110592      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36864       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_3[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 32  36864       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 112, 112, 32  9216        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 36  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 16  5184        ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 224, 224, 16  2304        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 16  64         ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 1)  145         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 18,787,025\n",
      "Non-trainable params: 11,474,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"Final_AVG_rgbDrop_0_earlyStop_True_e500\"\n",
    "\n",
    "def combine_log_files():\n",
    "    # Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "    filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "    with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "        # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "        outfile.write('sep=,\\n')\n",
    "\n",
    "        for i, fname in enumerate(filenames):\n",
    "            with open(fname) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                for j, row in enumerate(reader):\n",
    "                    # überspringen des 2. Headers\n",
    "                    if i == 1 and j == 0:\n",
    "                        continue\n",
    "\n",
    "                    delimiter = ','\n",
    "                    list_to_string = delimiter.join(row)\n",
    "                    list_to_string += '\\n'\n",
    "\n",
    "                    outfile.write(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.7961242198944092', '0.6587730646133423', '20309084.0', '44833484.0', '0.24731293320655823', '0.7116237282752991', '0.8449028730392456', '143743008.0', '110635216.0', '0.8323593139648438', '0.7104504108428955', '6571040.0', '11194135.0', '0.19853559136390686', '0.7745783925056458', '0.8540922403335571', '49742008.0', '38464532.0']\n",
      "['1', '0.8555810451507568', '0.7428621053695679', '19262012.0', '26882816.0', '0.17415392398834229', '0.8062108755111694', '0.8530752658843994', '161536704.0', '111839176.0', '0.8509215116500854', '0.7363330125808716', '7721061.0', '8077029.0', '0.17862582206726074', '0.8224303126335144', '0.8289172649383545', '52764112.0', '37409496.0']\n",
      "['2', '0.868036687374115', '0.7619959115982056', '18203548.0', '23961460.0', '0.15954600274562836', '0.8248876929283142', '0.8611232042312622', '164482416.0', '112873368.0', '0.855846107006073', '0.7469853162765503', '3632307.0', '11643931.0', '0.15823477506637573', '0.7808046936988831', '0.9194782376289368', '49218136.0', '41477340.0']\n",
      "['3', '0.8770635724067688', '0.7761090993881226', '17652532.0', '21628236.0', '0.14948749542236328', '0.8399236798286438', '0.8653879761695862', '166756288.0', '113483792.0', '0.8836488127708435', '0.7868425846099854', '7168806.0', '5161118.0', '0.1418834626674652', '0.8805040121078491', '0.8413925170898438', '55612164.0', '38029616.0']\n",
      "['4', '0.883385956287384', '0.7862225770950317', '16949292.0', '20311302.0', '0.14213760197162628', '0.8488912582397461', '0.8706685900688171', '168156272.0', '114103848.0', '0.8866237998008728', '0.7932666540145874', '5359944.0', '6654737.0', '0.13384389877319336', '0.8567112684249878', '0.8812807202339172', '54168920.0', '39788112.0']\n",
      "['5', '0.8867051005363464', '0.7916681170463562', '16491997.0', '19708040.0', '0.13844023644924164', '0.8533272743225098', '0.8742521405220032', '168661360.0', '114659360.0', '0.8920537829399109', '0.8013637065887451', '5901398.0', '5537848.0', '0.12899699807167053', '0.8761326670646667', '0.8690656423568726', '55362416.0', '39170048.0']\n",
      "['6', '0.8899984359741211', '0.797005295753479', '16219609.0', '18928164.0', '0.13410015404224396', '0.8585999608039856', '0.8763315081596375', '169438704.0', '114934304.0', '0.8933471441268921', '0.8045114278793335', '4735190.0', '6566981.0', '0.12450148910284042', '0.8601561188697815', '0.8950710296630859', '54277184.0', '40392380.0']\n",
      "['7', '0.8955606818199158', '0.8061417937278748', '15626842.0', '17743680.0', '0.1278112232685089', '0.866841197013855', '0.8808341026306152', '170641936.0', '115508360.0', '0.8974204063415527', '0.8101271390914917', '5816458.0', '5054095.0', '0.12367336452007294', '0.8860129714012146', '0.8710364103317261', '55816044.0', '39285116.0']\n",
      "['8', '0.8968602418899536', '0.8083475828170776', '15260560.0', '17694812.0', '0.12622345983982086', '0.8674541115760803', '0.8835651874542236', '170760672.0', '115804736.0', '0.898605465888977', '0.8104246854782104', '7315006.0', '3429948.0', '0.12633559107780457', '0.916635274887085', '0.8375488519668579', '57512820.0', '37713940.0']\n",
      "['9', '0.900827169418335', '0.814872145652771', '15107959.0', '16579737.0', '0.1218128651380539', '0.8749462366104126', '0.8847680687904358', '171831952.0', '116001152.0', '0.8998227715492249', '0.8146814703941345', '5080673.0', '5535273.0', '0.11853206157684326', '0.8784630298614502', '0.8873198628425598', '55347104.0', '40008656.0']\n",
      "['10', '0.9033365249633789', '0.8191630840301514', '14566899.0', '16319088.0', '0.1187213733792305', '0.8771561980247498', '0.8888803720474243', '172109632.0', '116525144.0', '0.9009268283843994', '0.8165515661239624', '5037168.0', '5461766.0', '0.11778794229030609', '0.8800939917564392', '0.8883749842643738', '55384136.0', '40088640.0']\n",
      "['11', '0.9063057899475098', '0.8241333961486816', '14384998.0', '15552271.0', '0.11546950787305832', '0.8824447989463806', '0.8902999758720398', '172838176.0', '116745344.0', '0.8959559202194214', '0.8076335787773132', '5974802.0', '5050926.0', '0.12591783702373505', '0.8857436776161194', '0.8676116466522217', '55789924.0', '39156056.0']\n",
      "['12', '0.9102160334587097', '0.8309040665626526', '13612249.0', '15075643.0', '0.10997866094112396', '0.8863572478294373', '0.8962439894676208', '173250304.0', '117582520.0', '0.9019008874893188', '0.8180277347564697', '5200968.0', '5194741.0', '0.11701411753892899', '0.8849327564239502', '0.8848106861114502', '55625476.0', '39950520.0']\n",
      "['13', '0.9113559722900391', '0.8327949643135071', '13592185.0', '14731369.0', '0.10891933739185333', '0.8886242508888245', '0.8963442444801331', '173661312.0', '117535936.0', '0.9012283086776733', '0.8175053596496582', '4434233.0', '6032764.0', '0.11556345224380493', '0.8707954287528992', '0.9016647934913635', '54845904.0', '40658800.0']\n",
      "['14', '0.9112589955329895', '0.8326512575149536', '13557967.0', '14796571.0', '0.10920999199151993', '0.8882356882095337', '0.8966241478919983', '173571968.0', '117594240.0', '0.9038447737693787', '0.8203587532043457', '6198846.0', '3990891.0', '0.11703916639089584', '0.9071902632713318', '0.862883985042572', '56772072.0', '39009900.0']\n",
      "['15', '0.9150487780570984', '0.8391707539558411', '13070933.0', '14072871.0', '0.10437954217195511', '0.893510639667511', '0.9003366827964783', '174296912.0', '118079960.0', '0.9026321172714233', '0.81894850730896', '5502799.0', '4815433.0', '0.11641963571310043', '0.8916648030281067', '0.8780860304832458', '56019548.0', '39633948.0']\n",
      "['16', '0.9170372486114502', '0.8425793647766113', '12875547.0', '13632801.0', '0.10238707065582275', '0.8966102004051208', '0.901789128780365', '174786896.0', '118225480.0', '0.9023330807685852', '0.8191585540771484', '4628317.0', '5721616.0', '0.11487342417240143', '0.8761098980903625', '0.8973531723022461', '55160384.0', '40461384.0']\n",
      "['17', '0.9163618683815002', '0.8415076732635498', '12748003.0', '13976263.0', '0.10324450582265854', '0.8944720029830933', '0.902845025062561', '174331424.0', '118465040.0', '0.9080192446708679', '0.82755446434021', '5744502.0', '4002860.0', '0.11195121705532074', '0.9076095223426819', '0.8725345134735107', '56901776.0', '39322596.0']\n",
      "['18', '0.9190995693206787', '0.8461706042289734', '12620972.0', '13228408.0', '0.0997830331325531', '0.8995869159698486', '0.9037539958953857', '175159920.0', '118511456.0', '0.9019047021865845', '0.8167356252670288', '6489242.0', '3906086.0', '0.12046819925308228', '0.9080408215522766', '0.8559849858283997', '57006160.0', '38570224.0']\n",
      "['19', '0.9203644394874573', '0.8483947515487671', '12331894.0', '13113312.0', '0.09815822541713715', '0.9005417823791504', '0.905910849571228', '175341472.0', '118734152.0', '0.9094333648681641', '0.830341100692749', '5351531.0', '4245958.0', '0.10895109176635742', '0.9036170840263367', '0.8814947605133057', '56567128.0', '39807088.0']\n"
     ]
    }
   ],
   "source": [
    "with open(f'../output/{output_folder_prefix}_logger/{model_name}_I.log') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " split_input (Lambda)           [(None, 224, 224, 1  0           ['input[0][0]']                  \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dropout_r (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_g (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][1]']            \n",
      "                                                                                                  \n",
      " dropout_b (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][2]']            \n",
      "                                                                                                  \n",
      " dropout_ir (Dropout)           (None, 224, 224, 1)  0           ['split_input[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_dropout (Concatena  (None, 224, 224, 4)  0          ['dropout_r[0][0]',              \n",
      " te)                                                              'dropout_g[0][0]',              \n",
      "                                                                  'dropout_b[0][0]',              \n",
      "                                                                  'dropout_ir[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 2048  0           ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 2304  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 256)  5308416     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 14, 256)  1024       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 14, 256)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 256)  589824      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  442368      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  147456      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   110592      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36864       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_3[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 32  36864       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 112, 112, 32  9216        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 36  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 16  5184        ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 224, 224, 16  2304        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 16  64         ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 1)  145         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 18,787,025\n",
      "Non-trainable params: 11,474,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "unet.save(f'{model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
