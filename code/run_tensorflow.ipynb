{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auszuführen mit Environment \"tf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importe & Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "import shutil\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufällige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            # Transformation in \"channels_last\"-Format\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            # Erstellen einer zusätzlichen Achse um Tensor-Dimension zu erreichen\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            # Skalierung der Werte\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "# Definition des Dice-Koeffizienten\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# Ableitung einer zu minimierenden Loss-Funktion aus Dice-Koeffzient\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Rückgängig machen der Normalisierung zur korrekten Anzeige der Bilder\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    # Speicherpfade der verschiedenen Architekturen\n",
    "    model_dict = {\n",
    "        'BN': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    # Auswahl der Architektur entsprechend der verwendeten Variante\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    # Laden der JSON\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    # Laden des Modells aus JSON\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulässt, werden immer die selben zufällig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    # entsprechend der Variante müssen Gewichte unterschiedlich gesetzt werden\n",
    "    if model_type == 'BN':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte können übernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte zufällig\n",
    "    if option == 'RNDM':\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren über geladene Gewichte und zufällige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Für 1. Conv-Layer stimmt shape nicht überein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte für RGB-Channel werden übernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen überein und können übernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufügen der zufälligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zusätzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer für RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die später übersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere über Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden für diesen Layer, iteriere über diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese können daher nicht übernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # für die übrigen Layer werden die Gewichte übernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zufälligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind für erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False):\n",
    "    # Anzahl der trainierbaren Encoder Layer, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= 27\n",
    "\n",
    "    # Encoder bleibt größtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM']:\n",
    "\n",
    "    # Für das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafür werden die Layer jetzt rückwärts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # für train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, output_folder_prefix):\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{output_folder_prefix}_logger/{model_name}'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + '.log')\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuchsreihe Freeze-From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 233s 546ms/step - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288 - val_loss: 0.1324 - val_accuracy: 0.7237 - val_binary_iou: 0.5219 - val_true_positives: 17575076.0000 - val_false_positives: 1821869.0000 - val_true_negatives: 59114264.0000 - val_false_negatives: 27460492.0000 - val_precision: 0.9061 - val_recall: 0.3902\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.1008 - accuracy: 0.8260 - binary_iou: 0.6955 - true_positives: 101502720.0000 - false_positives: 25956264.0000 - true_negatives: 162417888.0000 - false_negatives: 29643882.0000 - precision: 0.7964 - recall: 0.7740 - val_loss: 0.3162 - val_accuracy: 0.5801 - val_binary_iou: 0.2986 - val_true_positives: 944899.0000 - val_false_positives: 370912.0000 - val_true_negatives: 60533532.0000 - val_false_negatives: 44122376.0000 - val_precision: 0.7181 - val_recall: 0.0210\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834 - val_loss: 0.1000 - val_accuracy: 0.8302 - val_binary_iou: 0.6984 - val_true_positives: 31970022.0000 - val_false_positives: 4808101.0000 - val_true_negatives: 56008240.0000 - val_false_negatives: 13185362.0000 - val_precision: 0.8693 - val_recall: 0.7080\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 137s 343ms/step - loss: 0.0970 - accuracy: 0.8354 - binary_iou: 0.7095 - true_positives: 102972568.0000 - false_positives: 24451394.0000 - true_negatives: 163957824.0000 - false_negatives: 28139152.0000 - precision: 0.8081 - recall: 0.7854 - val_loss: 0.1056 - val_accuracy: 0.8190 - val_binary_iou: 0.6918 - val_true_positives: 38703920.0000 - val_false_positives: 12815742.0000 - val_true_negatives: 48088272.0000 - val_false_negatives: 6363783.0000 - val_precision: 0.7512 - val_recall: 0.8588\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0961 - accuracy: 0.8378 - binary_iou: 0.7132 - true_positives: 103382480.0000 - false_positives: 24086258.0000 - true_negatives: 164319424.0000 - false_negatives: 27732654.0000 - precision: 0.8110 - recall: 0.7885 - val_loss: 0.1097 - val_accuracy: 0.8059 - val_binary_iou: 0.6742 - val_true_positives: 39755736.0000 - val_false_positives: 15181283.0000 - val_true_negatives: 45644488.0000 - val_false_negatives: 5390192.0000 - val_precision: 0.7237 - val_recall: 0.8806\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0937 - accuracy: 0.8421 - binary_iou: 0.7197 - true_positives: 104078240.0000 - false_positives: 23499364.0000 - true_negatives: 164992912.0000 - false_negatives: 26950208.0000 - precision: 0.8158 - recall: 0.7943 - val_loss: 0.1153 - val_accuracy: 0.7939 - val_binary_iou: 0.6582 - val_true_positives: 41479488.0000 - val_false_positives: 18216578.0000 - val_true_negatives: 42647984.0000 - val_false_negatives: 3627668.0000 - val_precision: 0.6948 - val_recall: 0.9196\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0933 - accuracy: 0.8443 - binary_iou: 0.7231 - true_positives: 104509376.0000 - false_positives: 23135430.0000 - true_negatives: 165270080.0000 - false_negatives: 26605972.0000 - precision: 0.8188 - recall: 0.7971 - val_loss: 0.1052 - val_accuracy: 0.8228 - val_binary_iou: 0.6981 - val_true_positives: 40455752.0000 - val_false_positives: 14088869.0000 - val_true_negatives: 46733252.0000 - val_false_negatives: 4693854.0000 - val_precision: 0.7417 - val_recall: 0.8960\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024 - val_loss: 0.0954 - val_accuracy: 0.8371 - val_binary_iou: 0.7186 - val_true_positives: 40248520.0000 - val_false_positives: 12413144.0000 - val_true_negatives: 48463540.0000 - val_false_negatives: 4846510.0000 - val_precision: 0.7643 - val_recall: 0.8925\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0901 - accuracy: 0.8508 - binary_iou: 0.7330 - true_positives: 105533640.0000 - false_positives: 22092700.0000 - true_negatives: 166309040.0000 - false_negatives: 25585432.0000 - precision: 0.8269 - recall: 0.8049 - val_loss: 0.1245 - val_accuracy: 0.7245 - val_binary_iou: 0.5193 - val_true_positives: 16856334.0000 - val_false_positives: 888026.0000 - val_true_negatives: 59925316.0000 - val_false_negatives: 28302036.0000 - val_precision: 0.9500 - val_recall: 0.3733\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0893 - accuracy: 0.8526 - binary_iou: 0.7359 - true_positives: 105886944.0000 - false_positives: 21818420.0000 - true_negatives: 166548864.0000 - false_negatives: 25266544.0000 - precision: 0.8292 - recall: 0.8074 - val_loss: 0.1029 - val_accuracy: 0.8326 - val_binary_iou: 0.7124 - val_true_positives: 40830816.0000 - val_false_positives: 13431411.0000 - val_true_negatives: 47404960.0000 - val_false_negatives: 4304522.0000 - val_precision: 0.7525 - val_recall: 0.9046\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0876 - accuracy: 0.8564 - binary_iou: 0.7417 - true_positives: 106360520.0000 - false_positives: 21117784.0000 - true_negatives: 167273232.0000 - false_negatives: 24769200.0000 - precision: 0.8343 - recall: 0.8111 - val_loss: 0.1123 - val_accuracy: 0.8113 - val_binary_iou: 0.6824 - val_true_positives: 41546704.0000 - val_false_positives: 16377837.0000 - val_true_negatives: 44430472.0000 - val_false_negatives: 3616706.0000 - val_precision: 0.7173 - val_recall: 0.9199\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0871 - accuracy: 0.8573 - binary_iou: 0.7432 - true_positives: 106628432.0000 - false_positives: 21060946.0000 - true_negatives: 167308336.0000 - false_negatives: 24523056.0000 - precision: 0.8351 - recall: 0.8130 - val_loss: 0.1330 - val_accuracy: 0.7197 - val_binary_iou: 0.5101 - val_true_positives: 16018910.0000 - val_false_positives: 714509.0000 - val_true_negatives: 60247680.0000 - val_false_negatives: 28990608.0000 - val_precision: 0.9573 - val_recall: 0.3559\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166 - val_loss: 0.0904 - val_accuracy: 0.8501 - val_binary_iou: 0.7374 - val_true_positives: 39858736.0000 - val_false_positives: 10601939.0000 - val_true_negatives: 50232448.0000 - val_false_negatives: 5278578.0000 - val_precision: 0.7899 - val_recall: 0.8831\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0849 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107398296.0000 - false_positives: 20543202.0000 - true_negatives: 167856336.0000 - false_negatives: 23722896.0000 - precision: 0.8394 - recall: 0.8191 - val_loss: 0.1110 - val_accuracy: 0.8005 - val_binary_iou: 0.6440 - val_true_positives: 26109266.0000 - val_false_positives: 2097758.0000 - val_true_negatives: 58726144.0000 - val_false_negatives: 19038536.0000 - val_precision: 0.9256 - val_recall: 0.5783\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0847 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107239304.0000 - false_positives: 20393872.0000 - true_negatives: 168027744.0000 - false_negatives: 23859782.0000 - precision: 0.8402 - recall: 0.8180 - val_loss: 0.0989 - val_accuracy: 0.8373 - val_binary_iou: 0.7068 - val_true_positives: 31232048.0000 - val_false_positives: 3293441.0000 - val_true_negatives: 57497820.0000 - val_false_negatives: 13948394.0000 - val_precision: 0.9046 - val_recall: 0.6913\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215 - val_loss: 0.0895 - val_accuracy: 0.8523 - val_binary_iou: 0.7406 - val_true_positives: 39827064.0000 - val_false_positives: 10344540.0000 - val_true_negatives: 50490480.0000 - val_false_negatives: 5309619.0000 - val_precision: 0.7938 - val_recall: 0.8824\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211 - val_loss: 0.0852 - val_accuracy: 0.8639 - val_binary_iou: 0.7554 - val_true_positives: 37170488.0000 - val_false_positives: 6445220.0000 - val_true_negatives: 54378644.0000 - val_false_negatives: 7977376.0000 - val_precision: 0.8522 - val_recall: 0.8233\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 131s 327ms/step - loss: 0.0821 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108301392.0000 - false_positives: 19837088.0000 - true_negatives: 168606352.0000 - false_negatives: 22776036.0000 - precision: 0.8452 - recall: 0.8262 - val_loss: 0.1531 - val_accuracy: 0.7313 - val_binary_iou: 0.5348 - val_true_positives: 18643914.0000 - val_false_positives: 1994139.0000 - val_true_negatives: 58851064.0000 - val_false_negatives: 26482600.0000 - val_precision: 0.9034 - val_recall: 0.4131\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0818 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108285344.0000 - false_positives: 19770572.0000 - true_negatives: 168614816.0000 - false_negatives: 22850008.0000 - precision: 0.8456 - recall: 0.8258 - val_loss: 0.1024 - val_accuracy: 0.8322 - val_binary_iou: 0.7115 - val_true_positives: 40046760.0000 - val_false_positives: 12674211.0000 - val_true_negatives: 48147576.0000 - val_false_negatives: 5103174.0000 - val_precision: 0.7596 - val_recall: 0.8870\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0813 - accuracy: 0.8676 - binary_iou: 0.7596 - true_positives: 108523808.0000 - false_positives: 19610268.0000 - true_negatives: 168706416.0000 - false_negatives: 22680374.0000 - precision: 0.8470 - recall: 0.8271 - val_loss: 0.0870 - val_accuracy: 0.8546 - val_binary_iou: 0.7357 - val_true_positives: 33240562.0000 - val_false_positives: 3608494.0000 - val_true_negatives: 57325588.0000 - val_false_negatives: 11797062.0000 - val_precision: 0.9021 - val_recall: 0.7381\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 132s 330ms/step - loss: 0.0808 - accuracy: 0.8688 - binary_iou: 0.7614 - true_positives: 108646064.0000 - false_positives: 19449168.0000 - true_negatives: 168965888.0000 - false_negatives: 22459632.0000 - precision: 0.8482 - recall: 0.8287 - val_loss: 0.0867 - val_accuracy: 0.8618 - val_binary_iou: 0.7540 - val_true_positives: 38839240.0000 - val_false_positives: 8306769.0000 - val_true_negatives: 52484908.0000 - val_false_negatives: 6340797.0000 - val_precision: 0.8238 - val_recall: 0.8597\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0805 - accuracy: 0.8692 - binary_iou: 0.7619 - true_positives: 108503840.0000 - false_positives: 19143860.0000 - true_negatives: 169210224.0000 - false_negatives: 22662762.0000 - precision: 0.8500 - recall: 0.8272 - val_loss: 0.0967 - val_accuracy: 0.8472 - val_binary_iou: 0.7338 - val_true_positives: 40768900.0000 - val_false_positives: 11939663.0000 - val_true_negatives: 49015408.0000 - val_false_negatives: 4247704.0000 - val_precision: 0.7735 - val_recall: 0.9056\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 132s 333ms/step - loss: 0.0795 - accuracy: 0.8707 - binary_iou: 0.7643 - true_positives: 108716080.0000 - false_positives: 18938558.0000 - true_negatives: 169478768.0000 - false_negatives: 22387304.0000 - precision: 0.8516 - recall: 0.8292 - val_loss: 0.1078 - val_accuracy: 0.8230 - val_binary_iou: 0.6988 - val_true_positives: 41153548.0000 - val_false_positives: 14788690.0000 - val_true_negatives: 46060360.0000 - val_false_negatives: 3969113.0000 - val_precision: 0.7356 - val_recall: 0.9120\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0801 - accuracy: 0.8702 - binary_iou: 0.7636 - true_positives: 108823816.0000 - false_positives: 19210666.0000 - true_negatives: 169220608.0000 - false_negatives: 22265680.0000 - precision: 0.8500 - recall: 0.8301 - val_loss: 0.0927 - val_accuracy: 0.8444 - val_binary_iou: 0.7203 - val_true_positives: 32952966.0000 - val_false_positives: 4359997.0000 - val_true_negatives: 56526712.0000 - val_false_negatives: 12132058.0000 - val_precision: 0.8832 - val_recall: 0.7309\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0790 - accuracy: 0.8721 - binary_iou: 0.7667 - true_positives: 109167728.0000 - false_positives: 18871536.0000 - true_negatives: 169501680.0000 - false_negatives: 21979664.0000 - precision: 0.8526 - recall: 0.8324 - val_loss: 0.0850 - val_accuracy: 0.8600 - val_binary_iou: 0.7507 - val_true_positives: 38290392.0000 - val_false_positives: 8004973.0000 - val_true_negatives: 52842848.0000 - val_false_negatives: 6833502.0000 - val_precision: 0.8271 - val_recall: 0.8486\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0791 - accuracy: 0.8710 - binary_iou: 0.7649 - true_positives: 108841576.0000 - false_positives: 18948360.0000 - true_negatives: 169474752.0000 - false_negatives: 22256104.0000 - precision: 0.8517 - recall: 0.8302 - val_loss: 0.0908 - val_accuracy: 0.8506 - val_binary_iou: 0.7392 - val_true_positives: 41490552.0000 - val_false_positives: 12217507.0000 - val_true_negatives: 48650728.0000 - val_false_negatives: 3612923.0000 - val_precision: 0.7725 - val_recall: 0.9199\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.8688 - val_binary_iou: 0.7620 - val_true_positives: 36486688.0000 - val_false_positives: 5333113.0000 - val_true_negatives: 55582152.0000 - val_false_negatives: 8569759.0000 - val_precision: 0.8725 - val_recall: 0.8098\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.8727 - val_binary_iou: 0.7702 - val_true_positives: 38349988.0000 - val_false_positives: 6743923.0000 - val_true_negatives: 54133528.0000 - val_false_negatives: 6744254.0000 - val_precision: 0.8504 - val_recall: 0.8504\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348 - val_loss: 0.0788 - val_accuracy: 0.8748 - val_binary_iou: 0.7732 - val_true_positives: 38262152.0000 - val_false_positives: 6452901.0000 - val_true_negatives: 54439296.0000 - val_false_negatives: 6817371.0000 - val_precision: 0.8557 - val_recall: 0.8488\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0770 - accuracy: 0.8750 - binary_iou: 0.7714 - true_positives: 109860424.0000 - false_positives: 18651358.0000 - true_negatives: 169709808.0000 - false_negatives: 21299248.0000 - precision: 0.8549 - recall: 0.8376 - val_loss: 0.1144 - val_accuracy: 0.8331 - val_binary_iou: 0.7128 - val_true_positives: 40152272.0000 - val_false_positives: 12796243.0000 - val_true_negatives: 48135368.0000 - val_false_negatives: 4887845.0000 - val_precision: 0.7583 - val_recall: 0.8915\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351 - val_loss: 0.0760 - val_accuracy: 0.8774 - val_binary_iou: 0.7753 - val_true_positives: 36616788.0000 - val_false_positives: 4558136.0000 - val_true_negatives: 56358976.0000 - val_false_negatives: 8437822.0000 - val_precision: 0.8893 - val_recall: 0.8127\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0768 - accuracy: 0.8754 - binary_iou: 0.7720 - true_positives: 109704112.0000 - false_positives: 18303342.0000 - true_negatives: 170015376.0000 - false_negatives: 21497948.0000 - precision: 0.8570 - recall: 0.8361 - val_loss: 0.0893 - val_accuracy: 0.8511 - val_binary_iou: 0.7392 - val_true_positives: 40275688.0000 - val_false_positives: 11033940.0000 - val_true_negatives: 49917440.0000 - val_false_negatives: 4744650.0000 - val_precision: 0.7850 - val_recall: 0.8946\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0759 - accuracy: 0.8769 - binary_iou: 0.7744 - true_positives: 109680688.0000 - false_positives: 17862716.0000 - true_negatives: 170521232.0000 - false_negatives: 21456152.0000 - precision: 0.8599 - recall: 0.8364 - val_loss: 0.1278 - val_accuracy: 0.7639 - val_binary_iou: 0.5848 - val_true_positives: 21954286.0000 - val_false_positives: 1845093.0000 - val_true_negatives: 58996816.0000 - val_false_negatives: 23175526.0000 - val_precision: 0.9225 - val_recall: 0.4865\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0763 - accuracy: 0.8771 - binary_iou: 0.7746 - true_positives: 109722248.0000 - false_positives: 17865852.0000 - true_negatives: 170533120.0000 - false_negatives: 21399564.0000 - precision: 0.8600 - recall: 0.8368 - val_loss: 0.0804 - val_accuracy: 0.8689 - val_binary_iou: 0.7605 - val_true_positives: 35240620.0000 - val_false_positives: 4020838.0000 - val_true_negatives: 56843064.0000 - val_false_negatives: 9867173.0000 - val_precision: 0.8976 - val_recall: 0.7813\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0752 - accuracy: 0.8781 - binary_iou: 0.7763 - true_positives: 109918400.0000 - false_positives: 17765496.0000 - true_negatives: 170650224.0000 - false_negatives: 21186664.0000 - precision: 0.8609 - recall: 0.8384 - val_loss: 0.0844 - val_accuracy: 0.8658 - val_binary_iou: 0.7554 - val_true_positives: 35053628.0000 - val_false_positives: 4161809.0000 - val_true_negatives: 56692608.0000 - val_false_negatives: 10063672.0000 - val_precision: 0.8939 - val_recall: 0.7769\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0756 - accuracy: 0.8780 - binary_iou: 0.7762 - true_positives: 109991488.0000 - false_positives: 17822768.0000 - true_negatives: 170557728.0000 - false_negatives: 21148782.0000 - precision: 0.8606 - recall: 0.8387 - val_loss: 0.0847 - val_accuracy: 0.8642 - val_binary_iou: 0.7593 - val_true_positives: 40863752.0000 - val_false_positives: 10137314.0000 - val_true_negatives: 50722208.0000 - val_false_negatives: 4248468.0000 - val_precision: 0.8012 - val_recall: 0.9058\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0755 - accuracy: 0.8783 - binary_iou: 0.7766 - true_positives: 110056080.0000 - false_positives: 17851890.0000 - true_negatives: 170569152.0000 - false_negatives: 21043648.0000 - precision: 0.8604 - recall: 0.8395 - val_loss: 0.0940 - val_accuracy: 0.8438 - val_binary_iou: 0.7149 - val_true_positives: 30703540.0000 - val_false_positives: 2279773.0000 - val_true_negatives: 58713400.0000 - val_false_negatives: 14274987.0000 - val_precision: 0.9309 - val_recall: 0.6826\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0748 - accuracy: 0.8801 - binary_iou: 0.7794 - true_positives: 110202584.0000 - false_positives: 17466404.0000 - true_negatives: 170994736.0000 - false_negatives: 20856996.0000 - precision: 0.8632 - recall: 0.8409 - val_loss: 0.0782 - val_accuracy: 0.8715 - val_binary_iou: 0.7644 - val_true_positives: 35198112.0000 - val_false_positives: 3698824.0000 - val_true_negatives: 57161548.0000 - val_false_negatives: 9913227.0000 - val_precision: 0.9049 - val_recall: 0.7802\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0746 - accuracy: 0.8794 - binary_iou: 0.7784 - true_positives: 110242680.0000 - false_positives: 17726232.0000 - true_negatives: 170747120.0000 - false_negatives: 20804768.0000 - precision: 0.8615 - recall: 0.8412 - val_loss: 0.0825 - val_accuracy: 0.8634 - val_binary_iou: 0.7571 - val_true_positives: 39490388.0000 - val_false_positives: 8987308.0000 - val_true_negatives: 52010136.0000 - val_false_negatives: 5483891.0000 - val_precision: 0.8146 - val_recall: 0.8781\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0738 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110744256.0000 - false_positives: 17311324.0000 - true_negatives: 171002512.0000 - false_negatives: 20462732.0000 - precision: 0.8648 - recall: 0.8440 - val_loss: 0.0911 - val_accuracy: 0.8514 - val_binary_iou: 0.7390 - val_true_positives: 39461084.0000 - val_false_positives: 10119243.0000 - val_true_negatives: 50764184.0000 - val_false_negatives: 5627177.0000 - val_precision: 0.7959 - val_recall: 0.8752\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0740 - accuracy: 0.8811 - binary_iou: 0.7813 - true_positives: 110620672.0000 - false_positives: 17410712.0000 - true_negatives: 170911776.0000 - false_negatives: 20577528.0000 - precision: 0.8640 - recall: 0.8432 - val_loss: 0.0893 - val_accuracy: 0.8568 - val_binary_iou: 0.7480 - val_true_positives: 40675372.0000 - val_false_positives: 10765509.0000 - val_true_negatives: 50123008.0000 - val_false_negatives: 4407833.0000 - val_precision: 0.7907 - val_recall: 0.9022\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0741 - accuracy: 0.8810 - binary_iou: 0.7810 - true_positives: 110477176.0000 - false_positives: 17368754.0000 - true_negatives: 171013616.0000 - false_negatives: 20661116.0000 - precision: 0.8641 - recall: 0.8424 - val_loss: 0.0915 - val_accuracy: 0.8609 - val_binary_iou: 0.7545 - val_true_positives: 41110948.0000 - val_false_positives: 10759448.0000 - val_true_negatives: 50124624.0000 - val_false_negatives: 3976692.0000 - val_precision: 0.7926 - val_recall: 0.9118\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110759184.0000 - false_positives: 17434206.0000 - true_negatives: 170991264.0000 - false_negatives: 20336120.0000 - precision: 0.8640 - recall: 0.8449 - val_loss: 0.0767 - val_accuracy: 0.8763 - val_binary_iou: 0.7738 - val_true_positives: 36665456.0000 - val_false_positives: 4793163.0000 - val_true_negatives: 56202104.0000 - val_false_negatives: 8311005.0000 - val_precision: 0.8844 - val_recall: 0.8152\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0732 - accuracy: 0.8824 - binary_iou: 0.7833 - true_positives: 110589928.0000 - false_positives: 17049368.0000 - true_negatives: 171352096.0000 - false_negatives: 20529470.0000 - precision: 0.8664 - recall: 0.8434 - val_loss: 0.3467 - val_accuracy: 0.6217 - val_binary_iou: 0.3609 - val_true_positives: 5513703.0000 - val_false_positives: 492476.0000 - val_true_negatives: 60369508.0000 - val_false_negatives: 39596012.0000 - val_precision: 0.9180 - val_recall: 0.1222\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0728 - accuracy: 0.8823 - binary_iou: 0.7831 - true_positives: 110610448.0000 - false_positives: 17153838.0000 - true_negatives: 171295808.0000 - false_negatives: 20460704.0000 - precision: 0.8657 - recall: 0.8439 - val_loss: 0.1083 - val_accuracy: 0.8334 - val_binary_iou: 0.7133 - val_true_positives: 40344744.0000 - val_false_positives: 12932603.0000 - val_true_negatives: 47975588.0000 - val_false_negatives: 4718782.0000 - val_precision: 0.7573 - val_recall: 0.8953\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448 - val_loss: 0.0720 - val_accuracy: 0.8834 - val_binary_iou: 0.7860 - val_true_positives: 37677948.0000 - val_false_positives: 4890033.0000 - val_true_negatives: 55932928.0000 - val_false_negatives: 7470800.0000 - val_precision: 0.8851 - val_recall: 0.8345\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7851 - true_positives: 110872664.0000 - false_positives: 16952142.0000 - true_negatives: 171421840.0000 - false_negatives: 20274174.0000 - precision: 0.8674 - recall: 0.8454 - val_loss: 0.0791 - val_accuracy: 0.8718 - val_binary_iou: 0.7701 - val_true_positives: 39755304.0000 - val_false_positives: 8201396.0000 - val_true_negatives: 52630668.0000 - val_false_negatives: 5384339.0000 - val_precision: 0.8290 - val_recall: 0.8807\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0720 - accuracy: 0.8844 - binary_iou: 0.7866 - true_positives: 111036360.0000 - false_positives: 16833284.0000 - true_negatives: 171542160.0000 - false_negatives: 20108824.0000 - precision: 0.8684 - recall: 0.8467 - val_loss: 0.0752 - val_accuracy: 0.8761 - val_binary_iou: 0.7749 - val_true_positives: 37911000.0000 - val_false_positives: 6057223.0000 - val_true_negatives: 54926472.0000 - val_false_negatives: 7077021.0000 - val_precision: 0.8622 - val_recall: 0.8427\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473 - val_loss: 0.0718 - val_accuracy: 0.8838 - val_binary_iou: 0.7886 - val_true_positives: 39486004.0000 - val_false_positives: 6718828.0000 - val_true_negatives: 54175552.0000 - val_false_negatives: 5591349.0000 - val_precision: 0.8546 - val_recall: 0.8760\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0711 - accuracy: 0.8859 - binary_iou: 0.7891 - true_positives: 111437792.0000 - false_positives: 16779652.0000 - true_negatives: 171621232.0000 - false_negatives: 19682034.0000 - precision: 0.8691 - recall: 0.8499 - val_loss: 0.0789 - val_accuracy: 0.8750 - val_binary_iou: 0.7750 - val_true_positives: 39677440.0000 - val_false_positives: 7832372.0000 - val_true_negatives: 53050432.0000 - val_false_negatives: 5411455.0000 - val_precision: 0.8351 - val_recall: 0.8800\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0723 - accuracy: 0.8840 - binary_iou: 0.7860 - true_positives: 110917688.0000 - false_positives: 16858026.0000 - true_negatives: 171550656.0000 - false_negatives: 20194422.0000 - precision: 0.8681 - recall: 0.8460 - val_loss: 0.0761 - val_accuracy: 0.8785 - val_binary_iou: 0.7793 - val_true_positives: 38523632.0000 - val_false_positives: 6267567.0000 - val_true_negatives: 54571044.0000 - val_false_negatives: 6609449.0000 - val_precision: 0.8601 - val_recall: 0.8536\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.0713 - accuracy: 0.8857 - binary_iou: 0.7888 - true_positives: 111161040.0000 - false_positives: 16627165.0000 - true_negatives: 171846624.0000 - false_negatives: 19886010.0000 - precision: 0.8699 - recall: 0.8483 - val_loss: 0.0784 - val_accuracy: 0.8712 - val_binary_iou: 0.7654 - val_true_positives: 36260056.0000 - val_false_positives: 4831201.0000 - val_true_negatives: 56061988.0000 - val_false_negatives: 8818443.0000 - val_precision: 0.8824 - val_recall: 0.8044\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0713 - accuracy: 0.8850 - binary_iou: 0.7875 - true_positives: 110992376.0000 - false_positives: 16666216.0000 - true_negatives: 171785184.0000 - false_negatives: 20076980.0000 - precision: 0.8694 - recall: 0.8468 - val_loss: 0.0749 - val_accuracy: 0.8792 - val_binary_iou: 0.7783 - val_true_positives: 36636472.0000 - val_false_positives: 4348723.0000 - val_true_negatives: 56539000.0000 - val_false_negatives: 8447519.0000 - val_precision: 0.8939 - val_recall: 0.8126\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0712 - accuracy: 0.8865 - binary_iou: 0.7901 - true_positives: 111404088.0000 - false_positives: 16538362.0000 - true_negatives: 171853856.0000 - false_negatives: 19724452.0000 - precision: 0.8707 - recall: 0.8496 - val_loss: 0.0919 - val_accuracy: 0.8460 - val_binary_iou: 0.7183 - val_true_positives: 30782204.0000 - val_false_positives: 1975765.0000 - val_true_negatives: 58874352.0000 - val_false_negatives: 14339410.0000 - val_precision: 0.9397 - val_recall: 0.6822\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0705 - accuracy: 0.8877 - binary_iou: 0.7921 - true_positives: 111597744.0000 - false_positives: 16313104.0000 - true_negatives: 172038480.0000 - false_negatives: 19571406.0000 - precision: 0.8725 - recall: 0.8508 - val_loss: 0.0778 - val_accuracy: 0.8731 - val_binary_iou: 0.7718 - val_true_positives: 39438596.0000 - val_false_positives: 7786716.0000 - val_true_negatives: 53084064.0000 - val_false_negatives: 5662343.0000 - val_precision: 0.8351 - val_recall: 0.8745\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0707 - accuracy: 0.8871 - binary_iou: 0.7910 - true_positives: 111379944.0000 - false_positives: 16308250.0000 - true_negatives: 172061968.0000 - false_negatives: 19770506.0000 - precision: 0.8723 - recall: 0.8493 - val_loss: 0.0848 - val_accuracy: 0.8574 - val_binary_iou: 0.7399 - val_true_positives: 33218982.0000 - val_false_positives: 3312352.0000 - val_true_negatives: 57644400.0000 - val_false_negatives: 11795967.0000 - val_precision: 0.9093 - val_recall: 0.7380\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0705 - accuracy: 0.8872 - binary_iou: 0.7912 - true_positives: 111304640.0000 - false_positives: 16271008.0000 - true_negatives: 172181952.0000 - false_negatives: 19763074.0000 - precision: 0.8725 - recall: 0.8492 - val_loss: 0.0780 - val_accuracy: 0.8788 - val_binary_iou: 0.7815 - val_true_positives: 40363296.0000 - val_false_positives: 8102494.0000 - val_true_negatives: 52768896.0000 - val_false_negatives: 4737019.0000 - val_precision: 0.8328 - val_recall: 0.8950\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0703 - accuracy: 0.8879 - binary_iou: 0.7923 - true_positives: 111497272.0000 - false_positives: 16185796.0000 - true_negatives: 172192080.0000 - false_negatives: 19645634.0000 - precision: 0.8732 - recall: 0.8502 - val_loss: 0.0729 - val_accuracy: 0.8834 - val_binary_iou: 0.7850 - val_true_positives: 36861128.0000 - val_false_positives: 4175830.0000 - val_true_negatives: 56752168.0000 - val_false_negatives: 8182607.0000 - val_precision: 0.8982 - val_recall: 0.8183\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0702 - accuracy: 0.8878 - binary_iou: 0.7922 - true_positives: 111428296.0000 - false_positives: 16189002.0000 - true_negatives: 172243248.0000 - false_negatives: 19660228.0000 - precision: 0.8731 - recall: 0.8500 - val_loss: 0.0748 - val_accuracy: 0.8787 - val_binary_iou: 0.7808 - val_true_positives: 39858764.0000 - val_false_positives: 7576542.0000 - val_true_negatives: 53255492.0000 - val_false_negatives: 5280936.0000 - val_precision: 0.8403 - val_recall: 0.8830\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0699 - accuracy: 0.8884 - binary_iou: 0.7932 - true_positives: 111605032.0000 - false_positives: 16211818.0000 - true_negatives: 172253808.0000 - false_negatives: 19450116.0000 - precision: 0.8732 - recall: 0.8516 - val_loss: 0.0724 - val_accuracy: 0.8823 - val_binary_iou: 0.7848 - val_true_positives: 38025824.0000 - val_false_positives: 5357245.0000 - val_true_negatives: 55475288.0000 - val_false_negatives: 7113354.0000 - val_precision: 0.8765 - val_recall: 0.8424\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514 - val_loss: 0.0719 - val_accuracy: 0.8857 - val_binary_iou: 0.7920 - val_true_positives: 40008660.0000 - val_false_positives: 6950614.0000 - val_true_negatives: 53851884.0000 - val_false_negatives: 5160537.0000 - val_precision: 0.8520 - val_recall: 0.8858\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111832104.0000 - false_positives: 16087610.0000 - true_negatives: 172342992.0000 - false_negatives: 19257988.0000 - precision: 0.8742 - recall: 0.8531 - val_loss: 0.0860 - val_accuracy: 0.8592 - val_binary_iou: 0.7425 - val_true_positives: 33238404.0000 - val_false_positives: 3034032.0000 - val_true_negatives: 57809696.0000 - val_false_negatives: 11889571.0000 - val_precision: 0.9164 - val_recall: 0.7365\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111810888.0000 - false_positives: 16032721.0000 - true_negatives: 172367728.0000 - false_negatives: 19309438.0000 - precision: 0.8746 - recall: 0.8527 - val_loss: 0.0795 - val_accuracy: 0.8735 - val_binary_iou: 0.7676 - val_true_positives: 35400352.0000 - val_false_positives: 3689432.0000 - val_true_negatives: 57161040.0000 - val_false_negatives: 9720906.0000 - val_precision: 0.9056 - val_recall: 0.7846\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0695 - accuracy: 0.8884 - binary_iou: 0.7933 - true_positives: 111689736.0000 - false_positives: 16202075.0000 - true_negatives: 172186048.0000 - false_negatives: 19442862.0000 - precision: 0.8733 - recall: 0.8517 - val_loss: 0.0758 - val_accuracy: 0.8776 - val_binary_iou: 0.7791 - val_true_positives: 39693812.0000 - val_false_positives: 7559088.0000 - val_true_negatives: 53310804.0000 - val_false_negatives: 5407998.0000 - val_precision: 0.8400 - val_recall: 0.8801\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0689 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 111939024.0000 - false_positives: 15899358.0000 - true_negatives: 172475312.0000 - false_negatives: 19207072.0000 - precision: 0.8756 - recall: 0.8535 - val_loss: 0.1359 - val_accuracy: 0.7880 - val_binary_iou: 0.6222 - val_true_positives: 24266056.0000 - val_false_positives: 1582781.0000 - val_true_negatives: 59243448.0000 - val_false_negatives: 20879408.0000 - val_precision: 0.9388 - val_recall: 0.5375\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 428ms/step - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537 - val_loss: 0.0701 - val_accuracy: 0.8880 - val_binary_iou: 0.7950 - val_true_positives: 39279140.0000 - val_false_positives: 6042733.0000 - val_true_negatives: 54825964.0000 - val_false_negatives: 5823879.0000 - val_precision: 0.8667 - val_recall: 0.8709\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0688 - accuracy: 0.8901 - binary_iou: 0.7960 - true_positives: 111865480.0000 - false_positives: 15830442.0000 - true_negatives: 172532208.0000 - false_negatives: 19292612.0000 - precision: 0.8760 - recall: 0.8529 - val_loss: 0.0774 - val_accuracy: 0.8784 - val_binary_iou: 0.7808 - val_true_positives: 40402348.0000 - val_false_positives: 8221260.0000 - val_true_negatives: 52680000.0000 - val_false_negatives: 4668108.0000 - val_precision: 0.8309 - val_recall: 0.8964\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0690 - accuracy: 0.8891 - binary_iou: 0.7944 - true_positives: 111709696.0000 - false_positives: 15976760.0000 - true_negatives: 172388368.0000 - false_negatives: 19445922.0000 - precision: 0.8749 - recall: 0.8517 - val_loss: 0.0803 - val_accuracy: 0.8730 - val_binary_iou: 0.7725 - val_true_positives: 40478668.0000 - val_false_positives: 8900463.0000 - val_true_negatives: 52034368.0000 - val_false_negatives: 4558195.0000 - val_precision: 0.8198 - val_recall: 0.8988\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0688 - accuracy: 0.8902 - binary_iou: 0.7962 - true_positives: 111886672.0000 - false_positives: 15776121.0000 - true_negatives: 172563696.0000 - false_negatives: 19294172.0000 - precision: 0.8764 - recall: 0.8529 - val_loss: 0.0752 - val_accuracy: 0.8810 - val_binary_iou: 0.7845 - val_true_positives: 39947648.0000 - val_false_positives: 7431002.0000 - val_true_negatives: 53413960.0000 - val_false_negatives: 5179119.0000 - val_precision: 0.8432 - val_recall: 0.8852\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0691 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111791048.0000 - false_positives: 16044969.0000 - true_negatives: 172387392.0000 - false_negatives: 19297388.0000 - precision: 0.8745 - recall: 0.8528 - val_loss: 0.0951 - val_accuracy: 0.8679 - val_binary_iou: 0.7649 - val_true_positives: 40768648.0000 - val_false_positives: 9800652.0000 - val_true_negatives: 51205848.0000 - val_false_negatives: 4196562.0000 - val_precision: 0.8062 - val_recall: 0.9067\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0686 - accuracy: 0.8903 - binary_iou: 0.7963 - true_positives: 112000912.0000 - false_positives: 15904758.0000 - true_negatives: 172459744.0000 - false_negatives: 19155282.0000 - precision: 0.8757 - recall: 0.8540 - val_loss: 0.0771 - val_accuracy: 0.8741 - val_binary_iou: 0.7688 - val_true_positives: 35527912.0000 - val_false_positives: 3736203.0000 - val_true_negatives: 57103272.0000 - val_false_negatives: 9604338.0000 - val_precision: 0.9048 - val_recall: 0.7872\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0678 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112179992.0000 - false_positives: 15409854.0000 - true_negatives: 173029520.0000 - false_negatives: 18901586.0000 - precision: 0.8792 - recall: 0.8558 - val_loss: 0.0724 - val_accuracy: 0.8848 - val_binary_iou: 0.7907 - val_true_positives: 40174352.0000 - val_false_positives: 7346762.0000 - val_true_negatives: 53591184.0000 - val_false_negatives: 4859408.0000 - val_precision: 0.8454 - val_recall: 0.8921\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 171s 429ms/step - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540 - val_loss: 0.0689 - val_accuracy: 0.8901 - val_binary_iou: 0.7975 - val_true_positives: 38453356.0000 - val_false_positives: 4979271.0000 - val_true_negatives: 55869972.0000 - val_false_negatives: 6669114.0000 - val_precision: 0.8854 - val_recall: 0.8522\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 160s 402ms/step - loss: 0.0682 - accuracy: 0.8911 - binary_iou: 0.7976 - true_positives: 112027632.0000 - false_positives: 15746636.0000 - true_negatives: 172694192.0000 - false_negatives: 19052250.0000 - precision: 0.8768 - recall: 0.8547 - val_loss: 0.0703 - val_accuracy: 0.8876 - val_binary_iou: 0.7944 - val_true_positives: 39253120.0000 - val_false_positives: 6203339.0000 - val_true_negatives: 54812624.0000 - val_false_negatives: 5702634.0000 - val_precision: 0.8635 - val_recall: 0.8732\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0678 - accuracy: 0.8924 - binary_iou: 0.7998 - true_positives: 112174480.0000 - false_positives: 15427345.0000 - true_negatives: 172958144.0000 - false_negatives: 18960760.0000 - precision: 0.8791 - recall: 0.8554 - val_loss: 0.0714 - val_accuracy: 0.8860 - val_binary_iou: 0.7922 - val_true_positives: 39661624.0000 - val_false_positives: 6618287.0000 - val_true_negatives: 54230892.0000 - val_false_negatives: 5460903.0000 - val_precision: 0.8570 - val_recall: 0.8790\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0676 - accuracy: 0.8918 - binary_iou: 0.7988 - true_positives: 112268576.0000 - false_positives: 15669733.0000 - true_negatives: 172670096.0000 - false_negatives: 18912436.0000 - precision: 0.8775 - recall: 0.8558 - val_loss: 0.0768 - val_accuracy: 0.8799 - val_binary_iou: 0.7831 - val_true_positives: 40321992.0000 - val_false_positives: 7994599.0000 - val_true_negatives: 52923220.0000 - val_false_negatives: 4731924.0000 - val_precision: 0.8345 - val_recall: 0.8950\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 135s 338ms/step - loss: 0.0672 - accuracy: 0.8930 - binary_iou: 0.8009 - true_positives: 112414688.0000 - false_positives: 15411543.0000 - true_negatives: 172917456.0000 - false_negatives: 18777054.0000 - precision: 0.8794 - recall: 0.8569 - val_loss: 0.1484 - val_accuracy: 0.7818 - val_binary_iou: 0.6113 - val_true_positives: 23371532.0000 - val_false_positives: 1365110.0000 - val_true_negatives: 59475000.0000 - val_false_negatives: 21760066.0000 - val_precision: 0.9448 - val_recall: 0.5179\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0670 - accuracy: 0.8930 - binary_iou: 0.8007 - true_positives: 112071688.0000 - false_positives: 15228398.0000 - true_negatives: 173257568.0000 - false_negatives: 18963102.0000 - precision: 0.8804 - recall: 0.8553 - val_loss: 0.0730 - val_accuracy: 0.8837 - val_binary_iou: 0.7859 - val_true_positives: 37128412.0000 - val_false_positives: 4391111.0000 - val_true_negatives: 56520536.0000 - val_false_negatives: 7931644.0000 - val_precision: 0.8942 - val_recall: 0.8240\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 427ms/step - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554 - val_loss: 0.0678 - val_accuracy: 0.8915 - val_binary_iou: 0.7994 - val_true_positives: 38122228.0000 - val_false_positives: 4515762.0000 - val_true_negatives: 56352220.0000 - val_false_negatives: 6981488.0000 - val_precision: 0.8941 - val_recall: 0.8452\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 133s 333ms/step - loss: 0.0669 - accuracy: 0.8936 - binary_iou: 0.8018 - true_positives: 112442640.0000 - false_positives: 15260840.0000 - true_negatives: 173075456.0000 - false_negatives: 18741888.0000 - precision: 0.8805 - recall: 0.8571 - val_loss: 0.0707 - val_accuracy: 0.8882 - val_binary_iou: 0.7955 - val_true_positives: 39381688.0000 - val_false_positives: 6069700.0000 - val_true_negatives: 54746240.0000 - val_false_negatives: 5774078.0000 - val_precision: 0.8665 - val_recall: 0.8721\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0668 - accuracy: 0.8932 - binary_iou: 0.8013 - true_positives: 112449040.0000 - false_positives: 15470578.0000 - true_negatives: 172959840.0000 - false_negatives: 18641352.0000 - precision: 0.8791 - recall: 0.8578 - val_loss: 0.0734 - val_accuracy: 0.8809 - val_binary_iou: 0.7799 - val_true_positives: 35980932.0000 - val_false_positives: 3395829.0000 - val_true_negatives: 57365376.0000 - val_false_negatives: 9229588.0000 - val_precision: 0.9138 - val_recall: 0.7959\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8015 - true_positives: 112170456.0000 - false_positives: 15109560.0000 - true_negatives: 173310432.0000 - false_negatives: 18930238.0000 - precision: 0.8813 - recall: 0.8556 - val_loss: 0.0687 - val_accuracy: 0.8896 - val_binary_iou: 0.7965 - val_true_positives: 38277924.0000 - val_false_positives: 4777362.0000 - val_true_negatives: 55992768.0000 - val_false_negatives: 6923645.0000 - val_precision: 0.8890 - val_recall: 0.8468\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0665 - accuracy: 0.8945 - binary_iou: 0.8033 - true_positives: 112567264.0000 - false_positives: 15171494.0000 - true_negatives: 173237200.0000 - false_negatives: 18544780.0000 - precision: 0.8812 - recall: 0.8586 - val_loss: 0.1019 - val_accuracy: 0.8186 - val_binary_iou: 0.6723 - val_true_positives: 27651104.0000 - val_false_positives: 1777387.0000 - val_true_negatives: 59099132.0000 - val_false_negatives: 17444088.0000 - val_precision: 0.9396 - val_recall: 0.6132\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0674 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112299664.0000 - false_positives: 15546087.0000 - true_negatives: 172895488.0000 - false_negatives: 18779640.0000 - precision: 0.8784 - recall: 0.8567 - val_loss: 0.0816 - val_accuracy: 0.8774 - val_binary_iou: 0.7792 - val_true_positives: 40354892.0000 - val_false_positives: 8312571.0000 - val_true_negatives: 52624612.0000 - val_false_negatives: 4679636.0000 - val_precision: 0.8292 - val_recall: 0.8961\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0667 - accuracy: 0.8937 - binary_iou: 0.8020 - true_positives: 112282648.0000 - false_positives: 15109516.0000 - true_negatives: 173280112.0000 - false_negatives: 18848368.0000 - precision: 0.8814 - recall: 0.8563 - val_loss: 0.0783 - val_accuracy: 0.8691 - val_binary_iou: 0.7659 - val_true_positives: 39678192.0000 - val_false_positives: 8383734.0000 - val_true_negatives: 52426100.0000 - val_false_negatives: 5483700.0000 - val_precision: 0.8256 - val_recall: 0.8786\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8018 - true_positives: 112706776.0000 - false_positives: 15555337.0000 - true_negatives: 172791440.0000 - false_negatives: 18467180.0000 - precision: 0.8787 - recall: 0.8592 - val_loss: 0.0741 - val_accuracy: 0.8826 - val_binary_iou: 0.7877 - val_true_positives: 40878036.0000 - val_false_positives: 8097197.0000 - val_true_negatives: 52650636.0000 - val_false_negatives: 4345838.0000 - val_precision: 0.8347 - val_recall: 0.9039\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8952 - binary_iou: 0.8046 - true_positives: 112822448.0000 - false_positives: 15160487.0000 - true_negatives: 173219936.0000 - false_negatives: 18317834.0000 - precision: 0.8815 - recall: 0.8603 - val_loss: 0.0712 - val_accuracy: 0.8861 - val_binary_iou: 0.7889 - val_true_positives: 36594128.0000 - val_false_positives: 3547294.0000 - val_true_negatives: 57302372.0000 - val_false_negatives: 8527889.0000 - val_precision: 0.9116 - val_recall: 0.8110\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0661 - accuracy: 0.8949 - binary_iou: 0.8041 - true_positives: 112634032.0000 - false_positives: 15075881.0000 - true_negatives: 173317312.0000 - false_negatives: 18493656.0000 - precision: 0.8820 - recall: 0.8590 - val_loss: 0.1567 - val_accuracy: 0.7551 - val_binary_iou: 0.5705 - val_true_positives: 20908572.0000 - val_false_positives: 1721498.0000 - val_true_negatives: 59106516.0000 - val_false_negatives: 24235132.0000 - val_precision: 0.9239 - val_recall: 0.4632\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8953 - binary_iou: 0.8046 - true_positives: 112573032.0000 - false_positives: 14919423.0000 - true_negatives: 173497088.0000 - false_negatives: 18531148.0000 - precision: 0.8830 - recall: 0.8587 - val_loss: 0.0721 - val_accuracy: 0.8864 - val_binary_iou: 0.7910 - val_true_positives: 37871184.0000 - val_false_positives: 4839935.0000 - val_true_negatives: 56064496.0000 - val_false_negatives: 7196119.0000 - val_precision: 0.8867 - val_recall: 0.8403\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0654 - accuracy: 0.8963 - binary_iou: 0.8064 - true_positives: 112841192.0000 - false_positives: 14810634.0000 - true_negatives: 173555312.0000 - false_negatives: 18313536.0000 - precision: 0.8840 - recall: 0.8604 - val_loss: 0.0810 - val_accuracy: 0.8655 - val_binary_iou: 0.7549 - val_true_positives: 35077924.0000 - val_false_positives: 4263421.0000 - val_true_negatives: 56635472.0000 - val_false_negatives: 9994884.0000 - val_precision: 0.8916 - val_recall: 0.7783\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0652 - accuracy: 0.8962 - binary_iou: 0.8062 - true_positives: 112972344.0000 - false_positives: 15045884.0000 - true_negatives: 173367568.0000 - false_negatives: 18134990.0000 - precision: 0.8825 - recall: 0.8617 - val_loss: 0.0913 - val_accuracy: 0.8630 - val_binary_iou: 0.7575 - val_true_positives: 40925680.0000 - val_false_positives: 10408766.0000 - val_true_negatives: 50531900.0000 - val_false_negatives: 4105355.0000 - val_precision: 0.7972 - val_recall: 0.9088\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0655 - accuracy: 0.8956 - binary_iou: 0.8053 - true_positives: 112770296.0000 - false_positives: 14935553.0000 - true_negatives: 173408240.0000 - false_negatives: 18406754.0000 - precision: 0.8830 - recall: 0.8597 - val_loss: 0.0681 - val_accuracy: 0.8916 - val_binary_iou: 0.7991 - val_true_positives: 37650052.0000 - val_false_positives: 4016793.0000 - val_true_negatives: 56835504.0000 - val_false_negatives: 7469375.0000 - val_precision: 0.9036 - val_recall: 0.8345\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8965 - binary_iou: 0.8066 - true_positives: 112672744.0000 - false_positives: 14632333.0000 - true_negatives: 173781648.0000 - false_negatives: 18434098.0000 - precision: 0.8851 - recall: 0.8594 - val_loss: 0.0741 - val_accuracy: 0.8843 - val_binary_iou: 0.7891 - val_true_positives: 39229924.0000 - val_false_positives: 6452676.0000 - val_true_negatives: 54484932.0000 - val_false_negatives: 5804178.0000 - val_precision: 0.8587 - val_recall: 0.8711\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0654 - accuracy: 0.8961 - binary_iou: 0.8061 - true_positives: 112790800.0000 - false_positives: 14832199.0000 - true_negatives: 173542400.0000 - false_negatives: 18355386.0000 - precision: 0.8838 - recall: 0.8600 - val_loss: 0.0749 - val_accuracy: 0.8854 - val_binary_iou: 0.7920 - val_true_positives: 40681160.0000 - val_false_positives: 7715254.0000 - val_true_negatives: 53141616.0000 - val_false_negatives: 4433672.0000 - val_precision: 0.8406 - val_recall: 0.9017\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0653 - accuracy: 0.8962 - binary_iou: 0.8061 - true_positives: 112847560.0000 - false_positives: 14876293.0000 - true_negatives: 173496784.0000 - false_negatives: 18300084.0000 - precision: 0.8835 - recall: 0.8605 - val_loss: 0.0764 - val_accuracy: 0.8787 - val_binary_iou: 0.7810 - val_true_positives: 40074776.0000 - val_false_positives: 7857041.0000 - val_true_negatives: 53039168.0000 - val_false_negatives: 5000726.0000 - val_precision: 0.8361 - val_recall: 0.8891\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598 - val_loss: 0.0676 - val_accuracy: 0.8920 - val_binary_iou: 0.8012 - val_true_positives: 39038164.0000 - val_false_positives: 5411304.0000 - val_true_negatives: 55491768.0000 - val_false_negatives: 6030472.0000 - val_precision: 0.8783 - val_recall: 0.8662\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 133s 334ms/step - loss: 0.0649 - accuracy: 0.8968 - binary_iou: 0.8072 - true_positives: 112836920.0000 - false_positives: 14683751.0000 - true_negatives: 173715984.0000 - false_negatives: 18284156.0000 - precision: 0.8849 - recall: 0.8606 - val_loss: 0.0736 - val_accuracy: 0.8828 - val_binary_iou: 0.7850 - val_true_positives: 37599728.0000 - val_false_positives: 4910598.0000 - val_true_negatives: 55953576.0000 - val_false_negatives: 7507811.0000 - val_precision: 0.8845 - val_recall: 0.8336\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0644 - accuracy: 0.8975 - binary_iou: 0.8083 - true_positives: 113073528.0000 - false_positives: 14661790.0000 - true_negatives: 173689344.0000 - false_negatives: 18096160.0000 - precision: 0.8852 - recall: 0.8620 - val_loss: 0.0808 - val_accuracy: 0.8723 - val_binary_iou: 0.7642 - val_true_positives: 34353932.0000 - val_false_positives: 2753126.0000 - val_true_negatives: 58084044.0000 - val_false_negatives: 10780616.0000 - val_precision: 0.9258 - val_recall: 0.7611\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8971 - binary_iou: 0.8076 - true_positives: 112894736.0000 - false_positives: 14678940.0000 - true_negatives: 173739488.0000 - false_negatives: 18207648.0000 - precision: 0.8849 - recall: 0.8611 - val_loss: 0.0691 - val_accuracy: 0.8917 - val_binary_iou: 0.8007 - val_true_positives: 39146796.0000 - val_false_positives: 5586695.0000 - val_true_negatives: 55345212.0000 - val_false_negatives: 5892998.0000 - val_precision: 0.8751 - val_recall: 0.8692\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0648 - accuracy: 0.8970 - binary_iou: 0.8074 - true_positives: 112868432.0000 - false_positives: 14630436.0000 - true_negatives: 173732256.0000 - false_negatives: 18289650.0000 - precision: 0.8853 - recall: 0.8606 - val_loss: 0.0872 - val_accuracy: 0.8663 - val_binary_iou: 0.7620 - val_true_positives: 40245384.0000 - val_false_positives: 9343865.0000 - val_true_negatives: 51557684.0000 - val_false_negatives: 4824793.0000 - val_precision: 0.8116 - val_recall: 0.8929\n",
      "132/132 [==============================] - 45s 317ms/step - loss: 212.9752 - accuracy: 0.8897 - binary_iou: 0.7965 - true_positives: 38099952.0000 - false_positives: 5604668.0000 - true_negatives: 56180072.0000 - false_negatives: 6087014.0000 - precision: 0.8718 - recall: 0.8622\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 185s 442ms/step - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509 - val_loss: 0.1105 - val_accuracy: 0.8061 - val_binary_iou: 0.6605 - val_true_positives: 29558962.0000 - val_false_positives: 5074877.0000 - val_true_negatives: 55861256.0000 - val_false_negatives: 15476612.0000 - val_precision: 0.8535 - val_recall: 0.6563\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0969 - accuracy: 0.8330 - binary_iou: 0.7067 - true_positives: 103866728.0000 - false_positives: 26122214.0000 - true_negatives: 162309504.0000 - false_negatives: 27222196.0000 - precision: 0.7990 - recall: 0.7923 - val_loss: 0.1090 - val_accuracy: 0.7971 - val_binary_iou: 0.6466 - val_true_positives: 28650442.0000 - val_false_positives: 5022378.0000 - val_true_negatives: 55819924.0000 - val_false_negatives: 16478962.0000 - val_precision: 0.8508 - val_recall: 0.6349\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946 - val_loss: 0.1040 - val_accuracy: 0.8304 - val_binary_iou: 0.7052 - val_true_positives: 36088200.0000 - val_false_positives: 8909478.0000 - val_true_negatives: 51910856.0000 - val_false_negatives: 9063180.0000 - val_precision: 0.8020 - val_recall: 0.7993\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036 - val_loss: 0.0947 - val_accuracy: 0.8398 - val_binary_iou: 0.7195 - val_true_positives: 36842232.0000 - val_false_positives: 8677888.0000 - val_true_negatives: 52152584.0000 - val_false_negatives: 8299018.0000 - val_precision: 0.8094 - val_recall: 0.8162\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0914 - accuracy: 0.8468 - binary_iou: 0.7275 - true_positives: 106150000.0000 - false_positives: 23878964.0000 - true_negatives: 164412704.0000 - false_negatives: 25079016.0000 - precision: 0.8164 - recall: 0.8089 - val_loss: 0.1028 - val_accuracy: 0.8082 - val_binary_iou: 0.6639 - val_true_positives: 29808732.0000 - val_false_positives: 5023932.0000 - val_true_negatives: 55838920.0000 - val_false_negatives: 15300131.0000 - val_precision: 0.8558 - val_recall: 0.6608\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109 - val_loss: 0.0844 - val_accuracy: 0.8593 - val_binary_iou: 0.7474 - val_true_positives: 36334244.0000 - val_false_positives: 6082476.0000 - val_true_negatives: 54722900.0000 - val_false_negatives: 8832084.0000 - val_precision: 0.8566 - val_recall: 0.8045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0889 - accuracy: 0.8510 - binary_iou: 0.7339 - true_positives: 106864624.0000 - false_positives: 23327616.0000 - true_negatives: 165044144.0000 - false_negatives: 24284384.0000 - precision: 0.8208 - recall: 0.8148 - val_loss: 0.1001 - val_accuracy: 0.8204 - val_binary_iou: 0.6782 - val_true_positives: 29000756.0000 - val_false_positives: 3039177.0000 - val_true_negatives: 57938184.0000 - val_false_negatives: 15993596.0000 - val_precision: 0.9051 - val_recall: 0.6445\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0877 - accuracy: 0.8533 - binary_iou: 0.7374 - true_positives: 107015776.0000 - false_positives: 22760176.0000 - true_negatives: 165621696.0000 - false_negatives: 24123068.0000 - precision: 0.8246 - recall: 0.8160 - val_loss: 0.0992 - val_accuracy: 0.8232 - val_binary_iou: 0.6827 - val_true_positives: 29234104.0000 - val_false_positives: 2876097.0000 - val_true_negatives: 58006276.0000 - val_false_negatives: 15855237.0000 - val_precision: 0.9104 - val_recall: 0.6484\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0868 - accuracy: 0.8551 - binary_iou: 0.7402 - true_positives: 107298048.0000 - false_positives: 22419816.0000 - true_negatives: 165917520.0000 - false_negatives: 23885356.0000 - precision: 0.8272 - recall: 0.8179 - val_loss: 0.0907 - val_accuracy: 0.8447 - val_binary_iou: 0.7263 - val_true_positives: 36638376.0000 - val_false_positives: 7956607.0000 - val_true_negatives: 52870960.0000 - val_false_negatives: 8505777.0000 - val_precision: 0.8216 - val_recall: 0.8116\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0860 - accuracy: 0.8567 - binary_iou: 0.7427 - true_positives: 107560656.0000 - false_positives: 22263318.0000 - true_negatives: 166169616.0000 - false_negatives: 23527152.0000 - precision: 0.8285 - recall: 0.8205 - val_loss: 0.0871 - val_accuracy: 0.8539 - val_binary_iou: 0.7427 - val_true_positives: 39383768.0000 - val_false_positives: 9782407.0000 - val_true_negatives: 51109704.0000 - val_false_negatives: 5695821.0000 - val_precision: 0.8010 - val_recall: 0.8736\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0840 - accuracy: 0.8601 - binary_iou: 0.7481 - true_positives: 108232024.0000 - false_positives: 21758164.0000 - true_negatives: 166597248.0000 - false_negatives: 22933332.0000 - precision: 0.8326 - recall: 0.8252 - val_loss: 0.0899 - val_accuracy: 0.8479 - val_binary_iou: 0.7261 - val_true_positives: 33317968.0000 - val_false_positives: 4355052.0000 - val_true_negatives: 56538512.0000 - val_false_negatives: 11760183.0000 - val_precision: 0.8844 - val_recall: 0.7391\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262 - val_loss: 0.0843 - val_accuracy: 0.8626 - val_binary_iou: 0.7532 - val_true_positives: 36904740.0000 - val_false_positives: 6333535.0000 - val_true_negatives: 54509848.0000 - val_false_negatives: 8223592.0000 - val_precision: 0.8535 - val_recall: 0.8178\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0827 - accuracy: 0.8639 - binary_iou: 0.7537 - true_positives: 108190992.0000 - false_positives: 20585124.0000 - true_negatives: 167837744.0000 - false_negatives: 22906836.0000 - precision: 0.8401 - recall: 0.8253 - val_loss: 0.0861 - val_accuracy: 0.8567 - val_binary_iou: 0.7439 - val_true_positives: 36617192.0000 - val_false_positives: 6830996.0000 - val_true_negatives: 54164012.0000 - val_false_negatives: 8359509.0000 - val_precision: 0.8428 - val_recall: 0.8141\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304 - val_loss: 0.0832 - val_accuracy: 0.8657 - val_binary_iou: 0.7568 - val_true_positives: 36133160.0000 - val_false_positives: 5289682.0000 - val_true_negatives: 55606572.0000 - val_false_negatives: 8942304.0000 - val_precision: 0.8723 - val_recall: 0.8016\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0805 - accuracy: 0.8679 - binary_iou: 0.7603 - true_positives: 109205312.0000 - false_positives: 20384652.0000 - true_negatives: 168115712.0000 - false_negatives: 21815188.0000 - precision: 0.8427 - recall: 0.8335 - val_loss: 0.0826 - val_accuracy: 0.8640 - val_binary_iou: 0.7537 - val_true_positives: 35741368.0000 - val_false_positives: 5012108.0000 - val_true_negatives: 55818184.0000 - val_false_negatives: 9400030.0000 - val_precision: 0.8770 - val_recall: 0.7918\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0796 - accuracy: 0.8695 - binary_iou: 0.7628 - true_positives: 109519336.0000 - false_positives: 20095204.0000 - true_negatives: 168288400.0000 - false_negatives: 21617852.0000 - precision: 0.8450 - recall: 0.8352 - val_loss: 0.0904 - val_accuracy: 0.8553 - val_binary_iou: 0.7370 - val_true_positives: 33358712.0000 - val_false_positives: 3548969.0000 - val_true_negatives: 57280136.0000 - val_false_negatives: 11783893.0000 - val_precision: 0.9038 - val_recall: 0.7390\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0802 - accuracy: 0.8684 - binary_iou: 0.7611 - true_positives: 109389072.0000 - false_positives: 20335696.0000 - true_negatives: 168089696.0000 - false_negatives: 21706340.0000 - precision: 0.8432 - recall: 0.8344 - val_loss: 0.0819 - val_accuracy: 0.8643 - val_binary_iou: 0.7543 - val_true_positives: 35849168.0000 - val_false_positives: 5100314.0000 - val_true_negatives: 55738372.0000 - val_false_negatives: 9283861.0000 - val_precision: 0.8754 - val_recall: 0.7943\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0787 - accuracy: 0.8711 - binary_iou: 0.7654 - true_positives: 109737320.0000 - false_positives: 19834218.0000 - true_negatives: 168589664.0000 - false_negatives: 21359514.0000 - precision: 0.8469 - recall: 0.8371 - val_loss: 0.0840 - val_accuracy: 0.8606 - val_binary_iou: 0.7474 - val_true_positives: 34968736.0000 - val_false_positives: 4551350.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 10224023.0000 - val_precision: 0.8848 - val_recall: 0.7738\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404 - val_loss: 0.0795 - val_accuracy: 0.8686 - val_binary_iou: 0.7619 - val_true_positives: 36683320.0000 - val_false_positives: 5540348.0000 - val_true_negatives: 55363864.0000 - val_false_negatives: 8384161.0000 - val_precision: 0.8688 - val_recall: 0.8140\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0776 - accuracy: 0.8728 - binary_iou: 0.7680 - true_positives: 109780352.0000 - false_positives: 19325732.0000 - true_negatives: 169090848.0000 - false_negatives: 21323936.0000 - precision: 0.8503 - recall: 0.8374 - val_loss: 0.0809 - val_accuracy: 0.8656 - val_binary_iou: 0.7602 - val_true_positives: 39312376.0000 - val_false_positives: 8557187.0000 - val_true_negatives: 52416080.0000 - val_false_negatives: 5686077.0000 - val_precision: 0.8212 - val_recall: 0.8736\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410 - val_loss: 0.0794 - val_accuracy: 0.8732 - val_binary_iou: 0.7725 - val_true_positives: 40125432.0000 - val_false_positives: 8428567.0000 - val_true_negatives: 52404920.0000 - val_false_negatives: 5012805.0000 - val_precision: 0.8264 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0762 - accuracy: 0.8764 - binary_iou: 0.7739 - true_positives: 110538152.0000 - false_positives: 18913164.0000 - true_negatives: 169494592.0000 - false_negatives: 20574936.0000 - precision: 0.8539 - recall: 0.8431 - val_loss: 0.0951 - val_accuracy: 0.8363 - val_binary_iou: 0.7062 - val_true_positives: 31574824.0000 - val_false_positives: 3741021.0000 - val_true_negatives: 57054612.0000 - val_false_negatives: 13601249.0000 - val_precision: 0.8941 - val_recall: 0.6989\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442 - val_loss: 0.0744 - val_accuracy: 0.8783 - val_binary_iou: 0.7776 - val_true_positives: 37268520.0000 - val_false_positives: 5039199.0000 - val_true_negatives: 55808504.0000 - val_false_negatives: 7855478.0000 - val_precision: 0.8809 - val_recall: 0.8259\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0753 - accuracy: 0.8775 - binary_iou: 0.7757 - true_positives: 110844512.0000 - false_positives: 18808940.0000 - true_negatives: 169537376.0000 - false_negatives: 20330032.0000 - precision: 0.8549 - recall: 0.8450 - val_loss: 0.0757 - val_accuracy: 0.8756 - val_binary_iou: 0.7748 - val_true_positives: 38605216.0000 - val_false_positives: 6663971.0000 - val_true_negatives: 54178532.0000 - val_false_negatives: 6523988.0000 - val_precision: 0.8528 - val_recall: 0.8554\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0744 - accuracy: 0.8792 - binary_iou: 0.7784 - true_positives: 110836560.0000 - false_positives: 18290544.0000 - true_negatives: 170090624.0000 - false_negatives: 20303034.0000 - precision: 0.8584 - recall: 0.8452 - val_loss: 0.0838 - val_accuracy: 0.8686 - val_binary_iou: 0.7643 - val_true_positives: 38808680.0000 - val_false_positives: 7733552.0000 - val_true_negatives: 53238424.0000 - val_false_negatives: 6191043.0000 - val_precision: 0.8338 - val_recall: 0.8624\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455 - val_loss: 0.0743 - val_accuracy: 0.8803 - val_binary_iou: 0.7815 - val_true_positives: 37964788.0000 - val_false_positives: 5535672.0000 - val_true_negatives: 55320728.0000 - val_false_negatives: 7150529.0000 - val_precision: 0.8727 - val_recall: 0.8415\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8807 - binary_iou: 0.7808 - true_positives: 110972968.0000 - false_positives: 17974036.0000 - true_negatives: 170442016.0000 - false_negatives: 20131872.0000 - precision: 0.8606 - recall: 0.8464 - val_loss: 0.0780 - val_accuracy: 0.8706 - val_binary_iou: 0.7684 - val_true_positives: 39906784.0000 - val_false_positives: 8499998.0000 - val_true_negatives: 52356132.0000 - val_false_negatives: 5208790.0000 - val_precision: 0.8244 - val_recall: 0.8845\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0728 - accuracy: 0.8829 - binary_iou: 0.7843 - true_positives: 111373168.0000 - false_positives: 17715180.0000 - true_negatives: 170722176.0000 - false_negatives: 19710296.0000 - precision: 0.8628 - recall: 0.8496 - val_loss: 0.0770 - val_accuracy: 0.8757 - val_binary_iou: 0.7717 - val_true_positives: 35798568.0000 - val_false_positives: 3818787.0000 - val_true_negatives: 57002196.0000 - val_false_negatives: 9352164.0000 - val_precision: 0.9036 - val_recall: 0.7929\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0726 - accuracy: 0.8827 - binary_iou: 0.7841 - true_positives: 111452024.0000 - false_positives: 17798892.0000 - true_negatives: 170586352.0000 - false_negatives: 19683584.0000 - precision: 0.8623 - recall: 0.8499 - val_loss: 0.0810 - val_accuracy: 0.8639 - val_binary_iou: 0.7540 - val_true_positives: 36116544.0000 - val_false_positives: 5372076.0000 - val_true_negatives: 55429736.0000 - val_false_negatives: 9053340.0000 - val_precision: 0.8705 - val_recall: 0.7996\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505 - val_loss: 0.0704 - val_accuracy: 0.8863 - val_binary_iou: 0.7915 - val_true_positives: 38513900.0000 - val_false_positives: 5352287.0000 - val_true_negatives: 55406376.0000 - val_false_negatives: 6699139.0000 - val_precision: 0.8780 - val_recall: 0.8518\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0720 - accuracy: 0.8833 - binary_iou: 0.7852 - true_positives: 111675440.0000 - false_positives: 17808288.0000 - true_negatives: 170566208.0000 - false_negatives: 19470846.0000 - precision: 0.8625 - recall: 0.8515 - val_loss: 0.0821 - val_accuracy: 0.8666 - val_binary_iou: 0.7624 - val_true_positives: 40110328.0000 - val_false_positives: 9223599.0000 - val_true_negatives: 51725288.0000 - val_false_negatives: 4912495.0000 - val_precision: 0.8130 - val_recall: 0.8909\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0706 - accuracy: 0.8862 - binary_iou: 0.7899 - true_positives: 111930336.0000 - false_positives: 17126412.0000 - true_negatives: 171239056.0000 - false_negatives: 19225072.0000 - precision: 0.8673 - recall: 0.8534 - val_loss: 0.0739 - val_accuracy: 0.8792 - val_binary_iou: 0.7784 - val_true_positives: 36755232.0000 - val_false_positives: 4481793.0000 - val_true_negatives: 56420288.0000 - val_false_negatives: 8314384.0000 - val_precision: 0.8913 - val_recall: 0.8155\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0708 - accuracy: 0.8861 - binary_iou: 0.7896 - true_positives: 111675448.0000 - false_positives: 17012134.0000 - true_negatives: 171463120.0000 - false_negatives: 19370032.0000 - precision: 0.8678 - recall: 0.8522 - val_loss: 0.0725 - val_accuracy: 0.8842 - val_binary_iou: 0.7874 - val_true_positives: 37718920.0000 - val_false_positives: 4882348.0000 - val_true_negatives: 55984972.0000 - val_false_negatives: 7385472.0000 - val_precision: 0.8854 - val_recall: 0.8363\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0706 - accuracy: 0.8864 - binary_iou: 0.7901 - true_positives: 112083648.0000 - false_positives: 17320000.0000 - true_negatives: 171126784.0000 - false_negatives: 18990262.0000 - precision: 0.8662 - recall: 0.8551 - val_loss: 0.0778 - val_accuracy: 0.8782 - val_binary_iou: 0.7759 - val_true_positives: 36081004.0000 - val_false_positives: 3847325.0000 - val_true_negatives: 56984628.0000 - val_false_negatives: 9058767.0000 - val_precision: 0.9036 - val_recall: 0.7993\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0708 - accuracy: 0.8855 - binary_iou: 0.7886 - true_positives: 111719080.0000 - false_positives: 17155256.0000 - true_negatives: 171213584.0000 - false_negatives: 19432856.0000 - precision: 0.8669 - recall: 0.8518 - val_loss: 0.0713 - val_accuracy: 0.8854 - val_binary_iou: 0.7898 - val_true_positives: 38198888.0000 - val_false_positives: 5231896.0000 - val_true_negatives: 55629572.0000 - val_false_negatives: 6911343.0000 - val_precision: 0.8795 - val_recall: 0.8468\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 437ms/step - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573 - val_loss: 0.0690 - val_accuracy: 0.8875 - val_binary_iou: 0.7944 - val_true_positives: 39463176.0000 - val_false_positives: 6336379.0000 - val_true_negatives: 54590884.0000 - val_false_negatives: 5581280.0000 - val_precision: 0.8616 - val_recall: 0.8761\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0696 - accuracy: 0.8883 - binary_iou: 0.7932 - true_positives: 112009744.0000 - false_positives: 16654082.0000 - true_negatives: 171826960.0000 - false_negatives: 19029884.0000 - precision: 0.8706 - recall: 0.8548 - val_loss: 0.0782 - val_accuracy: 0.8673 - val_binary_iou: 0.7644 - val_true_positives: 41361104.0000 - val_false_positives: 10324735.0000 - val_true_negatives: 50551800.0000 - val_false_negatives: 3734080.0000 - val_precision: 0.8002 - val_recall: 0.9172\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569 - val_loss: 0.0699 - val_accuracy: 0.8879 - val_binary_iou: 0.7946 - val_true_positives: 38986240.0000 - val_false_positives: 5839663.0000 - val_true_negatives: 55106392.0000 - val_false_negatives: 6039420.0000 - val_precision: 0.8697 - val_recall: 0.8659\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0682 - accuracy: 0.8907 - binary_iou: 0.7971 - true_positives: 112353240.0000 - false_positives: 16102053.0000 - true_negatives: 172235680.0000 - false_negatives: 18829746.0000 - precision: 0.8746 - recall: 0.8565 - val_loss: 0.0704 - val_accuracy: 0.8881 - val_binary_iou: 0.7939 - val_true_positives: 38109872.0000 - val_false_positives: 4901732.0000 - val_true_negatives: 55998932.0000 - val_false_negatives: 6961182.0000 - val_precision: 0.8860 - val_recall: 0.8456\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568 - val_loss: 0.0682 - val_accuracy: 0.8908 - val_binary_iou: 0.7980 - val_true_positives: 37943940.0000 - val_false_positives: 4332921.0000 - val_true_negatives: 56451604.0000 - val_false_negatives: 7243249.0000 - val_precision: 0.8975 - val_recall: 0.8397\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0678 - accuracy: 0.8911 - binary_iou: 0.7979 - true_positives: 112549024.0000 - false_positives: 16229167.0000 - true_negatives: 172190704.0000 - false_negatives: 18551880.0000 - precision: 0.8740 - recall: 0.8585 - val_loss: 0.0777 - val_accuracy: 0.8769 - val_binary_iou: 0.7724 - val_true_positives: 34971264.0000 - val_false_positives: 2822913.0000 - val_true_negatives: 57959224.0000 - val_false_negatives: 10218323.0000 - val_precision: 0.9253 - val_recall: 0.7739\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557 - val_loss: 0.0680 - val_accuracy: 0.8908 - val_binary_iou: 0.7986 - val_true_positives: 38459688.0000 - val_false_positives: 4965429.0000 - val_true_negatives: 55937692.0000 - val_false_negatives: 6608893.0000 - val_precision: 0.8857 - val_recall: 0.8534\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0672 - accuracy: 0.8924 - binary_iou: 0.8000 - true_positives: 112625344.0000 - false_positives: 15909708.0000 - true_negatives: 172527040.0000 - false_negatives: 18458692.0000 - precision: 0.8762 - recall: 0.8592 - val_loss: 0.0681 - val_accuracy: 0.8911 - val_binary_iou: 0.7985 - val_true_positives: 37945288.0000 - val_false_positives: 4341430.0000 - val_true_negatives: 56481624.0000 - val_false_negatives: 7203356.0000 - val_precision: 0.8973 - val_recall: 0.8405\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0670 - accuracy: 0.8926 - binary_iou: 0.8004 - true_positives: 112697608.0000 - false_positives: 15912619.0000 - true_negatives: 172519168.0000 - false_negatives: 18391396.0000 - precision: 0.8763 - recall: 0.8597 - val_loss: 0.0695 - val_accuracy: 0.8885 - val_binary_iou: 0.7942 - val_true_positives: 37790920.0000 - val_false_positives: 4531809.0000 - val_true_negatives: 56360128.0000 - val_false_negatives: 7288845.0000 - val_precision: 0.8929 - val_recall: 0.8383\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0677 - accuracy: 0.8915 - binary_iou: 0.7986 - true_positives: 112710072.0000 - false_positives: 16261744.0000 - true_negatives: 172151872.0000 - false_negatives: 18397136.0000 - precision: 0.8739 - recall: 0.8597 - val_loss: 0.0678 - val_accuracy: 0.8902 - val_binary_iou: 0.7985 - val_true_positives: 39367096.0000 - val_false_positives: 5935776.0000 - val_true_negatives: 54966212.0000 - val_false_negatives: 5702605.0000 - val_precision: 0.8690 - val_recall: 0.8735\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 438ms/step - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633 - val_loss: 0.0660 - val_accuracy: 0.8946 - val_binary_iou: 0.8052 - val_true_positives: 39001808.0000 - val_false_positives: 4980377.0000 - val_true_negatives: 55796588.0000 - val_false_negatives: 6192927.0000 - val_precision: 0.8868 - val_recall: 0.8630\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0664 - accuracy: 0.8936 - binary_iou: 0.8020 - true_positives: 112788272.0000 - false_positives: 15639641.0000 - true_negatives: 172750048.0000 - false_negatives: 18342840.0000 - precision: 0.8782 - recall: 0.8601 - val_loss: 0.0699 - val_accuracy: 0.8875 - val_binary_iou: 0.7919 - val_true_positives: 37142420.0000 - val_false_positives: 4069980.0000 - val_true_negatives: 56904784.0000 - val_false_negatives: 7854534.0000 - val_precision: 0.9012 - val_recall: 0.8254\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0655 - accuracy: 0.8950 - binary_iou: 0.8044 - true_positives: 113115328.0000 - false_positives: 15486498.0000 - true_negatives: 172855152.0000 - false_negatives: 18063804.0000 - precision: 0.8796 - recall: 0.8623 - val_loss: 0.0692 - val_accuracy: 0.8888 - val_binary_iou: 0.7959 - val_true_positives: 38962320.0000 - val_false_positives: 5677038.0000 - val_true_negatives: 55221624.0000 - val_false_negatives: 6110758.0000 - val_precision: 0.8728 - val_recall: 0.8644\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0651 - accuracy: 0.8960 - binary_iou: 0.8059 - true_positives: 113075528.0000 - false_positives: 15203770.0000 - true_negatives: 173212272.0000 - false_negatives: 18029176.0000 - precision: 0.8815 - recall: 0.8625 - val_loss: 0.0729 - val_accuracy: 0.8840 - val_binary_iou: 0.7863 - val_true_positives: 37080092.0000 - val_false_positives: 4269862.0000 - val_true_negatives: 56597916.0000 - val_false_negatives: 8023830.0000 - val_precision: 0.8967 - val_recall: 0.8221\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0648 - accuracy: 0.8961 - binary_iou: 0.8062 - true_positives: 113327736.0000 - false_positives: 15474886.0000 - true_negatives: 172995104.0000 - false_negatives: 17722972.0000 - precision: 0.8799 - recall: 0.8648 - val_loss: 0.0675 - val_accuracy: 0.8916 - val_binary_iou: 0.7997 - val_true_positives: 38295708.0000 - val_false_positives: 4763659.0000 - val_true_negatives: 56185512.0000 - val_false_negatives: 6726823.0000 - val_precision: 0.8894 - val_recall: 0.8506\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0644 - accuracy: 0.8971 - binary_iou: 0.8078 - true_positives: 113363456.0000 - false_positives: 15155710.0000 - true_negatives: 173270416.0000 - false_negatives: 17731144.0000 - precision: 0.8821 - recall: 0.8647 - val_loss: 0.0699 - val_accuracy: 0.8883 - val_binary_iou: 0.7926 - val_true_positives: 36737004.0000 - val_false_positives: 3459131.0000 - val_true_negatives: 57393536.0000 - val_false_negatives: 8382044.0000 - val_precision: 0.9139 - val_recall: 0.8142\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0649 - accuracy: 0.8960 - binary_iou: 0.8061 - true_positives: 113351536.0000 - false_positives: 15406054.0000 - true_negatives: 172946240.0000 - false_negatives: 17816920.0000 - precision: 0.8803 - recall: 0.8642 - val_loss: 0.0693 - val_accuracy: 0.8881 - val_binary_iou: 0.7931 - val_true_positives: 37406232.0000 - val_false_positives: 4189810.0000 - val_true_negatives: 56703164.0000 - val_false_negatives: 7672504.0000 - val_precision: 0.8993 - val_recall: 0.8298\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 439ms/step - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635 - val_loss: 0.0644 - val_accuracy: 0.8982 - val_binary_iou: 0.8115 - val_true_positives: 39367752.0000 - val_false_positives: 4995223.0000 - val_true_negatives: 55818860.0000 - val_false_negatives: 5789865.0000 - val_precision: 0.8874 - val_recall: 0.8718\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0637 - accuracy: 0.8982 - binary_iou: 0.8098 - true_positives: 113737680.0000 - false_positives: 15229448.0000 - true_negatives: 173259152.0000 - false_negatives: 17294578.0000 - precision: 0.8819 - recall: 0.8680 - val_loss: 0.0701 - val_accuracy: 0.8890 - val_binary_iou: 0.7959 - val_true_positives: 38609764.0000 - val_false_positives: 5199589.0000 - val_true_negatives: 55594380.0000 - val_false_negatives: 6567994.0000 - val_precision: 0.8813 - val_recall: 0.8546\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0643 - accuracy: 0.8975 - binary_iou: 0.8085 - true_positives: 113463744.0000 - false_positives: 15104503.0000 - true_negatives: 173302384.0000 - false_negatives: 17650162.0000 - precision: 0.8825 - recall: 0.8654 - val_loss: 0.0674 - val_accuracy: 0.8904 - val_binary_iou: 0.7991 - val_true_positives: 39483080.0000 - val_false_positives: 5960064.0000 - val_true_negatives: 54877108.0000 - val_false_negatives: 5651467.0000 - val_precision: 0.8688 - val_recall: 0.8748\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0637 - accuracy: 0.8983 - binary_iou: 0.8098 - true_positives: 113509408.0000 - false_positives: 14836776.0000 - true_negatives: 173506304.0000 - false_negatives: 17668256.0000 - precision: 0.8844 - recall: 0.8653 - val_loss: 0.0679 - val_accuracy: 0.8912 - val_binary_iou: 0.7994 - val_true_positives: 38486376.0000 - val_false_positives: 4910151.0000 - val_true_negatives: 55960840.0000 - val_false_negatives: 6614339.0000 - val_precision: 0.8869 - val_recall: 0.8533\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0631 - accuracy: 0.8992 - binary_iou: 0.8113 - true_positives: 113698048.0000 - false_positives: 14690406.0000 - true_negatives: 173600240.0000 - false_negatives: 17532068.0000 - precision: 0.8856 - recall: 0.8664 - val_loss: 0.0652 - val_accuracy: 0.8966 - val_binary_iou: 0.8095 - val_true_positives: 40043744.0000 - val_false_positives: 5826681.0000 - val_true_negatives: 54969080.0000 - val_false_negatives: 5132186.0000 - val_precision: 0.8730 - val_recall: 0.8864\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0637 - accuracy: 0.8980 - binary_iou: 0.8094 - true_positives: 113588616.0000 - false_positives: 14980239.0000 - true_negatives: 173351664.0000 - false_negatives: 17600292.0000 - precision: 0.8835 - recall: 0.8658 - val_loss: 0.0656 - val_accuracy: 0.8946 - val_binary_iou: 0.8057 - val_true_positives: 39386224.0000 - val_false_positives: 5345324.0000 - val_true_negatives: 55416720.0000 - val_false_negatives: 5823438.0000 - val_precision: 0.8805 - val_recall: 0.8712\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0632 - accuracy: 0.8994 - binary_iou: 0.8117 - true_positives: 113913360.0000 - false_positives: 14901580.0000 - true_negatives: 173453984.0000 - false_negatives: 17251912.0000 - precision: 0.8843 - recall: 0.8685 - val_loss: 0.0677 - val_accuracy: 0.8909 - val_binary_iou: 0.7967 - val_true_positives: 36674312.0000 - val_false_positives: 3143865.0000 - val_true_negatives: 57733296.0000 - val_false_negatives: 8420255.0000 - val_precision: 0.9210 - val_recall: 0.8133\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0628 - accuracy: 0.8998 - binary_iou: 0.8124 - true_positives: 113707192.0000 - false_positives: 14696928.0000 - true_negatives: 173804480.0000 - false_negatives: 17312232.0000 - precision: 0.8855 - recall: 0.8679 - val_loss: 0.0644 - val_accuracy: 0.8966 - val_binary_iou: 0.8081 - val_true_positives: 38568048.0000 - val_false_positives: 4499647.0000 - val_true_negatives: 56449208.0000 - val_false_negatives: 6454799.0000 - val_precision: 0.8955 - val_recall: 0.8566\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0629 - accuracy: 0.8991 - binary_iou: 0.8111 - true_positives: 113587144.0000 - false_positives: 14703208.0000 - true_negatives: 173683136.0000 - false_negatives: 17547360.0000 - precision: 0.8854 - recall: 0.8662 - val_loss: 0.0652 - val_accuracy: 0.8961 - val_binary_iou: 0.8068 - val_true_positives: 38103600.0000 - val_false_positives: 3996850.0000 - val_true_negatives: 56860540.0000 - val_false_negatives: 7010724.0000 - val_precision: 0.9051 - val_recall: 0.8446\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9011 - binary_iou: 0.8147 - true_positives: 114228344.0000 - false_positives: 14679725.0000 - true_negatives: 173688992.0000 - false_negatives: 16923826.0000 - precision: 0.8861 - recall: 0.8710 - val_loss: 0.0670 - val_accuracy: 0.8930 - val_binary_iou: 0.8033 - val_true_positives: 39714736.0000 - val_false_positives: 5934338.0000 - val_true_negatives: 54915616.0000 - val_false_negatives: 5407036.0000 - val_precision: 0.8700 - val_recall: 0.8802\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0620 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114160192.0000 - false_positives: 14541802.0000 - true_negatives: 173797200.0000 - false_negatives: 17021584.0000 - precision: 0.8870 - recall: 0.8702 - val_loss: 0.0660 - val_accuracy: 0.8971 - val_binary_iou: 0.8080 - val_true_positives: 37770996.0000 - val_false_positives: 3567448.0000 - val_true_negatives: 57291268.0000 - val_false_negatives: 7341999.0000 - val_precision: 0.9137 - val_recall: 0.8373\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0617 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114073448.0000 - false_positives: 14479113.0000 - true_negatives: 173890848.0000 - false_negatives: 17077416.0000 - precision: 0.8874 - recall: 0.8698 - val_loss: 0.0689 - val_accuracy: 0.8869 - val_binary_iou: 0.7917 - val_true_positives: 37728168.0000 - val_false_positives: 4620711.0000 - val_true_negatives: 56262276.0000 - val_false_negatives: 7360528.0000 - val_precision: 0.8909 - val_recall: 0.8368\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9012 - binary_iou: 0.8148 - true_positives: 114021800.0000 - false_positives: 14454801.0000 - true_negatives: 173942048.0000 - false_negatives: 17102218.0000 - precision: 0.8875 - recall: 0.8696 - val_loss: 0.0649 - val_accuracy: 0.8959 - val_binary_iou: 0.8076 - val_true_positives: 39236980.0000 - val_false_positives: 5234554.0000 - val_true_negatives: 55702736.0000 - val_false_negatives: 5797450.0000 - val_precision: 0.8823 - val_recall: 0.8713\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0616 - accuracy: 0.9018 - binary_iou: 0.8158 - true_positives: 114294520.0000 - false_positives: 14557606.0000 - true_negatives: 173837216.0000 - false_negatives: 16831460.0000 - precision: 0.8870 - recall: 0.8716 - val_loss: 0.0668 - val_accuracy: 0.8935 - val_binary_iou: 0.8021 - val_true_positives: 37644852.0000 - val_false_positives: 3729698.0000 - val_true_negatives: 57043988.0000 - val_false_negatives: 7553180.0000 - val_precision: 0.9099 - val_recall: 0.8329\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0610 - accuracy: 0.9025 - binary_iou: 0.8171 - true_positives: 114541624.0000 - false_positives: 14579440.0000 - true_negatives: 173826448.0000 - false_negatives: 16573294.0000 - precision: 0.8871 - recall: 0.8736 - val_loss: 0.0697 - val_accuracy: 0.8909 - val_binary_iou: 0.8004 - val_true_positives: 40092472.0000 - val_false_positives: 6589798.0000 - val_true_negatives: 54318728.0000 - val_false_negatives: 4970714.0000 - val_precision: 0.8588 - val_recall: 0.8897\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 436ms/step - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715 - val_loss: 0.0628 - val_accuracy: 0.8995 - val_binary_iou: 0.8142 - val_true_positives: 40126964.0000 - val_false_positives: 5757267.0000 - val_true_negatives: 55192272.0000 - val_false_negatives: 4895184.0000 - val_precision: 0.8745 - val_recall: 0.8913\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0604 - accuracy: 0.9035 - binary_iou: 0.8187 - true_positives: 114372352.0000 - false_positives: 14042377.0000 - true_negatives: 174325200.0000 - false_negatives: 16780868.0000 - precision: 0.8906 - recall: 0.8721 - val_loss: 0.0720 - val_accuracy: 0.8868 - val_binary_iou: 0.7945 - val_true_positives: 40941160.0000 - val_false_positives: 7836965.0000 - val_true_negatives: 53037104.0000 - val_false_negatives: 4156491.0000 - val_precision: 0.8393 - val_recall: 0.9078\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0598 - accuracy: 0.9050 - binary_iou: 0.8213 - true_positives: 114764616.0000 - false_positives: 13977922.0000 - true_negatives: 174412896.0000 - false_negatives: 16365363.0000 - precision: 0.8914 - recall: 0.8752 - val_loss: 0.0632 - val_accuracy: 0.8991 - val_binary_iou: 0.8121 - val_true_positives: 38543120.0000 - val_false_positives: 4116308.0000 - val_true_negatives: 56735084.0000 - val_false_negatives: 6577184.0000 - val_precision: 0.9035 - val_recall: 0.8542\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0602 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114492112.0000 - false_positives: 14097260.0000 - true_negatives: 174293072.0000 - false_negatives: 16638253.0000 - precision: 0.8904 - recall: 0.8731 - val_loss: 0.0649 - val_accuracy: 0.8957 - val_binary_iou: 0.8085 - val_true_positives: 40805296.0000 - val_false_positives: 6699145.0000 - val_true_negatives: 54108424.0000 - val_false_negatives: 4358863.0000 - val_precision: 0.8590 - val_recall: 0.9035\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0605 - accuracy: 0.9037 - binary_iou: 0.8190 - true_positives: 114271792.0000 - false_positives: 13944031.0000 - true_negatives: 174493456.0000 - false_negatives: 16811372.0000 - precision: 0.8912 - recall: 0.8718 - val_loss: 0.0673 - val_accuracy: 0.8897 - val_binary_iou: 0.7995 - val_true_positives: 41579912.0000 - val_false_positives: 8194420.0000 - val_true_negatives: 52699744.0000 - val_false_negatives: 3497623.0000 - val_precision: 0.8354 - val_recall: 0.9224\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0606 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114383448.0000 - false_positives: 13910560.0000 - true_negatives: 174400160.0000 - false_negatives: 16826680.0000 - precision: 0.8916 - recall: 0.8718 - val_loss: 0.0766 - val_accuracy: 0.8862 - val_binary_iou: 0.7928 - val_true_positives: 40028572.0000 - val_false_positives: 7006960.0000 - val_true_negatives: 53881560.0000 - val_false_negatives: 5054641.0000 - val_precision: 0.8510 - val_recall: 0.8879\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739 - val_loss: 0.0630 - val_accuracy: 0.9009 - val_binary_iou: 0.8159 - val_true_positives: 39473896.0000 - val_false_positives: 4852153.0000 - val_true_negatives: 55992092.0000 - val_false_negatives: 5653550.0000 - val_precision: 0.8905 - val_recall: 0.8747\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0598 - accuracy: 0.9053 - binary_iou: 0.8217 - true_positives: 114655032.0000 - false_positives: 13736962.0000 - true_negatives: 174595376.0000 - false_negatives: 16533304.0000 - precision: 0.8930 - recall: 0.8740 - val_loss: 0.0671 - val_accuracy: 0.8912 - val_binary_iou: 0.7983 - val_true_positives: 37558328.0000 - val_false_positives: 3884693.0000 - val_true_negatives: 56883664.0000 - val_false_negatives: 7645055.0000 - val_precision: 0.9063 - val_recall: 0.8309\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750 - val_loss: 0.0613 - val_accuracy: 0.9038 - val_binary_iou: 0.8209 - val_true_positives: 39589588.0000 - val_false_positives: 4649140.0000 - val_true_negatives: 56191696.0000 - val_false_negatives: 5541295.0000 - val_precision: 0.8949 - val_recall: 0.8772\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9066 - binary_iou: 0.8240 - true_positives: 114924592.0000 - false_positives: 13616651.0000 - true_negatives: 174744976.0000 - false_negatives: 16234598.0000 - precision: 0.8941 - recall: 0.8762 - val_loss: 0.0657 - val_accuracy: 0.8950 - val_binary_iou: 0.8070 - val_true_positives: 40115272.0000 - val_false_positives: 6156170.0000 - val_true_negatives: 54733744.0000 - val_false_negatives: 4966526.0000 - val_precision: 0.8670 - val_recall: 0.8898\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0590 - accuracy: 0.9069 - binary_iou: 0.8244 - true_positives: 114822896.0000 - false_positives: 13371130.0000 - true_negatives: 174937648.0000 - false_negatives: 16389186.0000 - precision: 0.8957 - recall: 0.8751 - val_loss: 0.0643 - val_accuracy: 0.8999 - val_binary_iou: 0.8143 - val_true_positives: 39385200.0000 - val_false_positives: 4859034.0000 - val_true_negatives: 55981228.0000 - val_false_negatives: 5746234.0000 - val_precision: 0.8902 - val_recall: 0.8727\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0592 - accuracy: 0.9064 - binary_iou: 0.8238 - true_positives: 115060424.0000 - false_positives: 13745673.0000 - true_negatives: 174567392.0000 - false_negatives: 16147346.0000 - precision: 0.8933 - recall: 0.8769 - val_loss: 0.0611 - val_accuracy: 0.9035 - val_binary_iou: 0.8204 - val_true_positives: 39653136.0000 - val_false_positives: 4728918.0000 - val_true_negatives: 56094144.0000 - val_false_negatives: 5495510.0000 - val_precision: 0.8934 - val_recall: 0.8783\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9059 - binary_iou: 0.8228 - true_positives: 114785464.0000 - false_positives: 13761449.0000 - true_negatives: 174670400.0000 - false_negatives: 16303439.0000 - precision: 0.8929 - recall: 0.8756 - val_loss: 0.0693 - val_accuracy: 0.8904 - val_binary_iou: 0.7999 - val_true_positives: 40398372.0000 - val_false_positives: 6853430.0000 - val_true_negatives: 53963436.0000 - val_false_negatives: 4756454.0000 - val_precision: 0.8550 - val_recall: 0.8947\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0584 - accuracy: 0.9071 - binary_iou: 0.8249 - true_positives: 115098648.0000 - false_positives: 13609404.0000 - true_negatives: 174737072.0000 - false_negatives: 16075616.0000 - precision: 0.8943 - recall: 0.8774 - val_loss: 0.0620 - val_accuracy: 0.9023 - val_binary_iou: 0.8191 - val_true_positives: 40398948.0000 - val_false_positives: 5691739.0000 - val_true_negatives: 55220200.0000 - val_false_negatives: 4660829.0000 - val_precision: 0.8765 - val_recall: 0.8966\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0580 - accuracy: 0.9078 - binary_iou: 0.8260 - true_positives: 115041896.0000 - false_positives: 13368177.0000 - true_negatives: 175011792.0000 - false_negatives: 16098864.0000 - precision: 0.8959 - recall: 0.8772 - val_loss: 0.0618 - val_accuracy: 0.9024 - val_binary_iou: 0.8176 - val_true_positives: 38695004.0000 - val_false_positives: 3913730.0000 - val_true_negatives: 56928672.0000 - val_false_negatives: 6434295.0000 - val_precision: 0.9081 - val_recall: 0.8574\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0586 - accuracy: 0.9073 - binary_iou: 0.8253 - true_positives: 115108880.0000 - false_positives: 13592248.0000 - true_negatives: 174804848.0000 - false_negatives: 16014808.0000 - precision: 0.8944 - recall: 0.8779 - val_loss: 0.0632 - val_accuracy: 0.9009 - val_binary_iou: 0.8162 - val_true_positives: 39746444.0000 - val_false_positives: 5064269.0000 - val_true_negatives: 55720692.0000 - val_false_negatives: 5440308.0000 - val_precision: 0.8870 - val_recall: 0.8796\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783 - val_loss: 0.0609 - val_accuracy: 0.9045 - val_binary_iou: 0.8220 - val_true_positives: 39622044.0000 - val_false_positives: 4580523.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 5541544.0000 - val_precision: 0.8964 - val_recall: 0.8773\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0579 - accuracy: 0.9080 - binary_iou: 0.8265 - true_positives: 115247800.0000 - false_positives: 13446067.0000 - true_negatives: 174880816.0000 - false_negatives: 15946018.0000 - precision: 0.8955 - recall: 0.8785 - val_loss: 0.0743 - val_accuracy: 0.8851 - val_binary_iou: 0.7913 - val_true_positives: 40276164.0000 - val_false_positives: 7452888.0000 - val_true_negatives: 53520128.0000 - val_false_negatives: 4722535.0000 - val_precision: 0.8439 - val_recall: 0.8951\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0573 - accuracy: 0.9089 - binary_iou: 0.8280 - true_positives: 115350232.0000 - false_positives: 13306295.0000 - true_negatives: 175061568.0000 - false_negatives: 15802560.0000 - precision: 0.8966 - recall: 0.8795 - val_loss: 0.0687 - val_accuracy: 0.8928 - val_binary_iou: 0.8045 - val_true_positives: 41609304.0000 - val_false_positives: 7912378.0000 - val_true_negatives: 52998040.0000 - val_false_negatives: 3452000.0000 - val_precision: 0.8402 - val_recall: 0.9234\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0570 - accuracy: 0.9097 - binary_iou: 0.8295 - true_positives: 115566680.0000 - false_positives: 13204775.0000 - true_negatives: 175116896.0000 - false_negatives: 15632293.0000 - precision: 0.8975 - recall: 0.8809 - val_loss: 0.0618 - val_accuracy: 0.9033 - val_binary_iou: 0.8206 - val_true_positives: 40212672.0000 - val_false_positives: 5331110.0000 - val_true_negatives: 55514868.0000 - val_false_negatives: 4913069.0000 - val_precision: 0.8829 - val_recall: 0.8911\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0574 - accuracy: 0.9091 - binary_iou: 0.8283 - true_positives: 115335368.0000 - false_positives: 13241246.0000 - true_negatives: 175149360.0000 - false_negatives: 15794777.0000 - precision: 0.8970 - recall: 0.8795 - val_loss: 0.0619 - val_accuracy: 0.9025 - val_binary_iou: 0.8185 - val_true_positives: 39427960.0000 - val_false_positives: 4689384.0000 - val_true_negatives: 56207648.0000 - val_false_negatives: 5646732.0000 - val_precision: 0.8937 - val_recall: 0.8747\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0572 - accuracy: 0.9092 - binary_iou: 0.8284 - true_positives: 115450496.0000 - false_positives: 13292661.0000 - true_negatives: 175043360.0000 - false_negatives: 15734289.0000 - precision: 0.8968 - recall: 0.8801 - val_loss: 0.0653 - val_accuracy: 0.8978 - val_binary_iou: 0.8097 - val_true_positives: 38248656.0000 - val_false_positives: 3970812.0000 - val_true_negatives: 56891840.0000 - val_false_negatives: 6860412.0000 - val_precision: 0.9059 - val_recall: 0.8479\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0576 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115059888.0000 - false_positives: 13279338.0000 - true_negatives: 175221456.0000 - false_negatives: 15960160.0000 - precision: 0.8965 - recall: 0.8782 - val_loss: 0.0621 - val_accuracy: 0.9005 - val_binary_iou: 0.8159 - val_true_positives: 40226056.0000 - val_false_positives: 5739225.0000 - val_true_negatives: 55198836.0000 - val_false_negatives: 4807608.0000 - val_precision: 0.8751 - val_recall: 0.8932\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0567 - accuracy: 0.9100 - binary_iou: 0.8299 - true_positives: 115410632.0000 - false_positives: 13091224.0000 - true_negatives: 175366784.0000 - false_negatives: 15652111.0000 - precision: 0.8981 - recall: 0.8806 - val_loss: 0.0648 - val_accuracy: 0.8976 - val_binary_iou: 0.8096 - val_true_positives: 38385240.0000 - val_false_positives: 4143129.0000 - val_true_negatives: 56738792.0000 - val_false_negatives: 6704553.0000 - val_precision: 0.9026 - val_recall: 0.8513\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0569 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115559664.0000 - false_positives: 13187510.0000 - true_negatives: 175197328.0000 - false_negatives: 15576244.0000 - precision: 0.8976 - recall: 0.8812 - val_loss: 0.0616 - val_accuracy: 0.9021 - val_binary_iou: 0.8190 - val_true_positives: 40675596.0000 - val_false_positives: 5981493.0000 - val_true_negatives: 54921920.0000 - val_false_negatives: 4392702.0000 - val_precision: 0.8718 - val_recall: 0.9025\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817 - val_loss: 0.0604 - val_accuracy: 0.9043 - val_binary_iou: 0.8220 - val_true_positives: 40136756.0000 - val_false_positives: 5091398.0000 - val_true_negatives: 55688312.0000 - val_false_negatives: 5055239.0000 - val_precision: 0.8874 - val_recall: 0.8881\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0565 - accuracy: 0.9104 - binary_iou: 0.8305 - true_positives: 115524848.0000 - false_positives: 13007364.0000 - true_negatives: 175357504.0000 - false_negatives: 15631114.0000 - precision: 0.8988 - recall: 0.8808 - val_loss: 0.0637 - val_accuracy: 0.8973 - val_binary_iou: 0.8116 - val_true_positives: 41283940.0000 - val_false_positives: 7066725.0000 - val_true_negatives: 53805696.0000 - val_false_negatives: 3815342.0000 - val_precision: 0.8538 - val_recall: 0.9154\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0566 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115418920.0000 - false_positives: 13103144.0000 - true_negatives: 175337664.0000 - false_negatives: 15661151.0000 - precision: 0.8980 - recall: 0.8805 - val_loss: 0.0685 - val_accuracy: 0.8931 - val_binary_iou: 0.8000 - val_true_positives: 36465344.0000 - val_false_positives: 2706221.0000 - val_true_negatives: 58180776.0000 - val_false_negatives: 8619357.0000 - val_precision: 0.9309 - val_recall: 0.8088\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830 - val_loss: 0.0591 - val_accuracy: 0.9071 - val_binary_iou: 0.8267 - val_true_positives: 40077468.0000 - val_false_positives: 4810660.0000 - val_true_negatives: 56051568.0000 - val_false_negatives: 5032024.0000 - val_precision: 0.8928 - val_recall: 0.8884\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0561 - accuracy: 0.9108 - binary_iou: 0.8312 - true_positives: 115485504.0000 - false_positives: 12872387.0000 - true_negatives: 175535872.0000 - false_negatives: 15627070.0000 - precision: 0.8997 - recall: 0.8808 - val_loss: 0.0686 - val_accuracy: 0.8930 - val_binary_iou: 0.8049 - val_true_positives: 41539792.0000 - val_false_positives: 7744004.0000 - val_true_negatives: 53097324.0000 - val_false_negatives: 3590584.0000 - val_precision: 0.8429 - val_recall: 0.9204\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0560 - accuracy: 0.9111 - binary_iou: 0.8318 - true_positives: 115753184.0000 - false_positives: 13009851.0000 - true_negatives: 175361808.0000 - false_negatives: 15395915.0000 - precision: 0.8990 - recall: 0.8826 - val_loss: 0.0621 - val_accuracy: 0.9018 - val_binary_iou: 0.8154 - val_true_positives: 37469948.0000 - val_false_positives: 2734699.0000 - val_true_negatives: 58100136.0000 - val_false_negatives: 7666928.0000 - val_precision: 0.9320 - val_recall: 0.8301\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0557 - accuracy: 0.9119 - binary_iou: 0.8331 - true_positives: 115764048.0000 - false_positives: 12780396.0000 - true_negatives: 175605136.0000 - false_negatives: 15371262.0000 - precision: 0.9006 - recall: 0.8828 - val_loss: 0.0607 - val_accuracy: 0.9049 - val_binary_iou: 0.8227 - val_true_positives: 39667376.0000 - val_false_positives: 4631294.0000 - val_true_negatives: 56222816.0000 - val_false_negatives: 5450231.0000 - val_precision: 0.8955 - val_recall: 0.8792\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0556 - accuracy: 0.9117 - binary_iou: 0.8328 - true_positives: 115600880.0000 - false_positives: 12729907.0000 - true_negatives: 175719568.0000 - false_negatives: 15470327.0000 - precision: 0.9008 - recall: 0.8820 - val_loss: 0.0629 - val_accuracy: 0.8997 - val_binary_iou: 0.8149 - val_true_positives: 40599992.0000 - val_false_positives: 6119560.0000 - val_true_negatives: 54737740.0000 - val_false_negatives: 4514413.0000 - val_precision: 0.8690 - val_recall: 0.8999\n",
      "132/132 [==============================] - 20s 121ms/step - loss: 224.4008 - accuracy: 0.9036 - binary_iou: 0.8199 - true_positives: 38915348.0000 - false_positives: 4943305.0000 - true_negatives: 56841440.0000 - false_negatives: 5271624.0000 - precision: 0.8873 - recall: 0.8807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Durch RegEx kann aus den Layernamen der Index der Convolutional-Layer entnommen werden und diese dann nacheinander eingefroren werden\n",
    "\n",
    "conv_layers = [4, 7, 11, 15, 18, 22, 26, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 64, 68, 72, 75, 79, 83, 86, 90, 94, 95, 98, 102, 106, 110, 114, 118,\n",
    " 121, 125, 129, 132, 136, 140, 141, 144, 148, 152, 156, 160, 164, 167, 171, 175, 176, 179, 183, 190]\n",
    "\n",
    "import gc\n",
    "\n",
    "for number in conv_layers:      \n",
    "\n",
    "    training_split = 0.6\n",
    "\n",
    "    pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "    conf = {\n",
    "        'AVG': 'BN',\n",
    "        'RNDM': 'BN',\n",
    "        'EXTRA_CONV': 'CONV',\n",
    "        'RGB_SPLIT': 'SPLIT'\n",
    "        } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "    lr = 0.001 # Learning rate\n",
    "\n",
    "    rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "    ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "    l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "    l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "    #freeze = True # Trainierbarkeit des Encoders\n",
    "    freeze_from = 'input' # Ab diesem layer wird eingefroren, EXKLUSIVE (wird überschrieben bei SPLIT-Variante)!\n",
    "    train_encoder_layers = number # Anzahl an Layern (int) im Encoder, die trainiert werden. Rückwärts gezählt ab Bottleneck\n",
    "    #freeze_what = 'No1ConvBN' # Beschreibung ob 1. Layer eingefroren oder nicht\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    patch_size = 224 # Maße des inputs\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "\n",
    "    unet = load_model(conf[pretrained_weights])\n",
    "    set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "    set_weight_decay(unet, l1= l1, l2= l2)\n",
    "    set_pretrained_weights(unet, pretrained_weights)\n",
    "    set_encoder_frozen(unet, pretrained_weights, freeze_from= freeze_from, train_encoder_layers= train_encoder_layers)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "\n",
    "    loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "    model_name = f'FT_test_AVG_no_of_frozen_layers_{number}'\n",
    "\n",
    "    checkpoint_path = f'../saved_model_FT_test/{model_name}_e{str(epochs)}'\n",
    "    logger_path = f'../saved_history_FT_test/{model_name}_e{str(epochs)}.log'\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path)\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "\n",
    "\n",
    "    train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/masks'\n",
    "    )\n",
    "\n",
    "    val_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = True,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/masks'\n",
    "    )\n",
    "\n",
    "    test_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = False,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/masks'\n",
    "    )\n",
    "\n",
    "    model_history = unet.fit(train_data_generator, validation_data=val_data_generator, callbacks= [checkpoint_callback, history_logger], epochs=epochs)\n",
    "\n",
    "\n",
    "    # laden des besten models\n",
    "    unet = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "    # Evaluieren & Ergebnisse in Tabelle\n",
    "    eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "    with open('../results/FT_test_eval_output.csv', 'a') as f_object:\n",
    "        row = []\n",
    "        \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)\n",
    "\n",
    "        writer_object = csv.writer(f_object)\n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "    del unet\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob trainable oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfigurationen, Laden & Kompilieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BN',\n",
    "    'RNDM': 'BN',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0.2 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 480\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "model_name = f'Final_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}_e{initial_epochs + fine_tune_epochs}'\n",
    "\n",
    "# Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren der Data Generator & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.7867 - binary_iou: 0.6463 - true_positives: 111043808.0000 - false_positives: 48262192.0000 - true_negatives: 140314272.0000 - false_negatives: 19900488.0000 - precision: 0.6970 - recall: 0.8480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 456ms/step - loss: 0.2530 - accuracy: 0.7867 - binary_iou: 0.6463 - true_positives: 111043808.0000 - false_positives: 48262192.0000 - true_negatives: 140314272.0000 - false_negatives: 19900488.0000 - precision: 0.6970 - recall: 0.8480 - val_loss: 0.2177 - val_accuracy: 0.8243 - val_binary_iou: 0.6967 - val_true_positives: 36183816.0000 - val_false_positives: 9768367.0000 - val_true_negatives: 51167764.0000 - val_false_negatives: 8851754.0000 - val_precision: 0.7874 - val_recall: 0.8034\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.8503 - binary_iou: 0.7348 - true_positives: 111206328.0000 - false_positives: 27865604.0000 - true_negatives: 160480896.0000 - false_negatives: 19967952.0000 - precision: 0.7996 - recall: 0.8478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1797 - accuracy: 0.8503 - binary_iou: 0.7348 - true_positives: 111206328.0000 - false_positives: 27865604.0000 - true_negatives: 160480896.0000 - false_negatives: 19967952.0000 - precision: 0.7996 - recall: 0.8478 - val_loss: 0.1768 - val_accuracy: 0.8498 - val_binary_iou: 0.7353 - val_true_positives: 37936588.0000 - val_false_positives: 8678695.0000 - val_true_negatives: 52119008.0000 - val_false_negatives: 7237421.0000 - val_precision: 0.8138 - val_recall: 0.8398\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.1694 - accuracy: 0.8586 - binary_iou: 0.7476 - true_positives: 112447392.0000 - false_positives: 26535964.0000 - true_negatives: 161898704.0000 - false_negatives: 18638656.0000 - precision: 0.8091 - recall: 0.8578 - val_loss: 0.1696 - val_accuracy: 0.8434 - val_binary_iou: 0.7284 - val_true_positives: 41406300.0000 - val_false_positives: 12919748.0000 - val_true_negatives: 47966524.0000 - val_false_negatives: 3679141.0000 - val_precision: 0.7622 - val_recall: 0.9184\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.1594 - accuracy: 0.8676 - binary_iou: 0.7614 - true_positives: 112991728.0000 - false_positives: 24180304.0000 - true_negatives: 164223536.0000 - false_negatives: 18125208.0000 - precision: 0.8237 - recall: 0.8618 - val_loss: 0.1808 - val_accuracy: 0.8288 - val_binary_iou: 0.7072 - val_true_positives: 41683936.0000 - val_false_positives: 14784452.0000 - val_true_negatives: 46140320.0000 - val_false_negatives: 3362991.0000 - val_precision: 0.7382 - val_recall: 0.9253\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1539 - accuracy: 0.8730 - binary_iou: 0.7697 - true_positives: 113235904.0000 - false_positives: 22661028.0000 - true_negatives: 165692640.0000 - false_negatives: 17931140.0000 - precision: 0.8332 - recall: 0.8633 - val_loss: 0.2072 - val_accuracy: 0.8288 - val_binary_iou: 0.7017 - val_true_positives: 35156024.0000 - val_false_positives: 8233098.0000 - val_true_negatives: 52669072.0000 - val_false_negatives: 9913514.0000 - val_precision: 0.8102 - val_recall: 0.7800\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.1473 - accuracy: 0.8784 - binary_iou: 0.7784 - true_positives: 114011392.0000 - false_positives: 21770962.0000 - true_negatives: 166660272.0000 - false_negatives: 17078148.0000 - precision: 0.8397 - recall: 0.8697 - val_loss: 0.1675 - val_accuracy: 0.8437 - val_binary_iou: 0.7290 - val_true_positives: 41680636.0000 - val_false_positives: 13103984.0000 - val_true_negatives: 47724816.0000 - val_false_negatives: 3462292.0000 - val_precision: 0.7608 - val_recall: 0.9233\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.8811 - binary_iou: 0.7827 - true_positives: 114393776.0000 - false_positives: 21271064.0000 - true_negatives: 167122240.0000 - false_negatives: 16733604.0000 - precision: 0.8432 - recall: 0.8724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 445ms/step - loss: 0.1440 - accuracy: 0.8811 - binary_iou: 0.7827 - true_positives: 114393776.0000 - false_positives: 21271064.0000 - true_negatives: 167122240.0000 - false_negatives: 16733604.0000 - precision: 0.8432 - recall: 0.8724 - val_loss: 0.1669 - val_accuracy: 0.8602 - val_binary_iou: 0.7505 - val_true_positives: 37713636.0000 - val_false_positives: 7516429.0000 - val_true_negatives: 53444012.0000 - val_false_negatives: 7297637.0000 - val_precision: 0.8338 - val_recall: 0.8379\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.8849 - binary_iou: 0.7889 - true_positives: 114999336.0000 - false_positives: 20679376.0000 - true_negatives: 167741888.0000 - false_negatives: 16100101.0000 - precision: 0.8476 - recall: 0.8772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1397 - accuracy: 0.8849 - binary_iou: 0.7889 - true_positives: 114999336.0000 - false_positives: 20679376.0000 - true_negatives: 167741888.0000 - false_negatives: 16100101.0000 - precision: 0.8476 - recall: 0.8772 - val_loss: 0.1354 - val_accuracy: 0.8824 - val_binary_iou: 0.7870 - val_true_positives: 40299460.0000 - val_false_positives: 7671211.0000 - val_true_negatives: 53208184.0000 - val_false_negatives: 4792872.0000 - val_precision: 0.8401 - val_recall: 0.8937\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1353 - accuracy: 0.8892 - binary_iou: 0.7957 - true_positives: 114638944.0000 - false_positives: 18970384.0000 - true_negatives: 169485760.0000 - false_negatives: 16425623.0000 - precision: 0.8580 - recall: 0.8747 - val_loss: 0.1569 - val_accuracy: 0.8584 - val_binary_iou: 0.7505 - val_true_positives: 40856560.0000 - val_false_positives: 10655894.0000 - val_true_negatives: 50110464.0000 - val_false_negatives: 4348781.0000 - val_precision: 0.7931 - val_recall: 0.9038\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - 74s 374ms/step - loss: 0.1294 - accuracy: 0.8938 - binary_iou: 0.8034 - true_positives: 115608840.0000 - false_positives: 18361112.0000 - true_negatives: 169984368.0000 - false_negatives: 15566396.0000 - precision: 0.8629 - recall: 0.8813 - val_loss: 0.2568 - val_accuracy: 0.8132 - val_binary_iou: 0.6693 - val_true_positives: 29273444.0000 - val_false_positives: 3966531.0000 - val_true_negatives: 56906144.0000 - val_false_negatives: 15825595.0000 - val_precision: 0.8807 - val_recall: 0.6491\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.8953 - binary_iou: 0.8057 - true_positives: 115722160.0000 - false_positives: 18096608.0000 - true_negatives: 170331008.0000 - false_negatives: 15370898.0000 - precision: 0.8648 - recall: 0.8827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 440ms/step - loss: 0.1278 - accuracy: 0.8953 - binary_iou: 0.8057 - true_positives: 115722160.0000 - false_positives: 18096608.0000 - true_negatives: 170331008.0000 - false_negatives: 15370898.0000 - precision: 0.8648 - recall: 0.8827 - val_loss: 0.1322 - val_accuracy: 0.8918 - val_binary_iou: 0.8000 - val_true_positives: 38216200.0000 - val_false_positives: 4436075.0000 - val_true_negatives: 56287440.0000 - val_false_negatives: 7032006.0000 - val_precision: 0.8960 - val_recall: 0.8446\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.1234 - accuracy: 0.8995 - binary_iou: 0.8127 - true_positives: 115993240.0000 - false_positives: 17039420.0000 - true_negatives: 171406992.0000 - false_negatives: 15081117.0000 - precision: 0.8719 - recall: 0.8849 - val_loss: 0.1386 - val_accuracy: 0.8799 - val_binary_iou: 0.7831 - val_true_positives: 40182664.0000 - val_false_positives: 7800029.0000 - val_true_negatives: 53065372.0000 - val_false_negatives: 4923645.0000 - val_precision: 0.8374 - val_recall: 0.8908\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1213 - accuracy: 0.9009 - binary_iou: 0.8152 - true_positives: 116559416.0000 - false_positives: 17118276.0000 - true_negatives: 171295424.0000 - false_negatives: 14547673.0000 - precision: 0.8719 - recall: 0.8890 - val_loss: 0.1421 - val_accuracy: 0.8746 - val_binary_iou: 0.7751 - val_true_positives: 40642440.0000 - val_false_positives: 8783600.0000 - val_true_negatives: 52038120.0000 - val_false_negatives: 4507543.0000 - val_precision: 0.8223 - val_recall: 0.9002\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.1194 - accuracy: 0.9026 - binary_iou: 0.8180 - true_positives: 116646776.0000 - false_positives: 16637965.0000 - true_negatives: 171761392.0000 - false_negatives: 14474606.0000 - precision: 0.8752 - recall: 0.8896 - val_loss: 0.1696 - val_accuracy: 0.8451 - val_binary_iou: 0.7305 - val_true_positives: 40641952.0000 - val_false_positives: 11934879.0000 - val_true_negatives: 48911596.0000 - val_false_negatives: 4483273.0000 - val_precision: 0.7730 - val_recall: 0.9006\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.1175 - accuracy: 0.9040 - binary_iou: 0.8203 - true_positives: 116874728.0000 - false_positives: 16479334.0000 - true_negatives: 171966000.0000 - false_negatives: 14200654.0000 - precision: 0.8764 - recall: 0.8917 - val_loss: 0.1644 - val_accuracy: 0.8605 - val_binary_iou: 0.7515 - val_true_positives: 38347908.0000 - val_false_positives: 7986545.0000 - val_true_negatives: 52835852.0000 - val_false_negatives: 6801397.0000 - val_precision: 0.8276 - val_recall: 0.8494\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1130 - accuracy: 0.9078 - binary_iou: 0.8267 - true_positives: 117159816.0000 - false_positives: 15511851.0000 - true_negatives: 172892432.0000 - false_negatives: 13956604.0000 - precision: 0.8831 - recall: 0.8936 - val_loss: 0.1774 - val_accuracy: 0.8445 - val_binary_iou: 0.7282 - val_true_positives: 38698016.0000 - val_false_positives: 10038660.0000 - val_true_negatives: 50796784.0000 - val_false_negatives: 6438257.0000 - val_precision: 0.7940 - val_recall: 0.8574\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.1116 - accuracy: 0.9088 - binary_iou: 0.8285 - true_positives: 117442272.0000 - false_positives: 15450539.0000 - true_negatives: 172932256.0000 - false_negatives: 13695691.0000 - precision: 0.8837 - recall: 0.8956 - val_loss: 0.2216 - val_accuracy: 0.8261 - val_binary_iou: 0.6940 - val_true_positives: 32733368.0000 - val_false_positives: 6001649.0000 - val_true_negatives: 54806864.0000 - val_false_negatives: 12429828.0000 - val_precision: 0.8451 - val_recall: 0.7248\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.1107 - accuracy: 0.9101 - binary_iou: 0.8306 - true_positives: 117300144.0000 - false_positives: 14963131.0000 - true_negatives: 173498800.0000 - false_negatives: 13758712.0000 - precision: 0.8869 - recall: 0.8950 - val_loss: 0.1296 - val_accuracy: 0.8889 - val_binary_iou: 0.7970 - val_true_positives: 39977888.0000 - val_false_positives: 6724283.0000 - val_true_negatives: 54215616.0000 - val_false_negatives: 5053912.0000 - val_precision: 0.8560 - val_recall: 0.8878\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1106 - accuracy: 0.9099 - binary_iou: 0.8304 - true_positives: 117366416.0000 - false_positives: 14966230.0000 - true_negatives: 173373680.0000 - false_negatives: 13814412.0000 - precision: 0.8869 - recall: 0.8947 - val_loss: 0.1267 - val_accuracy: 0.8892 - val_binary_iou: 0.7985 - val_true_positives: 41107320.0000 - val_false_positives: 7720637.0000 - val_true_negatives: 53125932.0000 - val_false_negatives: 4017818.0000 - val_precision: 0.8419 - val_recall: 0.9110\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1068 - accuracy: 0.9130 - binary_iou: 0.8357 - true_positives: 117830272.0000 - false_positives: 14455578.0000 - true_negatives: 173900384.0000 - false_negatives: 13334564.0000 - precision: 0.8907 - recall: 0.8983 - val_loss: 0.1551 - val_accuracy: 0.8592 - val_binary_iou: 0.7518 - val_true_positives: 41172792.0000 - val_false_positives: 10981330.0000 - val_true_negatives: 49874412.0000 - val_false_negatives: 3943181.0000 - val_precision: 0.7894 - val_recall: 0.9126\n",
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 2 trainable: True\n",
      "170 conv5_block1_3_conv trainable weights: 2 trainable: True\n",
      "171 conv5_block1_out trainable weights: 0 trainable: True\n",
      "172 conv5_block2_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: True\n",
      "174 conv5_block2_1_conv trainable weights: 1 trainable: True\n",
      "175 conv5_block2_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: True\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: True\n",
      "178 conv5_block2_2_conv trainable weights: 1 trainable: True\n",
      "179 conv5_block2_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: True\n",
      "181 conv5_block2_3_conv trainable weights: 2 trainable: True\n",
      "182 conv5_block2_out trainable weights: 0 trainable: True\n",
      "183 conv5_block3_preact_bn trainable weights: 2  trainable:  True  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: True\n",
      "185 conv5_block3_1_conv trainable weights: 1 trainable: True\n",
      "186 conv5_block3_1_bn trainable weights: 2  trainable:  True  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: True\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: True\n",
      "189 conv5_block3_2_conv trainable weights: 1 trainable: True\n",
      "190 conv5_block3_2_bn trainable weights: 2  trainable:  True  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: True\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2  trainable:  True  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 20/300\n",
      "199/199 [==============================] - 80s 385ms/step - loss: 0.1102 - accuracy: 0.9102 - binary_iou: 0.8308 - true_positives: 117355328.0000 - false_positives: 14923478.0000 - true_negatives: 173467456.0000 - false_negatives: 13774491.0000 - precision: 0.8872 - recall: 0.8950 - val_loss: 0.1533 - val_accuracy: 0.8685 - val_binary_iou: 0.7644 - val_true_positives: 39136048.0000 - val_false_positives: 7995532.0000 - val_true_negatives: 52895400.0000 - val_false_negatives: 5944726.0000 - val_precision: 0.8304 - val_recall: 0.8681\n",
      "Epoch 21/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0998 - accuracy: 0.9188 - binary_iou: 0.8458 - true_positives: 118692888.0000 - false_positives: 13476758.0000 - true_negatives: 174894880.0000 - false_negatives: 12456214.0000 - precision: 0.8980 - recall: 0.9050 - val_loss: 0.1647 - val_accuracy: 0.8560 - val_binary_iou: 0.7457 - val_true_positives: 39241244.0000 - val_false_positives: 9388413.0000 - val_true_negatives: 51472936.0000 - val_false_negatives: 5869113.0000 - val_precision: 0.8069 - val_recall: 0.8699\n",
      "Epoch 22/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0935 - accuracy: 0.9244 - binary_iou: 0.8554 - true_positives: 119276576.0000 - false_positives: 12346751.0000 - true_negatives: 176073328.0000 - false_negatives: 11824045.0000 - precision: 0.9062 - recall: 0.9098 - val_loss: 0.1584 - val_accuracy: 0.8642 - val_binary_iou: 0.7577 - val_true_positives: 38890768.0000 - val_false_positives: 8310546.0000 - val_true_negatives: 52691164.0000 - val_false_negatives: 6079232.0000 - val_precision: 0.8239 - val_recall: 0.8648\n",
      "Epoch 23/300\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0894 - accuracy: 0.9277 - binary_iou: 0.8614 - true_positives: 119829672.0000 - false_positives: 11795770.0000 - true_negatives: 176602592.0000 - false_negatives: 11292713.0000 - precision: 0.9104 - recall: 0.9139 - val_loss: 0.1902 - val_accuracy: 0.8396 - val_binary_iou: 0.7190 - val_true_positives: 36740352.0000 - val_false_positives: 8564972.0000 - val_true_negatives: 52230576.0000 - val_false_negatives: 8435806.0000 - val_precision: 0.8109 - val_recall: 0.8133\n",
      "Epoch 24/300\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0844 - accuracy: 0.9315 - binary_iou: 0.8681 - true_positives: 120375520.0000 - false_positives: 11190987.0000 - true_negatives: 177258720.0000 - false_negatives: 10695585.0000 - precision: 0.9149 - recall: 0.9184 - val_loss: 0.1732 - val_accuracy: 0.8533 - val_binary_iou: 0.7403 - val_true_positives: 37801488.0000 - val_false_positives: 8171298.0000 - val_true_negatives: 52624892.0000 - val_false_negatives: 7374033.0000 - val_precision: 0.8223 - val_recall: 0.8368\n",
      "Epoch 25/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0816 - accuracy: 0.9340 - binary_iou: 0.8726 - true_positives: 120743664.0000 - false_positives: 10688978.0000 - true_negatives: 177678368.0000 - false_negatives: 10409802.0000 - precision: 0.9187 - recall: 0.9206 - val_loss: 0.1687 - val_accuracy: 0.8570 - val_binary_iou: 0.7457 - val_true_positives: 37821720.0000 - val_false_positives: 7846076.0000 - val_true_negatives: 52991028.0000 - val_false_negatives: 7312886.0000 - val_precision: 0.8282 - val_recall: 0.8380\n",
      "Epoch 26/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0792 - accuracy: 0.9359 - binary_iou: 0.8760 - true_positives: 120970208.0000 - false_positives: 10302724.0000 - true_negatives: 178068112.0000 - false_negatives: 10179642.0000 - precision: 0.9215 - recall: 0.9224 - val_loss: 0.1691 - val_accuracy: 0.8603 - val_binary_iou: 0.7499 - val_true_positives: 37086832.0000 - val_false_positives: 6882977.0000 - val_true_negatives: 54079244.0000 - val_false_negatives: 7922662.0000 - val_precision: 0.8435 - val_recall: 0.8240\n",
      "Epoch 27/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0784 - accuracy: 0.9369 - binary_iou: 0.8778 - true_positives: 121040984.0000 - false_positives: 10085414.0000 - true_negatives: 178317440.0000 - false_negatives: 10076909.0000 - precision: 0.9231 - recall: 0.9231 - val_loss: 0.1596 - val_accuracy: 0.8627 - val_binary_iou: 0.7555 - val_true_positives: 39014384.0000 - val_false_positives: 8430896.0000 - val_true_negatives: 52406036.0000 - val_false_negatives: 6120405.0000 - val_precision: 0.8223 - val_recall: 0.8644\n",
      "Epoch 28/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0753 - accuracy: 0.9389 - binary_iou: 0.8815 - true_positives: 121378176.0000 - false_positives: 9757199.0000 - true_negatives: 178630304.0000 - false_negatives: 9755018.0000 - precision: 0.9256 - recall: 0.9256 - val_loss: 0.1730 - val_accuracy: 0.8553 - val_binary_iou: 0.7424 - val_true_positives: 37052692.0000 - val_false_positives: 7301166.0000 - val_true_negatives: 53583392.0000 - val_false_negatives: 8034445.0000 - val_precision: 0.8354 - val_recall: 0.8218\n",
      "Epoch 29/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0732 - accuracy: 0.9409 - binary_iou: 0.8850 - true_positives: 121638552.0000 - false_positives: 9446453.0000 - true_negatives: 178986208.0000 - false_negatives: 9449476.0000 - precision: 0.9279 - recall: 0.9279 - val_loss: 0.1479 - val_accuracy: 0.8755 - val_binary_iou: 0.7745 - val_true_positives: 38366088.0000 - val_false_positives: 6451831.0000 - val_true_negatives: 54411688.0000 - val_false_negatives: 6742119.0000 - val_precision: 0.8560 - val_recall: 0.8505\n",
      "Epoch 30/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0712 - accuracy: 0.9427 - binary_iou: 0.8884 - true_positives: 121885136.0000 - false_positives: 9056807.0000 - true_negatives: 179322080.0000 - false_negatives: 9256750.0000 - precision: 0.9308 - recall: 0.9294 - val_loss: 0.1411 - val_accuracy: 0.8783 - val_binary_iou: 0.7801 - val_true_positives: 39681324.0000 - val_false_positives: 7515209.0000 - val_true_negatives: 53393864.0000 - val_false_negatives: 5381316.0000 - val_precision: 0.8408 - val_recall: 0.8806\n",
      "Epoch 31/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0696 - accuracy: 0.9437 - binary_iou: 0.8903 - true_positives: 122102336.0000 - false_positives: 8896953.0000 - true_negatives: 179442128.0000 - false_negatives: 9079421.0000 - precision: 0.9321 - recall: 0.9308 - val_loss: 0.1602 - val_accuracy: 0.8647 - val_binary_iou: 0.7576 - val_true_positives: 38060028.0000 - val_false_positives: 7337428.0000 - val_true_negatives: 53569596.0000 - val_false_negatives: 7004659.0000 - val_precision: 0.8384 - val_recall: 0.8446\n",
      "Epoch 32/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0688 - accuracy: 0.9447 - binary_iou: 0.8920 - true_positives: 122256176.0000 - false_positives: 8745585.0000 - true_negatives: 179582352.0000 - false_negatives: 8936645.0000 - precision: 0.9332 - recall: 0.9319 - val_loss: 0.1434 - val_accuracy: 0.8755 - val_binary_iou: 0.7758 - val_true_positives: 39732704.0000 - val_false_positives: 7793475.0000 - val_true_negatives: 53048208.0000 - val_false_negatives: 5397325.0000 - val_precision: 0.8360 - val_recall: 0.8804\n",
      "Epoch 33/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0671 - accuracy: 0.9459 - binary_iou: 0.8942 - true_positives: 122282704.0000 - false_positives: 8491503.0000 - true_negatives: 179941312.0000 - false_negatives: 8805240.0000 - precision: 0.9351 - recall: 0.9328 - val_loss: 0.1576 - val_accuracy: 0.8660 - val_binary_iou: 0.7600 - val_true_positives: 38414088.0000 - val_false_positives: 7554219.0000 - val_true_negatives: 53357360.0000 - val_false_negatives: 6646050.0000 - val_precision: 0.8357 - val_recall: 0.8525\n",
      "Epoch 34/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0661 - accuracy: 0.9467 - binary_iou: 0.8958 - true_positives: 122491304.0000 - false_positives: 8436640.0000 - true_negatives: 180012096.0000 - false_negatives: 8580699.0000 - precision: 0.9356 - recall: 0.9345 - val_loss: 0.1566 - val_accuracy: 0.8676 - val_binary_iou: 0.7625 - val_true_positives: 38579700.0000 - val_false_positives: 7472669.0000 - val_true_negatives: 53359820.0000 - val_false_negatives: 6559521.0000 - val_precision: 0.8377 - val_recall: 0.8547\n",
      "Epoch 35/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0645 - accuracy: 0.9479 - binary_iou: 0.8980 - true_positives: 122662144.0000 - false_positives: 8213388.0000 - true_negatives: 180222832.0000 - false_negatives: 8422407.0000 - precision: 0.9372 - recall: 0.9357 - val_loss: 0.1438 - val_accuracy: 0.8782 - val_binary_iou: 0.7792 - val_true_positives: 38947864.0000 - val_false_positives: 6708055.0000 - val_true_negatives: 54114864.0000 - val_false_negatives: 6200927.0000 - val_precision: 0.8531 - val_recall: 0.8627\n",
      "Epoch 36/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0635 - accuracy: 0.9486 - binary_iou: 0.8993 - true_positives: 122791104.0000 - false_positives: 8102850.0000 - true_negatives: 180313472.0000 - false_negatives: 8313276.0000 - precision: 0.9381 - recall: 0.9366 - val_loss: 0.1519 - val_accuracy: 0.8713 - val_binary_iou: 0.7681 - val_true_positives: 38503968.0000 - val_false_positives: 6990396.0000 - val_true_negatives: 53825388.0000 - val_false_negatives: 6651964.0000 - val_precision: 0.8463 - val_recall: 0.8527\n",
      "Epoch 37/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0621 - accuracy: 0.9498 - binary_iou: 0.9016 - true_positives: 123125144.0000 - false_positives: 7931892.0000 - true_negatives: 180365584.0000 - false_negatives: 8098081.0000 - precision: 0.9395 - recall: 0.9383 - val_loss: 0.1527 - val_accuracy: 0.8705 - val_binary_iou: 0.7670 - val_true_positives: 38482804.0000 - val_false_positives: 7111299.0000 - val_true_negatives: 53770800.0000 - val_false_negatives: 6606818.0000 - val_precision: 0.8440 - val_recall: 0.8535\n",
      "Epoch 38/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0612 - accuracy: 0.9504 - binary_iou: 0.9026 - true_positives: 123198872.0000 - false_positives: 7859627.0000 - true_negatives: 180470272.0000 - false_negatives: 7992009.0000 - precision: 0.9400 - recall: 0.9391 - val_loss: 0.1374 - val_accuracy: 0.8804 - val_binary_iou: 0.7840 - val_true_positives: 40462768.0000 - val_false_positives: 8003803.0000 - val_true_negatives: 52833096.0000 - val_false_negatives: 4672042.0000 - val_precision: 0.8349 - val_recall: 0.8965\n",
      "Epoch 39/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0605 - accuracy: 0.9512 - binary_iou: 0.9042 - true_positives: 123262672.0000 - false_positives: 7685584.0000 - true_negatives: 180676544.0000 - false_negatives: 7895927.0000 - precision: 0.9413 - recall: 0.9398 - val_loss: 0.1457 - val_accuracy: 0.8751 - val_binary_iou: 0.7749 - val_true_positives: 39427800.0000 - val_false_positives: 7511030.0000 - val_true_negatives: 53308404.0000 - val_false_negatives: 5724489.0000 - val_precision: 0.8400 - val_recall: 0.8732\n",
      "Epoch 40/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0593 - accuracy: 0.9521 - binary_iou: 0.9057 - true_positives: 123480720.0000 - false_positives: 7598116.0000 - true_negatives: 180720064.0000 - false_negatives: 7721942.0000 - precision: 0.9420 - recall: 0.9411 - val_loss: 0.1517 - val_accuracy: 0.8737 - val_binary_iou: 0.7714 - val_true_positives: 38001772.0000 - val_false_positives: 6186966.0000 - val_true_negatives: 54590168.0000 - val_false_negatives: 7192793.0000 - val_precision: 0.8600 - val_recall: 0.8408\n",
      "Epoch 41/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0594 - accuracy: 0.9523 - binary_iou: 0.9061 - true_positives: 123466816.0000 - false_positives: 7551386.0000 - true_negatives: 180803632.0000 - false_negatives: 7698929.0000 - precision: 0.9424 - recall: 0.9413 - val_loss: 0.1539 - val_accuracy: 0.8662 - val_binary_iou: 0.7612 - val_true_positives: 39360844.0000 - val_false_positives: 8510896.0000 - val_true_negatives: 52434776.0000 - val_false_negatives: 5665198.0000 - val_precision: 0.8222 - val_recall: 0.8742\n",
      "Epoch 42/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0584 - accuracy: 0.9530 - binary_iou: 0.9074 - true_positives: 123384384.0000 - false_positives: 7305634.0000 - true_negatives: 181114448.0000 - false_negatives: 7716311.0000 - precision: 0.9441 - recall: 0.9411 - val_loss: 0.1657 - val_accuracy: 0.8592 - val_binary_iou: 0.7493 - val_true_positives: 37971728.0000 - val_false_positives: 7752052.0000 - val_true_negatives: 53080808.0000 - val_false_negatives: 7167131.0000 - val_precision: 0.8305 - val_recall: 0.8412\n",
      "Epoch 43/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0569 - accuracy: 0.9541 - binary_iou: 0.9095 - true_positives: 123623008.0000 - false_positives: 7193699.0000 - true_negatives: 181224928.0000 - false_negatives: 7479139.0000 - precision: 0.9450 - recall: 0.9430 - val_loss: 0.1598 - val_accuracy: 0.8654 - val_binary_iou: 0.7585 - val_true_positives: 37924304.0000 - val_false_positives: 7051738.0000 - val_true_negatives: 53783808.0000 - val_false_negatives: 7211865.0000 - val_precision: 0.8432 - val_recall: 0.8402\n",
      "Epoch 44/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0570 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123755928.0000 - false_positives: 7295953.0000 - true_negatives: 181029200.0000 - false_negatives: 7439621.0000 - precision: 0.9443 - recall: 0.9433 - val_loss: 0.1342 - val_accuracy: 0.8858 - val_binary_iou: 0.7918 - val_true_positives: 39619136.0000 - val_false_positives: 6547396.0000 - val_true_negatives: 54249804.0000 - val_false_negatives: 5555375.0000 - val_precision: 0.8582 - val_recall: 0.8770\n",
      "Epoch 45/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0553 - accuracy: 0.9553 - binary_iou: 0.9119 - true_positives: 123859272.0000 - false_positives: 6977136.0000 - true_negatives: 181391808.0000 - false_negatives: 7292541.0000 - precision: 0.9467 - recall: 0.9444 - val_loss: 0.1538 - val_accuracy: 0.8721 - val_binary_iou: 0.7685 - val_true_positives: 37756504.0000 - val_false_positives: 6182531.0000 - val_true_negatives: 54658532.0000 - val_false_negatives: 7374142.0000 - val_precision: 0.8593 - val_recall: 0.8366\n",
      "Epoch 46/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0549 - accuracy: 0.9556 - binary_iou: 0.9124 - true_positives: 123907208.0000 - false_positives: 7033529.0000 - true_negatives: 181428624.0000 - false_negatives: 7151389.0000 - precision: 0.9463 - recall: 0.9454 - val_loss: 0.1548 - val_accuracy: 0.8701 - val_binary_iou: 0.7657 - val_true_positives: 37948540.0000 - val_false_positives: 6595123.0000 - val_true_negatives: 54252516.0000 - val_false_negatives: 7175543.0000 - val_precision: 0.8519 - val_recall: 0.8410\n",
      "Epoch 47/300\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0542 - accuracy: 0.9562 - binary_iou: 0.9135 - true_positives: 124036728.0000 - false_positives: 6925606.0000 - true_negatives: 181482672.0000 - false_negatives: 7075720.0000 - precision: 0.9471 - recall: 0.9460 - val_loss: 0.1516 - val_accuracy: 0.8750 - val_binary_iou: 0.7731 - val_true_positives: 37821568.0000 - val_false_positives: 6008902.0000 - val_true_negatives: 54902364.0000 - val_false_negatives: 7238884.0000 - val_precision: 0.8629 - val_recall: 0.8394\n",
      "Epoch 48/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0534 - accuracy: 0.9569 - binary_iou: 0.9149 - true_positives: 124107008.0000 - false_positives: 6757289.0000 - true_negatives: 181657632.0000 - false_negatives: 6998804.0000 - precision: 0.9484 - recall: 0.9466 - val_loss: 0.1448 - val_accuracy: 0.8728 - val_binary_iou: 0.7724 - val_true_positives: 40772680.0000 - val_false_positives: 9089778.0000 - val_true_negatives: 51718232.0000 - val_false_negatives: 4391015.0000 - val_precision: 0.8177 - val_recall: 0.9028\n",
      "Epoch 49/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9572 - binary_iou: 0.9153 - true_positives: 124190864.0000 - false_positives: 6691404.0000 - true_negatives: 181643760.0000 - false_negatives: 6994768.0000 - precision: 0.9489 - recall: 0.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 460ms/step - loss: 0.0531 - accuracy: 0.9572 - binary_iou: 0.9153 - true_positives: 124190864.0000 - false_positives: 6691404.0000 - true_negatives: 181643760.0000 - false_negatives: 6994768.0000 - precision: 0.9489 - recall: 0.9467 - val_loss: 0.1224 - val_accuracy: 0.8936 - val_binary_iou: 0.8055 - val_true_positives: 41051852.0000 - val_false_positives: 7188811.0000 - val_true_negatives: 53647204.0000 - val_false_negatives: 4083851.0000 - val_precision: 0.8510 - val_recall: 0.9095\n",
      "Epoch 50/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0533 - accuracy: 0.9570 - binary_iou: 0.9150 - true_positives: 124206712.0000 - false_positives: 6805104.0000 - true_negatives: 181564480.0000 - false_negatives: 6944451.0000 - precision: 0.9481 - recall: 0.9471 - val_loss: 0.1403 - val_accuracy: 0.8786 - val_binary_iou: 0.7810 - val_true_positives: 40166796.0000 - val_false_positives: 7955312.0000 - val_true_negatives: 52939928.0000 - val_false_negatives: 4909676.0000 - val_precision: 0.8347 - val_recall: 0.8911\n",
      "Epoch 51/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0520 - accuracy: 0.9580 - binary_iou: 0.9169 - true_positives: 124383808.0000 - false_positives: 6662078.0000 - true_negatives: 181718064.0000 - false_negatives: 6756795.0000 - precision: 0.9492 - recall: 0.9485 - val_loss: 0.1331 - val_accuracy: 0.8829 - val_binary_iou: 0.7884 - val_true_positives: 41040476.0000 - val_false_positives: 8270205.0000 - val_true_negatives: 52523124.0000 - val_false_negatives: 4137891.0000 - val_precision: 0.8323 - val_recall: 0.9084\n",
      "Epoch 52/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0507 - accuracy: 0.9591 - binary_iou: 0.9189 - true_positives: 124519472.0000 - false_positives: 6480976.0000 - true_negatives: 181918720.0000 - false_negatives: 6601561.0000 - precision: 0.9505 - recall: 0.9497 - val_loss: 0.1331 - val_accuracy: 0.8850 - val_binary_iou: 0.7911 - val_true_positives: 40312048.0000 - val_false_positives: 7313449.0000 - val_true_negatives: 53472680.0000 - val_false_negatives: 4873532.0000 - val_precision: 0.8464 - val_recall: 0.8921\n",
      "Epoch 53/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0510 - accuracy: 0.9588 - binary_iou: 0.9184 - true_positives: 124464448.0000 - false_positives: 6523479.0000 - true_negatives: 181891648.0000 - false_negatives: 6641210.0000 - precision: 0.9502 - recall: 0.9493 - val_loss: 0.1248 - val_accuracy: 0.8919 - val_binary_iou: 0.8025 - val_true_positives: 40879444.0000 - val_false_positives: 7144993.0000 - val_true_negatives: 53635480.0000 - val_false_negatives: 4311807.0000 - val_precision: 0.8512 - val_recall: 0.9046\n",
      "Epoch 54/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0504 - accuracy: 0.9593 - binary_iou: 0.9194 - true_positives: 124560848.0000 - false_positives: 6408760.0000 - true_negatives: 181965760.0000 - false_negatives: 6585380.0000 - precision: 0.9511 - recall: 0.9498 - val_loss: 0.1280 - val_accuracy: 0.8891 - val_binary_iou: 0.7979 - val_true_positives: 40666132.0000 - val_false_positives: 7241171.0000 - val_true_negatives: 53549152.0000 - val_false_negatives: 4515256.0000 - val_precision: 0.8489 - val_recall: 0.9001\n",
      "Epoch 55/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0501 - accuracy: 0.9596 - binary_iou: 0.9199 - true_positives: 124591528.0000 - false_positives: 6377012.0000 - true_negatives: 182006560.0000 - false_negatives: 6545674.0000 - precision: 0.9513 - recall: 0.9501 - val_loss: 0.1444 - val_accuracy: 0.8751 - val_binary_iou: 0.7751 - val_true_positives: 39678008.0000 - val_false_positives: 7789454.0000 - val_true_negatives: 53060240.0000 - val_false_negatives: 5443997.0000 - val_precision: 0.8359 - val_recall: 0.8793\n",
      "Epoch 56/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0499 - accuracy: 0.9597 - binary_iou: 0.9202 - true_positives: 124655336.0000 - false_positives: 6317833.0000 - true_negatives: 181996416.0000 - false_negatives: 6551179.0000 - precision: 0.9518 - recall: 0.9501 - val_loss: 0.1295 - val_accuracy: 0.8865 - val_binary_iou: 0.7940 - val_true_positives: 41016612.0000 - val_false_positives: 7990725.0000 - val_true_negatives: 52926616.0000 - val_false_negatives: 4037752.0000 - val_precision: 0.8369 - val_recall: 0.9104\n",
      "Epoch 57/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0491 - accuracy: 0.9604 - binary_iou: 0.9215 - true_positives: 124744160.0000 - false_positives: 6252158.0000 - true_negatives: 182124560.0000 - false_negatives: 6399873.0000 - precision: 0.9523 - recall: 0.9512 - val_loss: 0.1249 - val_accuracy: 0.8917 - val_binary_iou: 0.8021 - val_true_positives: 40708744.0000 - val_false_positives: 7059497.0000 - val_true_negatives: 53786380.0000 - val_false_negatives: 4417087.0000 - val_precision: 0.8522 - val_recall: 0.9021\n",
      "Epoch 58/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0486 - accuracy: 0.9608 - binary_iou: 0.9223 - true_positives: 124796360.0000 - false_positives: 6166478.0000 - true_negatives: 182213040.0000 - false_negatives: 6344825.0000 - precision: 0.9529 - recall: 0.9516 - val_loss: 0.1396 - val_accuracy: 0.8786 - val_binary_iou: 0.7807 - val_true_positives: 39882548.0000 - val_false_positives: 7650451.0000 - val_true_negatives: 53225792.0000 - val_false_negatives: 5212937.0000 - val_precision: 0.8390 - val_recall: 0.8844\n",
      "Epoch 59/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0474 - accuracy: 0.9617 - binary_iou: 0.9240 - true_positives: 124856752.0000 - false_positives: 6008575.0000 - true_negatives: 182434432.0000 - false_negatives: 6221096.0000 - precision: 0.9541 - recall: 0.9525 - val_loss: 0.1437 - val_accuracy: 0.8766 - val_binary_iou: 0.7773 - val_true_positives: 39628516.0000 - val_false_positives: 7570976.0000 - val_true_negatives: 53262956.0000 - val_false_negatives: 5509264.0000 - val_precision: 0.8396 - val_recall: 0.8779\n",
      "Epoch 60/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0482 - accuracy: 0.9613 - binary_iou: 0.9231 - true_positives: 124932784.0000 - false_positives: 6153825.0000 - true_negatives: 182211328.0000 - false_negatives: 6222892.0000 - precision: 0.9531 - recall: 0.9526 - val_loss: 0.1332 - val_accuracy: 0.8866 - val_binary_iou: 0.7937 - val_true_positives: 40253084.0000 - val_false_positives: 7133141.0000 - val_true_negatives: 53704920.0000 - val_false_negatives: 4880562.0000 - val_precision: 0.8495 - val_recall: 0.8919\n",
      "Epoch 61/300\n",
      "199/199 [==============================] - 76s 381ms/step - loss: 0.0474 - accuracy: 0.9618 - binary_iou: 0.9241 - true_positives: 124947544.0000 - false_positives: 6058574.0000 - true_negatives: 182362272.0000 - false_negatives: 6152393.0000 - precision: 0.9538 - recall: 0.9531 - val_loss: 0.1244 - val_accuracy: 0.8933 - val_binary_iou: 0.8046 - val_true_positives: 40491824.0000 - val_false_positives: 6587527.0000 - val_true_negatives: 54175248.0000 - val_false_negatives: 4717113.0000 - val_precision: 0.8601 - val_recall: 0.8957\n",
      "Epoch 62/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0467 - accuracy: 0.9625 - binary_iou: 0.9255 - true_positives: 125049016.0000 - false_positives: 5936787.0000 - true_negatives: 182487808.0000 - false_negatives: 6047171.0000 - precision: 0.9547 - recall: 0.9539 - val_loss: 0.1285 - val_accuracy: 0.8876 - val_binary_iou: 0.7957 - val_true_positives: 40954904.0000 - val_false_positives: 7736609.0000 - val_true_negatives: 53105536.0000 - val_false_negatives: 4174647.0000 - val_precision: 0.8411 - val_recall: 0.9075\n",
      "Epoch 63/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0457 - accuracy: 0.9630 - binary_iou: 0.9264 - true_positives: 125117640.0000 - false_positives: 5856439.0000 - true_negatives: 182584368.0000 - false_negatives: 5962358.0000 - precision: 0.9553 - recall: 0.9545 - val_loss: 0.1323 - val_accuracy: 0.8873 - val_binary_iou: 0.7943 - val_true_positives: 39808800.0000 - val_false_positives: 6661618.0000 - val_true_negatives: 54216584.0000 - val_false_negatives: 5284727.0000 - val_precision: 0.8566 - val_recall: 0.8828\n",
      "Epoch 64/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0453 - accuracy: 0.9633 - binary_iou: 0.9271 - true_positives: 125236832.0000 - false_positives: 5799776.0000 - true_negatives: 182567968.0000 - false_negatives: 5916113.0000 - precision: 0.9557 - recall: 0.9549 - val_loss: 0.1242 - val_accuracy: 0.8927 - val_binary_iou: 0.8035 - val_true_positives: 40447092.0000 - val_false_positives: 6696174.0000 - val_true_negatives: 54150400.0000 - val_false_negatives: 4678049.0000 - val_precision: 0.8580 - val_recall: 0.8963\n",
      "Epoch 65/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0455 - accuracy: 0.9634 - binary_iou: 0.9272 - true_positives: 125150472.0000 - false_positives: 5794920.0000 - true_negatives: 182685408.0000 - false_negatives: 5889951.0000 - precision: 0.9557 - recall: 0.9551 - val_loss: 0.1249 - val_accuracy: 0.8920 - val_binary_iou: 0.8026 - val_true_positives: 40712612.0000 - val_false_positives: 7040544.0000 - val_true_negatives: 53814552.0000 - val_false_negatives: 4404009.0000 - val_precision: 0.8526 - val_recall: 0.9024\n",
      "Epoch 66/300\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0452 - accuracy: 0.9636 - binary_iou: 0.9276 - true_positives: 125190992.0000 - false_positives: 5726393.0000 - true_negatives: 182696160.0000 - false_negatives: 5907227.0000 - precision: 0.9563 - recall: 0.9549 - val_loss: 0.1274 - val_accuracy: 0.8902 - val_binary_iou: 0.7993 - val_true_positives: 40217396.0000 - val_false_positives: 6751547.0000 - val_true_negatives: 54120324.0000 - val_false_negatives: 4882457.0000 - val_precision: 0.8563 - val_recall: 0.8917\n",
      "Epoch 67/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0449 - accuracy: 0.9639 - binary_iou: 0.9281 - true_positives: 125344096.0000 - false_positives: 5695700.0000 - true_negatives: 182638784.0000 - false_negatives: 5842164.0000 - precision: 0.9565 - recall: 0.9555 - val_loss: 0.1255 - val_accuracy: 0.8908 - val_binary_iou: 0.8007 - val_true_positives: 40860812.0000 - val_false_positives: 7320436.0000 - val_true_negatives: 53533928.0000 - val_false_negatives: 4256534.0000 - val_precision: 0.8481 - val_recall: 0.9057\n",
      "Epoch 68/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0445 - accuracy: 0.9642 - binary_iou: 0.9287 - true_positives: 125332760.0000 - false_positives: 5638060.0000 - true_negatives: 182737760.0000 - false_negatives: 5812179.0000 - precision: 0.9570 - recall: 0.9557 - val_loss: 0.1385 - val_accuracy: 0.8808 - val_binary_iou: 0.7839 - val_true_positives: 39670904.0000 - val_false_positives: 7306383.0000 - val_true_negatives: 53666224.0000 - val_false_negatives: 5328217.0000 - val_precision: 0.8445 - val_recall: 0.8816\n",
      "Epoch 69/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0442 - accuracy: 0.9644 - binary_iou: 0.9291 - true_positives: 125380920.0000 - false_positives: 5670895.0000 - true_negatives: 182764752.0000 - false_negatives: 5704159.0000 - precision: 0.9567 - recall: 0.9565 - val_loss: 0.1474 - val_accuracy: 0.8763 - val_binary_iou: 0.7758 - val_true_positives: 38506796.0000 - val_false_positives: 6493311.0000 - val_true_negatives: 54351536.0000 - val_false_negatives: 6620081.0000 - val_precision: 0.8557 - val_recall: 0.8533\n",
      "Epoch 70/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0436 - accuracy: 0.9648 - binary_iou: 0.9299 - true_positives: 125411872.0000 - false_positives: 5535413.0000 - true_negatives: 182865456.0000 - false_negatives: 5708037.0000 - precision: 0.9577 - recall: 0.9565 - val_loss: 0.1363 - val_accuracy: 0.8844 - val_binary_iou: 0.7894 - val_true_positives: 39406496.0000 - val_false_positives: 6473311.0000 - val_true_negatives: 54311988.0000 - val_false_negatives: 5779911.0000 - val_precision: 0.8589 - val_recall: 0.8721\n",
      "Epoch 71/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0432 - accuracy: 0.9650 - binary_iou: 0.9303 - true_positives: 125522208.0000 - false_positives: 5511531.0000 - true_negatives: 182820384.0000 - false_negatives: 5666645.0000 - precision: 0.9579 - recall: 0.9568 - val_loss: 0.1317 - val_accuracy: 0.8861 - val_binary_iou: 0.7928 - val_true_positives: 40235800.0000 - val_false_positives: 7147035.0000 - val_true_negatives: 53666704.0000 - val_false_negatives: 4922173.0000 - val_precision: 0.8492 - val_recall: 0.8910\n",
      "Epoch 72/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0429 - accuracy: 0.9653 - binary_iou: 0.9308 - true_positives: 125527552.0000 - false_positives: 5464186.0000 - true_negatives: 182891200.0000 - false_negatives: 5637824.0000 - precision: 0.9583 - recall: 0.9570 - val_loss: 0.1262 - val_accuracy: 0.8904 - val_binary_iou: 0.8002 - val_true_positives: 40849704.0000 - val_false_positives: 7349679.0000 - val_true_negatives: 53508840.0000 - val_false_negatives: 4263487.0000 - val_precision: 0.8475 - val_recall: 0.9055\n",
      "Epoch 73/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0433 - accuracy: 0.9651 - binary_iou: 0.9305 - true_positives: 125359712.0000 - false_positives: 5453836.0000 - true_negatives: 183011856.0000 - false_negatives: 5695352.0000 - precision: 0.9583 - recall: 0.9565 - val_loss: 0.1258 - val_accuracy: 0.8927 - val_binary_iou: 0.8033 - val_true_positives: 40226168.0000 - val_false_positives: 6541107.0000 - val_true_negatives: 54372680.0000 - val_false_negatives: 4831756.0000 - val_precision: 0.8601 - val_recall: 0.8928\n",
      "Epoch 74/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0426 - accuracy: 0.9656 - binary_iou: 0.9313 - true_positives: 125676456.0000 - false_positives: 5499757.0000 - true_negatives: 182837584.0000 - false_negatives: 5507007.0000 - precision: 0.9581 - recall: 0.9580 - val_loss: 0.1366 - val_accuracy: 0.8820 - val_binary_iou: 0.7863 - val_true_positives: 40072232.0000 - val_false_positives: 7431242.0000 - val_true_negatives: 53399696.0000 - val_false_negatives: 5068548.0000 - val_precision: 0.8436 - val_recall: 0.8877\n",
      "Epoch 75/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0421 - accuracy: 0.9660 - binary_iou: 0.9323 - true_positives: 125668784.0000 - false_positives: 5360537.0000 - true_negatives: 183000464.0000 - false_negatives: 5490982.0000 - precision: 0.9591 - recall: 0.9581 - val_loss: 0.1321 - val_accuracy: 0.8869 - val_binary_iou: 0.7939 - val_true_positives: 40018788.0000 - val_false_positives: 6848179.0000 - val_true_negatives: 53969800.0000 - val_false_negatives: 5134937.0000 - val_precision: 0.8539 - val_recall: 0.8863\n",
      "Epoch 76/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0418 - accuracy: 0.9663 - binary_iou: 0.9328 - true_positives: 125682656.0000 - false_positives: 5336545.0000 - true_negatives: 183076640.0000 - false_negatives: 5424925.0000 - precision: 0.9593 - recall: 0.9586 - val_loss: 0.1301 - val_accuracy: 0.8875 - val_binary_iou: 0.7950 - val_true_positives: 40259408.0000 - val_false_positives: 7076109.0000 - val_true_negatives: 53786484.0000 - val_false_negatives: 4849707.0000 - val_precision: 0.8505 - val_recall: 0.8925\n",
      "Epoch 77/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0414 - accuracy: 0.9665 - binary_iou: 0.9331 - true_positives: 125743640.0000 - false_positives: 5306695.0000 - true_negatives: 183071360.0000 - false_negatives: 5399117.0000 - precision: 0.9595 - recall: 0.9588 - val_loss: 0.1327 - val_accuracy: 0.8853 - val_binary_iou: 0.7915 - val_true_positives: 40278660.0000 - val_false_positives: 7286132.0000 - val_true_negatives: 53535720.0000 - val_false_negatives: 4871201.0000 - val_precision: 0.8468 - val_recall: 0.8921\n",
      "Epoch 78/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0409 - accuracy: 0.9670 - binary_iou: 0.9341 - true_positives: 125692192.0000 - false_positives: 5185485.0000 - true_negatives: 183288688.0000 - false_negatives: 5354359.0000 - precision: 0.9604 - recall: 0.9591 - val_loss: 0.1376 - val_accuracy: 0.8832 - val_binary_iou: 0.7874 - val_true_positives: 39402556.0000 - val_false_positives: 6671738.0000 - val_true_negatives: 54187432.0000 - val_false_negatives: 5709995.0000 - val_precision: 0.8552 - val_recall: 0.8734\n",
      "Epoch 79/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9668 - binary_iou: 0.9338 - true_positives: 125826584.0000 - false_positives: 5214493.0000 - true_negatives: 183098784.0000 - false_negatives: 5380905.0000 - precision: 0.9602 - recall: 0.9590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0410 - accuracy: 0.9668 - binary_iou: 0.9338 - true_positives: 125826584.0000 - false_positives: 5214493.0000 - true_negatives: 183098784.0000 - false_negatives: 5380905.0000 - precision: 0.9602 - recall: 0.9590 - val_loss: 0.1211 - val_accuracy: 0.8960 - val_binary_iou: 0.8090 - val_true_positives: 40688928.0000 - val_false_positives: 6655291.0000 - val_true_negatives: 54262540.0000 - val_false_negatives: 4364945.0000 - val_precision: 0.8594 - val_recall: 0.9031\n",
      "Epoch 80/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9673 - binary_iou: 0.9347 - true_positives: 125833560.0000 - false_positives: 5149075.0000 - true_negatives: 183241344.0000 - false_negatives: 5296792.0000 - precision: 0.9607 - recall: 0.9596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 93s 468ms/step - loss: 0.0404 - accuracy: 0.9673 - binary_iou: 0.9347 - true_positives: 125833560.0000 - false_positives: 5149075.0000 - true_negatives: 183241344.0000 - false_negatives: 5296792.0000 - precision: 0.9607 - recall: 0.9596 - val_loss: 0.1189 - val_accuracy: 0.8992 - val_binary_iou: 0.8138 - val_true_positives: 40246868.0000 - val_false_positives: 5827465.0000 - val_true_negatives: 55037596.0000 - val_false_negatives: 4859781.0000 - val_precision: 0.8735 - val_recall: 0.8923\n",
      "Epoch 81/300\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0406 - accuracy: 0.9672 - binary_iou: 0.9345 - true_positives: 125901040.0000 - false_positives: 5218970.0000 - true_negatives: 183135776.0000 - false_negatives: 5265047.0000 - precision: 0.9602 - recall: 0.9599 - val_loss: 0.1312 - val_accuracy: 0.8885 - val_binary_iou: 0.7962 - val_true_positives: 39719364.0000 - val_false_positives: 6454110.0000 - val_true_negatives: 54436096.0000 - val_false_negatives: 5362147.0000 - val_precision: 0.8602 - val_recall: 0.8811\n",
      "Epoch 82/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0402 - accuracy: 0.9674 - binary_iou: 0.9349 - true_positives: 125878616.0000 - false_positives: 5151220.0000 - true_negatives: 183232640.0000 - false_negatives: 5258341.0000 - precision: 0.9607 - recall: 0.9599 - val_loss: 0.1273 - val_accuracy: 0.8913 - val_binary_iou: 0.8011 - val_true_positives: 40250888.0000 - val_false_positives: 6693823.0000 - val_true_negatives: 54199444.0000 - val_false_negatives: 4827539.0000 - val_precision: 0.8574 - val_recall: 0.8929\n",
      "Epoch 83/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0399 - accuracy: 0.9677 - binary_iou: 0.9354 - true_positives: 125938240.0000 - false_positives: 5149368.0000 - true_negatives: 183253344.0000 - false_negatives: 5179859.0000 - precision: 0.9607 - recall: 0.9605 - val_loss: 0.1248 - val_accuracy: 0.8929 - val_binary_iou: 0.8039 - val_true_positives: 40506000.0000 - val_false_positives: 6863397.0000 - val_true_negatives: 54116696.0000 - val_false_negatives: 4485626.0000 - val_precision: 0.8551 - val_recall: 0.9003\n",
      "Epoch 84/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0395 - accuracy: 0.9682 - binary_iou: 0.9363 - true_positives: 125941432.0000 - false_positives: 5017609.0000 - true_negatives: 183404352.0000 - false_negatives: 5157383.0000 - precision: 0.9617 - recall: 0.9607 - val_loss: 0.1337 - val_accuracy: 0.8854 - val_binary_iou: 0.7913 - val_true_positives: 39770140.0000 - val_false_positives: 6837606.0000 - val_true_negatives: 54056176.0000 - val_false_negatives: 5307799.0000 - val_precision: 0.8533 - val_recall: 0.8823\n",
      "Epoch 85/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0395 - accuracy: 0.9682 - binary_iou: 0.9365 - true_positives: 126005840.0000 - false_positives: 5043673.0000 - true_negatives: 183358432.0000 - false_negatives: 5112826.0000 - precision: 0.9615 - recall: 0.9610 - val_loss: 0.1185 - val_accuracy: 0.8975 - val_binary_iou: 0.8116 - val_true_positives: 40862840.0000 - val_false_positives: 6608031.0000 - val_true_negatives: 54245340.0000 - val_false_negatives: 4255472.0000 - val_precision: 0.8608 - val_recall: 0.9057\n",
      "Epoch 86/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0390 - accuracy: 0.9685 - binary_iou: 0.9370 - true_positives: 126059808.0000 - false_positives: 4980750.0000 - true_negatives: 183400688.0000 - false_negatives: 5079390.0000 - precision: 0.9620 - recall: 0.9613 - val_loss: 0.1192 - val_accuracy: 0.8978 - val_binary_iou: 0.8119 - val_true_positives: 40770092.0000 - val_false_positives: 6512216.0000 - val_true_negatives: 54366352.0000 - val_false_negatives: 4323036.0000 - val_precision: 0.8623 - val_recall: 0.9041\n",
      "Epoch 87/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9690 - binary_iou: 0.9379 - true_positives: 126197784.0000 - false_positives: 4942512.0000 - true_negatives: 183404160.0000 - false_negatives: 4976309.0000 - precision: 0.9623 - recall: 0.9621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0385 - accuracy: 0.9690 - binary_iou: 0.9379 - true_positives: 126197784.0000 - false_positives: 4942512.0000 - true_negatives: 183404160.0000 - false_negatives: 4976309.0000 - precision: 0.9623 - recall: 0.9621 - val_loss: 0.1173 - val_accuracy: 0.8990 - val_binary_iou: 0.8142 - val_true_positives: 41028432.0000 - val_false_positives: 6562191.0000 - val_true_negatives: 54241048.0000 - val_false_negatives: 4140038.0000 - val_precision: 0.8621 - val_recall: 0.9083\n",
      "Epoch 88/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0389 - accuracy: 0.9687 - binary_iou: 0.9374 - true_positives: 126125472.0000 - false_positives: 4950957.0000 - true_negatives: 183386096.0000 - false_negatives: 5058277.0000 - precision: 0.9622 - recall: 0.9614 - val_loss: 0.1257 - val_accuracy: 0.8918 - val_binary_iou: 0.8019 - val_true_positives: 40361652.0000 - val_false_positives: 6745363.0000 - val_true_negatives: 54139580.0000 - val_false_negatives: 4725118.0000 - val_precision: 0.8568 - val_recall: 0.8952\n",
      "Epoch 89/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0382 - accuracy: 0.9691 - binary_iou: 0.9382 - true_positives: 126138448.0000 - false_positives: 4895951.0000 - true_negatives: 183504720.0000 - false_negatives: 4981623.0000 - precision: 0.9626 - recall: 0.9620 - val_loss: 0.1430 - val_accuracy: 0.8808 - val_binary_iou: 0.7830 - val_true_positives: 38679812.0000 - val_false_positives: 6268144.0000 - val_true_negatives: 54657684.0000 - val_false_negatives: 6366061.0000 - val_precision: 0.8605 - val_recall: 0.8587\n",
      "Epoch 90/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0378 - accuracy: 0.9695 - binary_iou: 0.9390 - true_positives: 126135312.0000 - false_positives: 4800330.0000 - true_negatives: 183654912.0000 - false_negatives: 4930250.0000 - precision: 0.9633 - recall: 0.9624 - val_loss: 0.1277 - val_accuracy: 0.8895 - val_binary_iou: 0.7985 - val_true_positives: 40575024.0000 - val_false_positives: 7164729.0000 - val_true_negatives: 53690784.0000 - val_false_negatives: 4541184.0000 - val_precision: 0.8499 - val_recall: 0.8993\n",
      "Epoch 91/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0375 - accuracy: 0.9697 - binary_iou: 0.9393 - true_positives: 126272896.0000 - false_positives: 4785030.0000 - true_negatives: 183555168.0000 - false_negatives: 4907744.0000 - precision: 0.9635 - recall: 0.9626 - val_loss: 0.1382 - val_accuracy: 0.8801 - val_binary_iou: 0.7832 - val_true_positives: 40025704.0000 - val_false_positives: 7683408.0000 - val_true_negatives: 53243064.0000 - val_false_negatives: 5019541.0000 - val_precision: 0.8390 - val_recall: 0.8886\n",
      "Epoch 92/300\n",
      "199/199 [==============================] - 78s 391ms/step - loss: 0.0377 - accuracy: 0.9697 - binary_iou: 0.9393 - true_positives: 126237488.0000 - false_positives: 4797218.0000 - true_negatives: 183598096.0000 - false_negatives: 4887910.0000 - precision: 0.9634 - recall: 0.9627 - val_loss: 0.1270 - val_accuracy: 0.8902 - val_binary_iou: 0.7997 - val_true_positives: 40716256.0000 - val_false_positives: 7237269.0000 - val_true_negatives: 53620108.0000 - val_false_negatives: 4398084.0000 - val_precision: 0.8491 - val_recall: 0.9025\n",
      "Epoch 93/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0371 - accuracy: 0.9700 - binary_iou: 0.9399 - true_positives: 126342984.0000 - false_positives: 4743315.0000 - true_negatives: 183593824.0000 - false_negatives: 4840680.0000 - precision: 0.9638 - recall: 0.9631 - val_loss: 0.1240 - val_accuracy: 0.8916 - val_binary_iou: 0.8020 - val_true_positives: 40930880.0000 - val_false_positives: 7231613.0000 - val_true_negatives: 53548472.0000 - val_false_negatives: 4260752.0000 - val_precision: 0.8498 - val_recall: 0.9057\n",
      "Epoch 94/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0372 - accuracy: 0.9700 - binary_iou: 0.9398 - true_positives: 126309928.0000 - false_positives: 4774565.0000 - true_negatives: 183611648.0000 - false_negatives: 4824698.0000 - precision: 0.9636 - recall: 0.9632 - val_loss: 0.1214 - val_accuracy: 0.8958 - val_binary_iou: 0.8085 - val_true_positives: 40427384.0000 - val_false_positives: 6310184.0000 - val_true_negatives: 54502188.0000 - val_false_negatives: 4731966.0000 - val_precision: 0.8650 - val_recall: 0.8952\n",
      "Epoch 95/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0369 - accuracy: 0.9702 - binary_iou: 0.9402 - true_positives: 126340080.0000 - false_positives: 4776206.0000 - true_negatives: 183646800.0000 - false_negatives: 4757637.0000 - precision: 0.9636 - recall: 0.9637 - val_loss: 0.1208 - val_accuracy: 0.8953 - val_binary_iou: 0.8082 - val_true_positives: 41058668.0000 - val_false_positives: 7017896.0000 - val_true_negatives: 53817884.0000 - val_false_negatives: 4077258.0000 - val_precision: 0.8540 - val_recall: 0.9097\n",
      "Epoch 96/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0364 - accuracy: 0.9705 - binary_iou: 0.9410 - true_positives: 126412504.0000 - false_positives: 4638195.0000 - true_negatives: 183698160.0000 - false_negatives: 4771950.0000 - precision: 0.9646 - recall: 0.9636 - val_loss: 0.1178 - val_accuracy: 0.8973 - val_binary_iou: 0.8115 - val_true_positives: 41139564.0000 - val_false_positives: 6882456.0000 - val_true_negatives: 53952144.0000 - val_false_negatives: 3997543.0000 - val_precision: 0.8567 - val_recall: 0.9114\n",
      "Epoch 97/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0367 - accuracy: 0.9704 - binary_iou: 0.9407 - true_positives: 126337528.0000 - false_positives: 4674102.0000 - true_negatives: 183722624.0000 - false_negatives: 4786496.0000 - precision: 0.9643 - recall: 0.9635 - val_loss: 0.1238 - val_accuracy: 0.8917 - val_binary_iou: 0.8025 - val_true_positives: 41279044.0000 - val_false_positives: 7650375.0000 - val_true_negatives: 53213488.0000 - val_false_negatives: 3828801.0000 - val_precision: 0.8436 - val_recall: 0.9151\n",
      "Epoch 98/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0365 - accuracy: 0.9706 - binary_iou: 0.9411 - true_positives: 126356104.0000 - false_positives: 4633043.0000 - true_negatives: 183778144.0000 - false_negatives: 4753429.0000 - precision: 0.9646 - recall: 0.9637 - val_loss: 0.1178 - val_accuracy: 0.8974 - val_binary_iou: 0.8117 - val_true_positives: 41300664.0000 - val_false_positives: 7093535.0000 - val_true_negatives: 53797556.0000 - val_false_negatives: 3779963.0000 - val_precision: 0.8534 - val_recall: 0.9162\n",
      "Epoch 99/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0362 - accuracy: 0.9707 - binary_iou: 0.9413 - true_positives: 126404904.0000 - false_positives: 4689436.0000 - true_negatives: 183753872.0000 - false_negatives: 4672542.0000 - precision: 0.9642 - recall: 0.9644 - val_loss: 0.1222 - val_accuracy: 0.8964 - val_binary_iou: 0.8094 - val_true_positives: 40294264.0000 - val_false_positives: 6169027.0000 - val_true_negatives: 54702936.0000 - val_false_negatives: 4805478.0000 - val_precision: 0.8672 - val_recall: 0.8934\n",
      "Epoch 100/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0358 - accuracy: 0.9710 - binary_iou: 0.9419 - true_positives: 126532776.0000 - false_positives: 4636033.0000 - true_negatives: 183718000.0000 - false_negatives: 4633946.0000 - precision: 0.9647 - recall: 0.9647 - val_loss: 0.1223 - val_accuracy: 0.8935 - val_binary_iou: 0.8053 - val_true_positives: 41027936.0000 - val_false_positives: 7182040.0000 - val_true_negatives: 53661840.0000 - val_false_negatives: 4099892.0000 - val_precision: 0.8510 - val_recall: 0.9091\n",
      "Epoch 101/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0359 - accuracy: 0.9711 - binary_iou: 0.9420 - true_positives: 126426304.0000 - false_positives: 4573718.0000 - true_negatives: 183851296.0000 - false_negatives: 4669383.0000 - precision: 0.9651 - recall: 0.9644 - val_loss: 0.1262 - val_accuracy: 0.8914 - val_binary_iou: 0.8014 - val_true_positives: 40325340.0000 - val_false_positives: 6688132.0000 - val_true_negatives: 54141900.0000 - val_false_negatives: 4816332.0000 - val_precision: 0.8577 - val_recall: 0.8933\n",
      "Epoch 102/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9712 - binary_iou: 0.9422 - true_positives: 126400232.0000 - false_positives: 4558592.0000 - true_negatives: 183911504.0000 - false_negatives: 4650407.0000 - precision: 0.9652 - recall: 0.9645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0358 - accuracy: 0.9712 - binary_iou: 0.9422 - true_positives: 126400232.0000 - false_positives: 4558592.0000 - true_negatives: 183911504.0000 - false_negatives: 4650407.0000 - precision: 0.9652 - recall: 0.9645 - val_loss: 0.1147 - val_accuracy: 0.9014 - val_binary_iou: 0.8178 - val_true_positives: 40633532.0000 - val_false_positives: 6000315.0000 - val_true_negatives: 54889100.0000 - val_false_negatives: 4448775.0000 - val_precision: 0.8713 - val_recall: 0.9013\n",
      "Epoch 103/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0352 - accuracy: 0.9715 - binary_iou: 0.9428 - true_positives: 126506848.0000 - false_positives: 4524074.0000 - true_negatives: 183903488.0000 - false_negatives: 4586364.0000 - precision: 0.9655 - recall: 0.9650 - val_loss: 0.1196 - val_accuracy: 0.8962 - val_binary_iou: 0.8098 - val_true_positives: 41185892.0000 - val_false_positives: 7072328.0000 - val_true_negatives: 53790224.0000 - val_false_negatives: 3923283.0000 - val_precision: 0.8534 - val_recall: 0.9130\n",
      "Epoch 104/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0353 - accuracy: 0.9715 - binary_iou: 0.9428 - true_positives: 126556816.0000 - false_positives: 4507274.0000 - true_negatives: 183858720.0000 - false_negatives: 4597953.0000 - precision: 0.9656 - recall: 0.9649 - val_loss: 0.1166 - val_accuracy: 0.9002 - val_binary_iou: 0.8158 - val_true_positives: 40614952.0000 - val_false_positives: 6111206.0000 - val_true_negatives: 54779160.0000 - val_false_negatives: 4466386.0000 - val_precision: 0.8692 - val_recall: 0.9009\n",
      "Epoch 105/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0350 - accuracy: 0.9716 - binary_iou: 0.9431 - true_positives: 126555448.0000 - false_positives: 4483441.0000 - true_negatives: 183903296.0000 - false_negatives: 4578510.0000 - precision: 0.9658 - recall: 0.9651 - val_loss: 0.1198 - val_accuracy: 0.8961 - val_binary_iou: 0.8095 - val_true_positives: 41079212.0000 - val_false_positives: 7022818.0000 - val_true_negatives: 53885896.0000 - val_false_negatives: 3983785.0000 - val_precision: 0.8540 - val_recall: 0.9116\n",
      "Epoch 106/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0343 - accuracy: 0.9722 - binary_iou: 0.9442 - true_positives: 126648080.0000 - false_positives: 4453989.0000 - true_negatives: 183992480.0000 - false_negatives: 4426219.0000 - precision: 0.9660 - recall: 0.9662 - val_loss: 0.1204 - val_accuracy: 0.8953 - val_binary_iou: 0.8082 - val_true_positives: 41081364.0000 - val_false_positives: 7072027.0000 - val_true_negatives: 53798608.0000 - val_false_negatives: 4019699.0000 - val_precision: 0.8531 - val_recall: 0.9109\n",
      "Epoch 107/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0341 - accuracy: 0.9724 - binary_iou: 0.9447 - true_positives: 126805408.0000 - false_positives: 4422716.0000 - true_negatives: 183904784.0000 - false_negatives: 4387830.0000 - precision: 0.9663 - recall: 0.9666 - val_loss: 0.1173 - val_accuracy: 0.8990 - val_binary_iou: 0.8141 - val_true_positives: 40894608.0000 - val_false_positives: 6507236.0000 - val_true_negatives: 54374840.0000 - val_false_negatives: 4195031.0000 - val_precision: 0.8627 - val_recall: 0.9070\n",
      "Epoch 108/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0342 - accuracy: 0.9725 - binary_iou: 0.9448 - true_positives: 126631680.0000 - false_positives: 4353448.0000 - true_negatives: 184098048.0000 - false_negatives: 4437575.0000 - precision: 0.9668 - recall: 0.9661 - val_loss: 0.1224 - val_accuracy: 0.8939 - val_binary_iou: 0.8057 - val_true_positives: 40869436.0000 - val_false_positives: 6969499.0000 - val_true_negatives: 53855688.0000 - val_false_negatives: 4277085.0000 - val_precision: 0.8543 - val_recall: 0.9053\n",
      "Epoch 109/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0341 - accuracy: 0.9723 - binary_iou: 0.9445 - true_positives: 126773728.0000 - false_positives: 4406292.0000 - true_negatives: 183909056.0000 - false_negatives: 4431659.0000 - precision: 0.9664 - recall: 0.9662 - val_loss: 0.1225 - val_accuracy: 0.8940 - val_binary_iou: 0.8058 - val_true_positives: 40754128.0000 - val_false_positives: 6833923.0000 - val_true_negatives: 53984744.0000 - val_false_negatives: 4398924.0000 - val_precision: 0.8564 - val_recall: 0.9026\n",
      "Epoch 110/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0337 - accuracy: 0.9727 - binary_iou: 0.9452 - true_positives: 126746392.0000 - false_positives: 4321262.0000 - true_negatives: 184054512.0000 - false_negatives: 4398581.0000 - precision: 0.9670 - recall: 0.9665 - val_loss: 0.1248 - val_accuracy: 0.8937 - val_binary_iou: 0.8049 - val_true_positives: 40106208.0000 - val_false_positives: 6287806.0000 - val_true_negatives: 54605688.0000 - val_false_negatives: 4972009.0000 - val_precision: 0.8645 - val_recall: 0.8897\n",
      "Epoch 111/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0336 - accuracy: 0.9729 - binary_iou: 0.9455 - true_positives: 126877072.0000 - false_positives: 4319419.0000 - true_negatives: 183970032.0000 - false_negatives: 4354285.0000 - precision: 0.9671 - recall: 0.9668 - val_loss: 0.1243 - val_accuracy: 0.8916 - val_binary_iou: 0.8021 - val_true_positives: 40973048.0000 - val_false_positives: 7340763.0000 - val_true_negatives: 53506712.0000 - val_false_negatives: 4151176.0000 - val_precision: 0.8481 - val_recall: 0.9080\n",
      "Epoch 112/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0333 - accuracy: 0.9731 - binary_iou: 0.9460 - true_positives: 126810136.0000 - false_positives: 4309674.0000 - true_negatives: 184117152.0000 - false_negatives: 4283788.0000 - precision: 0.9671 - recall: 0.9673 - val_loss: 0.1236 - val_accuracy: 0.8951 - val_binary_iou: 0.8072 - val_true_positives: 40229208.0000 - val_false_positives: 6302173.0000 - val_true_negatives: 54622848.0000 - val_false_negatives: 4817497.0000 - val_precision: 0.8646 - val_recall: 0.8931\n",
      "Epoch 113/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0338 - accuracy: 0.9727 - binary_iou: 0.9452 - true_positives: 126757632.0000 - false_positives: 4312104.0000 - true_negatives: 184041616.0000 - false_negatives: 4409442.0000 - precision: 0.9671 - recall: 0.9664 - val_loss: 0.1190 - val_accuracy: 0.8982 - val_binary_iou: 0.8124 - val_true_positives: 40569468.0000 - val_false_positives: 6338738.0000 - val_true_negatives: 54609308.0000 - val_false_negatives: 4454201.0000 - val_precision: 0.8649 - val_recall: 0.9011\n",
      "Epoch 114/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0334 - accuracy: 0.9731 - binary_iou: 0.9459 - true_positives: 126799784.0000 - false_positives: 4276012.0000 - true_negatives: 184113600.0000 - false_negatives: 4331404.0000 - precision: 0.9674 - recall: 0.9670 - val_loss: 0.1208 - val_accuracy: 0.8964 - val_binary_iou: 0.8095 - val_true_positives: 40472488.0000 - val_false_positives: 6356568.0000 - val_true_negatives: 54520264.0000 - val_false_negatives: 4622399.0000 - val_precision: 0.8643 - val_recall: 0.8975\n",
      "Epoch 115/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0332 - accuracy: 0.9731 - binary_iou: 0.9460 - true_positives: 126867360.0000 - false_positives: 4291189.0000 - true_negatives: 184070112.0000 - false_negatives: 4292143.0000 - precision: 0.9673 - recall: 0.9673 - val_loss: 0.1200 - val_accuracy: 0.8960 - val_binary_iou: 0.8093 - val_true_positives: 41025252.0000 - val_false_positives: 6884398.0000 - val_true_negatives: 53928084.0000 - val_false_negatives: 4133972.0000 - val_precision: 0.8563 - val_recall: 0.9085\n",
      "Epoch 116/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0329 - accuracy: 0.9734 - binary_iou: 0.9465 - true_positives: 126780976.0000 - false_positives: 4201263.0000 - true_negatives: 184232048.0000 - false_negatives: 4306548.0000 - precision: 0.9679 - recall: 0.9671 - val_loss: 0.1200 - val_accuracy: 0.8952 - val_binary_iou: 0.8080 - val_true_positives: 41145660.0000 - val_false_positives: 7049656.0000 - val_true_negatives: 53716640.0000 - val_false_negatives: 4059752.0000 - val_precision: 0.8537 - val_recall: 0.9102\n",
      "Epoch 117/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0326 - accuracy: 0.9736 - binary_iou: 0.9470 - true_positives: 126930632.0000 - false_positives: 4209346.0000 - true_negatives: 184168512.0000 - false_negatives: 4212304.0000 - precision: 0.9679 - recall: 0.9679 - val_loss: 0.1224 - val_accuracy: 0.8936 - val_binary_iou: 0.8051 - val_true_positives: 40627280.0000 - val_false_positives: 6850225.0000 - val_true_negatives: 54068968.0000 - val_false_negatives: 4425233.0000 - val_precision: 0.8557 - val_recall: 0.9018\n",
      "Epoch 118/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0323 - accuracy: 0.9738 - binary_iou: 0.9474 - true_positives: 126949784.0000 - false_positives: 4148367.0000 - true_negatives: 184204544.0000 - false_negatives: 4218108.0000 - precision: 0.9684 - recall: 0.9678 - val_loss: 0.1173 - val_accuracy: 0.8996 - val_binary_iou: 0.8150 - val_true_positives: 40754492.0000 - val_false_positives: 6249336.0000 - val_true_negatives: 54581868.0000 - val_false_negatives: 4386014.0000 - val_precision: 0.8670 - val_recall: 0.9028\n",
      "Epoch 119/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0326 - accuracy: 0.9736 - binary_iou: 0.9470 - true_positives: 126806992.0000 - false_positives: 4167234.0000 - true_negatives: 184291552.0000 - false_negatives: 4254941.0000 - precision: 0.9682 - recall: 0.9675 - val_loss: 0.1220 - val_accuracy: 0.8958 - val_binary_iou: 0.8084 - val_true_positives: 40363136.0000 - val_false_positives: 6321843.0000 - val_true_negatives: 54563520.0000 - val_false_negatives: 4723219.0000 - val_precision: 0.8646 - val_recall: 0.8952\n",
      "Epoch 120/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0320 - accuracy: 0.9741 - binary_iou: 0.9480 - true_positives: 127001424.0000 - false_positives: 4125654.0000 - true_negatives: 184252656.0000 - false_negatives: 4141013.0000 - precision: 0.9685 - recall: 0.9684 - val_loss: 0.1189 - val_accuracy: 0.8979 - val_binary_iou: 0.8122 - val_true_positives: 40702264.0000 - val_false_positives: 6491146.0000 - val_true_negatives: 54454612.0000 - val_false_negatives: 4323671.0000 - val_precision: 0.8625 - val_recall: 0.9040\n",
      "Epoch 121/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0318 - accuracy: 0.9743 - binary_iou: 0.9483 - true_positives: 127050280.0000 - false_positives: 4076635.0000 - true_negatives: 184257664.0000 - false_negatives: 4136190.0000 - precision: 0.9689 - recall: 0.9685 - val_loss: 0.1158 - val_accuracy: 0.8995 - val_binary_iou: 0.8150 - val_true_positives: 41051032.0000 - val_false_positives: 6519950.0000 - val_true_negatives: 54274980.0000 - val_false_negatives: 4125756.0000 - val_precision: 0.8629 - val_recall: 0.9087\n",
      "Epoch 122/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0320 - accuracy: 0.9742 - binary_iou: 0.9481 - true_positives: 126962608.0000 - false_positives: 4112492.0000 - true_negatives: 184315872.0000 - false_negatives: 4129769.0000 - precision: 0.9686 - recall: 0.9685 - val_loss: 0.1183 - val_accuracy: 0.8984 - val_binary_iou: 0.8130 - val_true_positives: 40808588.0000 - val_false_positives: 6468702.0000 - val_true_negatives: 54395220.0000 - val_false_negatives: 4299205.0000 - val_precision: 0.8632 - val_recall: 0.9047\n",
      "Epoch 123/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0320 - accuracy: 0.9742 - binary_iou: 0.9480 - true_positives: 126973488.0000 - false_positives: 4100056.0000 - true_negatives: 184291776.0000 - false_negatives: 4155481.0000 - precision: 0.9687 - recall: 0.9683 - val_loss: 0.1163 - val_accuracy: 0.9004 - val_binary_iou: 0.8163 - val_true_positives: 40762016.0000 - val_false_positives: 6143717.0000 - val_true_negatives: 54657596.0000 - val_false_negatives: 4408369.0000 - val_precision: 0.8690 - val_recall: 0.9024\n",
      "Epoch 124/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0315 - accuracy: 0.9745 - binary_iou: 0.9487 - true_positives: 126995048.0000 - false_positives: 4061460.0000 - true_negatives: 184373920.0000 - false_negatives: 4090377.0000 - precision: 0.9690 - recall: 0.9688 - val_loss: 0.1207 - val_accuracy: 0.8970 - val_binary_iou: 0.8102 - val_true_positives: 40147552.0000 - val_false_positives: 5999407.0000 - val_true_negatives: 54905200.0000 - val_false_negatives: 4919555.0000 - val_precision: 0.8700 - val_recall: 0.8908\n",
      "Epoch 125/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0318 - accuracy: 0.9743 - binary_iou: 0.9483 - true_positives: 126895880.0000 - false_positives: 4029320.0000 - true_negatives: 184421472.0000 - false_negatives: 4174135.0000 - precision: 0.9692 - recall: 0.9682 - val_loss: 0.1206 - val_accuracy: 0.8954 - val_binary_iou: 0.8083 - val_true_positives: 40945824.0000 - val_false_positives: 6977920.0000 - val_true_negatives: 53943568.0000 - val_false_negatives: 4104398.0000 - val_precision: 0.8544 - val_recall: 0.9089\n",
      "Epoch 126/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0312 - accuracy: 0.9747 - binary_iou: 0.9492 - true_positives: 127059504.0000 - false_positives: 3986961.0000 - true_negatives: 184388512.0000 - false_negatives: 4085929.0000 - precision: 0.9696 - recall: 0.9688 - val_loss: 0.1189 - val_accuracy: 0.8962 - val_binary_iou: 0.8098 - val_true_positives: 41400384.0000 - val_false_positives: 7258941.0000 - val_true_negatives: 53566468.0000 - val_false_negatives: 3745912.0000 - val_precision: 0.8508 - val_recall: 0.9170\n",
      "Epoch 127/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0311 - accuracy: 0.9749 - binary_iou: 0.9494 - true_positives: 127145520.0000 - false_positives: 4055427.0000 - true_negatives: 184348656.0000 - false_negatives: 3971176.0000 - precision: 0.9691 - recall: 0.9697 - val_loss: 0.1186 - val_accuracy: 0.8988 - val_binary_iou: 0.8136 - val_true_positives: 40771548.0000 - val_false_positives: 6435423.0000 - val_true_negatives: 54471360.0000 - val_false_negatives: 4293373.0000 - val_precision: 0.8637 - val_recall: 0.9047\n",
      "Epoch 128/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0306 - accuracy: 0.9753 - binary_iou: 0.9502 - true_positives: 127195808.0000 - false_positives: 3926520.0000 - true_negatives: 184424848.0000 - false_negatives: 3973600.0000 - precision: 0.9701 - recall: 0.9697 - val_loss: 0.1192 - val_accuracy: 0.8977 - val_binary_iou: 0.8116 - val_true_positives: 40488488.0000 - val_false_positives: 6178631.0000 - val_true_negatives: 54641768.0000 - val_false_negatives: 4662822.0000 - val_precision: 0.8676 - val_recall: 0.8967\n",
      "Epoch 129/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0307 - accuracy: 0.9753 - binary_iou: 0.9502 - true_positives: 127142512.0000 - false_positives: 3931477.0000 - true_negatives: 184472576.0000 - false_negatives: 3974138.0000 - precision: 0.9700 - recall: 0.9697 - val_loss: 0.1181 - val_accuracy: 0.8972 - val_binary_iou: 0.8114 - val_true_positives: 41252936.0000 - val_false_positives: 7060847.0000 - val_true_negatives: 53823708.0000 - val_false_negatives: 3834225.0000 - val_precision: 0.8539 - val_recall: 0.9150\n",
      "Epoch 130/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0307 - accuracy: 0.9753 - binary_iou: 0.9502 - true_positives: 127150640.0000 - false_positives: 3925494.0000 - true_negatives: 184464912.0000 - false_negatives: 3979753.0000 - precision: 0.9701 - recall: 0.9697 - val_loss: 0.1214 - val_accuracy: 0.8942 - val_binary_iou: 0.8065 - val_true_positives: 41255220.0000 - val_false_positives: 7356539.0000 - val_true_negatives: 53505660.0000 - val_false_negatives: 3854301.0000 - val_precision: 0.8487 - val_recall: 0.9146\n",
      "Epoch 131/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0306 - accuracy: 0.9753 - binary_iou: 0.9502 - true_positives: 127199000.0000 - false_positives: 3956162.0000 - true_negatives: 184417056.0000 - false_negatives: 3948602.0000 - precision: 0.9698 - recall: 0.9699 - val_loss: 0.1162 - val_accuracy: 0.9008 - val_binary_iou: 0.8168 - val_true_positives: 40553900.0000 - val_false_positives: 6004807.0000 - val_true_negatives: 54907204.0000 - val_false_negatives: 4505818.0000 - val_precision: 0.8710 - val_recall: 0.9000\n",
      "Epoch 132/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0304 - accuracy: 0.9754 - binary_iou: 0.9505 - true_positives: 127134680.0000 - false_positives: 3913470.0000 - true_negatives: 184535472.0000 - false_negatives: 3937098.0000 - precision: 0.9701 - recall: 0.9700 - val_loss: 0.1171 - val_accuracy: 0.8990 - val_binary_iou: 0.8142 - val_true_positives: 41166852.0000 - val_false_positives: 6831848.0000 - val_true_negatives: 54099592.0000 - val_false_negatives: 3873416.0000 - val_precision: 0.8577 - val_recall: 0.9140\n",
      "Epoch 133/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0300 - accuracy: 0.9757 - binary_iou: 0.9511 - true_positives: 127208888.0000 - false_positives: 3867753.0000 - true_negatives: 184547712.0000 - false_negatives: 3896461.0000 - precision: 0.9705 - recall: 0.9703 - val_loss: 0.1170 - val_accuracy: 0.8988 - val_binary_iou: 0.8138 - val_true_positives: 41023680.0000 - val_false_positives: 6549019.0000 - val_true_negatives: 54224140.0000 - val_false_negatives: 4174883.0000 - val_precision: 0.8623 - val_recall: 0.9076\n",
      "Epoch 134/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0300 - accuracy: 0.9758 - binary_iou: 0.9512 - true_positives: 127323376.0000 - false_positives: 3856483.0000 - true_negatives: 184456832.0000 - false_negatives: 3884075.0000 - precision: 0.9706 - recall: 0.9704 - val_loss: 0.1158 - val_accuracy: 0.8998 - val_binary_iou: 0.8155 - val_true_positives: 41166504.0000 - val_false_positives: 6663939.0000 - val_true_negatives: 54184724.0000 - val_false_negatives: 3956546.0000 - val_precision: 0.8607 - val_recall: 0.9123\n",
      "Epoch 135/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0298 - accuracy: 0.9758 - binary_iou: 0.9513 - true_positives: 127273752.0000 - false_positives: 3848838.0000 - true_negatives: 184517968.0000 - false_negatives: 3880238.0000 - precision: 0.9706 - recall: 0.9704 - val_loss: 0.1194 - val_accuracy: 0.8965 - val_binary_iou: 0.8101 - val_true_positives: 41136628.0000 - val_false_positives: 7066731.0000 - val_true_negatives: 53864568.0000 - val_false_negatives: 3903798.0000 - val_precision: 0.8534 - val_recall: 0.9133\n",
      "Epoch 136/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0302 - accuracy: 0.9757 - binary_iou: 0.9510 - true_positives: 127167712.0000 - false_positives: 3882576.0000 - true_negatives: 184582176.0000 - false_negatives: 3888314.0000 - precision: 0.9704 - recall: 0.9703 - val_loss: 0.1172 - val_accuracy: 0.8978 - val_binary_iou: 0.8125 - val_true_positives: 41474620.0000 - val_false_positives: 7189002.0000 - val_true_negatives: 53667312.0000 - val_false_negatives: 3640779.0000 - val_precision: 0.8523 - val_recall: 0.9193\n",
      "Epoch 137/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0300 - accuracy: 0.9758 - binary_iou: 0.9513 - true_positives: 127181704.0000 - false_positives: 3844139.0000 - true_negatives: 184613296.0000 - false_negatives: 3881591.0000 - precision: 0.9707 - recall: 0.9704 - val_loss: 0.1193 - val_accuracy: 0.8974 - val_binary_iou: 0.8114 - val_true_positives: 40859644.0000 - val_false_positives: 6604726.0000 - val_true_negatives: 54237924.0000 - val_false_negatives: 4269425.0000 - val_precision: 0.8608 - val_recall: 0.9054\n",
      "Epoch 138/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0296 - accuracy: 0.9760 - binary_iou: 0.9516 - true_positives: 127275040.0000 - false_positives: 3828746.0000 - true_negatives: 184567248.0000 - false_negatives: 3849760.0000 - precision: 0.9708 - recall: 0.9706 - val_loss: 0.1215 - val_accuracy: 0.8950 - val_binary_iou: 0.8075 - val_true_positives: 40966956.0000 - val_false_positives: 6973299.0000 - val_true_negatives: 53873016.0000 - val_false_negatives: 4158451.0000 - val_precision: 0.8545 - val_recall: 0.9078\n",
      "Epoch 139/300\n",
      "199/199 [==============================] - 77s 384ms/step - loss: 0.0294 - accuracy: 0.9762 - binary_iou: 0.9521 - true_positives: 127344912.0000 - false_positives: 3787471.0000 - true_negatives: 184573328.0000 - false_negatives: 3814971.0000 - precision: 0.9711 - recall: 0.9709 - val_loss: 0.1200 - val_accuracy: 0.8967 - val_binary_iou: 0.8104 - val_true_positives: 40910736.0000 - val_false_positives: 6762992.0000 - val_true_negatives: 54116472.0000 - val_false_negatives: 4181506.0000 - val_precision: 0.8581 - val_recall: 0.9073\n",
      "Epoch 140/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0295 - accuracy: 0.9762 - binary_iou: 0.9521 - true_positives: 127353744.0000 - false_positives: 3766693.0000 - true_negatives: 184575248.0000 - false_negatives: 3825096.0000 - precision: 0.9713 - recall: 0.9708 - val_loss: 0.1169 - val_accuracy: 0.8989 - val_binary_iou: 0.8138 - val_true_positives: 40817276.0000 - val_false_positives: 6432876.0000 - val_true_negatives: 54436216.0000 - val_false_negatives: 4285346.0000 - val_precision: 0.8639 - val_recall: 0.9050\n",
      "Epoch 141/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0293 - accuracy: 0.9763 - binary_iou: 0.9523 - true_positives: 127289176.0000 - false_positives: 3760504.0000 - true_negatives: 184669744.0000 - false_negatives: 3801381.0000 - precision: 0.9713 - recall: 0.9710 - val_loss: 0.1204 - val_accuracy: 0.8970 - val_binary_iou: 0.8105 - val_true_positives: 40422340.0000 - val_false_positives: 6188659.0000 - val_true_negatives: 54639248.0000 - val_false_negatives: 4721465.0000 - val_precision: 0.8672 - val_recall: 0.8954\n",
      "Epoch 142/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0293 - accuracy: 0.9763 - binary_iou: 0.9523 - true_positives: 127402960.0000 - false_positives: 3789311.0000 - true_negatives: 184553184.0000 - false_negatives: 3775301.0000 - precision: 0.9711 - recall: 0.9712 - val_loss: 0.1151 - val_accuracy: 0.8998 - val_binary_iou: 0.8155 - val_true_positives: 41271528.0000 - val_false_positives: 6840811.0000 - val_true_negatives: 54076548.0000 - val_false_negatives: 3782813.0000 - val_precision: 0.8578 - val_recall: 0.9160\n",
      "Epoch 143/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0291 - accuracy: 0.9765 - binary_iou: 0.9525 - true_positives: 127372464.0000 - false_positives: 3744909.0000 - true_negatives: 184624608.0000 - false_negatives: 3778853.0000 - precision: 0.9714 - recall: 0.9712 - val_loss: 0.1164 - val_accuracy: 0.8994 - val_binary_iou: 0.8149 - val_true_positives: 41119728.0000 - val_false_positives: 6617569.0000 - val_true_negatives: 54191968.0000 - val_false_negatives: 4042456.0000 - val_precision: 0.8614 - val_recall: 0.9105\n",
      "Epoch 144/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127321792.0000 - false_positives: 3725566.0000 - true_negatives: 184715936.0000 - false_negatives: 3757482.0000 - precision: 0.9716 - recall: 0.9713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 457ms/step - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127321792.0000 - false_positives: 3725566.0000 - true_negatives: 184715936.0000 - false_negatives: 3757482.0000 - precision: 0.9716 - recall: 0.9713 - val_loss: 0.1149 - val_accuracy: 0.9015 - val_binary_iou: 0.8182 - val_true_positives: 40949936.0000 - val_false_positives: 6352211.0000 - val_true_negatives: 54586504.0000 - val_false_negatives: 4083054.0000 - val_precision: 0.8657 - val_recall: 0.9093\n",
      "Epoch 145/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0289 - accuracy: 0.9766 - binary_iou: 0.9528 - true_positives: 127417072.0000 - false_positives: 3745761.0000 - true_negatives: 184627920.0000 - false_negatives: 3729971.0000 - precision: 0.9714 - recall: 0.9716 - val_loss: 0.1178 - val_accuracy: 0.8981 - val_binary_iou: 0.8127 - val_true_positives: 41079236.0000 - val_false_positives: 6731872.0000 - val_true_negatives: 54093396.0000 - val_false_negatives: 4067203.0000 - val_precision: 0.8592 - val_recall: 0.9099\n",
      "Epoch 146/300\n",
      "199/199 [==============================] - 77s 386ms/step - loss: 0.0288 - accuracy: 0.9768 - binary_iou: 0.9531 - true_positives: 127344952.0000 - false_positives: 3696886.0000 - true_negatives: 184747904.0000 - false_negatives: 3730972.0000 - precision: 0.9718 - recall: 0.9715 - val_loss: 0.1165 - val_accuracy: 0.8998 - val_binary_iou: 0.8154 - val_true_positives: 40950520.0000 - val_false_positives: 6457385.0000 - val_true_negatives: 54403836.0000 - val_false_negatives: 4159970.0000 - val_precision: 0.8638 - val_recall: 0.9078\n",
      "Epoch 147/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0288 - accuracy: 0.9767 - binary_iou: 0.9531 - true_positives: 127450744.0000 - false_positives: 3701427.0000 - true_negatives: 184635280.0000 - false_negatives: 3733321.0000 - precision: 0.9718 - recall: 0.9715 - val_loss: 0.1176 - val_accuracy: 0.8975 - val_binary_iou: 0.8120 - val_true_positives: 41531848.0000 - val_false_positives: 7238208.0000 - val_true_negatives: 53574268.0000 - val_false_negatives: 3627388.0000 - val_precision: 0.8516 - val_recall: 0.9197\n",
      "Epoch 148/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0284 - accuracy: 0.9770 - binary_iou: 0.9536 - true_positives: 127380160.0000 - false_positives: 3670820.0000 - true_negatives: 184787472.0000 - false_negatives: 3682265.0000 - precision: 0.9720 - recall: 0.9719 - val_loss: 0.1208 - val_accuracy: 0.8949 - val_binary_iou: 0.8075 - val_true_positives: 41062588.0000 - val_false_positives: 7063887.0000 - val_true_negatives: 53771504.0000 - val_false_negatives: 4073743.0000 - val_precision: 0.8532 - val_recall: 0.9097\n",
      "Epoch 149/300\n",
      "199/199 [==============================] - 77s 385ms/step - loss: 0.0283 - accuracy: 0.9771 - binary_iou: 0.9539 - true_positives: 127459984.0000 - false_positives: 3640265.0000 - true_negatives: 184756192.0000 - false_negatives: 3664363.0000 - precision: 0.9722 - recall: 0.9721 - val_loss: 0.1177 - val_accuracy: 0.8993 - val_binary_iou: 0.8145 - val_true_positives: 40882960.0000 - val_false_positives: 6421701.0000 - val_true_negatives: 54418720.0000 - val_false_negatives: 4248326.0000 - val_precision: 0.8642 - val_recall: 0.9059\n",
      "Epoch 150/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0281 - accuracy: 0.9773 - binary_iou: 0.9542 - true_positives: 127505640.0000 - false_positives: 3627322.0000 - true_negatives: 184765648.0000 - false_negatives: 3622166.0000 - precision: 0.9723 - recall: 0.9724 - val_loss: 0.1166 - val_accuracy: 0.8995 - val_binary_iou: 0.8151 - val_true_positives: 41133632.0000 - val_false_positives: 6626373.0000 - val_true_negatives: 54188732.0000 - val_false_negatives: 4022974.0000 - val_precision: 0.8613 - val_recall: 0.9109\n",
      "Epoch 151/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0278 - accuracy: 0.9775 - binary_iou: 0.9545 - true_positives: 127557152.0000 - false_positives: 3574210.0000 - true_negatives: 184763600.0000 - false_negatives: 3625748.0000 - precision: 0.9727 - recall: 0.9724 - val_loss: 0.1168 - val_accuracy: 0.8994 - val_binary_iou: 0.8148 - val_true_positives: 41092612.0000 - val_false_positives: 6592848.0000 - val_true_negatives: 54218044.0000 - val_false_negatives: 4068191.0000 - val_precision: 0.8617 - val_recall: 0.9099\n",
      "Epoch 152/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0282 - accuracy: 0.9773 - binary_iou: 0.9541 - true_positives: 127578080.0000 - false_positives: 3663855.0000 - true_negatives: 184678288.0000 - false_negatives: 3600609.0000 - precision: 0.9721 - recall: 0.9726 - val_loss: 0.1169 - val_accuracy: 0.8986 - val_binary_iou: 0.8137 - val_true_positives: 41235320.0000 - val_false_positives: 6831751.0000 - val_true_negatives: 53994548.0000 - val_false_negatives: 3910098.0000 - val_precision: 0.8579 - val_recall: 0.9134\n",
      "Epoch 153/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0277 - accuracy: 0.9776 - binary_iou: 0.9548 - true_positives: 127527616.0000 - false_positives: 3591113.0000 - true_negatives: 184830528.0000 - false_negatives: 3571582.0000 - precision: 0.9726 - recall: 0.9728 - val_loss: 0.1165 - val_accuracy: 0.8997 - val_binary_iou: 0.8153 - val_true_positives: 41039228.0000 - val_false_positives: 6621291.0000 - val_true_negatives: 54304972.0000 - val_false_negatives: 4006225.0000 - val_precision: 0.8611 - val_recall: 0.9111\n",
      "Epoch 154/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0274 - accuracy: 0.9778 - binary_iou: 0.9553 - true_positives: 127512560.0000 - false_positives: 3538539.0000 - true_negatives: 184926672.0000 - false_negatives: 3543061.0000 - precision: 0.9730 - recall: 0.9730 - val_loss: 0.1169 - val_accuracy: 0.8984 - val_binary_iou: 0.8134 - val_true_positives: 41211216.0000 - val_false_positives: 6852340.0000 - val_true_negatives: 53997484.0000 - val_false_negatives: 3910667.0000 - val_precision: 0.8574 - val_recall: 0.9133\n",
      "Epoch 155/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0275 - accuracy: 0.9778 - binary_iou: 0.9552 - true_positives: 127543024.0000 - false_positives: 3572413.0000 - true_negatives: 184881792.0000 - false_negatives: 3523531.0000 - precision: 0.9728 - recall: 0.9731 - val_loss: 0.1182 - val_accuracy: 0.8983 - val_binary_iou: 0.8130 - val_true_positives: 41006880.0000 - val_false_positives: 6685736.0000 - val_true_negatives: 54186024.0000 - val_false_negatives: 4093077.0000 - val_precision: 0.8598 - val_recall: 0.9092\n",
      "Epoch 156/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0272 - accuracy: 0.9780 - binary_iou: 0.9556 - true_positives: 127531592.0000 - false_positives: 3524928.0000 - true_negatives: 184963040.0000 - false_negatives: 3501227.0000 - precision: 0.9731 - recall: 0.9733 - val_loss: 0.1146 - val_accuracy: 0.9011 - val_binary_iou: 0.8178 - val_true_positives: 41227084.0000 - val_false_positives: 6643525.0000 - val_true_negatives: 54268696.0000 - val_false_negatives: 3832406.0000 - val_precision: 0.8612 - val_recall: 0.9149\n",
      "Epoch 157/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0270 - accuracy: 0.9781 - binary_iou: 0.9557 - true_positives: 127621552.0000 - false_positives: 3522666.0000 - true_negatives: 184886672.0000 - false_negatives: 3489810.0000 - precision: 0.9731 - recall: 0.9734 - val_loss: 0.1144 - val_accuracy: 0.9014 - val_binary_iou: 0.8180 - val_true_positives: 40966972.0000 - val_false_positives: 6355423.0000 - val_true_negatives: 54556240.0000 - val_false_negatives: 4093079.0000 - val_precision: 0.8657 - val_recall: 0.9092\n",
      "Epoch 158/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0274 - accuracy: 0.9778 - binary_iou: 0.9553 - true_positives: 127592680.0000 - false_positives: 3498442.0000 - true_negatives: 184849744.0000 - false_negatives: 3579801.0000 - precision: 0.9733 - recall: 0.9727 - val_loss: 0.1182 - val_accuracy: 0.8972 - val_binary_iou: 0.8115 - val_true_positives: 41319120.0000 - val_false_positives: 7083548.0000 - val_true_negatives: 53761936.0000 - val_false_negatives: 3807113.0000 - val_precision: 0.8537 - val_recall: 0.9156\n",
      "Epoch 159/300\n",
      "199/199 [==============================] - 76s 384ms/step - loss: 0.0274 - accuracy: 0.9779 - binary_iou: 0.9553 - true_positives: 127541160.0000 - false_positives: 3523648.0000 - true_negatives: 184904544.0000 - false_negatives: 3551397.0000 - precision: 0.9731 - recall: 0.9729 - val_loss: 0.1176 - val_accuracy: 0.8991 - val_binary_iou: 0.8143 - val_true_positives: 40895800.0000 - val_false_positives: 6533151.0000 - val_true_negatives: 54385952.0000 - val_false_negatives: 4156799.0000 - val_precision: 0.8623 - val_recall: 0.9077\n",
      "Epoch 160/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0271 - accuracy: 0.9781 - binary_iou: 0.9557 - true_positives: 127651416.0000 - false_positives: 3503752.0000 - true_negatives: 184858592.0000 - false_negatives: 3507038.0000 - precision: 0.9733 - recall: 0.9733 - val_loss: 0.1168 - val_accuracy: 0.8993 - val_binary_iou: 0.8148 - val_true_positives: 41203288.0000 - val_false_positives: 6693123.0000 - val_true_negatives: 54100088.0000 - val_false_negatives: 3975219.0000 - val_precision: 0.8603 - val_recall: 0.9120\n",
      "Epoch 161/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0268 - accuracy: 0.9783 - binary_iou: 0.9561 - true_positives: 127681488.0000 - false_positives: 3471980.0000 - true_negatives: 184890352.0000 - false_negatives: 3476990.0000 - precision: 0.9735 - recall: 0.9735 - val_loss: 0.1183 - val_accuracy: 0.8966 - val_binary_iou: 0.8105 - val_true_positives: 41226444.0000 - val_false_positives: 7045977.0000 - val_true_negatives: 53792324.0000 - val_false_negatives: 3906967.0000 - val_precision: 0.8540 - val_recall: 0.9134\n",
      "Epoch 162/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0269 - accuracy: 0.9782 - binary_iou: 0.9560 - true_positives: 127626128.0000 - false_positives: 3457734.0000 - true_negatives: 184931328.0000 - false_negatives: 3505537.0000 - precision: 0.9736 - recall: 0.9733 - val_loss: 0.1212 - val_accuracy: 0.8944 - val_binary_iou: 0.8069 - val_true_positives: 41235644.0000 - val_false_positives: 7271796.0000 - val_true_negatives: 53548988.0000 - val_false_negatives: 3915282.0000 - val_precision: 0.8501 - val_recall: 0.9133\n",
      "Epoch 163/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0265 - accuracy: 0.9786 - binary_iou: 0.9568 - true_positives: 127696808.0000 - false_positives: 3405003.0000 - true_negatives: 184984960.0000 - false_negatives: 3434011.0000 - precision: 0.9740 - recall: 0.9738 - val_loss: 0.1162 - val_accuracy: 0.8992 - val_binary_iou: 0.8147 - val_true_positives: 41396272.0000 - val_false_positives: 7010789.0000 - val_true_negatives: 53891672.0000 - val_false_negatives: 3672975.0000 - val_precision: 0.8552 - val_recall: 0.9185\n",
      "Epoch 164/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0265 - accuracy: 0.9786 - binary_iou: 0.9567 - true_positives: 127716656.0000 - false_positives: 3420937.0000 - true_negatives: 184962912.0000 - false_negatives: 3420299.0000 - precision: 0.9739 - recall: 0.9739 - val_loss: 0.1140 - val_accuracy: 0.9009 - val_binary_iou: 0.8175 - val_true_positives: 41291284.0000 - val_false_positives: 6741147.0000 - val_true_negatives: 54181572.0000 - val_false_negatives: 3757701.0000 - val_precision: 0.8597 - val_recall: 0.9166\n",
      "Epoch 165/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0265 - accuracy: 0.9786 - binary_iou: 0.9567 - true_positives: 127744656.0000 - false_positives: 3400371.0000 - true_negatives: 184934720.0000 - false_negatives: 3441011.0000 - precision: 0.9741 - recall: 0.9738 - val_loss: 0.1179 - val_accuracy: 0.8971 - val_binary_iou: 0.8112 - val_true_positives: 41123112.0000 - val_false_positives: 7013738.0000 - val_true_negatives: 53949048.0000 - val_false_negatives: 3885812.0000 - val_precision: 0.8543 - val_recall: 0.9137\n",
      "Epoch 166/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0263 - accuracy: 0.9788 - binary_iou: 0.9571 - true_positives: 127801288.0000 - false_positives: 3408320.0000 - true_negatives: 184931824.0000 - false_negatives: 3379333.0000 - precision: 0.9740 - recall: 0.9742 - val_loss: 0.1208 - val_accuracy: 0.8953 - val_binary_iou: 0.8083 - val_true_positives: 41067920.0000 - val_false_positives: 7138950.0000 - val_true_negatives: 53813808.0000 - val_false_negatives: 3951036.0000 - val_precision: 0.8519 - val_recall: 0.9122\n",
      "Epoch 167/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0265 - accuracy: 0.9786 - binary_iou: 0.9568 - true_positives: 127709456.0000 - false_positives: 3417672.0000 - true_negatives: 184972816.0000 - false_negatives: 3420794.0000 - precision: 0.9739 - recall: 0.9739 - val_loss: 0.1191 - val_accuracy: 0.8965 - val_binary_iou: 0.8102 - val_true_positives: 41283888.0000 - val_false_positives: 7029609.0000 - val_true_negatives: 53716116.0000 - val_false_negatives: 3942104.0000 - val_precision: 0.8545 - val_recall: 0.9128\n",
      "Epoch 168/300\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0260 - accuracy: 0.9789 - binary_iou: 0.9574 - true_positives: 127749496.0000 - false_positives: 3350895.0000 - true_negatives: 185038368.0000 - false_negatives: 3382089.0000 - precision: 0.9744 - recall: 0.9742 - val_loss: 0.1157 - val_accuracy: 0.8999 - val_binary_iou: 0.8157 - val_true_positives: 41252068.0000 - val_false_positives: 6702185.0000 - val_true_negatives: 54109704.0000 - val_false_negatives: 3907745.0000 - val_precision: 0.8602 - val_recall: 0.9135\n",
      "Epoch 169/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0262 - accuracy: 0.9787 - binary_iou: 0.9571 - true_positives: 127711536.0000 - false_positives: 3392186.0000 - true_negatives: 185019408.0000 - false_negatives: 3397677.0000 - precision: 0.9741 - recall: 0.9741 - val_loss: 0.1194 - val_accuracy: 0.8971 - val_binary_iou: 0.8109 - val_true_positives: 40762280.0000 - val_false_positives: 6682764.0000 - val_true_negatives: 54309080.0000 - val_false_negatives: 4217597.0000 - val_precision: 0.8591 - val_recall: 0.9062\n",
      "Epoch 170/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0261 - accuracy: 0.9789 - binary_iou: 0.9573 - true_positives: 127806288.0000 - false_positives: 3342055.0000 - true_negatives: 184961472.0000 - false_negatives: 3411008.0000 - precision: 0.9745 - recall: 0.9740 - val_loss: 0.1151 - val_accuracy: 0.9004 - val_binary_iou: 0.8168 - val_true_positives: 41445524.0000 - val_false_positives: 6892815.0000 - val_true_negatives: 53973952.0000 - val_false_negatives: 3659413.0000 - val_precision: 0.8574 - val_recall: 0.9189\n",
      "Epoch 171/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9790 - binary_iou: 0.9575 - true_positives: 127768096.0000 - false_positives: 3387724.0000 - true_negatives: 185040960.0000 - false_negatives: 3324052.0000 - precision: 0.9742 - recall: 0.9746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0260 - accuracy: 0.9790 - binary_iou: 0.9575 - true_positives: 127768096.0000 - false_positives: 3387724.0000 - true_negatives: 185040960.0000 - false_negatives: 3324052.0000 - precision: 0.9742 - recall: 0.9746 - val_loss: 0.1144 - val_accuracy: 0.9018 - val_binary_iou: 0.8186 - val_true_positives: 40926720.0000 - val_false_positives: 6184756.0000 - val_true_negatives: 54633464.0000 - val_false_negatives: 4226772.0000 - val_precision: 0.8687 - val_recall: 0.9064\n",
      "Epoch 172/300\n",
      "199/199 [==============================] - 77s 383ms/step - loss: 0.0260 - accuracy: 0.9790 - binary_iou: 0.9575 - true_positives: 127705200.0000 - false_positives: 3364236.0000 - true_negatives: 185101280.0000 - false_negatives: 3350064.0000 - precision: 0.9743 - recall: 0.9744 - val_loss: 0.1159 - val_accuracy: 0.9000 - val_binary_iou: 0.8160 - val_true_positives: 41257456.0000 - val_false_positives: 6786822.0000 - val_true_negatives: 54118056.0000 - val_false_negatives: 3809376.0000 - val_precision: 0.8587 - val_recall: 0.9155\n",
      "Epoch 173/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0254 - accuracy: 0.9795 - binary_iou: 0.9584 - true_positives: 127747752.0000 - false_positives: 3285680.0000 - true_negatives: 185207280.0000 - false_negatives: 3280082.0000 - precision: 0.9749 - recall: 0.9750 - val_loss: 0.1140 - val_accuracy: 0.9014 - val_binary_iou: 0.8183 - val_true_positives: 41356084.0000 - val_false_positives: 6625081.0000 - val_true_negatives: 54164216.0000 - val_false_negatives: 3826343.0000 - val_precision: 0.8619 - val_recall: 0.9153\n",
      "Epoch 174/300\n",
      "199/199 [==============================] - 76s 383ms/step - loss: 0.0254 - accuracy: 0.9794 - binary_iou: 0.9584 - true_positives: 127814912.0000 - false_positives: 3272809.0000 - true_negatives: 185126480.0000 - false_negatives: 3306630.0000 - precision: 0.9750 - recall: 0.9748 - val_loss: 0.1165 - val_accuracy: 0.8991 - val_binary_iou: 0.8143 - val_true_positives: 41034720.0000 - val_false_positives: 6627620.0000 - val_true_negatives: 54244028.0000 - val_false_negatives: 4065343.0000 - val_precision: 0.8609 - val_recall: 0.9099\n",
      "Epoch 175/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0255 - accuracy: 0.9794 - binary_iou: 0.9584 - true_positives: 127879320.0000 - false_positives: 3303584.0000 - true_negatives: 185066176.0000 - false_negatives: 3271547.0000 - precision: 0.9748 - recall: 0.9751 - val_loss: 0.1173 - val_accuracy: 0.8987 - val_binary_iou: 0.8137 - val_true_positives: 41146240.0000 - val_false_positives: 6701753.0000 - val_true_negatives: 54088448.0000 - val_false_negatives: 4035276.0000 - val_precision: 0.8599 - val_recall: 0.9107\n",
      "Epoch 176/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0252 - accuracy: 0.9796 - binary_iou: 0.9588 - true_positives: 127800784.0000 - false_positives: 3226868.0000 - true_negatives: 185207072.0000 - false_negatives: 3286013.0000 - precision: 0.9754 - recall: 0.9749 - val_loss: 0.1177 - val_accuracy: 0.8978 - val_binary_iou: 0.8124 - val_true_positives: 41243624.0000 - val_false_positives: 6990843.0000 - val_true_negatives: 53900584.0000 - val_false_negatives: 3836654.0000 - val_precision: 0.8551 - val_recall: 0.9149\n",
      "Epoch 177/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0251 - accuracy: 0.9798 - binary_iou: 0.9591 - true_positives: 127867272.0000 - false_positives: 3250217.0000 - true_negatives: 185188784.0000 - false_negatives: 3214479.0000 - precision: 0.9752 - recall: 0.9755 - val_loss: 0.1146 - val_accuracy: 0.9003 - val_binary_iou: 0.8163 - val_true_positives: 41129644.0000 - val_false_positives: 6602763.0000 - val_true_negatives: 54274344.0000 - val_false_negatives: 3964954.0000 - val_precision: 0.8617 - val_recall: 0.9121\n",
      "Epoch 178/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0255 - accuracy: 0.9794 - binary_iou: 0.9584 - true_positives: 127793752.0000 - false_positives: 3296341.0000 - true_negatives: 185146784.0000 - false_negatives: 3283885.0000 - precision: 0.9749 - recall: 0.9749 - val_loss: 0.1172 - val_accuracy: 0.8975 - val_binary_iou: 0.8120 - val_true_positives: 41575972.0000 - val_false_positives: 7271121.0000 - val_true_negatives: 53530672.0000 - val_false_negatives: 3593952.0000 - val_precision: 0.8511 - val_recall: 0.9204\n",
      "Epoch 179/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0251 - accuracy: 0.9797 - binary_iou: 0.9589 - true_positives: 127919408.0000 - false_positives: 3256854.0000 - true_negatives: 185101840.0000 - false_negatives: 3242600.0000 - precision: 0.9752 - recall: 0.9753 - val_loss: 0.1173 - val_accuracy: 0.8988 - val_binary_iou: 0.8137 - val_true_positives: 40897308.0000 - val_false_positives: 6503394.0000 - val_true_negatives: 54348532.0000 - val_false_negatives: 4222464.0000 - val_precision: 0.8628 - val_recall: 0.9064\n",
      "Epoch 180/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0250 - accuracy: 0.9798 - binary_iou: 0.9591 - true_positives: 127814216.0000 - false_positives: 3214578.0000 - true_negatives: 185253104.0000 - false_negatives: 3238921.0000 - precision: 0.9755 - recall: 0.9753 - val_loss: 0.1169 - val_accuracy: 0.8990 - val_binary_iou: 0.8144 - val_true_positives: 41343176.0000 - val_false_positives: 6920385.0000 - val_true_negatives: 53929080.0000 - val_false_negatives: 3779069.0000 - val_precision: 0.8566 - val_recall: 0.9162\n",
      "Epoch 181/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0246 - accuracy: 0.9801 - binary_iou: 0.9597 - true_positives: 128038000.0000 - false_positives: 3199457.0000 - true_negatives: 185122576.0000 - false_negatives: 3160728.0000 - precision: 0.9756 - recall: 0.9759 - val_loss: 0.1178 - val_accuracy: 0.8986 - val_binary_iou: 0.8132 - val_true_positives: 40759760.0000 - val_false_positives: 6346590.0000 - val_true_negatives: 54462016.0000 - val_false_negatives: 4403358.0000 - val_precision: 0.8653 - val_recall: 0.9025\n",
      "Epoch 182/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0249 - accuracy: 0.9799 - binary_iou: 0.9594 - true_positives: 127932456.0000 - false_positives: 3214982.0000 - true_negatives: 185168608.0000 - false_negatives: 3204691.0000 - precision: 0.9755 - recall: 0.9756 - val_loss: 0.1199 - val_accuracy: 0.8968 - val_binary_iou: 0.8105 - val_true_positives: 40993664.0000 - val_false_positives: 6883486.0000 - val_true_negatives: 54038896.0000 - val_false_negatives: 4055663.0000 - val_precision: 0.8562 - val_recall: 0.9100\n",
      "Epoch 183/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0247 - accuracy: 0.9801 - binary_iou: 0.9597 - true_positives: 127859384.0000 - false_positives: 3166264.0000 - true_negatives: 185295696.0000 - false_negatives: 3199423.0000 - precision: 0.9758 - recall: 0.9756 - val_loss: 0.1173 - val_accuracy: 0.8977 - val_binary_iou: 0.8122 - val_true_positives: 41358824.0000 - val_false_positives: 7073157.0000 - val_true_negatives: 53769552.0000 - val_false_negatives: 3770166.0000 - val_precision: 0.8540 - val_recall: 0.9165\n",
      "Epoch 184/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9800 - binary_iou: 0.9595 - true_positives: 127926184.0000 - false_positives: 3190944.0000 - true_negatives: 185204528.0000 - false_negatives: 3199192.0000 - precision: 0.9757 - recall: 0.9756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0248 - accuracy: 0.9800 - binary_iou: 0.9595 - true_positives: 127926184.0000 - false_positives: 3190944.0000 - true_negatives: 185204528.0000 - false_negatives: 3199192.0000 - precision: 0.9757 - recall: 0.9756 - val_loss: 0.1144 - val_accuracy: 0.9019 - val_binary_iou: 0.8190 - val_true_positives: 41212236.0000 - val_false_positives: 6565922.0000 - val_true_negatives: 54359640.0000 - val_false_negatives: 3833913.0000 - val_precision: 0.8626 - val_recall: 0.9149\n",
      "Epoch 185/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0245 - accuracy: 0.9802 - binary_iou: 0.9600 - true_positives: 127993776.0000 - false_positives: 3153454.0000 - true_negatives: 185205328.0000 - false_negatives: 3168139.0000 - precision: 0.9760 - recall: 0.9758 - val_loss: 0.1168 - val_accuracy: 0.8983 - val_binary_iou: 0.8134 - val_true_positives: 41475832.0000 - val_false_positives: 7056995.0000 - val_true_negatives: 53723568.0000 - val_false_negatives: 3715323.0000 - val_precision: 0.8546 - val_recall: 0.9178\n",
      "Epoch 186/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9601 - true_positives: 128000320.0000 - false_positives: 3161783.0000 - true_negatives: 185214320.0000 - false_negatives: 3144432.0000 - precision: 0.9759 - recall: 0.9760 - val_loss: 0.1159 - val_accuracy: 0.8997 - val_binary_iou: 0.8154 - val_true_positives: 41202804.0000 - val_false_positives: 6652428.0000 - val_true_negatives: 54139496.0000 - val_false_negatives: 3976984.0000 - val_precision: 0.8610 - val_recall: 0.9120\n",
      "Epoch 187/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9805 - binary_iou: 0.9604 - true_positives: 127973736.0000 - false_positives: 3124180.0000 - true_negatives: 185304560.0000 - false_negatives: 3118269.0000 - precision: 0.9762 - recall: 0.9762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0241 - accuracy: 0.9805 - binary_iou: 0.9604 - true_positives: 127973736.0000 - false_positives: 3124180.0000 - true_negatives: 185304560.0000 - false_negatives: 3118269.0000 - precision: 0.9762 - recall: 0.9762 - val_loss: 0.1133 - val_accuracy: 0.9021 - val_binary_iou: 0.8194 - val_true_positives: 41338408.0000 - val_false_positives: 6575537.0000 - val_true_negatives: 54254872.0000 - val_false_negatives: 3802905.0000 - val_precision: 0.8628 - val_recall: 0.9158\n",
      "Epoch 188/300\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0244 - accuracy: 0.9803 - binary_iou: 0.9600 - true_positives: 127973032.0000 - false_positives: 3147553.0000 - true_negatives: 185238720.0000 - false_negatives: 3161487.0000 - precision: 0.9760 - recall: 0.9759 - val_loss: 0.1161 - val_accuracy: 0.8993 - val_binary_iou: 0.8149 - val_true_positives: 41301604.0000 - val_false_positives: 6851404.0000 - val_true_negatives: 54003020.0000 - val_false_negatives: 3815686.0000 - val_precision: 0.8577 - val_recall: 0.9154\n",
      "Epoch 189/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0245 - accuracy: 0.9802 - binary_iou: 0.9599 - true_positives: 127921728.0000 - false_positives: 3151528.0000 - true_negatives: 185269936.0000 - false_negatives: 3177523.0000 - precision: 0.9760 - recall: 0.9758 - val_loss: 0.1178 - val_accuracy: 0.8965 - val_binary_iou: 0.8104 - val_true_positives: 41518312.0000 - val_false_positives: 7365267.0000 - val_true_negatives: 53485600.0000 - val_false_negatives: 3602536.0000 - val_precision: 0.8493 - val_recall: 0.9202\n",
      "Epoch 190/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0243 - accuracy: 0.9803 - binary_iou: 0.9601 - true_positives: 127939256.0000 - false_positives: 3144492.0000 - true_negatives: 185281488.0000 - false_negatives: 3155487.0000 - precision: 0.9760 - recall: 0.9759 - val_loss: 0.1201 - val_accuracy: 0.8943 - val_binary_iou: 0.8068 - val_true_positives: 41542956.0000 - val_false_positives: 7605111.0000 - val_true_negatives: 53223612.0000 - val_false_negatives: 3600022.0000 - val_precision: 0.8453 - val_recall: 0.9203\n",
      "Epoch 191/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0244 - accuracy: 0.9802 - binary_iou: 0.9600 - true_positives: 127974712.0000 - false_positives: 3160958.0000 - true_negatives: 185230224.0000 - false_negatives: 3154906.0000 - precision: 0.9759 - recall: 0.9759 - val_loss: 0.1147 - val_accuracy: 0.9005 - val_binary_iou: 0.8168 - val_true_positives: 41279984.0000 - val_false_positives: 6719768.0000 - val_true_negatives: 54152224.0000 - val_false_negatives: 3819738.0000 - val_precision: 0.8600 - val_recall: 0.9153\n",
      "Epoch 192/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0241 - accuracy: 0.9805 - binary_iou: 0.9606 - true_positives: 128011528.0000 - false_positives: 3089482.0000 - true_negatives: 185283600.0000 - false_negatives: 3136134.0000 - precision: 0.9764 - recall: 0.9761 - val_loss: 0.1132 - val_accuracy: 0.9010 - val_binary_iou: 0.8177 - val_true_positives: 41459544.0000 - val_false_positives: 6826572.0000 - val_true_negatives: 54018408.0000 - val_false_negatives: 3667189.0000 - val_precision: 0.8586 - val_recall: 0.9187\n",
      "Epoch 193/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0238 - accuracy: 0.9807 - binary_iou: 0.9609 - true_positives: 128088728.0000 - false_positives: 3077849.0000 - true_negatives: 185264560.0000 - false_negatives: 3089563.0000 - precision: 0.9765 - recall: 0.9764 - val_loss: 0.1138 - val_accuracy: 0.9017 - val_binary_iou: 0.8188 - val_true_positives: 41272912.0000 - val_false_positives: 6564801.0000 - val_true_negatives: 54286376.0000 - val_false_negatives: 3847634.0000 - val_precision: 0.8628 - val_recall: 0.9147\n",
      "Epoch 194/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0238 - accuracy: 0.9807 - binary_iou: 0.9610 - true_positives: 128124896.0000 - false_positives: 3078480.0000 - true_negatives: 185239072.0000 - false_negatives: 3078381.0000 - precision: 0.9765 - recall: 0.9765 - val_loss: 0.1150 - val_accuracy: 0.9002 - val_binary_iou: 0.8163 - val_true_positives: 41207412.0000 - val_false_positives: 6627336.0000 - val_true_negatives: 54191636.0000 - val_false_negatives: 3945320.0000 - val_precision: 0.8615 - val_recall: 0.9126\n",
      "Epoch 195/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0237 - accuracy: 0.9808 - binary_iou: 0.9612 - true_positives: 128060624.0000 - false_positives: 3050934.0000 - true_negatives: 185338304.0000 - false_negatives: 3070897.0000 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.1176 - val_accuracy: 0.8976 - val_binary_iou: 0.8120 - val_true_positives: 41229376.0000 - val_false_positives: 6971668.0000 - val_true_negatives: 53887848.0000 - val_false_negatives: 3882817.0000 - val_precision: 0.8554 - val_recall: 0.9139\n",
      "Epoch 196/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0236 - accuracy: 0.9809 - binary_iou: 0.9613 - true_positives: 127977456.0000 - false_positives: 3052508.0000 - true_negatives: 185430688.0000 - false_negatives: 3060126.0000 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.1143 - val_accuracy: 0.9013 - val_binary_iou: 0.8180 - val_true_positives: 41125112.0000 - val_false_positives: 6543941.0000 - val_true_negatives: 54388200.0000 - val_false_negatives: 3914452.0000 - val_precision: 0.8627 - val_recall: 0.9131\n",
      "Epoch 197/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0237 - accuracy: 0.9809 - binary_iou: 0.9612 - true_positives: 128017808.0000 - false_positives: 3055503.0000 - true_negatives: 185386464.0000 - false_negatives: 3061035.0000 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.1183 - val_accuracy: 0.8972 - val_binary_iou: 0.8113 - val_true_positives: 41094436.0000 - val_false_positives: 6871320.0000 - val_true_negatives: 53983152.0000 - val_false_negatives: 4022807.0000 - val_precision: 0.8567 - val_recall: 0.9108\n",
      "Epoch 198/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0235 - accuracy: 0.9810 - binary_iou: 0.9616 - true_positives: 128088576.0000 - false_positives: 3028320.0000 - true_negatives: 185375264.0000 - false_negatives: 3028634.0000 - precision: 0.9769 - recall: 0.9769 - val_loss: 0.1160 - val_accuracy: 0.8994 - val_binary_iou: 0.8152 - val_true_positives: 41570352.0000 - val_false_positives: 7089894.0000 - val_true_negatives: 53740884.0000 - val_false_negatives: 3570578.0000 - val_precision: 0.8543 - val_recall: 0.9209\n",
      "Epoch 199/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9616 - true_positives: 128189872.0000 - false_positives: 3039186.0000 - true_negatives: 185277968.0000 - false_negatives: 3013764.0000 - precision: 0.9768 - recall: 0.9770 - val_loss: 0.1169 - val_accuracy: 0.8984 - val_binary_iou: 0.8134 - val_true_positives: 41341228.0000 - val_false_positives: 7079218.0000 - val_true_negatives: 53866960.0000 - val_false_negatives: 3684307.0000 - val_precision: 0.8538 - val_recall: 0.9182\n",
      "Epoch 200/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0234 - accuracy: 0.9811 - binary_iou: 0.9617 - true_positives: 128083184.0000 - false_positives: 3008838.0000 - true_negatives: 185398176.0000 - false_negatives: 3030603.0000 - precision: 0.9770 - recall: 0.9769 - val_loss: 0.1180 - val_accuracy: 0.8977 - val_binary_iou: 0.8123 - val_true_positives: 41462712.0000 - val_false_positives: 7243105.0000 - val_true_negatives: 53667888.0000 - val_false_negatives: 3598006.0000 - val_precision: 0.8513 - val_recall: 0.9202\n",
      "Epoch 201/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0233 - accuracy: 0.9811 - binary_iou: 0.9618 - true_positives: 128144936.0000 - false_positives: 3019790.0000 - true_negatives: 185344208.0000 - false_negatives: 3011872.0000 - precision: 0.9770 - recall: 0.9770 - val_loss: 0.1182 - val_accuracy: 0.8974 - val_binary_iou: 0.8116 - val_true_positives: 41079872.0000 - val_false_positives: 6815943.0000 - val_true_negatives: 54022320.0000 - val_false_negatives: 4053576.0000 - val_precision: 0.8577 - val_recall: 0.9102\n",
      "Epoch 202/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0231 - accuracy: 0.9814 - binary_iou: 0.9622 - true_positives: 128228320.0000 - false_positives: 2981492.0000 - true_negatives: 185334432.0000 - false_negatives: 2976513.0000 - precision: 0.9773 - recall: 0.9773 - val_loss: 0.1154 - val_accuracy: 0.9005 - val_binary_iou: 0.8169 - val_true_positives: 41441860.0000 - val_false_positives: 6899521.0000 - val_true_negatives: 53988396.0000 - val_false_negatives: 3641939.0000 - val_precision: 0.8573 - val_recall: 0.9192\n",
      "Epoch 203/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9814 - binary_iou: 0.9623 - true_positives: 128186712.0000 - false_positives: 2971915.0000 - true_negatives: 185396560.0000 - false_negatives: 2965596.0000 - precision: 0.9773 - recall: 0.9774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 460ms/step - loss: 0.0230 - accuracy: 0.9814 - binary_iou: 0.9623 - true_positives: 128186712.0000 - false_positives: 2971915.0000 - true_negatives: 185396560.0000 - false_negatives: 2965596.0000 - precision: 0.9773 - recall: 0.9774 - val_loss: 0.1125 - val_accuracy: 0.9035 - val_binary_iou: 0.8215 - val_true_positives: 40935580.0000 - val_false_positives: 6058089.0000 - val_true_negatives: 54812840.0000 - val_false_negatives: 4165202.0000 - val_precision: 0.8711 - val_recall: 0.9076\n",
      "Epoch 204/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0230 - accuracy: 0.9814 - binary_iou: 0.9623 - true_positives: 128194960.0000 - false_positives: 2969834.0000 - true_negatives: 185381728.0000 - false_negatives: 2974227.0000 - precision: 0.9774 - recall: 0.9773 - val_loss: 0.1132 - val_accuracy: 0.9019 - val_binary_iou: 0.8190 - val_true_positives: 41257772.0000 - val_false_positives: 6542881.0000 - val_true_negatives: 54314956.0000 - val_false_negatives: 3856103.0000 - val_precision: 0.8631 - val_recall: 0.9145\n",
      "Epoch 205/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0227 - accuracy: 0.9815 - binary_iou: 0.9626 - true_positives: 128105040.0000 - false_positives: 2948257.0000 - true_negatives: 185514768.0000 - false_negatives: 2952696.0000 - precision: 0.9775 - recall: 0.9775 - val_loss: 0.1132 - val_accuracy: 0.9026 - val_binary_iou: 0.8201 - val_true_positives: 41168108.0000 - val_false_positives: 6322329.0000 - val_true_negatives: 54479224.0000 - val_false_negatives: 4002054.0000 - val_precision: 0.8669 - val_recall: 0.9114\n",
      "Epoch 206/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0228 - accuracy: 0.9815 - binary_iou: 0.9626 - true_positives: 128148376.0000 - false_positives: 2930083.0000 - true_negatives: 185474736.0000 - false_negatives: 2967524.0000 - precision: 0.9776 - recall: 0.9774 - val_loss: 0.1179 - val_accuracy: 0.8992 - val_binary_iou: 0.8146 - val_true_positives: 41142248.0000 - val_false_positives: 6746400.0000 - val_true_negatives: 54150504.0000 - val_false_negatives: 3932562.0000 - val_precision: 0.8591 - val_recall: 0.9128\n",
      "Epoch 207/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0227 - accuracy: 0.9816 - binary_iou: 0.9627 - true_positives: 128154472.0000 - false_positives: 2948914.0000 - true_negatives: 185481808.0000 - false_negatives: 2935602.0000 - precision: 0.9775 - recall: 0.9776 - val_loss: 0.1138 - val_accuracy: 0.9022 - val_binary_iou: 0.8194 - val_true_positives: 41054212.0000 - val_false_positives: 6380405.0000 - val_true_negatives: 54555576.0000 - val_false_negatives: 3981526.0000 - val_precision: 0.8655 - val_recall: 0.9116\n",
      "Epoch 208/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0227 - accuracy: 0.9816 - binary_iou: 0.9626 - true_positives: 128189280.0000 - false_positives: 2919696.0000 - true_negatives: 185441808.0000 - false_negatives: 2969994.0000 - precision: 0.9777 - recall: 0.9774 - val_loss: 0.1165 - val_accuracy: 0.8987 - val_binary_iou: 0.8139 - val_true_positives: 41383000.0000 - val_false_positives: 7049475.0000 - val_true_negatives: 53854088.0000 - val_false_negatives: 3685156.0000 - val_precision: 0.8544 - val_recall: 0.9182\n",
      "Epoch 209/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0227 - accuracy: 0.9817 - binary_iou: 0.9628 - true_positives: 128291304.0000 - false_positives: 2935377.0000 - true_negatives: 185369440.0000 - false_negatives: 2924641.0000 - precision: 0.9776 - recall: 0.9777 - val_loss: 0.1167 - val_accuracy: 0.8993 - val_binary_iou: 0.8147 - val_true_positives: 41165656.0000 - val_false_positives: 6688924.0000 - val_true_negatives: 54131304.0000 - val_false_negatives: 3985841.0000 - val_precision: 0.8602 - val_recall: 0.9117\n",
      "Epoch 210/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0223 - accuracy: 0.9819 - binary_iou: 0.9633 - true_positives: 128238920.0000 - false_positives: 2890336.0000 - true_negatives: 185489840.0000 - false_negatives: 2901695.0000 - precision: 0.9780 - recall: 0.9779 - val_loss: 0.1155 - val_accuracy: 0.8999 - val_binary_iou: 0.8158 - val_true_positives: 41371720.0000 - val_false_positives: 6847416.0000 - val_true_negatives: 53987532.0000 - val_false_negatives: 3765053.0000 - val_precision: 0.8580 - val_recall: 0.9166\n",
      "Epoch 211/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0221 - accuracy: 0.9821 - binary_iou: 0.9636 - true_positives: 128231512.0000 - false_positives: 2870986.0000 - true_negatives: 185554320.0000 - false_negatives: 2863919.0000 - precision: 0.9781 - recall: 0.9782 - val_loss: 0.1156 - val_accuracy: 0.8999 - val_binary_iou: 0.8159 - val_true_positives: 41469468.0000 - val_false_positives: 6927529.0000 - val_true_negatives: 53892852.0000 - val_false_negatives: 3681856.0000 - val_precision: 0.8569 - val_recall: 0.9185\n",
      "Epoch 212/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0223 - accuracy: 0.9820 - binary_iou: 0.9635 - true_positives: 128190448.0000 - false_positives: 2870278.0000 - true_negatives: 185572160.0000 - false_negatives: 2887874.0000 - precision: 0.9781 - recall: 0.9780 - val_loss: 0.1128 - val_accuracy: 0.9025 - val_binary_iou: 0.8199 - val_true_positives: 41056252.0000 - val_false_positives: 6315100.0000 - val_true_negatives: 54582672.0000 - val_false_negatives: 4017687.0000 - val_precision: 0.8667 - val_recall: 0.9109\n",
      "Epoch 213/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0223 - accuracy: 0.9819 - binary_iou: 0.9634 - true_positives: 128257208.0000 - false_positives: 2881179.0000 - true_negatives: 185487008.0000 - false_negatives: 2895362.0000 - precision: 0.9780 - recall: 0.9779 - val_loss: 0.1146 - val_accuracy: 0.9010 - val_binary_iou: 0.8174 - val_true_positives: 41084784.0000 - val_false_positives: 6464787.0000 - val_true_negatives: 54391280.0000 - val_false_negatives: 4030852.0000 - val_precision: 0.8640 - val_recall: 0.9107\n",
      "Epoch 214/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0223 - accuracy: 0.9820 - binary_iou: 0.9636 - true_positives: 128221048.0000 - false_positives: 2872737.0000 - true_negatives: 185556240.0000 - false_negatives: 2870677.0000 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.1153 - val_accuracy: 0.9009 - val_binary_iou: 0.8172 - val_true_positives: 41016200.0000 - val_false_positives: 6408100.0000 - val_true_negatives: 54449944.0000 - val_false_negatives: 4097469.0000 - val_precision: 0.8649 - val_recall: 0.9092\n",
      "Epoch 215/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0221 - accuracy: 0.9821 - binary_iou: 0.9638 - true_positives: 128336712.0000 - false_positives: 2871438.0000 - true_negatives: 185478576.0000 - false_negatives: 2834042.0000 - precision: 0.9781 - recall: 0.9784 - val_loss: 0.1200 - val_accuracy: 0.8955 - val_binary_iou: 0.8087 - val_true_positives: 41315712.0000 - val_false_positives: 7292969.0000 - val_true_negatives: 53586376.0000 - val_false_negatives: 3776639.0000 - val_precision: 0.8500 - val_recall: 0.9162\n",
      "Epoch 216/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0220 - accuracy: 0.9822 - binary_iou: 0.9638 - true_positives: 128210720.0000 - false_positives: 2854257.0000 - true_negatives: 185612848.0000 - false_negatives: 2842906.0000 - precision: 0.9782 - recall: 0.9783 - val_loss: 0.1156 - val_accuracy: 0.8998 - val_binary_iou: 0.8156 - val_true_positives: 41136544.0000 - val_false_positives: 6680109.0000 - val_true_negatives: 54220336.0000 - val_false_negatives: 3934714.0000 - val_precision: 0.8603 - val_recall: 0.9127\n",
      "Epoch 217/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0218 - accuracy: 0.9823 - binary_iou: 0.9642 - true_positives: 128292192.0000 - false_positives: 2790112.0000 - true_negatives: 185581232.0000 - false_negatives: 2857141.0000 - precision: 0.9787 - recall: 0.9782 - val_loss: 0.1184 - val_accuracy: 0.8979 - val_binary_iou: 0.8124 - val_true_positives: 41139272.0000 - val_false_positives: 6819014.0000 - val_true_negatives: 54008240.0000 - val_false_negatives: 4005198.0000 - val_precision: 0.8578 - val_recall: 0.9113\n",
      "Epoch 218/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0220 - accuracy: 0.9823 - binary_iou: 0.9640 - true_positives: 128217032.0000 - false_positives: 2824485.0000 - true_negatives: 185634688.0000 - false_negatives: 2844481.0000 - precision: 0.9784 - recall: 0.9783 - val_loss: 0.1146 - val_accuracy: 0.9006 - val_binary_iou: 0.8169 - val_true_positives: 41304984.0000 - val_false_positives: 6799947.0000 - val_true_negatives: 54131156.0000 - val_false_negatives: 3735626.0000 - val_precision: 0.8586 - val_recall: 0.9171\n",
      "Epoch 219/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0216 - accuracy: 0.9825 - binary_iou: 0.9645 - true_positives: 128391344.0000 - false_positives: 2814743.0000 - true_negatives: 185530080.0000 - false_negatives: 2784641.0000 - precision: 0.9785 - recall: 0.9788 - val_loss: 0.1154 - val_accuracy: 0.9003 - val_binary_iou: 0.8165 - val_true_positives: 41292596.0000 - val_false_positives: 6883265.0000 - val_true_negatives: 54114332.0000 - val_false_negatives: 3681517.0000 - val_precision: 0.8571 - val_recall: 0.9181\n",
      "Epoch 220/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0217 - accuracy: 0.9825 - binary_iou: 0.9644 - true_positives: 128301776.0000 - false_positives: 2802968.0000 - true_negatives: 185616064.0000 - false_negatives: 2799859.0000 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.1157 - val_accuracy: 0.8995 - val_binary_iou: 0.8153 - val_true_positives: 41584860.0000 - val_false_positives: 7138391.0000 - val_true_negatives: 53736236.0000 - val_false_negatives: 3512221.0000 - val_precision: 0.8535 - val_recall: 0.9221\n",
      "Epoch 221/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0218 - accuracy: 0.9825 - binary_iou: 0.9645 - true_positives: 128364120.0000 - false_positives: 2799793.0000 - true_negatives: 185565984.0000 - false_negatives: 2790885.0000 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.1141 - val_accuracy: 0.9008 - val_binary_iou: 0.8174 - val_true_positives: 41521412.0000 - val_false_positives: 6784169.0000 - val_true_negatives: 53938420.0000 - val_false_negatives: 3727722.0000 - val_precision: 0.8596 - val_recall: 0.9176\n",
      "Epoch 222/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0218 - accuracy: 0.9823 - binary_iou: 0.9641 - true_positives: 128264944.0000 - false_positives: 2814145.0000 - true_negatives: 185604752.0000 - false_negatives: 2836969.0000 - precision: 0.9785 - recall: 0.9784 - val_loss: 0.1182 - val_accuracy: 0.8979 - val_binary_iou: 0.8124 - val_true_positives: 41021128.0000 - val_false_positives: 6748843.0000 - val_true_negatives: 54131744.0000 - val_false_negatives: 4069980.0000 - val_precision: 0.8587 - val_recall: 0.9097\n",
      "Epoch 223/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0218 - accuracy: 0.9824 - binary_iou: 0.9643 - true_positives: 128327544.0000 - false_positives: 2851942.0000 - true_negatives: 185561632.0000 - false_negatives: 2779580.0000 - precision: 0.9783 - recall: 0.9788 - val_loss: 0.1150 - val_accuracy: 0.9003 - val_binary_iou: 0.8164 - val_true_positives: 41345120.0000 - val_false_positives: 6876187.0000 - val_true_negatives: 54057060.0000 - val_false_negatives: 3693351.0000 - val_precision: 0.8574 - val_recall: 0.9180\n",
      "Epoch 224/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0217 - accuracy: 0.9824 - binary_iou: 0.9644 - true_positives: 128314824.0000 - false_positives: 2800065.0000 - true_negatives: 185597200.0000 - false_negatives: 2808618.0000 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.1155 - val_accuracy: 0.9003 - val_binary_iou: 0.8163 - val_true_positives: 41138532.0000 - val_false_positives: 6637981.0000 - val_true_negatives: 54265084.0000 - val_false_negatives: 3930117.0000 - val_precision: 0.8611 - val_recall: 0.9128\n",
      "Epoch 225/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0215 - accuracy: 0.9825 - binary_iou: 0.9646 - true_positives: 128395000.0000 - false_positives: 2785106.0000 - true_negatives: 185542448.0000 - false_negatives: 2798226.0000 - precision: 0.9788 - recall: 0.9787 - val_loss: 0.1134 - val_accuracy: 0.9025 - val_binary_iou: 0.8200 - val_true_positives: 41162456.0000 - val_false_positives: 6337296.0000 - val_true_negatives: 54480236.0000 - val_false_negatives: 3991730.0000 - val_precision: 0.8666 - val_recall: 0.9116\n",
      "Epoch 226/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0214 - accuracy: 0.9827 - binary_iou: 0.9648 - true_positives: 128235376.0000 - false_positives: 2780180.0000 - true_negatives: 185744128.0000 - false_negatives: 2761038.0000 - precision: 0.9788 - recall: 0.9789 - val_loss: 0.1167 - val_accuracy: 0.8993 - val_binary_iou: 0.8145 - val_true_positives: 40936864.0000 - val_false_positives: 6532334.0000 - val_true_negatives: 54360984.0000 - val_false_negatives: 4141527.0000 - val_precision: 0.8624 - val_recall: 0.9081\n",
      "Epoch 227/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0217 - accuracy: 0.9825 - binary_iou: 0.9645 - true_positives: 128363824.0000 - false_positives: 2780619.0000 - true_negatives: 185564032.0000 - false_negatives: 2812276.0000 - precision: 0.9788 - recall: 0.9786 - val_loss: 0.1200 - val_accuracy: 0.8948 - val_binary_iou: 0.8078 - val_true_positives: 41593056.0000 - val_false_positives: 7647113.0000 - val_true_negatives: 53235544.0000 - val_false_negatives: 3495998.0000 - val_precision: 0.8447 - val_recall: 0.9225\n",
      "Epoch 228/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0215 - accuracy: 0.9826 - binary_iou: 0.9646 - true_positives: 128308464.0000 - false_positives: 2791923.0000 - true_negatives: 185643552.0000 - false_negatives: 2776870.0000 - precision: 0.9787 - recall: 0.9788 - val_loss: 0.1146 - val_accuracy: 0.9012 - val_binary_iou: 0.8178 - val_true_positives: 41104464.0000 - val_false_positives: 6549969.0000 - val_true_negatives: 54396712.0000 - val_false_negatives: 3920567.0000 - val_precision: 0.8626 - val_recall: 0.9129\n",
      "Epoch 229/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0212 - accuracy: 0.9829 - binary_iou: 0.9653 - true_positives: 128389704.0000 - false_positives: 2732154.0000 - true_negatives: 185663616.0000 - false_negatives: 2735230.0000 - precision: 0.9792 - recall: 0.9791 - val_loss: 0.1177 - val_accuracy: 0.8973 - val_binary_iou: 0.8116 - val_true_positives: 41339968.0000 - val_false_positives: 7080541.0000 - val_true_negatives: 53745636.0000 - val_false_negatives: 3805576.0000 - val_precision: 0.8538 - val_recall: 0.9157\n",
      "Epoch 230/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0211 - accuracy: 0.9830 - binary_iou: 0.9654 - true_positives: 128408064.0000 - false_positives: 2733607.0000 - true_negatives: 185666960.0000 - false_negatives: 2712106.0000 - precision: 0.9792 - recall: 0.9793 - val_loss: 0.1160 - val_accuracy: 0.9001 - val_binary_iou: 0.8159 - val_true_positives: 40936456.0000 - val_false_positives: 6481059.0000 - val_true_negatives: 54452896.0000 - val_false_negatives: 4101306.0000 - val_precision: 0.8633 - val_recall: 0.9089\n",
      "Epoch 231/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0211 - accuracy: 0.9829 - binary_iou: 0.9653 - true_positives: 128428536.0000 - false_positives: 2737083.0000 - true_negatives: 185631504.0000 - false_negatives: 2723699.0000 - precision: 0.9791 - recall: 0.9792 - val_loss: 0.1160 - val_accuracy: 0.8990 - val_binary_iou: 0.8144 - val_true_positives: 41360056.0000 - val_false_positives: 6887706.0000 - val_true_negatives: 53911420.0000 - val_false_negatives: 3812515.0000 - val_precision: 0.8572 - val_recall: 0.9156\n",
      "Epoch 232/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9655 - true_positives: 128471360.0000 - false_positives: 2717650.0000 - true_negatives: 185621792.0000 - false_negatives: 2710047.0000 - precision: 0.9793 - recall: 0.9793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 91s 459ms/step - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9655 - true_positives: 128471360.0000 - false_positives: 2717650.0000 - true_negatives: 185621792.0000 - false_negatives: 2710047.0000 - precision: 0.9793 - recall: 0.9793 - val_loss: 0.1122 - val_accuracy: 0.9037 - val_binary_iou: 0.8218 - val_true_positives: 40983572.0000 - val_false_positives: 6073201.0000 - val_true_negatives: 54779708.0000 - val_false_negatives: 4135232.0000 - val_precision: 0.8709 - val_recall: 0.9083\n",
      "Epoch 233/300\n",
      "199/199 [==============================] - 78s 388ms/step - loss: 0.0210 - accuracy: 0.9830 - binary_iou: 0.9655 - true_positives: 128377568.0000 - false_positives: 2697423.0000 - true_negatives: 185718304.0000 - false_negatives: 2727516.0000 - precision: 0.9794 - recall: 0.9792 - val_loss: 0.1143 - val_accuracy: 0.9008 - val_binary_iou: 0.8173 - val_true_positives: 41465048.0000 - val_false_positives: 6841121.0000 - val_true_negatives: 53991488.0000 - val_false_negatives: 3674059.0000 - val_precision: 0.8584 - val_recall: 0.9186\n",
      "Epoch 234/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0209 - accuracy: 0.9832 - binary_iou: 0.9659 - true_positives: 128430672.0000 - false_positives: 2706938.0000 - true_negatives: 185715616.0000 - false_negatives: 2667492.0000 - precision: 0.9794 - recall: 0.9797 - val_loss: 0.1123 - val_accuracy: 0.9034 - val_binary_iou: 0.8214 - val_true_positives: 41126904.0000 - val_false_positives: 6227347.0000 - val_true_negatives: 54608020.0000 - val_false_negatives: 4009458.0000 - val_precision: 0.8685 - val_recall: 0.9112\n",
      "Epoch 235/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0209 - accuracy: 0.9831 - binary_iou: 0.9657 - true_positives: 128469040.0000 - false_positives: 2707609.0000 - true_negatives: 185651008.0000 - false_negatives: 2693101.0000 - precision: 0.9794 - recall: 0.9795 - val_loss: 0.1132 - val_accuracy: 0.9006 - val_binary_iou: 0.8171 - val_true_positives: 41626148.0000 - val_false_positives: 7090025.0000 - val_true_negatives: 53808892.0000 - val_false_negatives: 3446657.0000 - val_precision: 0.8545 - val_recall: 0.9235\n",
      "Epoch 236/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0208 - accuracy: 0.9832 - binary_iou: 0.9660 - true_positives: 128472400.0000 - false_positives: 2681006.0000 - true_negatives: 185689888.0000 - false_negatives: 2677470.0000 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.1172 - val_accuracy: 0.8975 - val_binary_iou: 0.8120 - val_true_positives: 41374424.0000 - val_false_positives: 7134353.0000 - val_true_negatives: 53737164.0000 - val_false_negatives: 3725783.0000 - val_precision: 0.8529 - val_recall: 0.9174\n",
      "Epoch 237/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0208 - accuracy: 0.9832 - binary_iou: 0.9658 - true_positives: 128435648.0000 - false_positives: 2683420.0000 - true_negatives: 185707344.0000 - false_negatives: 2694406.0000 - precision: 0.9795 - recall: 0.9795 - val_loss: 0.1140 - val_accuracy: 0.9012 - val_binary_iou: 0.8180 - val_true_positives: 41338272.0000 - val_false_positives: 6647790.0000 - val_true_negatives: 54164036.0000 - val_false_negatives: 3821632.0000 - val_precision: 0.8615 - val_recall: 0.9154\n",
      "Epoch 238/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0206 - accuracy: 0.9833 - binary_iou: 0.9661 - true_positives: 128433832.0000 - false_positives: 2679773.0000 - true_negatives: 185754672.0000 - false_negatives: 2652483.0000 - precision: 0.9796 - recall: 0.9798 - val_loss: 0.1133 - val_accuracy: 0.9017 - val_binary_iou: 0.8187 - val_true_positives: 41323232.0000 - val_false_positives: 6663395.0000 - val_true_negatives: 54228412.0000 - val_false_negatives: 3756677.0000 - val_precision: 0.8611 - val_recall: 0.9167\n",
      "Epoch 239/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0205 - accuracy: 0.9834 - binary_iou: 0.9662 - true_positives: 128492984.0000 - false_positives: 2671078.0000 - true_negatives: 185709808.0000 - false_negatives: 2646931.0000 - precision: 0.9796 - recall: 0.9798 - val_loss: 0.1140 - val_accuracy: 0.9019 - val_binary_iou: 0.8190 - val_true_positives: 41126668.0000 - val_false_positives: 6413070.0000 - val_true_negatives: 54454328.0000 - val_false_negatives: 3977635.0000 - val_precision: 0.8651 - val_recall: 0.9118\n",
      "Epoch 240/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0206 - accuracy: 0.9834 - binary_iou: 0.9662 - true_positives: 128496160.0000 - false_positives: 2648008.0000 - true_negatives: 185710800.0000 - false_negatives: 2665805.0000 - precision: 0.9798 - recall: 0.9797 - val_loss: 0.1148 - val_accuracy: 0.9001 - val_binary_iou: 0.8161 - val_true_positives: 41180528.0000 - val_false_positives: 6631169.0000 - val_true_negatives: 54206668.0000 - val_false_negatives: 3953346.0000 - val_precision: 0.8613 - val_recall: 0.9124\n",
      "Epoch 241/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9664 - true_positives: 128500416.0000 - false_positives: 2657006.0000 - true_negatives: 185740896.0000 - false_negatives: 2622465.0000 - precision: 0.9797 - recall: 0.9800 - val_loss: 0.1171 - val_accuracy: 0.8982 - val_binary_iou: 0.8133 - val_true_positives: 41584196.0000 - val_false_positives: 7198609.0000 - val_true_negatives: 53600792.0000 - val_false_negatives: 3588100.0000 - val_precision: 0.8524 - val_recall: 0.9206\n",
      "Epoch 242/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9664 - true_positives: 128561656.0000 - false_positives: 2657097.0000 - true_negatives: 185672320.0000 - false_negatives: 2629733.0000 - precision: 0.9798 - recall: 0.9800 - val_loss: 0.1153 - val_accuracy: 0.8995 - val_binary_iou: 0.8152 - val_true_positives: 41275312.0000 - val_false_positives: 6905649.0000 - val_true_negatives: 54050048.0000 - val_false_negatives: 3740698.0000 - val_precision: 0.8567 - val_recall: 0.9169\n",
      "Epoch 243/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0204 - accuracy: 0.9835 - binary_iou: 0.9666 - true_positives: 128542400.0000 - false_positives: 2627216.0000 - true_negatives: 185716224.0000 - false_negatives: 2634946.0000 - precision: 0.9800 - recall: 0.9799 - val_loss: 0.1136 - val_accuracy: 0.9016 - val_binary_iou: 0.8186 - val_true_positives: 41378220.0000 - val_false_positives: 6761663.0000 - val_true_negatives: 54163852.0000 - val_false_negatives: 3667972.0000 - val_precision: 0.8595 - val_recall: 0.9186\n",
      "Epoch 244/300\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0203 - accuracy: 0.9836 - binary_iou: 0.9667 - true_positives: 128506152.0000 - false_positives: 2619869.0000 - true_negatives: 185781152.0000 - false_negatives: 2613577.0000 - precision: 0.9800 - recall: 0.9801 - val_loss: 0.1143 - val_accuracy: 0.9007 - val_binary_iou: 0.8171 - val_true_positives: 41293516.0000 - val_false_positives: 6651015.0000 - val_true_negatives: 54151960.0000 - val_false_negatives: 3875219.0000 - val_precision: 0.8613 - val_recall: 0.9142\n",
      "Epoch 245/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0202 - accuracy: 0.9837 - binary_iou: 0.9668 - true_positives: 128571360.0000 - false_positives: 2620297.0000 - true_negatives: 185729040.0000 - false_negatives: 2600066.0000 - precision: 0.9800 - recall: 0.9802 - val_loss: 0.1142 - val_accuracy: 0.9012 - val_binary_iou: 0.8178 - val_true_positives: 41122408.0000 - val_false_positives: 6499834.0000 - val_true_negatives: 54377704.0000 - val_false_negatives: 3971746.0000 - val_precision: 0.8635 - val_recall: 0.9119\n",
      "Epoch 246/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0201 - accuracy: 0.9838 - binary_iou: 0.9671 - true_positives: 128569288.0000 - false_positives: 2598437.0000 - true_negatives: 185771088.0000 - false_negatives: 2581945.0000 - precision: 0.9802 - recall: 0.9803 - val_loss: 0.1131 - val_accuracy: 0.9021 - val_binary_iou: 0.8195 - val_true_positives: 41409512.0000 - val_false_positives: 6658399.0000 - val_true_negatives: 54186120.0000 - val_false_negatives: 3717691.0000 - val_precision: 0.8615 - val_recall: 0.9176\n",
      "Epoch 247/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0201 - accuracy: 0.9837 - binary_iou: 0.9669 - true_positives: 128557976.0000 - false_positives: 2610172.0000 - true_negatives: 185751712.0000 - false_negatives: 2600954.0000 - precision: 0.9801 - recall: 0.9802 - val_loss: 0.1135 - val_accuracy: 0.9006 - val_binary_iou: 0.8171 - val_true_positives: 41618788.0000 - val_false_positives: 6949805.0000 - val_true_negatives: 53818048.0000 - val_false_negatives: 3585060.0000 - val_precision: 0.8569 - val_recall: 0.9207\n",
      "Epoch 248/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0202 - accuracy: 0.9837 - binary_iou: 0.9669 - true_positives: 128511664.0000 - false_positives: 2597846.0000 - true_negatives: 185801520.0000 - false_negatives: 2609746.0000 - precision: 0.9802 - recall: 0.9801 - val_loss: 0.1160 - val_accuracy: 0.8995 - val_binary_iou: 0.8151 - val_true_positives: 41291124.0000 - val_false_positives: 6820235.0000 - val_true_negatives: 54026720.0000 - val_false_negatives: 3833637.0000 - val_precision: 0.8582 - val_recall: 0.9150\n",
      "Epoch 249/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0200 - accuracy: 0.9838 - binary_iou: 0.9671 - true_positives: 128539136.0000 - false_positives: 2588350.0000 - true_negatives: 185804176.0000 - false_negatives: 2589062.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.1160 - val_accuracy: 0.8995 - val_binary_iou: 0.8152 - val_true_positives: 41440504.0000 - val_false_positives: 6988728.0000 - val_true_negatives: 53878416.0000 - val_false_negatives: 3664065.0000 - val_precision: 0.8557 - val_recall: 0.9188\n",
      "Epoch 250/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0198 - accuracy: 0.9839 - binary_iou: 0.9674 - true_positives: 128580336.0000 - false_positives: 2571593.0000 - true_negatives: 185811264.0000 - false_negatives: 2557613.0000 - precision: 0.9804 - recall: 0.9805 - val_loss: 0.1119 - val_accuracy: 0.9020 - val_binary_iou: 0.8195 - val_true_positives: 41543104.0000 - val_false_positives: 6830655.0000 - val_true_negatives: 54048488.0000 - val_false_negatives: 3549449.0000 - val_precision: 0.8588 - val_recall: 0.9213\n",
      "Epoch 251/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0199 - accuracy: 0.9839 - binary_iou: 0.9673 - true_positives: 128536624.0000 - false_positives: 2585270.0000 - true_negatives: 185837904.0000 - false_negatives: 2560945.0000 - precision: 0.9803 - recall: 0.9805 - val_loss: 0.1127 - val_accuracy: 0.9015 - val_binary_iou: 0.8186 - val_true_positives: 41517344.0000 - val_false_positives: 6854208.0000 - val_true_negatives: 54017720.0000 - val_false_negatives: 3582448.0000 - val_precision: 0.8583 - val_recall: 0.9206\n",
      "Epoch 252/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9840 - binary_iou: 0.9675 - true_positives: 128600120.0000 - false_positives: 2547578.0000 - true_negatives: 185810672.0000 - false_negatives: 2562371.0000 - precision: 0.9806 - recall: 0.9805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0197 - accuracy: 0.9840 - binary_iou: 0.9675 - true_positives: 128600120.0000 - false_positives: 2547578.0000 - true_negatives: 185810672.0000 - false_negatives: 2562371.0000 - precision: 0.9806 - recall: 0.9805 - val_loss: 0.1116 - val_accuracy: 0.9041 - val_binary_iou: 0.8226 - val_true_positives: 41217736.0000 - val_false_positives: 6326229.0000 - val_true_negatives: 54590596.0000 - val_false_negatives: 3837162.0000 - val_precision: 0.8669 - val_recall: 0.9148\n",
      "Epoch 253/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0198 - accuracy: 0.9840 - binary_iou: 0.9674 - true_positives: 128518968.0000 - false_positives: 2556228.0000 - true_negatives: 185875072.0000 - false_negatives: 2570496.0000 - precision: 0.9805 - recall: 0.9804 - val_loss: 0.1147 - val_accuracy: 0.9013 - val_binary_iou: 0.8182 - val_true_positives: 41430336.0000 - val_false_positives: 6750144.0000 - val_true_negatives: 54083784.0000 - val_false_negatives: 3707448.0000 - val_precision: 0.8599 - val_recall: 0.9179\n",
      "Epoch 254/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0195 - accuracy: 0.9842 - binary_iou: 0.9678 - true_positives: 128641216.0000 - false_positives: 2537565.0000 - true_negatives: 185819200.0000 - false_negatives: 2522806.0000 - precision: 0.9807 - recall: 0.9808 - val_loss: 0.1143 - val_accuracy: 0.9011 - val_binary_iou: 0.8179 - val_true_positives: 41490552.0000 - val_false_positives: 6853814.0000 - val_true_negatives: 54001928.0000 - val_false_negatives: 3625418.0000 - val_precision: 0.8582 - val_recall: 0.9196\n",
      "Epoch 255/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0198 - accuracy: 0.9840 - binary_iou: 0.9675 - true_positives: 128485280.0000 - false_positives: 2536045.0000 - true_negatives: 185932736.0000 - false_negatives: 2566710.0000 - precision: 0.9806 - recall: 0.9804 - val_loss: 0.1152 - val_accuracy: 0.9003 - val_binary_iou: 0.8164 - val_true_positives: 41205800.0000 - val_false_positives: 6657131.0000 - val_true_negatives: 54202760.0000 - val_false_negatives: 3906031.0000 - val_precision: 0.8609 - val_recall: 0.9134\n",
      "Epoch 256/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128600696.0000 - false_positives: 2531201.0000 - true_negatives: 185852688.0000 - false_negatives: 2536195.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1133 - val_accuracy: 0.9011 - val_binary_iou: 0.8180 - val_true_positives: 41547612.0000 - val_false_positives: 6852045.0000 - val_true_negatives: 53947664.0000 - val_false_negatives: 3624403.0000 - val_precision: 0.8584 - val_recall: 0.9198\n",
      "Epoch 257/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128585984.0000 - false_positives: 2541572.0000 - true_negatives: 185866496.0000 - false_negatives: 2526659.0000 - precision: 0.9806 - recall: 0.9807 - val_loss: 0.1129 - val_accuracy: 0.9013 - val_binary_iou: 0.8182 - val_true_positives: 41584316.0000 - val_false_positives: 6848949.0000 - val_true_negatives: 53925004.0000 - val_false_negatives: 3613424.0000 - val_precision: 0.8586 - val_recall: 0.9201\n",
      "Epoch 258/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128650944.0000 - false_positives: 2544261.0000 - true_negatives: 185805200.0000 - false_negatives: 2520332.0000 - precision: 0.9806 - recall: 0.9808 - val_loss: 0.1134 - val_accuracy: 0.9022 - val_binary_iou: 0.8195 - val_true_positives: 41237916.0000 - val_false_positives: 6512282.0000 - val_true_negatives: 54367280.0000 - val_false_negatives: 3854231.0000 - val_precision: 0.8636 - val_recall: 0.9145\n",
      "Epoch 259/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0196 - accuracy: 0.9841 - binary_iou: 0.9678 - true_positives: 128608912.0000 - false_positives: 2525410.0000 - true_negatives: 185843040.0000 - false_negatives: 2543439.0000 - precision: 0.9807 - recall: 0.9806 - val_loss: 0.1123 - val_accuracy: 0.9024 - val_binary_iou: 0.8199 - val_true_positives: 41422060.0000 - val_false_positives: 6632358.0000 - val_true_negatives: 54202992.0000 - val_false_negatives: 3714308.0000 - val_precision: 0.8620 - val_recall: 0.9177\n",
      "Epoch 260/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0196 - accuracy: 0.9842 - binary_iou: 0.9679 - true_positives: 128638720.0000 - false_positives: 2549737.0000 - true_negatives: 185829760.0000 - false_negatives: 2502508.0000 - precision: 0.9806 - recall: 0.9809 - val_loss: 0.1130 - val_accuracy: 0.9012 - val_binary_iou: 0.8181 - val_true_positives: 41495024.0000 - val_false_positives: 6814214.0000 - val_true_negatives: 54011384.0000 - val_false_negatives: 3651075.0000 - val_precision: 0.8589 - val_recall: 0.9191\n",
      "Epoch 261/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0194 - accuracy: 0.9843 - binary_iou: 0.9682 - true_positives: 128584624.0000 - false_positives: 2488910.0000 - true_negatives: 185930480.0000 - false_negatives: 2516789.0000 - precision: 0.9810 - recall: 0.9808 - val_loss: 0.1116 - val_accuracy: 0.9029 - val_binary_iou: 0.8209 - val_true_positives: 41569632.0000 - val_false_positives: 6704797.0000 - val_true_negatives: 54109644.0000 - val_false_negatives: 3587633.0000 - val_precision: 0.8611 - val_recall: 0.9206\n",
      "Epoch 262/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0190 - accuracy: 0.9846 - binary_iou: 0.9687 - true_positives: 128649224.0000 - false_positives: 2472894.0000 - true_negatives: 185944560.0000 - false_negatives: 2454100.0000 - precision: 0.9811 - recall: 0.9813 - val_loss: 0.1129 - val_accuracy: 0.9016 - val_binary_iou: 0.8186 - val_true_positives: 41405056.0000 - val_false_positives: 6816795.0000 - val_true_negatives: 54136928.0000 - val_false_negatives: 3612929.0000 - val_precision: 0.8586 - val_recall: 0.9197\n",
      "Epoch 263/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0193 - accuracy: 0.9844 - binary_iou: 0.9683 - true_positives: 128528488.0000 - false_positives: 2502730.0000 - true_negatives: 186008736.0000 - false_negatives: 2480853.0000 - precision: 0.9809 - recall: 0.9811 - val_loss: 0.1128 - val_accuracy: 0.9022 - val_binary_iou: 0.8196 - val_true_positives: 41437632.0000 - val_false_positives: 6779581.0000 - val_true_negatives: 54168964.0000 - val_false_negatives: 3585531.0000 - val_precision: 0.8594 - val_recall: 0.9204\n",
      "Epoch 264/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0192 - accuracy: 0.9845 - binary_iou: 0.9684 - true_positives: 128629728.0000 - false_positives: 2488037.0000 - true_negatives: 185925360.0000 - false_negatives: 2477781.0000 - precision: 0.9810 - recall: 0.9811 - val_loss: 0.1132 - val_accuracy: 0.9020 - val_binary_iou: 0.8195 - val_true_positives: 41622512.0000 - val_false_positives: 6799552.0000 - val_true_negatives: 53964752.0000 - val_false_negatives: 3584905.0000 - val_precision: 0.8596 - val_recall: 0.9207\n",
      "Epoch 265/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9686 - true_positives: 128712024.0000 - false_positives: 2465519.0000 - true_negatives: 185880736.0000 - false_negatives: 2462479.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.1141 - val_accuracy: 0.9011 - val_binary_iou: 0.8179 - val_true_positives: 41516388.0000 - val_false_positives: 6842265.0000 - val_true_negatives: 53975856.0000 - val_false_negatives: 3637206.0000 - val_precision: 0.8585 - val_recall: 0.9194\n",
      "Epoch 266/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9685 - true_positives: 128628544.0000 - false_positives: 2482039.0000 - true_negatives: 185943488.0000 - false_negatives: 2466692.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1118 - val_accuracy: 0.9033 - val_binary_iou: 0.8214 - val_true_positives: 41306892.0000 - val_false_positives: 6430027.0000 - val_true_negatives: 54419496.0000 - val_false_negatives: 3815304.0000 - val_precision: 0.8653 - val_recall: 0.9154\n",
      "Epoch 267/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0190 - accuracy: 0.9846 - binary_iou: 0.9688 - true_positives: 128683480.0000 - false_positives: 2459343.0000 - true_negatives: 185931296.0000 - false_negatives: 2446730.0000 - precision: 0.9812 - recall: 0.9813 - val_loss: 0.1138 - val_accuracy: 0.9012 - val_binary_iou: 0.8180 - val_true_positives: 41508476.0000 - val_false_positives: 6910828.0000 - val_true_negatives: 53991036.0000 - val_false_negatives: 3561362.0000 - val_precision: 0.8573 - val_recall: 0.9210\n",
      "Epoch 268/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9687 - true_positives: 128664464.0000 - false_positives: 2467060.0000 - true_negatives: 185934144.0000 - false_negatives: 2455142.0000 - precision: 0.9812 - recall: 0.9813 - val_loss: 0.1122 - val_accuracy: 0.9033 - val_binary_iou: 0.8213 - val_true_positives: 41179000.0000 - val_false_positives: 6272876.0000 - val_true_negatives: 54545760.0000 - val_false_negatives: 3974073.0000 - val_precision: 0.8678 - val_recall: 0.9120\n",
      "Epoch 269/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0190 - accuracy: 0.9846 - binary_iou: 0.9688 - true_positives: 128655080.0000 - false_positives: 2446806.0000 - true_negatives: 185958336.0000 - false_negatives: 2460500.0000 - precision: 0.9813 - recall: 0.9812 - val_loss: 0.1143 - val_accuracy: 0.9006 - val_binary_iou: 0.8171 - val_true_positives: 41454112.0000 - val_false_positives: 6925499.0000 - val_true_negatives: 53984488.0000 - val_false_negatives: 3607607.0000 - val_precision: 0.8569 - val_recall: 0.9199\n",
      "Epoch 270/300\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9690 - true_positives: 128695104.0000 - false_positives: 2453907.0000 - true_negatives: 185948848.0000 - false_negatives: 2422895.0000 - precision: 0.9813 - recall: 0.9815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_AVG_rgbDrop_0.2_earlyStop_False\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 461ms/step - loss: 0.0189 - accuracy: 0.9847 - binary_iou: 0.9690 - true_positives: 128695104.0000 - false_positives: 2453907.0000 - true_negatives: 185948848.0000 - false_negatives: 2422895.0000 - precision: 0.9813 - recall: 0.9815 - val_loss: 0.1104 - val_accuracy: 0.9055 - val_binary_iou: 0.8248 - val_true_positives: 41003172.0000 - val_false_positives: 6007034.0000 - val_true_negatives: 54955320.0000 - val_false_negatives: 4006192.0000 - val_precision: 0.8722 - val_recall: 0.9110\n",
      "Epoch 271/300\n",
      "199/199 [==============================] - 78s 389ms/step - loss: 0.0187 - accuracy: 0.9848 - binary_iou: 0.9691 - true_positives: 128657064.0000 - false_positives: 2423557.0000 - true_negatives: 186016576.0000 - false_negatives: 2423496.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.1132 - val_accuracy: 0.9019 - val_binary_iou: 0.8192 - val_true_positives: 41424740.0000 - val_false_positives: 6679837.0000 - val_true_negatives: 54153840.0000 - val_false_negatives: 3713291.0000 - val_precision: 0.8611 - val_recall: 0.9177\n",
      "Epoch 272/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0191 - accuracy: 0.9845 - binary_iou: 0.9686 - true_positives: 128619336.0000 - false_positives: 2472127.0000 - true_negatives: 185963312.0000 - false_negatives: 2465940.0000 - precision: 0.9811 - recall: 0.9812 - val_loss: 0.1140 - val_accuracy: 0.9021 - val_binary_iou: 0.8192 - val_true_positives: 41122468.0000 - val_false_positives: 6499658.0000 - val_true_negatives: 54469528.0000 - val_false_negatives: 3880041.0000 - val_precision: 0.8635 - val_recall: 0.9138\n",
      "Epoch 273/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0190 - accuracy: 0.9846 - binary_iou: 0.9688 - true_positives: 128673088.0000 - false_positives: 2461035.0000 - true_negatives: 185937120.0000 - false_negatives: 2449502.0000 - precision: 0.9812 - recall: 0.9813 - val_loss: 0.1135 - val_accuracy: 0.9012 - val_binary_iou: 0.8181 - val_true_positives: 41592052.0000 - val_false_positives: 7028003.0000 - val_true_negatives: 53909660.0000 - val_false_negatives: 3441981.0000 - val_precision: 0.8555 - val_recall: 0.9236\n",
      "Epoch 274/300\n",
      "199/199 [==============================] - 78s 390ms/step - loss: 0.0191 - accuracy: 0.9846 - binary_iou: 0.9686 - true_positives: 128662808.0000 - false_positives: 2464759.0000 - true_negatives: 185925360.0000 - false_negatives: 2467842.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.1139 - val_accuracy: 0.9010 - val_binary_iou: 0.8179 - val_true_positives: 41591380.0000 - val_false_positives: 7053894.0000 - val_true_negatives: 53893552.0000 - val_false_negatives: 3432880.0000 - val_precision: 0.8550 - val_recall: 0.9238\n",
      "Epoch 275/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0190 - accuracy: 0.9847 - binary_iou: 0.9689 - true_positives: 128737696.0000 - false_positives: 2467648.0000 - true_negatives: 185890848.0000 - false_negatives: 2424521.0000 - precision: 0.9812 - recall: 0.9815 - val_loss: 0.1125 - val_accuracy: 0.9026 - val_binary_iou: 0.8203 - val_true_positives: 41489672.0000 - val_false_positives: 6674978.0000 - val_true_negatives: 54157488.0000 - val_false_negatives: 3649593.0000 - val_precision: 0.8614 - val_recall: 0.9191\n",
      "Epoch 276/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0187 - accuracy: 0.9849 - binary_iou: 0.9693 - true_positives: 128681392.0000 - false_positives: 2420361.0000 - true_negatives: 186019104.0000 - false_negatives: 2399873.0000 - precision: 0.9815 - recall: 0.9817 - val_loss: 0.1120 - val_accuracy: 0.9029 - val_binary_iou: 0.8208 - val_true_positives: 41553100.0000 - val_false_positives: 6655624.0000 - val_true_negatives: 54123708.0000 - val_false_negatives: 3639290.0000 - val_precision: 0.8619 - val_recall: 0.9195\n",
      "Epoch 277/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0184 - accuracy: 0.9851 - binary_iou: 0.9696 - true_positives: 128789304.0000 - false_positives: 2393306.0000 - true_negatives: 185962288.0000 - false_negatives: 2375769.0000 - precision: 0.9818 - recall: 0.9819 - val_loss: 0.1129 - val_accuracy: 0.9022 - val_binary_iou: 0.8196 - val_true_positives: 41410120.0000 - val_false_positives: 6752666.0000 - val_true_negatives: 54194028.0000 - val_false_negatives: 3614906.0000 - val_precision: 0.8598 - val_recall: 0.9197\n",
      "Epoch 278/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0186 - accuracy: 0.9850 - binary_iou: 0.9694 - true_positives: 128727744.0000 - false_positives: 2420212.0000 - true_negatives: 185992912.0000 - false_negatives: 2379899.0000 - precision: 0.9815 - recall: 0.9818 - val_loss: 0.1130 - val_accuracy: 0.9023 - val_binary_iou: 0.8199 - val_true_positives: 41400224.0000 - val_false_positives: 6647952.0000 - val_true_negatives: 54223072.0000 - val_false_negatives: 3700470.0000 - val_precision: 0.8616 - val_recall: 0.9180\n",
      "Epoch 279/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0185 - accuracy: 0.9850 - binary_iou: 0.9696 - true_positives: 128727048.0000 - false_positives: 2391623.0000 - true_negatives: 186012096.0000 - false_negatives: 2390066.0000 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.1132 - val_accuracy: 0.9022 - val_binary_iou: 0.8195 - val_true_positives: 41325852.0000 - val_false_positives: 6671173.0000 - val_true_negatives: 54279288.0000 - val_false_negatives: 3695401.0000 - val_precision: 0.8610 - val_recall: 0.9179\n",
      "Epoch 280/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0184 - accuracy: 0.9851 - binary_iou: 0.9697 - true_positives: 128804792.0000 - false_positives: 2375937.0000 - true_negatives: 185955072.0000 - false_negatives: 2385008.0000 - precision: 0.9819 - recall: 0.9818 - val_loss: 0.1134 - val_accuracy: 0.9013 - val_binary_iou: 0.8183 - val_true_positives: 41544864.0000 - val_false_positives: 6846696.0000 - val_true_negatives: 53968028.0000 - val_false_negatives: 3612131.0000 - val_precision: 0.8585 - val_recall: 0.9200\n",
      "Epoch 281/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0183 - accuracy: 0.9852 - binary_iou: 0.9698 - true_positives: 128712336.0000 - false_positives: 2362100.0000 - true_negatives: 186072544.0000 - false_negatives: 2373792.0000 - precision: 0.9820 - recall: 0.9819 - val_loss: 0.1135 - val_accuracy: 0.9017 - val_binary_iou: 0.8188 - val_true_positives: 41336620.0000 - val_false_positives: 6654268.0000 - val_true_negatives: 54216652.0000 - val_false_negatives: 3764174.0000 - val_precision: 0.8613 - val_recall: 0.9165\n",
      "Epoch 282/300\n",
      "199/199 [==============================] - 77s 389ms/step - loss: 0.0182 - accuracy: 0.9853 - binary_iou: 0.9701 - true_positives: 128748488.0000 - false_positives: 2343349.0000 - true_negatives: 186077632.0000 - false_negatives: 2351293.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1146 - val_accuracy: 0.9009 - val_binary_iou: 0.8175 - val_true_positives: 41468872.0000 - val_false_positives: 6900936.0000 - val_true_negatives: 53998820.0000 - val_false_negatives: 3603080.0000 - val_precision: 0.8573 - val_recall: 0.9201\n",
      "Epoch 283/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0181 - accuracy: 0.9853 - binary_iou: 0.9702 - true_positives: 128846128.0000 - false_positives: 2353676.0000 - true_negatives: 185991936.0000 - false_negatives: 2328959.0000 - precision: 0.9821 - recall: 0.9822 - val_loss: 0.1142 - val_accuracy: 0.9004 - val_binary_iou: 0.8166 - val_true_positives: 41359216.0000 - val_false_positives: 6777069.0000 - val_true_negatives: 54053116.0000 - val_false_negatives: 3782310.0000 - val_precision: 0.8592 - val_recall: 0.9162\n",
      "Epoch 284/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0182 - accuracy: 0.9853 - binary_iou: 0.9700 - true_positives: 128825416.0000 - false_positives: 2354418.0000 - true_negatives: 185990960.0000 - false_negatives: 2350035.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1134 - val_accuracy: 0.9016 - val_binary_iou: 0.8186 - val_true_positives: 41421144.0000 - val_false_positives: 6727720.0000 - val_true_negatives: 54118508.0000 - val_false_negatives: 3704335.0000 - val_precision: 0.8603 - val_recall: 0.9179\n",
      "Epoch 285/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0181 - accuracy: 0.9853 - binary_iou: 0.9702 - true_positives: 128749456.0000 - false_positives: 2363764.0000 - true_negatives: 186085792.0000 - false_negatives: 2321748.0000 - precision: 0.9820 - recall: 0.9823 - val_loss: 0.1133 - val_accuracy: 0.9013 - val_binary_iou: 0.8183 - val_true_positives: 41527412.0000 - val_false_positives: 6860239.0000 - val_true_negatives: 53985448.0000 - val_false_negatives: 3598604.0000 - val_precision: 0.8582 - val_recall: 0.9203\n",
      "Epoch 286/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0185 - accuracy: 0.9851 - binary_iou: 0.9697 - true_positives: 128741728.0000 - false_positives: 2374772.0000 - true_negatives: 186023168.0000 - false_negatives: 2381085.0000 - precision: 0.9819 - recall: 0.9818 - val_loss: 0.1132 - val_accuracy: 0.9014 - val_binary_iou: 0.8183 - val_true_positives: 41406008.0000 - val_false_positives: 6808160.0000 - val_true_negatives: 54117728.0000 - val_false_negatives: 3639829.0000 - val_precision: 0.8588 - val_recall: 0.9192\n",
      "Epoch 287/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0181 - accuracy: 0.9853 - binary_iou: 0.9702 - true_positives: 128674112.0000 - false_positives: 2321844.0000 - true_negatives: 186164688.0000 - false_negatives: 2360157.0000 - precision: 0.9823 - recall: 0.9820 - val_loss: 0.1130 - val_accuracy: 0.9026 - val_binary_iou: 0.8201 - val_true_positives: 41202840.0000 - val_false_positives: 6450340.0000 - val_true_negatives: 54442572.0000 - val_false_negatives: 3875966.0000 - val_precision: 0.8646 - val_recall: 0.9140\n",
      "Epoch 288/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0180 - accuracy: 0.9855 - binary_iou: 0.9704 - true_positives: 128696832.0000 - false_positives: 2335339.0000 - true_negatives: 186180176.0000 - false_negatives: 2308323.0000 - precision: 0.9822 - recall: 0.9824 - val_loss: 0.1138 - val_accuracy: 0.9017 - val_binary_iou: 0.8187 - val_true_positives: 41381116.0000 - val_false_positives: 6794321.0000 - val_true_negatives: 54168864.0000 - val_false_negatives: 3627405.0000 - val_precision: 0.8590 - val_recall: 0.9194\n",
      "Epoch 289/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0179 - accuracy: 0.9855 - binary_iou: 0.9705 - true_positives: 128851760.0000 - false_positives: 2318334.0000 - true_negatives: 186034864.0000 - false_negatives: 2315825.0000 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.1112 - val_accuracy: 0.9036 - val_binary_iou: 0.8219 - val_true_positives: 41330056.0000 - val_false_positives: 6436595.0000 - val_true_negatives: 54429184.0000 - val_false_negatives: 3775872.0000 - val_precision: 0.8652 - val_recall: 0.9163\n",
      "Epoch 290/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0181 - accuracy: 0.9855 - binary_iou: 0.9704 - true_positives: 128857528.0000 - false_positives: 2328175.0000 - true_negatives: 186015328.0000 - false_negatives: 2319660.0000 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.1110 - val_accuracy: 0.9033 - val_binary_iou: 0.8216 - val_true_positives: 41502376.0000 - val_false_positives: 6572012.0000 - val_true_negatives: 54227028.0000 - val_false_negatives: 3670300.0000 - val_precision: 0.8633 - val_recall: 0.9187\n",
      "Epoch 291/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0178 - accuracy: 0.9856 - binary_iou: 0.9707 - true_positives: 128849904.0000 - false_positives: 2299515.0000 - true_negatives: 186077312.0000 - false_negatives: 2294015.0000 - precision: 0.9825 - recall: 0.9825 - val_loss: 0.1133 - val_accuracy: 0.9013 - val_binary_iou: 0.8182 - val_true_positives: 41407480.0000 - val_false_positives: 6752783.0000 - val_true_negatives: 54106604.0000 - val_false_negatives: 3704838.0000 - val_precision: 0.8598 - val_recall: 0.9179\n",
      "Epoch 292/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0180 - accuracy: 0.9854 - binary_iou: 0.9704 - true_positives: 128831672.0000 - false_positives: 2330644.0000 - true_negatives: 186037648.0000 - false_negatives: 2320784.0000 - precision: 0.9822 - recall: 0.9823 - val_loss: 0.1118 - val_accuracy: 0.9024 - val_binary_iou: 0.8200 - val_true_positives: 41416184.0000 - val_false_positives: 6633046.0000 - val_true_negatives: 54214216.0000 - val_false_negatives: 3708258.0000 - val_precision: 0.8620 - val_recall: 0.9178\n",
      "Epoch 293/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0180 - accuracy: 0.9854 - binary_iou: 0.9703 - true_positives: 128761456.0000 - false_positives: 2324739.0000 - true_negatives: 186101456.0000 - false_negatives: 2333152.0000 - precision: 0.9823 - recall: 0.9822 - val_loss: 0.1151 - val_accuracy: 0.8995 - val_binary_iou: 0.8154 - val_true_positives: 41711576.0000 - val_false_positives: 7235276.0000 - val_true_negatives: 53605824.0000 - val_false_negatives: 3419039.0000 - val_precision: 0.8522 - val_recall: 0.9242\n",
      "Epoch 294/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0176 - accuracy: 0.9857 - binary_iou: 0.9709 - true_positives: 128922088.0000 - false_positives: 2308411.0000 - true_negatives: 186027872.0000 - false_negatives: 2262419.0000 - precision: 0.9824 - recall: 0.9828 - val_loss: 0.1148 - val_accuracy: 0.9006 - val_binary_iou: 0.8171 - val_true_positives: 41461224.0000 - val_false_positives: 6958019.0000 - val_true_negatives: 53980316.0000 - val_false_negatives: 3572159.0000 - val_precision: 0.8563 - val_recall: 0.9207\n",
      "Epoch 295/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0176 - accuracy: 0.9858 - binary_iou: 0.9710 - true_positives: 128838072.0000 - false_positives: 2285841.0000 - true_negatives: 186130592.0000 - false_negatives: 2266169.0000 - precision: 0.9826 - recall: 0.9827 - val_loss: 0.1125 - val_accuracy: 0.9027 - val_binary_iou: 0.8204 - val_true_positives: 41311176.0000 - val_false_positives: 6478292.0000 - val_true_negatives: 54346648.0000 - val_false_negatives: 3835599.0000 - val_precision: 0.8644 - val_recall: 0.9150\n",
      "Epoch 296/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0177 - accuracy: 0.9857 - binary_iou: 0.9708 - true_positives: 128876328.0000 - false_positives: 2282146.0000 - true_negatives: 186062464.0000 - false_negatives: 2299723.0000 - precision: 0.9826 - recall: 0.9825 - val_loss: 0.1157 - val_accuracy: 0.8999 - val_binary_iou: 0.8158 - val_true_positives: 41341124.0000 - val_false_positives: 6958231.0000 - val_true_negatives: 54019520.0000 - val_false_negatives: 3652833.0000 - val_precision: 0.8559 - val_recall: 0.9188\n",
      "Epoch 297/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0177 - accuracy: 0.9857 - binary_iou: 0.9709 - true_positives: 128836184.0000 - false_positives: 2305035.0000 - true_negatives: 186109088.0000 - false_negatives: 2270489.0000 - precision: 0.9824 - recall: 0.9827 - val_loss: 0.1149 - val_accuracy: 0.9000 - val_binary_iou: 0.8161 - val_true_positives: 41475908.0000 - val_false_positives: 7072367.0000 - val_true_negatives: 53897468.0000 - val_false_negatives: 3525975.0000 - val_precision: 0.8543 - val_recall: 0.9216\n",
      "Epoch 298/300\n",
      "199/199 [==============================] - 77s 388ms/step - loss: 0.0175 - accuracy: 0.9859 - binary_iou: 0.9712 - true_positives: 128852928.0000 - false_positives: 2269177.0000 - true_negatives: 186149104.0000 - false_negatives: 2249524.0000 - precision: 0.9827 - recall: 0.9828 - val_loss: 0.1139 - val_accuracy: 0.9010 - val_binary_iou: 0.8177 - val_true_positives: 41481992.0000 - val_false_positives: 6793908.0000 - val_true_negatives: 53993988.0000 - val_false_negatives: 3701828.0000 - val_precision: 0.8593 - val_recall: 0.9181\n",
      "Epoch 299/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0175 - accuracy: 0.9858 - binary_iou: 0.9712 - true_positives: 128955920.0000 - false_positives: 2262741.0000 - true_negatives: 186041824.0000 - false_negatives: 2260259.0000 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.1130 - val_accuracy: 0.9016 - val_binary_iou: 0.8188 - val_true_positives: 41601732.0000 - val_false_positives: 6906495.0000 - val_true_negatives: 53941408.0000 - val_false_negatives: 3522083.0000 - val_precision: 0.8576 - val_recall: 0.9219\n",
      "Epoch 300/300\n",
      "199/199 [==============================] - 77s 387ms/step - loss: 0.0174 - accuracy: 0.9859 - binary_iou: 0.9713 - true_positives: 128809344.0000 - false_positives: 2256550.0000 - true_negatives: 186213136.0000 - false_negatives: 2241727.0000 - precision: 0.9828 - recall: 0.9829 - val_loss: 0.1158 - val_accuracy: 0.8984 - val_binary_iou: 0.8135 - val_true_positives: 41609896.0000 - val_false_positives: 7202194.0000 - val_true_negatives: 53592992.0000 - val_false_negatives: 3566638.0000 - val_precision: 0.8525 - val_recall: 0.9211\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "# Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\n",
    "shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= model_history.epoch[-1])\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 11s 133ms/step - loss: 372.0455 - accuracy: 0.9028 - binary_iou: 0.8198 - true_positives: 40186796.0000 - false_positives: 6295103.0000 - true_negatives: 55489636.0000 - false_negatives: 4000174.0000 - precision: 0.8646 - recall: 0.9095\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_name = 'testlauf_fine_tune_first_layerFalse'\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "# Zusammenführen von Training- und Fine-Tuning-History\n",
    "iou = model_history.history['binary_iou']\n",
    "iou += history_fine.history['binary_iou']\n",
    "\n",
    "val_iou = model_history.history['val_binary_iou']\n",
    "val_iou += history_fine.history['val_binary_iou']\n",
    "\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "# Schreiben der Eval-Ergebnisse in csv\n",
    "with open('../output/final_runs.csv', 'a') as f_object:\n",
    "    row = []\n",
    "    \n",
    "    row.append(model_name + \"_300e\")\n",
    "\n",
    "    for x in eval_out:\n",
    "        row.append(x)\n",
    "\n",
    "    # Einfügen der Trainingszeit in Minuten\n",
    "    row.append(training_time/60)\n",
    "\n",
    "    # Einfügen der maximalen Val-IoU\n",
    "    row.append(max(val_iou))\n",
    "\n",
    "    # Einfügen des Index der maximalen Val-IoU\n",
    "    row.append(np.argmax(val_iou))\n",
    "\n",
    "    writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "    writer_object.writerow(row)\n",
    "\n",
    "\n",
    "# Plotten\n",
    "\n",
    "#acc = model_history.history['accuracy']\n",
    "#val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(val_iou)+1)\n",
    "\n",
    "#plt.plot(epochs, acc, 'y', label= 'Training accuracy')\n",
    "#plt.plot(epochs, val_acc, 'r', label= 'Validation accuracy')\n",
    "plt.plot(epochs[0:300], iou[0:300], 'g', label= 'Training IoU')\n",
    "plt.plot(epochs[0:300], val_iou[0:300], 'b', label= 'Validation IoU')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "#plt.title('Train & Val accuracy & IoU')\n",
    "plt.title('Training & Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/{model_name}/iou_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Final_AVG_rgbDrop_0_earlyStop_False_300e'\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACPPklEQVR4nO3dd3hTZf8G8DtN23QP2tIBpWWUDWVXNkqlBUSWAsor41VRBMcPUUBliQgCKioIKgpOQJT1KrsCyt677JYyuih07+T5/XE8GW3apisp5P5cV64kJ+ecPDkt5O73ec5zFEIIASIiIiIrYmPpBhARERGZGwMQERERWR0GICIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8MARERERFaHAYiIiIisDgMQ0QNozJgxCA4OrtC2s2bNgkKhqNoGPeD27NkDhUKBPXv2aJeZeoxjY2OhUCiwatWqKm1TcHAwxowZU6X7JCIdBiCiKqRQKEy66X/RWhuNRoNFixYhJCQEjo6OaNiwIcaPH4/MzEyTtm/dujXq1auH0q7i07VrV/j6+qKwsLCqml0tDhw4gFmzZiE1NdXSTdFatWoVFAoFjh07ZummEFUrW0s3gOhh8uOPPxo8/+GHH7Bz585iy5s1a1ap9/nmm2+g0WgqtO17772HqVOnVur9K+Ozzz7DW2+9hUGDBuGtt97CjRs3sHr1akyZMgUuLi5lbj9y5EhMnToV//zzD3r06FHs9djYWBw8eBATJ06ErW3F/4urzDE21YEDBzB79myMGTMGHh4eBq9dunQJNjb8G5WoujAAEVWh//znPwbPDx06hJ07dxZbXlR2djacnJxMfh87O7sKtQ8AbG1tKxUMKmvNmjVo0aIF1q9fr+2KmzNnjslh49lnn8W0adPwyy+/GA1Aq1evhhACI0eOrFQ7K3OMq4JKpbLo+xM97PjnBZGZ9erVCy1btsTx48fRo0cPODk54Z133gEAbNq0Cf3790dAQABUKhUaNmyIOXPmQK1WG+yj6PgUeRzKokWL8PXXX6Nhw4ZQqVTo2LEjjh49arCtsTFACoUCEydOxMaNG9GyZUuoVCq0aNEC27ZtK9b+PXv2oEOHDnBwcEDDhg3x1VdflWtckY2NDTQajcH6NjY2JoeywMBA9OjRA7/99hsKCgqKvf7LL7+gYcOGCAsLw40bN/DKK6+gSZMmcHR0hJeXF55++mnExsaW+T7GxgClpqZizJgxcHd3h4eHB0aPHm20++rMmTMYM2YMGjRoAAcHB/j5+eG///0vUlJStOvMmjULb731FgCgfv362u5RuW3GxgBdv34dTz/9NGrVqgUnJyc88sgj+PPPPw3Wkccz/frrr5g7dy7q1q0LBwcH9O7dG1evXi3zc5vq5MmT6Nu3L9zc3ODi4oLevXvj0KFDBusUFBRg9uzZCAkJgYODA7y8vNCtWzfs3LlTu05CQgLGjh2LunXrQqVSwd/fHwMHDjTpZ0RUGawAEVlASkoK+vbtixEjRuA///kPfH19AUjjL1xcXDBp0iS4uLjgr7/+wowZM5Ceno6FCxeWud9ffvkFGRkZeOmll6BQKLBgwQIMGTIE169fL7OisW/fPqxfvx6vvPIKXF1d8fnnn2Po0KGIi4uDl5cXAOlLLzIyEv7+/pg9ezbUajXef/99+Pj4mPzZx44di5deeglfffUVXnrpJZO30zdy5EiMGzcO27dvxxNPPKFdfvbsWZw7dw4zZswAABw9ehQHDhzAiBEjULduXcTGxmLZsmXo1asXLly4UK6qmxACAwcOxL59+/Dyyy+jWbNm2LBhA0aPHl1s3Z07d+L69esYO3Ys/Pz8cP78eXz99dc4f/48Dh06BIVCgSFDhuDy5ctYvXo1Pv30U3h7ewNAiccyMTERXbp0QXZ2Nl577TV4eXnh+++/x5NPPonffvsNgwcPNlh//vz5sLGxweTJk5GWloYFCxZg5MiROHz4sMmfuSTnz59H9+7d4ebmhrfffht2dnb46quv0KtXL+zduxdhYWEApJA3b948vPDCC+jUqRPS09Nx7NgxnDhxAo8//jgAYOjQoTh//jxeffVVBAcHIykpCTt37kRcXFyFB/oTmUQQUbWZMGGCKPrPrGfPngKAWL58ebH1s7Oziy176aWXhJOTk8jNzdUuGz16tAgKCtI+j4mJEQCEl5eXuHfvnnb5pk2bBADxv//9T7ts5syZxdoEQNjb24urV69ql50+fVoAEF988YV22YABA4STk5O4ffu2dtmVK1eEra1tsX2WZOrUqcLe3l4olUqxfv16k7Yp6t69e0KlUolnnnmm2L4BiEuXLgkhjB/PgwcPCgDihx9+0C7bvXu3ACB2796tXVb0GG/cuFEAEAsWLNAuKywsFN27dxcAxMqVK7XLjb3v6tWrBQDx999/a5ctXLhQABAxMTHF1g8KChKjR4/WPn/jjTcEAPHPP/9ol2VkZIj69euL4OBgoVarDT5Ls2bNRF5ennbdzz77TAAQZ8+eLfZe+lauXCkAiKNHj5a4zqBBg4S9vb24du2adtmdO3eEq6ur6NGjh3ZZaGio6N+/f4n7uX//vgAgFi5cWGqbiKoDu8CILEClUmHs2LHFljs6OmofZ2Rk4O7du+jevTuys7Nx8eLFMvc7fPhweHp6ap93794dgNR1Upbw8HA0bNhQ+7x169Zwc3PTbqtWq7Fr1y4MGjQIAQEB2vUaNWqEvn37lrl/APj888/xySefYP/+/XjmmWcwYsQI7Nixw2AdlUqF6dOnl7ofT09P9OvXD5s3b0ZWVhYAqUKzZs0adOjQAY0bNwZgeDwLCgqQkpKCRo0awcPDAydOnDCpzbItW7bA1tYW48eP1y5TKpV49dVXi62r/765ubm4e/cuHnnkEQAo9/vqv3+nTp3QrVs37TIXFxeMGzcOsbGxuHDhgsH6Y8eOhb29vfZ5eX4XSqNWq7Fjxw4MGjQIDRo00C739/fHs88+i3379iE9PR0A4OHhgfPnz+PKlStG9+Xo6Ah7e3vs2bMH9+/fr1S7iMqLAYjIAurUqWPw5SQ7f/48Bg8eDHd3d7i5ucHHx0c7gDotLa3M/darV8/guRyGTPlyKbqtvL28bVJSEnJyctCoUaNi6xlbVlROTg5mzpyJF154AR06dMDKlSvx2GOPYfDgwdi3bx8A4MqVK8jPz9d2oZRm5MiRyMrKwqZNmwBIZ1TFxsYaDH7OycnBjBkzEBgYCJVKBW9vb/j4+CA1NdWk46nvxo0b8Pf3L3amWpMmTYqte+/ePbz++uvw9fWFo6MjfHx8UL9+fQCm/RxLen9j7yWfUXjjxg2D5ZX5XShNcnIysrOzS2yLRqPBzZs3AQDvv/8+UlNT0bhxY7Rq1QpvvfUWzpw5o11fpVLho48+wtatW+Hr64sePXpgwYIFSEhIqFQbiUzBAERkAfoVAllqaip69uyJ06dP4/3338f//vc/7Ny5Ex999BEAmHSWlFKpNLpclDJnTlVsa4ro6GikpqZqKyG2trb47bff0LJlS/Tv3x8nTpzA119/jdq1a2vHh5TmiSeegLu7O3755RcA0vgnpVKJESNGaNd59dVXMXfuXAwbNgy//vorduzYgZ07d8LLy6taT3EfNmwYvvnmG7z88stYv349duzYoR1QXt2n1suq++dpih49euDatWv47rvv0LJlS6xYsQLt2rXDihUrtOu88cYbuHz5MubNmwcHBwdMnz4dzZo1w8mTJ83WTrJOHARNVEPs2bMHKSkpWL9+vcHp3TExMRZslU7t2rXh4OBg9EwiU84uks/6kqsDAODs7IwtW7agW7duiIiIQG5uLj744AOTTgFXqVR46qmn8MMPPyAxMRHr1q3DY489Bj8/P+06v/32G0aPHo2PP/5Yuyw3N7dCEw8GBQUhKioKmZmZBlWgS5cuGax3//59REVFYfbs2drB2ACMdgOVZ0buoKCgYu8FQNs1GhQUZPK+KsPHxwdOTk4ltsXGxgaBgYHaZbVq1cLYsWMxduxYZGZmokePHpg1axZeeOEF7ToNGzbEm2++iTfffBNXrlxBmzZt8PHHH+Onn34yy2ci68QKEFENIf/Frv8Xen5+Pr788ktLNcmAUqlEeHg4Nm7ciDt37miXX716FVu3bi1z+1atWsHX1xdLlixBUlKSdrmXlxdWrlyJu3fvIicnBwMGDDC5TSNHjkRBQQFeeuklJCcnF5v7R6lUFqt4fPHFF8WmFTBFv379UFhYiGXLlmmXqdVqfPHFF8XeEyheaVm8eHGxfTo7OwOASYGsX79+OHLkCA4ePKhdlpWVha+//hrBwcFo3ry5qR+lUpRKJfr06YNNmzYZnKqemJiIX375Bd26dYObmxsAGJz2D0hjlho1aoS8vDwA0vxXubm5Bus0bNgQrq6u2nWIqgsrQEQ1RJcuXeDp6YnRo0fjtddeg0KhwI8//mjWLouyzJo1Czt27EDXrl0xfvx4qNVqLFmyBC1btsSpU6dK3dbW1hZLlizB8OHD0apVK7z00ksICgpCdHQ0vvvuO7Rq1Qq3bt3CwIEDsX//fu2XaGl69uyJunXrYtOmTXB0dMSQIUMMXn/iiSfw448/wt3dHc2bN8fBgwexa9cu7Wn95TFgwAB07doVU6dORWxsLJo3b47169cXG9Pj5uamHctSUFCAOnXqYMeOHUYree3btwcAvPvuuxgxYgTs7OwwYMAAbTDSN3XqVKxevRp9+/bFa6+9hlq1auH7779HTEwMfv/99yqfNfq7774zOg/U66+/jg8++AA7d+5Et27d8Morr8DW1hZfffUV8vLysGDBAu26zZs3R69evdC+fXvUqlULx44dw2+//YaJEycCAC5fvozevXtj2LBhaN68OWxtbbFhwwYkJiYadGUSVQvLnYBG9PAr6TT4Fi1aGF1///794pFHHhGOjo4iICBAvP3222L79u1lnqItnwZv7HRiAGLmzJna5yWdBj9hwoRi2xY9FVsIIaKiokTbtm2Fvb29aNiwoVixYoV48803hYODQwlHwdDff/8tIiIihJubm1CpVKJly5Zi3rx5Ijs7W2zdulXY2NiIPn36iIKCApP299ZbbwkAYtiwYcVeu3//vhg7dqzw9vYWLi4uIiIiQly8eLHY5zLlNHghhEhJSRHPPfeccHNzE+7u7uK5554TJ0+eLHYa/K1bt8TgwYOFh4eHcHd3F08//bS4c+dOsZ+FEELMmTNH1KlTR9jY2BicEm/s2F+7dk089dRTwsPDQzg4OIhOnTqJP/74w2Ad+bOsW7fOYLn8O6LfTmPk0+BLut28eVMIIcSJEydERESEcHFxEU5OTuLRRx8VBw4cMNjXBx98IDp16iQ8PDyEo6OjaNq0qZg7d67Iz88XQghx9+5dMWHCBNG0aVPh7Ows3N3dRVhYmPj1119LbSNRVVAIUYP+vCSiB9KgQYNKPd2ZiKim4RggIiqXnJwcg+dXrlzBli1b0KtXL8s0iIioAlgBIqJy8ff3117n6saNG1i2bBny8vJw8uRJhISEWLp5REQm4SBoIiqXyMhIrF69GgkJCVCpVOjcuTM+/PBDhh8ieqCwAkRERERWh2OAiIiIyOowABEREZHV4RggIzQaDe7cuQNXV9dyTVVPREREliOEQEZGBgICAsqcHJQByIg7d+4YXMuGiIiIHhw3b95E3bp1S12HAcgIV1dXANIBNGU6fiIiIrK89PR0BAYGar/HS8MAZITc7eXm5sYARERE9IAxZfgKB0ETERGR1WEAIiIiIqvDAERERERWh2OAiIioVBqNBvn5+ZZuBhHs7OygVCqrZF8MQEREVKL8/HzExMRAo9FYuilEAAAPDw/4+flVep4+BiAiIjJKCIH4+HgolUoEBgaWObEcUXUSQiA7OxtJSUkAAH9//0rtjwGIiIiMKiwsRHZ2NgICAuDk5GTp5hDB0dERAJCUlITatWtXqjuMcZ6IiIxSq9UAAHt7ewu3hEhHDuMFBQWV2g8DEBERlYrXRKSapKp+HxmAiIiIyOowABEREZUhODgYixcvNnn9PXv2QKFQIDU1tdraRJXDAERERA8NhUJR6m3WrFkV2u/Ro0cxbtw4k9fv0qUL4uPj4e7uXqH3MxWDVsXxLLCHlRBAdrb02MkJYB8+EVmB+Ph47eO1a9dixowZuHTpknaZi4uL9rEQAmq1Gra2ZX8V+vj4lKsd9vb28PPzK9c2ZF6sAD2ssrMBFxfpJgchIqKHnJ+fn/bm7u4OhUKhfX7x4kW4urpi69ataN++PVQqFfbt24dr165h4MCB8PX1hYuLCzp27Ihdu3YZ7LdoF5hCocCKFSswePBgODk5ISQkBJs3b9a+XrQys2rVKnh4eGD79u1o1qwZXFxcEBkZaRDYCgsL8dprr8HDwwNeXl6YMmUKRo8ejUGDBlX4eNy/fx+jRo2Cp6cnnJyc0LdvX1y5ckX7+o0bNzBgwAB4enrC2dkZLVq0wJYtW7Tbjhw5Ej4+PnB0dERISAhWrlxZ4bbUNAxARERkEiEEsvKzLHITQlTZ55g6dSrmz5+P6OhotG7dGpmZmejXrx+ioqJw8uRJREZGYsCAAYiLiyt1P7Nnz8awYcNw5swZ9OvXDyNHjsS9e/dKXD87OxuLFi3Cjz/+iL///htxcXGYPHmy9vWPPvoIP//8M1auXIn9+/cjPT0dGzdurNRnHTNmDI4dO4bNmzfj4MGDEEKgX79+2lPIJ0yYgLy8PPz99984e/YsPvroI22VbPr06bhw4QK2bt2K6OhoLFu2DN7e3pVqT03CLjAiIjJJdkE2XOa5lL1iNciclglne+cq2df777+Pxx9/XPu8Vq1aCA0N1T6fM2cONmzYgM2bN2PixIkl7mfMmDF45plnAAAffvghPv/8cxw5cgSRkZFG1y8oKMDy5cvRsGFDAMDEiRPx/vvva1//4osvMG3aNAwePBgAsGTJEm01piKuXLmCzZs3Y//+/ejSpQsA4Oeff0ZgYCA2btyIp59+GnFxcRg6dChatWoFAGjQoIF2+7i4OLRt2xYdOnQAIFXBHiasABERkVWRv9BlmZmZmDx5Mpo1awYPDw+4uLggOjq6zApQ69attY+dnZ3h5uamvUyDMU5OTtrwA0iXcpDXT0tLQ2JiIjp16qR9XalUon379uX6bPqio6Nha2uLsLAw7TIvLy80adIE0dHRAIDXXnsNH3zwAbp27YqZM2fizJkz2nXHjx+PNWvWoE2bNnj77bdx4MCBCrelJmIFiIiITOJk54TMaZkWe++q4uxsWEmaPHkydu7ciUWLFqFRo0ZwdHTEU089hfz8/FL3Y2dnZ/BcoVCUetFYY+tXZddeRbzwwguIiIjAn3/+iR07dmDevHn4+OOP8eqrr6Jv3764ceMGtmzZgp07d6J3796YMGECFi1aZNE2VxVWgIiIyCQKhQLO9s4WuVXnbNT79+/HmDFjMHjwYLRq1Qp+fn6IjY2ttvczxt3dHb6+vjh69Kh2mVqtxokTJyq8z2bNmqGwsBCHDx/WLktJScGlS5fQvHlz7bLAwEC8/PLLWL9+Pd58801888032td8fHwwevRo/PTTT1i8eDG+/vrrCrenpmEFiIiIrFpISAjWr1+PAQMGQKFQYPr06aVWcqrLq6++innz5qFRo0Zo2rQpvvjiC9y/f9+k8Hf27Fm4urpqnysUCoSGhmLgwIF48cUX8dVXX8HV1RVTp05FnTp1MHDgQADAG2+8gb59+6Jx48a4f/8+du/ejWbNmgEAZsyYgfbt26NFixbIy8vDH3/8oX3tYcAAREREVu2TTz7Bf//7X3Tp0gXe3t6YMmUK0tPTzd6OKVOmICEhAaNGjYJSqcS4ceMQERFh0hXPe/ToYfBcqVSisLAQK1euxOuvv44nnngC+fn56NGjB7Zs2aLtjlOr1ZgwYQJu3boFNzc3REZG4tNPPwUgzWU0bdo0xMbGwtHREd27d8eaNWuq/oNbiEJYugOyBkpPT4e7uzvS0tLg5uZm6eZUTFaWNAcQAGRmAs5Vc/YEEVmP3NxcxMTEoH79+nBwcLB0c6yORqNBs2bNMGzYMMyZM8fSzakxSvu9LM/3NytARERENcCNGzewY8cO9OzZE3l5eViyZAliYmLw7LPPWrppDyUOgiYiIqoBbGxssGrVKnTs2BFdu3bF2bNnsWvXrodq3E1NwgoQERFRDRAYGIj9+/dbuhlWgxUgIiIisjoMQERERGR1GICIiIjI6jAAPQAWLgSGDAEKCy3dEiIioocDB0E/ABYvBu7cAc6fB/QuWExEREQVxArQA6CgQLpnBYiIiKhqMAA9ANRq6d4Cl6YhIrJKvXr1whtvvKF9HhwcjMWLF5e6jUKhwMaNGyv93lW1HyodA9ADQA5A8j0RERk3YMAAREZGGn3tn3/+gUKhwJkzZ8q936NHj2LcuHGVbZ6BWbNmoU2bNsWWx8fHo2/fvlX6XkWtWrUKHh4e1foeNR0DkBkt2L8Aqg9UeOl/L5VrO1aAiIhM8/zzz2Pnzp24detWsddWrlyJDh06oHXr1uXer4+PD5ycnKqiiWXy8/ODSqUyy3tZsxoRgJYuXYrg4GA4ODggLCwMR44cKXHdb775Bt27d4enpyc8PT0RHh5ebP0xY8ZAoVAY3Er6i8CchBDIV+cjX5Nfru1YASIiMs0TTzwBHx8frFq1ymB5ZmYm1q1bh+effx4pKSl45plnUKdOHTg5OaFVq1ZYvXp1qfst2gV25coV9OjRAw4ODmjevDl27txZbJspU6agcePGcHJyQoMGDTB9+nQU/Duoc9WqVZg9ezZOnz6t/Z6S21y0C+zs2bN47LHH4OjoCC8vL4wbNw6ZmZna18eMGYNBgwZh0aJF8Pf3h5eXFyZMmKB9r4qIi4vDwIED4eLiAjc3NwwbNgyJiYna10+fPo1HH30Urq6ucHNzQ/v27XHs2DEA0jXNBgwYAE9PTzg7O6NFixbYsmVLhdtSXSx+FtjatWsxadIkLF++HGFhYVi8eDEiIiJw6dIl1K5du9j6e/bswTPPPIMuXbrAwcEBH330Efr06YPz58+jTp062vUiIyOxcuVK7fOakKbtlHYAgEJN+UYzswJERDWBEEB2tmXe28kJUCjKXs/W1hajRo3CqlWr8O6770Lx70br1q2DWq3GM888g8zMTLRv3x5TpkyBm5sb/vzzTzz33HNo2LAhOnXqVOZ7aDQaDBkyBL6+vjh8+DDS0tIMxgvJXF1dsWrVKgQEBODs2bN48cUX4erqirfffhvDhw/HuXPnsG3bNuzatQsA4O7uXmwfWVlZiIiIQOfOnXH06FEkJSXhhRdewMSJEw1C3u7du+Hv74/du3fj6tWrGD58ONq0aYMXX3yx7INm5PPJ4Wfv3r0oLCzEhAkTMHz4cOzZswcAMHLkSLRt2xbLli2DUqnEqVOnYGcnfcdNmDAB+fn5+Pvvv+Hs7IwLFy7AxcWl3O2odsLCOnXqJCZMmKB9rlarRUBAgJg3b55J2xcWFgpXV1fx/fffa5eNHj1aDBw4sMJtSktLEwBEWlpahfdhzGeHPhOYBTHitxHl2k6pFAIQ4q+/yrFRZqa0ESA9JiIqp5ycHHHhwgWRk5MjhDD8b8Xct/L8NxYdHS0AiN27d2uXde/eXfznP/8pcZv+/fuLN998U/u8Z8+e4vXXX9c+DwoKEp9++qkQQojt27cLW1tbcfv2be3rW7duFQDEhg0bSnyPhQsXivbt22ufz5w5U4SGhhZbT38/X3/9tfD09BSZegfgzz//FDY2NiIhIUEIIX3nBQUFicLCQu06Tz/9tBg+fHiJbVm5cqVwd3c3+tqOHTuEUqkUcXFx2mXnz58XAMSRI0eEEEK4urqKVatWGd2+VatWYtasWSW+d2UV/b3UV57vb4t2geXn5+P48eMIDw/XLrOxsUF4eDgOHjxo0j6ys7NRUFCAWrVqGSzfs2cPateujSZNmmD8+PFISUkpcR95eXlIT083uFUHWxup4FbRChC7wIiIyta0aVN06dIF3333HQDg6tWr+Oeff/D8888DANRqNebMmYNWrVqhVq1acHFxwfbt2xEXF2fS/qOjoxEYGIiAgADtss6dOxdbb+3atejatSv8/Pzg4uKC9957z+T30H+v0NBQODs7a5d17doVGo0Gly5d0i5r0aIFlEql9rm/vz+SkpLK9V767xkYGIjAwEDtsubNm8PDwwPR0dEAgEmTJuGFF15AeHg45s+fj2vXrmnXfe211/DBBx+ga9eumDlzZoUGnZuDRQPQ3bt3oVar4evra7Dc19cXCQkJJu1jypQpCAgIMAhRkZGR+OGHHxAVFYWPPvoIe/fuRd++faEuIUHMmzcP7u7u2pv+D70qVSQA6Xd7sQuMiCzJyQnIzLTMrbzjj59//nn8/vvvyMjIwMqVK9GwYUP07NkTALBw4UJ89tlnmDJlCnbv3o1Tp04hIiIC+fnlG59ZmoMHD2LkyJHo168f/vjjD5w8eRLvvvtulb6HPrn7SaZQKKCpxi+NWbNm4fz58+jfvz/++usvNG/eHBs2bAAAvPDCC7h+/Tqee+45nD17Fh06dMAXX3xRbW2pqBoxCLqi5s+fjzVr1mDDhg1wcHDQLh8xYgSefPJJtGrVCoMGDcIff/yBo0ePavsui5o2bRrS0tK0t5s3b1ZLeysSgPQzGytARGRJCgXg7GyZmynjf/QNGzYMNjY2+OWXX/DDDz/gv//9r3Y80P79+zFw4ED85z//QWhoKBo0aIDLly+bvO9mzZrh5s2biI+P1y47dOiQwToHDhxAUFAQ3n33XXTo0AEhISG4ceOGwTr29vYl/mGu/16nT59GVlaWdtn+/fthY2ODJk2amNzm8pA/n/534YULF5CamormzZtrlzVu3Bj/93//hx07dmDIkCEG424DAwPx8ssvY/369XjzzTfxzTffVEtbK8OiAcjb2xtKpdJgZDkAJCYmws/Pr9RtFy1ahPnz52PHjh1lntLYoEEDeHt74+rVq0ZfV6lUcHNzM7hVh8oGIFaAiIhM4+LiguHDh2PatGmIj4/HmDFjtK+FhIRg586dOHDgAKKjo/HSSy8V+x4qTXh4OBo3bozRo0fj9OnT+Oeff/Duu+8arBMSEoK4uDisWbMG165dw+eff66tkMiCg4MRExODU6dO4e7du8jLyyv2XiNHjoSDgwNGjx6Nc+fOYffu3Xj11Vfx3HPPFes9KS+1Wo1Tp04Z3KKjoxEeHo5WrVph5MiROHHiBI4cOYJRo0ahZ8+e6NChA3JycjBx4kTs2bMHN27cwP79+3H06FE0a9YMAPDGG29g+/btiImJwYkTJ7B7927tazWJRQOQvb092rdvj6ioKO0yjUaDqKgoo/2psgULFmDOnDnYtm0bOnToUOb73Lp1CykpKfD396+SdleUHIAK1KafmsgKEBFRxTz//PO4f/8+IiIiDMbrvPfee2jXrh0iIiLQq1cv+Pn5YdCgQSbv18bGBhs2bEBOTg46deqEF154AXPnzjVY58knn8T//d//YeLEiWjTpg0OHDiA6dOnG6wzdOhQREZG4tFHH4WPj4/RU/GdnJywfft23Lt3Dx07dsRTTz2F3r17Y8mSJeU7GEZkZmaibdu2BrcBAwZAoVBg06ZN8PT0RI8ePRAeHo4GDRpg7dq1AAClUomUlBSMGjUKjRs3xrBhw9C3b1/Mnj0bgBSsJkyYgGbNmiEyMhKNGzfGl19+Wen2VrnqGKFdHmvWrBEqlUqsWrVKXLhwQYwbN054eHhoR7c/99xzYurUqdr158+fL+zt7cVvv/0m4uPjtbeMjAwhhBAZGRli8uTJ4uDBgyImJkbs2rVLtGvXToSEhIjc3FyT2lRdZ4GtPbdWYBZEz5U9Td4mLU13FkQpJxcUx7PAiKiSSjvbhshSquosMIvPAzR8+HAkJydjxowZSEhIQJs2bbBt2zZtaS8uLg42NrpC1bJly5Cfn4+nnnrKYD8zZ87ErFmzoFQqcebMGXz//fdITU1FQEAA+vTpgzlz5lh8LiA7m/LPA8QuMCIioqpn8QAEABMnTsTEiRONvlZ04HJsbGyp+3J0dMT27durqGVVi4OgiYiIaoYH+iywBw0HQRMREdUMDEBmxAoQERFRzcAAZEasABEREdUMDEBmxAoQERFRzcAAZEbaeYA0FZsHiBUgIiKiqsEAZEbsAiMiIqoZGIDMyE5Z/nmACvVWZRcYERFR1WAAMiNWgIiIyJg9e/ZAoVAgNTXV0k2plODgYCxevNjSzTAJA5AZcRA0EVH1S05Oxvjx41GvXj2oVCr4+fkhIiIC+/fv166jUCiwcePGKnm/2NhYKBQKnDp1yqT1it7+85//oEuXLoiPj4e7u3uVtMkYY++tf5s1a1al3+Po0aMYN25c5RtrBjViJmhrwQoQEVH1Gzp0KPLz8/H999+jQYMGSExMRFRUFFJSUqr8vfLz88u9za5du9CiRQvtc0dHR9jb28PPz68qm1ZMfHy89vHatWsxY8YMXLp0SbvMxcWl0u/h4+NT6X2YCytAZsQKEBFR9UpNTcU///yDjz76CI8++iiCgoLQqVMnTJs2DU8++SQAqZsGAAYPHgyFQqF9fu3aNQwcOBC+vr5wcXFBx44dsWvXLoP9BwcHY86cORg1ahTc3Nwwbtw41K9fHwDQtm1bKBQK9OrVq9Q2enl5wc/PT3tzd3cv1gW2atUqeHh4YPv27WjWrBlcXFwQGRlpEGIAYMWKFWjWrBkcHBzQtGnTUq+6XvQ9FQqF9vny5cvRrVs3g/UXL16sPTYAMGbMGAwaNAiLFi2Cv78/vLy8MGHCBBQU6M5sLtoFplAosGLFCgwePBhOTk4ICQnB5s2bDd5n8+bNCAkJgYODAx599FF8//33ZukOZAAyI1aAiOiBJgSQlWWZmxAmNdHFxQUuLi7YuHEj8vLyjK5z9OhRAMDKlSsRHx+vfZ6ZmYl+/fohKioKJ0+eRGRkJAYMGIC4uDiD7RctWoTQ0FCcPHkS06dPx5EjRwBIlZ34+HisX7++okfYQHZ2NhYtWoQff/wRf//9N+Li4jB58mTt6z///DNmzJiBuXPnIjo6Gh9++CGmT5+O77//vkre35jdu3fj2rVr2L17N77//nusWrUKq1atKnWb2bNnY9iwYThz5gz69euHkSNH4t69ewCAmJgYPPXUUxg0aBBOnz6Nl156Ce+++261tV8fu8DMSDsPkJrzABHRAyg7G6iCbpIKycwEnJ3LXM3W1harVq3Ciy++iOXLl6Ndu3bo2bMnRowYgdatWwPQddN4eHgYdDuFhoYiNDRU+3zOnDnYsGEDNm/ebHDB7sceewxvvvmm9rlSqQSgq+yUpUuXLrCx0dUf/vnnH6PrFRQUYPny5WjYsCEA6cLh77//vvb1mTNn4uOPP8aQIUMAAPXr18eFCxfw1VdfYfTo0WW2oyI8PT2xZMkSKJVKNG3aFP3790dUVBRefPHFErcZM2YMnnnmGQDAhx9+iM8//xxHjhxBZGQkvvrqKzRp0gQLFy4EADRp0gTnzp3D3Llzq6X9+lgBMiM5AAkIaIRpaYZdYERE5TN06FDcuXMHmzdvRmRkJPbs2YN27dqVWanIzMzE5MmT0axZM3h4eMDFxQXR0dHFKkAdOnSoVPvWrl2LU6dOaW/Nmzc3up6Tk5M2/ACAv78/kpKSAABZWVm4du0ann/+eW3Vy8XFBR988AGuXbtWqfaVpkWLFtrAV7RNJZGDJwA4OzvDzc1Nu82lS5fQsWNHg/U7depUhS0uGStAZmRnY6d9XKgphL3SvsxtWAEiohrDyUmqxFjqvcvBwcEBjz/+OB5//HFMnz4dL7zwAmbOnIkxY8aUuM3kyZOxc+dOLFq0CI0aNYKjoyOeeuqpYgOdnU2oRJUmMDAQjRo1KnM9Ozs7g+cKhQLi367AzH9/Dt988w3CwsIM1tMPKKaysbHR7lumP7antDZpyvhyqsg25sAAZEZyBQioWABiBYiILEqhMKkbqiZq3ry5wWnvdnZ2UBf5T3X//v0YM2YMBg8eDEAKGbGxsWXu295e+r+86P6qk6+vLwICAnD9+nWMHDmy0vvz8fFBQkIChBBQKBQAUOZp/VWhSZMm2LJli8EyeUxWdWMXmBkVDUCmYAWIiMh0KSkpeOyxx/DTTz/hzJkziImJwbp167BgwQIMHDhQu15wcDCioqKQkJCA+/fvAwBCQkKwfv16nDp1CqdPn8azzz5rUqWidu3acHR0xLZt25CYmIi0tLRq+3z6Zs+ejXnz5uHzzz/H5cuXcfbsWaxcuRKffPJJuffVq1cvJCcnY8GCBbh27RqWLl2KrVu3VkOrDb300ku4ePEipkyZgsuXL+PXX3/VdlXKQay6MACZUWUDECtARESlc3FxQVhYGD799FP06NEDLVu2xPTp0/Hiiy9iyZIl2vU+/vhj7Ny5E4GBgWjbti0A4JNPPoGnpye6dOmCAQMGICIiAu3atSvzPW1tbfH555/jq6++QkBAgEHQqk4vvPACVqxYgZUrV6JVq1bo2bMnVq1apT0tvzyaNWuGL7/8EkuXLkVoaCiOHDlicMZZdalfvz5+++03rF+/Hq1bt8ayZcu0Z4GpVKpqfW+FKNrpR0hPT4e7uzvS0tLg5uZWZfsVQsDmfSlzJk5ORG3n2mVus3kzIP9beu89YM4cE98sK0t3toaJZ08QEenLzc1FTEwM6tevDwcHB0s3h6zE3LlzsXz5cty8edPo66X9Xpbn+5tjgMxIoVDA1sYWhZpCdoEREREB+PLLL9GxY0d4eXlh//79WLhwocG0A9WFAcjM5ABk6lxA7AIjIqKH2ZUrV/DBBx/g3r17qFevHt58801Mmzat2t+XAcjMyjsbNCtARET0MPv000/x6aefmv19OQjazOS5gDgImoiIyHIYgMyMFSAietDwXBmqSarq95EByMwqE4BYASIic5JnFC46EzKRJWVnZwMoPsN0eXEMkJmxAkREDwpbW1s4OTkhOTkZdnZ2BhfwJDI3IQSys7ORlJQEDw+PCl3yQx8DkJkxABHRg0KhUMDf3x8xMTG4ceOGpZtDBADw8PCAn59fpffDAGRmcgAq0PA0eCKq+ezt7RESEsJuMKoR7OzsKl35kTEAmVl1VoDi44FBg4CXXwbGDqtgA4mIirCxseFM0PTQYYeumVXnIOjdu4EjR4Aff6xo64iIiKwDA5CZ2SkrPg9QWRWgvDzpvtC0XRMREVktBiAzq84KEAMQERGRaRiAzKw6xwDJAYiDpYmIiErHAGRGixYBhyfsAP5cwgBERERkQQxAZqTRAOpcZyDfhV1gREREFsQAZEYq1b8PClUoUJd/HiBWgIiIiKoGA5AZaQOQWlUtFSB5njIGICIiotIxAJmRdh6xQgeOASIiIrIgBiAz0u8C4xggIiIiy2EAMiNWgIiIiGoGBiAzquwYIAYgIiKiqsEAZEbsAiMiIqoZGIDMiF1gRERENQMDkBnpd4EVaMo/DxBPgyciIqoaDEBmVJEKkH53FitAREREVYMByIw4BoiIiKhmYAAyI20FqMhZYBkZwMcfA7GxxbfhGCAiIqKqxwBkRgZjgAp1KWX1amDyZGDu3OLbMAARERFVPQYgM9IGIAB5+UL7OClJuk9JKb4Nu8CIiIiqHgOQGWm7wADk5Sq0j7Oy/l2WV3yb8lSA5LPAhJBuREREZBwDkBnZ2+se64edzEzpPje3+DYVqQCZsi4REZE1YwAyI4UCsLWX+qfy8nXLq6oCpL89u8GIiIhKViMC0NKlSxEcHAwHBweEhYXhyJEjJa77zTffoHv37vD09ISnpyfCw8OLrS+EwIwZM+Dv7w9HR0eEh4fjypUr1f0xTGJrJyWa/DzdoWcFiIiIyLwsHoDWrl2LSZMmYebMmThx4gRCQ0MRERGBJHlkcBF79uzBM888g927d+PgwYMIDAxEnz59cPv2be06CxYswOeff47ly5fj8OHDcHZ2RkREBHKNJQwzs7WXA1DxMUBlBaDSKkBCMAARERGZyuIB6JNPPsGLL76IsWPHonnz5li+fDmcnJzw3XffGV3/559/xiuvvII2bdqgadOmWLFiBTQaDaKiogBI1Z/Fixfjvffew8CBA9G6dWv88MMPuHPnDjZu3GjGT2acnX3JFaDKdIEVFLmyBgMQERFRySwagPLz83H8+HGEh4drl9nY2CA8PBwHDx40aR/Z2dkoKChArVq1AAAxMTFISEgw2Ke7uzvCwsJM3md1srOXUkxBvu7Qm1oBKi3UFA1PHANERERUMltLvvndu3ehVqvh6+trsNzX1xcXL140aR9TpkxBQECANvAkJCRo91F0n/JrReXl5SFPL0Gkp6eb/BnKy04lpZiCfF0XWFVUgPLzDZ+XNWCaiIjImlm8C6wy5s+fjzVr1mDDhg1w0J9kp5zmzZsHd3d37S0wMLAKW2lIrgDl5ym1y6qjAsQuMCIiopJZNAB5e3tDqVQiMTHRYHliYiL8/PxK3XbRokWYP38+duzYgdatW2uXy9uVZ5/Tpk1DWlqa9nbz5s2KfByT2NlLMxQW5usCkKlngZVW1WEXGBERkeksGoDs7e3Rvn177QBmANoBzZ07dy5xuwULFmDOnDnYtm0bOnToYPBa/fr14efnZ7DP9PR0HD58uMR9qlQquLm5Gdyqi0olV4CKjwEqKCgeclgBIiIiqnoWHQMEAJMmTcLo0aPRoUMHdOrUCYsXL0ZWVhbGjh0LABg1ahTq1KmDefPmAQA++ugjzJgxA7/88guCg4O143pcXFzg4uIChUKBN954Ax988AFCQkJQv359TJ8+HQEBARg0aJClPqaWtgJUIFWA8vMNz+DKywMcHXXPK1oBYgAiIiIqmcUD0PDhw5GcnIwZM2YgISEBbdq0wbZt27SDmOPi4mBjo6uWLFu2DPn5+XjqqacM9jNz5kzMmjULAPD2228jKysL48aNQ2pqKrp164Zt27ZVapxQVVE5GHaBydUfGQMQERFR9bN4AAKAiRMnYuLEiUZf27Nnj8Hz2NjYMvenUCjw/vvv4/3336+C1lUte+0YIOnQFw1ARccBmdoFVvQsMI4BIiIiKtkDfRbYg0ilku7V/3aByQOgZaUFoPJUgHgaPBERUckYgMzMQSVXgOwAGO8C08dB0ERERFWPAcjM7LUVIKkLrLoqQOwCIyIiKhkDkJnJ47DlAMQKEBERkfkxAJmZg7YCJHWBVVcFiAGIiIioZAxAZqZykK4BpimhAlTRAFT0LLCyAtAPPwCRkUBaWunrERERPYwYgMzM8d8ApC6wB1C8AlRVXWBljQFasgTYvh3QmzCbiIjIajAAmZmDXAEqNH4WWGkVIAAQwvh+y3savPy+9+6Vvh4REdHDiAHIzJwcpUMuCo2PASprLE9JVaDyjgHKzpbuGYCIiMgaMQCZmYNKHgMkjYYubwWopMpOebvAcnKkewYgIiKyRgxAZuboUHoFqKwAxAoQERFR5TEAmZmuC0waBF2eeYAA0ytAZQUguQJ0/37p6xERET2MGIDMTK4AocABGqHRVoAUUs9YhbvAynMx1IIC3eusABERkTViADIzZ6d/D7lahUJNobYC5Okp3ZtjELRc/QEYgIiIyDoxAJmZo4N0FXgUOqBQU6itAHl5Sff6FSAhild8TO0CK+00eHn8D8AARERE1okByMyctAHIsAJkLAAZCzGsABEREVUeA5CZuThJl8CQu8CKVoD0g4yxEFMVp8HrV4AyM4uPHyIiInrYMQCZmXYQ9L9dYHIFyNtbutevABkLQFVdAQJ4JhgREVkfBiAzc3T893SvQhXyCwuRmio99fWV7itaASrPxVD1K0AAAxAREVkfBiAzU6n+fSBsEXerAIWFgI0NEBQkLdavAOl3Y9n8+5MqqwvM3r74tkUVrQBxHBAREVkbBiAz0wYgACej0wBI1R8XF2lZSV1gdnbFl+mTA5CTU+nrAcUrQAxARERkbRiAzMzBQff47EUpidSpowtGJXWByQGorAqQHIBKOw2eFSAiIrJ2DEBmZmsLKGykdHLlqpRw6tTRBSNjFSAbG0CpNFxWlBxqWAEiIiIqGwOQBaicpZRz/aIrgLIrQEpl2WOAkpOlez8/6Z5jgIiIiErGAGQBAfXTAQC3zjQEUHYFSKksvQKUmwukS7tEnTolrydjBYiIiKwdA5AFNGpcAAAozHEGYFoAKq0ClJgo3dvbA7VqGW5rDOcBIiIia8cAZAGhrewMnpvSBSZXgEoLQL6+0hgjwLSZoOXZp1kBIiIia8MAZAFhbdwMnpenAmSssmMsAJlSAapbV7qXxw/JMjKALl2A+fPL+CBEREQPKAYgC+gQ6mTwXD8AVWQQdEKCdO/rW/bZYoCuAtSunXR/9qzhuKD9+4GDB4EVK0z4MERERA8gBiALCAwEbFRS4nBwKoSrq64LrCKDoOUKkJ9f6V1lMrkC1Lq1VAXKz5dCT9H9yRdqJSIietgwAFmAjQ3gWucWAMDdOxMKha4CpFbrxu+UdxB0eccAOTkBvXtLj//6S/d6UpJ0zwBEREQPKwYgC/ENlkYeO9T6915vhmi5G6ysCtA//wBffGEYgEzpAtOfNPGxx6THUVG61+UAlJVVeiWJiIjoQWVr6QZYq5DmWbj8F2DnHQeggcE1wnJzAWfnsitAPXoY7tPXF9qry5syBsjREQgLkx4fPw706gX85z+6QCWvK1+njIiI6GHBCpCFDHr2LhDxBnz6fQlACjly95U8DsjU0+Bl+mOATJkJ2slJGgPUpIm03717gblzdRUggN1gRET0cGIAspAmAQFA58+QpDyhXSZXgY4ele5NPQ1eZupp8PoVIABYsgSIiJAex8UBd+7o1mUAIiKihxEDkIXUc68HALiZfhMaIZV1goOl1wYPBhYuLL0LzFglqLxjgOQAFB4ObNkiXXFeowEuXNCtywBEREQPIwYgCwlwDYCNwgb56nwkZUl9Ttu3AwMHSq8fOFD6IOiil7Owtwc8PMo3D5CT3nRENjZAUFDxbasyAH3xBbBhQ9Xtj4iIqKIYgCzETmkHfxd/AMDNtJsApAkRhw6VXs/OLr0ClJVluD9fX0ChKL0LLD1dmvSwaAVIJleg9FVVAIqNBV57DRg5EigoqJp9EhERVRQDkAXJ3WBxaXHaZXIoyckpvQJkLADJ6+qvp2/kSGnyw4wM6bmT4YTU1RqAbtyQ7nNygPPnq2afREREFcUAZEHGApAcSspbAWrbVrcuYDwAnT5t+NycFaD4eN3jEydKXo+IiMgcGIAsqLQKUNEAVPQ0eDkABQUB164BS5fq1gWKnwav0RiGEKB4BUgeA6SvqgKQ/pllx49XzT6JiIgqihMhWlCgWyAA6UwwmRxKinaBFT0NXg5Azs5Agwa6fZY0Big52TAUKRTSwGl91VkBYgAiIqKahBUgCypPF1hJFSBnZ8N9ltQFdvu24XNbWykE6TNXF9jp06VP1EhERFTdGIAsqDyDoItWgORT2U0NQPoVGMD4mVj+/tJcQIAuHMkB6Pp14OuvpSvHV4T+++fmAtHRFdsPERFRVWAAsiA5ACVmJSKvULoCankHQRcNQCV1gRWtABmjVAL1pCahbl3pXg5Ab70FvPQS8L//lb0fY+QKkHzRV3aDERGRJTEAWVAtx1pwtpMSzPX71wHoKkBqte6aYKWdBl/RClBJ5LPJOnWS7uUAJAeoW7dM209R8vt37Fi5/RAREVUFBiALUigUaOPXBgBw9I50ATD9M7Pk+XrKUwEydQxQSb75RpqFum9f6bkcgOSrzN+7J7UhIcG0/cn7kD9L48bSfdHT+ImIiMyJAcjCOtWRSi2Hbx0GIJ2ZJYcdOXxUZBB00UHGcgVm4UKgSxfdafNFeXgAnTsDrq6GbdAPQJMnS+OFpkwp/er0Mrn7y8VF2k5/v0RERJbA0+AtLKxOGADg8G0pACkUUjdYVpZhBUgOGmV1gZU1BqhVKynAlMXFRbqXg0pamnR/755uIsMFC6RB0Z9+Wvq+5PDl7198v0RERJbACpCFhdWVAtDpxNPILZQG/cjdYMnJ0r2zc+VOg9dodCEkIMC0dukHldxc3XgkuQtM9sMPZe9L/70ZgIiIqCZgALKwIPcg1HaujUJNIU7GnwSgGwgtj7Nxcyt9IkR9xgJQUBBw9670uE4d09old4FlZOiqP4AUgORgJj8v69R4uQvM31/XXjkA5eYC774LfPmlae0iIiKqCgxAFqZQKHTjgP7tBpMrQHIAcnev3Gnw9+5L93Z2gKenae3Sr9TI438AIDERuH/fcN2kpNL3ZawClJUlhbJHHwU+/BCYOBGIiyt5H0RERFWJAagGkMcBHbl9BEDxAOTmVvnT4AFp8sOisz+XRD8A6QceOaTY2OgGNOufESaE4X6EAP75R3ocGGi43wULgEOHdOv9/LNpbSMiIqosiwegpUuXIjg4GA4ODggLC8ORI0dKXPf8+fMYOnQogoODoVAosHjx4mLrzJo1CwqFwuDWtGnTavwEldfWT5p850ziGQC6LjC5sqLfBVa0AlT0gqalBaCBA01vkxxUip7yLgccLy/deKKEBCAlBRg5EvDxMZzkcNMm4MgRqZ3DhxsGoJgY6XGbNtL9jz8WD1BERETVwaIBaO3atZg0aRJmzpyJEydOIDQ0FBEREUgqoU8lOzsbDRo0wPz58+Hn51fiflu0aIH4+Hjtbd++fdX1EapEa9/WAICLdy8irzBPG2rkEKNfAaroafBr1gArVpjeJv1gZWzSwtq1AV9f6fG1a9IEh7/8IgWh3bt17X/nHenxG28UPwtMHlv0/PPSDNHR0ZwhmoiIzMOiAeiTTz7Biy++iLFjx6J58+ZYvnw5nJyc8N133xldv2PHjli4cCFGjBgBlUpV4n5tbW3h5+envXl7e1fXR6gSdd3qwtPBE2qhRvTd6GJVnfIMgi7pNPjevYHyHAalUheCjE2i6OMDyBl00yZdNQeQQhAAnDolhRo3N+Dtt6Vl+mOA5ABUr56uOrV5s+ltJCIiqiiLBaD8/HwcP34c4eHhusbY2CA8PBwHDx6s1L6vXLmCgIAANGjQACNHjkRcDR9dq1AotFWg0wmntV1gsopUgIoGoKKhyhRyWCmpAiQHIHkcj0w+4+zYMen+kUekgdz67dUfXO3uLk3OCABnz5a/nUREROVlsQB09+5dqNVq+Mr9KP/y9fVFQnmus1BEWFgYVq1ahW3btmHZsmWIiYlB9+7dkSHPKmhEXl4e0tPTDW7mJgegM4lnKlUBMhaAFECxUGWK0gKQfgUoJ0e6ly90KgcgecLEdu2K71N/bJGHB9CypfSYAYiIiMzB4oOgq1rfvn3x9NNPo3Xr1oiIiMCWLVuQmpqKX3/9tcRt5s2bB3d3d+0tMDDQjC2WaANQ0hmjFSD9QdBClK8LzMnJ9LO/9JUVgIpkV3TuLN3LXWDyeJ727Q3bIpNzpru7LgBdv87rhBERUfWzWADy9vaGUqlEYmKiwfLExMRSBziXl4eHBxo3boyrV6+WuM60adOQlpamvd28ebPK3t9Uob6hAEquAOlXdvLzdQHHlApQRbq/ANO7wGRyALp7V2qjXM3RD0D6Y4tk7u7S/mrXlsJddHTF2lsV7t7lmWhERNbAYgHI3t4e7du3R1RUlHaZRqNBVFQUOsvfpFUgMzMT165dg788aY0RKpUKbm5uBjdza1G7BRRQICkrCWqlYXdd0YkQ9SskppwFVtEA5OMj3cuXwbC3N3ytaAB65BHpPiUFOH9eCkGenkBwsOF6crCSyYfb0t1gUVHS55o+3TLvT0RE5mPRLrBJkybhm2++wffff4/o6GiMHz8eWVlZGDt2LABg1KhRmDZtmnb9/Px8nDp1CqdOnUJ+fj5u376NU6dOGVR3Jk+ejL179yI2NhYHDhzA4MGDoVQq8cwzz5j985WHk50T2vlLg2WuZegSgJ0doFIZDoKWA5CdnXTTV5UVoBYtDJ/Xr697XLQCpFIBbaXpjJCSohsA3a5d8e43/QDk6qprsxyAzp2rWHsra+9e6f7AAcu8PxERmU+FrgZ/8+ZNKBQK1K1bFwBw5MgR/PLLL2jevDnGjRtn8n6GDx+O5ORkzJgxAwkJCWjTpg22bdumHRgdFxcHGxtdRrtz5w7ayt+yABYtWoRFixahZ8+e2LNnDwDg1q1beOaZZ5CSkgIfHx9069YNhw4dgo9czqjBRrYaiePxx3H63kEA0mlRbm5SgNAfBF3S+B+g5DFAFSEHElmDBsClS9JjHx8pvDg6SoOgGzXSVYzUauCvv6TH+gOgZfrt9vDQPW7VSrq3VAXo+nXp3thp/0RE9HCpUAB69tlnMW7cODz33HNISEjA448/jhYtWuDnn39GQkICZsyYYfK+Jk6ciIkTJxp9TQ41suDgYIgyBmisWbPG5PeuaUa0HIHJOycjNlM3CEbuHjJWATIWgIxVgIytZwpjAUhWu7YUzHx9gdhYICREqgK5uEinuMtzT8qhRp9+BUg+PV7//UypAGVnAzt2AOHhxbvUKkoOQLduSeOAKjJwnIiIHgwV6gI7d+4cOnWSLuD566+/omXLljhw4AB+/vlnrFq1qirbZ1X8Xf0R3iAcsMvWLpMDkKkVIDkA6cfEipwCDwBNmugqSoAuACmVuouqyt1gjRtL9/Jki/LA6ZCQ4vstKQDJ68bHS9ctK83SpcDgwcAnnxguz88HfvrJ8AKuppIDUHa2bpJGIiJ6OFUoABUUFGhnYt61axeefPJJAEDTpk0RHx9fda2zQiNajDAagEytANkaqelVtAJkb284gFkOQF5eukAmBx/5el5eXob7aNSo+H71A5B+F5j+2PNSpm0CIF1+Q/9eNn8+8NxzwLx5pW9fVFaWdKV7mTm7wYQAli3jZUCIiMypQgGoRYsWWL58Of755x/s3LkTkZGRAKQxOl5FvwGpXCIaRQB2OdrnFa0A6avoGCBAuoK77NFHpaAzerRu2aJFwO+/A08/LT3Xv9yGu3vxQASUXAGys9NNpljWXJT37kn38qSLso0bpfsLF0rfvii5+iMzZwA6dAh45RWgHMPniIiokio0Buijjz7C4MGDsXDhQowePRqhodIcNps3b9Z2jVHFBLgGINjHF7H/Pi8agDQaXaXC1bX49lUdgP4d5w5ACisnTxq+7uMDDBmie64fgBo1Mj6OpqQKECB93tzcsitA8mSL+gEoIUHXvvJO5VQ0ABmb+6i6yGHLnO9JRGTtKhSAevXqhbt37yI9PR2e8mAQAOPGjYNTZb5tCQDQObiNNgDJFRL9LrANG6THPXoU37aqA5CxLqzS6Fd8StpWv3KlXwECpFCXlCRVgHJzpc9T9FR/wHgFaNs23ePKBiBzVoDu35fuU1Kkn6/NQzc/OxFRzVOh/2pzcnKQl5enDT83btzA4sWLcenSJdSuXbtKG2iNeoR00D52dZWGM8tfinfuALt3S4+HDy++rbExQJUJQK+9BjRvDrz1lmnrF60AGVNSFxigq3jdvy/NQ9Smje4CsPrkAJScrFu2davh69nZMJkcgOQAac4AJH8WtZqDr4mIzKVCAWjgwIH44YcfAACpqakICwvDxx9/jEGDBmHZsmVV2kBr1KOhLgAV2kl9PfIX88aNUiAICzOcmFBmrAJU0UHQgNRFdf48sGCBaeuXNwAV7QKTu/WuXJFCyYULwI0bxfchd4FlZAB5edJA4p07DdcpT5eSHIDkeYssUQECdJ+LiIiqV4UC0IkTJ9C9e3cAwG+//QZfX1/cuHEDP/zwAz7//PMqbaA18nLXlWxu5UlzAhXtFhkxwvi2CkXxcTfm7JU0pQvMlApQXJxuWdEBzXl5hpcDSUmRuszkICGfuVaebjA5AMndiuYcjyNXgACporV6teVmwyYishYVCkDZ2dlw/fdP9R07dmDIkCGwsbHBI488ghvG/lynctEPLFezTgAoXtl54omSty/aDWbOAFRVFSD9X6OiAUi/YgJI44DkrjBnZ918QuUJQHLg6iJNwF2uCtCvvwIvv1z23EUl0f8827cDzz4rncpPRETVp0IBqFGjRti4cSNu3ryJ7du3o0+fPgCApKQki1xI9GGjP3HhxcwjKNQUGlSA3NwMZ2UuqmhYMmcA+vcqJnB11T0uqrIVoKLdRHfv6gZD+/joTt03NQBlZurGC8lXrk9OlipN+q5e1V0vTCaENBbrq6+AzZtNe7+i9CtA8nXIrlzhVemJiKpThQLQjBkzMHnyZAQHB6NTp07aq7fv2LHD4FpdVDG2toCdnfTtl2OTgCO3jxgEoNatSz9TqGgAqswYoPJq3hyYOlWaqbmkS0mUdRYYUHoFSD8wAIYVIP0AZGo3VkKCdO/kBNSrJ13SA5AGnOsbNkyaC0l/KoCLF3WPc3NNe7+i9CtA8r6zssqeC4mIiCquQgHoqaeeQlxcHI4dO4bt27drl/fu3RuffvpplTXOmjk5/ZseVOnYeW2nQaj5d9qlEhXtAqvopTAqQqGQZmEurQunrHmAAMPT2y9cMKyGFA1AycnGA5CpFSB5XiU/P6n9TZpIz+Ur2gPSwPNz56R2bNmiW/7337rHmZmmvV9R+p9H/3PzoqxERNWnwjOO+Pn5oW3btrhz5w5u/fundqdOndC0adMqa5w1a9UKUDkWAJ7X8Hfc3wYVn7ICkCUrQKYorQvM2OSOmZmG1RxjXWByAPL2rngAkrvsHn1UupevaA9I+5fH+OzapVuuH4CKBjNTFR3TJGMAIiKqPhUKQBqNBu+//z7c3d0RFBSEoKAgeHh4YM6cOdAYm7SFym3nTmDr0WjA6T5OxJ+AQqErgZQ3AJmzAmQKueqjUhUfn1TSELLz53WPjXWBVWYMUNEA9Nhj0r083xJgGMAOHJDGDAlhOCaotFPY//wTeOklICfHcHlhYcldXQxARETVp0IzQb/77rv49ttvMX/+fHTt2hUAsG/fPsyaNQu5ubmYO3dulTbSGjk4AF2bNoW90h6puam4fO8+gFoAgJYtS9+2pleA6tYFZswAAgKKjxMyVgECgP79gT59pO4nOWjY2koB4u5d3bgdHx/d5TvS0qR5gkrap0weAyQHoB49pDFWly5JIaROHcMAlJ8P7NsnnW2mH1JKqwC98w5w5ox09t6AAbrlpV21ngGIiKj6VKgC9P3332PFihUYP348WrdujdatW+OVV17BN998g1WrVlVxE62XvdIerX1bAwAOn9BNa1zWWV2WPA3eVLNnSxWRoopWgLp1k+41GulSF3fu6IKGfCZc0S4wV1eglpQVERsr3Z8/DzzyCLBjR/H3LFoB8vDQnQ0mV4GKDqjetUt34VVZSQFICOkMMkC6zIcp2wAMQERE1alCAejevXtGx/o0bdoU9yo6EIKMau8vfRPXf1waeTt0aNnbWPI0+MoqWq35v/+Two086/XVq7rQ0LixdJ+cbNgFBujCkTzB4cKFwOHDwJdfFn9P/UHQsqLjgOQAFBAg3X/7LbB4sfS4d2/pXm6XEMDPPwMxMdLzpCTdafZFu8kYgIiILKNCASg0NBRLliwptnzJkiVo3bp1pRtFOh0CpMtiJPutRWysNEtwWWr6GKDSFK0AeXpKVR35zKyrV3UhQl5W9DR4QBeArl2Tusn+9z/p+ZUrxd+zaAUI0M0IffCgdC8HoAkTpC7Ie/ekuYq8vaWQBujatWkT8J//FA9hclv1yQOg9cOXjAGIiKj6VGgM0IIFC9C/f3/s2rVLOwfQwYMHcfPmTWzRP0eYKk2uAJ2IP4F69QQUJU2uo6doF9iDdHXxohWgf6+3q51V2lgF6O5d3RXj5QDUsKF0f/26NF5H3ubqVemio/ohsegYIADo1Em6v3hRGqcjB6DgYOCLL3QVoldekcYIAbr3OHVKt5+bN0sPQPI2ISG6dnh6SsGIAYiIqPpU6KuxZ8+euHz5MgYPHozU1FSkpqZiyJAhOH/+PH788ceqbqNVa1G7hXYg9IGbB0zaRh4Q/CAyVgECdAHoypXiASgvTzcHj3wpDv0KkP5Ynfz84meHGasA+fjo9nH0qC4A1a0L9OoFvPWWdNmM117TjTe6d0/q/lKrdfv53/9MqwD5+uo+e1iYrl0VvbwGERGVrsK1gYCAAMydOxe///47fv/9d3zwwQe4f/8+vv3226psn9WzV9rjqeZPAQCe2/Ac0nLTytzm3yuTPJCKVoDkU+b1K0ByV1O9erpKDyBVgeR5heTlRQMQAFy+rHusfxmMopfukIPI4cOGAQgAFiwA9u+XLv4qXwA2P1+awTk+XrePzZt1Y4GAkitAtWrpwlu7dlIVTwhdVYiIiKrWA9Q5Yr2W9luKYI9gxKTG4J2od8pcf9w4MzSqmtja6sYs2djoApEcgC5d0gUWLy/dAGRAChByD6FcvblyRbqshkoFhIfrlgHAhg3SZTsAaaC4/gSNgC4Abdmiu8yFPAhan5MTYG8vPb53zzAA/fWXYZdYSRUgeawTAAQFAf7+0mN2gxERVQ8GoAeAh4MHlvZbCgDYeGkjRBlXyZS7hh5UcleQh4du/FL9+tJjOYi0bStVe4oGIFndurpxQYA0ZqdNG+nx5cvSAObhw6VrlgFS9afo8Co5AMkDoX18pPmZilIoDLvB9Ks2BQWG1w4rrQI0cKD0GR57TDeuSL96ZIqcHGnKACIiKh0D0APisfqPwcHWAXcy7iD6bnSZ6y8zcrr3g0Ku+sjjfwCpwhIUpHs+erR0Lw9GBgy/+JVKacCyrF8/aaAxIFWAFi40HF9jLFO2aWMYouTuL2PkAJSSoqsAGbseWmqqdFaaTL8C9M470inzjRpJ44sAYN26kt+zqORkqevvQe4CJSIyl3KdBTZkyJBSX08tbVpbqhQHWwd0r9cdO6/vxK7ru9Dcp3mp648aBeAV87StqskVIP0ABEjBICZG6iZ79llpmXzWF2B4uQxA6gaTu7v69tWN4/nrL8PLXADFL8oKSNWe558Hli+Xnpc2A7c8Dig5WTfZ4XvvAUXPCRBCCj1yu+XT9+Xt5SrUf/8LfPKJNIg6IcH4afJFLV8uha/4+OJnupWmoECqcrVvX/NmDSciqi7lqgC5u7uXegsKCsKoUaOqq61WL7yBNIhl5/WdFm5J9TJWAQJ0FZx+/QyDj1zxKDpJpDwQunFjKTzJ2+flSV1pjzwCREcDkZFSRciYZcukMUS//gosWlRym+UK0OXLUvhQKKQANmKEbh358+h3g127Jt3LEz3KWrQAOneWqkXff1/y++o7fFj3uOiM06V54w2gZ0+pwvXOOyVfm4yI6KEiqJi0tDQBQKSlpVm6KQZO3DkhMAvC5UMXkV+YX/rKmZlCSAUH6fEDZMAAqdlPP224/OJFIYYNEyI62nD5vXtCLFokRHy84fJ166T9zJ0rPddohPDykpY1b158P5Uxdqy032HDpPvataXlaWlCvPCCEJs3CxESIr3299/Sa6mpuh+RsV+1b7+VXmvQQIjCQsPPW6+eEMOH65ZlZwvh6Kjb39GjprX7yhUhlErddoAQfn5CnDtXseNARGRJ5fn+5higB0ioXyh8nHyQmZ+JNefWWLo51aakClCTJsDatUDRq7B4egJvvlm8m2joUOlaYPKZXgqF1KX066/ShUmNXM2lwuQuLLkbTj6Ly80N+OYb6QKo8iBtuQIkV39q1y4+/xEgDdL28pLmEfr9d93y3bulQdzr1klnxKnVwB9/GF5p/s6d0ttbWCh1Bb7xhrR9ZKR0VlzDhlKX28cfG9/uyhXpTDwiogcdA9ADxEZhg/97RLruwpRdU5CRl2HhFlUPeS4fuVupohQKaeC0/kzYnTsDTz9t+vgYU8ltlQOQsTE7RQOQfIFU+RT/opydgYkTpccffaQbqH3ihHSv0QD//COFlmHDDLctKwDNni2dQffnn9LzuXOBQYN0Z8VFRRUfGJ6YKI0TCguTusneeUdqnznPOktJ4VluRFQ1GIAeMJM6T0KjWo0QnxmPOX/PsXRzqsXo0dKcPfJA5wdB0bAmV4D0lTcAAVLAcHSUQs+rr0pnkR0/rnt97lxpjJIc9rp2lZaXNX/Q1q3SfadO0qU92rWTnnfrJg0yj4uTKk83bugCx+LFQEYGkJYmVZ/mzZMC0969xt/j1i2pHfpnvek7elQKil9/XXpbZTt3StMVPPVUxULQpUtS26tKQYFUQTPW/vh46WdFRDUXA9ADRmWrwuKIxQCAxYcW49Ldh68/IixM+rJr1crSLTFd0QkSjVWA5G6y8gQgb2/g3Xelx0uXSmezyRUgQKoAAdIFWWNjpdeB4hWg7GzprLLBg6XuP3luot9/11WZAKnq9Mgj0uOBA6WpBB57TKoIydUhQKpIyVauLN7udeuAwEBpYHWrVsZntF60SKoqmRKACgt13XUbNgAffCAt/+EHYOxY3fxQJTl4EGjeXPr8VWX9euCzz6Rgqv/+t29L3bWhobp5nqpaQUH5LpNy7Rpw7Fj1tKUybt2SQnVl3bihO6OSyGRmGJP0wKmpg6D19f+5v8AsiMifIoVGoym+wgM8CPpBlJsrRHCw7pB/9lnxdebP1w3ujokRont36fkvv5S9/x07DAc5F71t3Sqt99130vOICCFmzhTim2+EyMgQokkT3br160v3QUHG32vmzJLfR6EovszRsfgg7iFDDNfp318ahK7RCHH9ujQA3MFBek2plNpY1Nmz0uBxIYT46itpXXkbhUKIw4eFcHWVnv/6a+nHTx6kDghx4ULZx9sUPXvq9vnPP7rlM2bolssD1TMyhFi/XoiCgsq/b1aWEC1aSL9v6ellr5+aKoS3txB2dkLcuFH5968qFy8KoVIJER5euf3cuCGEi4sQzZpJv19k3crz/c0AZMSDEIAu370s7OfYC8yC+O38b8VXYAAyux9/1B3yn38u/vqKFbrXbWx0j48cMW3/Y8botvHx0T22t5e+FIUQYts23TL5febMkR7LYUG+jRxp/H327tWtM2SIEE8+KZ111rChdLad/j7k9/n6a2nb7GzpjDUPD2n5ihW6dSIihGjXTnpcr57hfv76y7ANhYVC1KmjO5a+vtLjxYuFGDxYety0qW77//u/ko9bVpb0BSmvO2WKace7NBcuGLb/ww+l5fn5Qvj7G762aZMQL70kPV60qPLvPXu2bt+fflq+9Y39XlqK/u9SYqIQycnS7095ffihbj/Xr1d9O+nBwgBUSQ9CABJCiPei3hOYBeG/yF+k5qQavsgAZHZqtXR6vY2NEJcuFX990ybjVZV790zb/6FDum3GjNGd0v/oo7p1zp4tvn85bH3wgfRXsrx82TLj75OXJ52y36SJEPfvG75WWCiEm5uucvPee9Ljzp2lKgwgxIgR0r27u1Tx+PzzkitKtra6tunTD2HyafoNG0pt27q1+H4eecRw+5gY6Xir1VKFTf+9AgIMpxUo6tNPhejUSYjYWOn5/ftCdOwoRI8eQuzcKS2Tw6hKJd336yctX79eF1AnTpQe9+0rRK1a0uPu3Ut+X9nNm0LcvWv8tbg4IZycdJ+7Xr3Sq0r370s/B3n9V181vl5qqnSsTp6Ufr6zZ+teW7FCanejRiX/zpw9K8SqVeWrwMjTXQBS1czZueRq0K+/Sj/jK1cMl2s0UjVM3s8vvwhx547p/6bo4cMAVEkPSgDKKcgRIZ+HCMyCeGPrG4YvMgBZREZG8f+kZenpQgwdWryLyVQajRBt2kjbfPmlVFEBhJg3T7dOSorxoKFQSF0FCxbolp09W/J7FRZKYcOYPn2k7Tt1kr5s5IDi52f4noMG6bY5cUKIhQuF+PhjIbZsEcLTUwoPkyZJ63boIMT77wsxfboQGzZIX9RFP4PczaVfHdKvROXm6o6T/KX42mtCtG4tPZ46VRca335bqgydOyfEn39KgbWw0PD4yJUieT4m+darl+6YLl6sC3uFhUIMHKjb9vz54p9BqZTChjGbN0vHAZCqSBkZUnXj8ceFeOwxId56S4jAQOn1sDBprilAiNWrpe2N/XclhzA7O+m+Y8fi62zbJrXr7beFeOUV3fqxsbqAK988PHTVRn0tW0qvy12WZSksNAxm+hVRY9108v5ffNFw+alThu17+mkpwNWpI1WVSnP7tvT5kpONv/7XX0Js327a56GagwGokh6UACSEEJsubhKYBVHn4zqGY4EYgGq0P/+U/tMfMKB8250/LwWonBwhTp+WvhT1x89oNLpxMvpVj8cek16Pj5fCR0iI9Bd/RSxZYhi8+vc3HrqWLi15H4mJQly+LMSxY8a3lb+wIyN1FSb9X+9p06TlderougPnzpXatGVL8f15eUmVlaVLS65GyZUt+daggfSeTz4pPW/TxvCLesYMqfoid68dOqSrzpw4IbWzVavi77N+vfSaWq0bF6XfvSnf5G6zoreQECmwzZolPe/SReraUiik4yV/8e/apdtGHkNla2vYzaTRSEFW/vz6wVI/0L7zjm6M27ffGv4sb9/WrTdunDQOrUUL6Zi/9JLULVjUiRMl/xyWLDFc98YN3Wvu7obtf+st4z87QKrKxcWVXO0bNUpa7/nni7928aIUChUKqRpZlpgYKUw/AF8ZDz0GoEp6kAJQVn6WdizQxeSLuhcYgGq8a9eMD/6trAYNpB+7i4vUtaRQCPHHH7rX79yRKkUVpVZLwUX+YvntN92v2lNP6UKCsW7AovLzpa4PQOrO+c9/dPtydZWC3h9/FP8rPTFRCo9r1+oCinyTB4sHBUn3vr6G1a7vvtONS3Jzk76s5SqWh4cUMOV9/P237vGpU9Jg59atpXbKn//xx6XXu3WT7uvW1YU1/fEpcvfjuHFSEG3USBoT9fvvuurQW29J1aOiX+QrVkjv+eabui/ZO3d0AVfuYpOP4717usHu48dL7ZHHUe3frzsWf/9dPDjI+5Qfy91eH30kLevQwfBn8fPPuvUDAoqPNevZUwpCUVG6bT75RHrt0Ud13Yjy7fHHpZA4frxU0Xn3XcPX33lHqiRmZEjHGpCqiyUFqg4dinfNFRbqjpmLS/H/IocPNwzCpf0XumqVYdAu2m1cVEX/8HhQaTTSeK8PPjDPVxEDUCU9SAFICCF6reolMAti6RG9P7kZgKyW/EUcESH951MdIUtfXp70JeHtLURSkjT25qefTN9+9Wqpe0o+o2nuXKn9L79s2vbz5hn/4jtzRoh9+6Q2FZWWJoUq+YsxMVGq4Mjdfk89Je1DruAEBZU8vkU/AMiBQ3b9uhS2fHx044O8vKSuKHl9uWI3ebK0jX63ovw5SiK3U67YyF1kvXtL997eup+/3D33ySfSc7VaF970B4kPGCB1HbZtKx0/WXKyLqzoD9x/4YXix75JE+m46IcbHx+pm/KXX3SVpo8+EuKJJ6THclWvpJv+wH9AGhMkV4VycnSvu7pKgVF/MPqxY4bH7Z9/DPf1ww+61w4e1C2XuxknTDB+/AsKdH9wyLc1awzXiY6WunX375cCb1CQVI2sqU6dkqpZFT2j7ttvpT8aunSR/jjSP57165t+0kdFMQBV0oMWgObsnSMwC2LI2iG6hQxAVmv0aN2Xi7mkpVWuqlRUTIzxrhNjLl2SKjkjR0rTDwCVP7VaHtAt3157reR11WrdOCNA6oLTd/y41MbsbN314ABdFQqQgsKdO7pt5KpWRETp7dTv5vrkE6laU7RaIpOnYWjWTPp5jRunq/LoD9D/6quS30+u0I0Zo1smBwD5zD9AiC++0H32d97RdafJZ/ABUli7fVuIhASpS1ij0Z3ZZ2cnhQ79rq1166SwqF+hAnRdWPKg6nHjdG0bOlRa9uabUjfwkCFS9UeusskBrWtXaWzTggW6ZSNGSIPe5fcZO1YKWUFB0r+xjAwp7MihVh4/9dxzuvfXD2b6tyF6/1WbQqMR4vvvpWOZmyv9/OQK68yZUlhNSJCeJydL47lWrJAqjStXSl3npvj0U10b69UTYuNG4+udPy/97Iy1s3Fj3T5sbHRhXL45Ouq6gasDA1AlPWgB6EDcAYFZEJ7zPUWh+t+6PAOQ1YqNlUrOOTmWbon56HcrnD5d8kBjU+XlCfHf/0pnnplycdg//tBVH0o77vfvC/HGG1L3159/SmeIAdKXp77Ll6Uv2cuXS39fjUYagxUWJn2BZ2VJY7wAqYoUF6dbNylJVxWRu6lsbHQVi6FDpVBS0qBgIYQ4cEBXtfr5Z904JaVS6uKQ9110fiL5Nfn2yivGB1Nv2iRVhOSL+a5dq6scyHNI3bkjdQvK+5KnUDh1ShokrX9RZHlqCv35q5Yu1XVHzp+vq7bpj52LjNSdiffyy8YrUm3b6ipuM2cKsXu3ruom/z7KAcnWVmpD7966APf++1JgjYyUjmVhoTTeSK7Y3b0r/Vvet89wXq0PP5QqSQqF9L7yZ1u0SKpiBgQUb6uHhy4waTTSNA7/+590huYrr0gBsGFD4+G8Vy8p+D7/vDRofORIXYCVf9ePHpV+X+XucAcHKXDqt2HDBt3vuxxKSzrRojIYgCrpQQtABeoC4fqhq8AsiB9P/ygtZAAiMhuNRvoS27OnfNulpkp/qRsLAxX1zjvSP/unny7+2r59ui9gd/fydVUKYXgmov6ta1cp3A0cKI2JKSoxUfel2qpV+b74/vlHiKtXDZedPStVaho3Ln1Mzb17xStG8s3OTnr91191VRpvb6kLR7/7JyNDiNBQKVj8/LMUHOSQCUjLk5OliqUcLHv1kqqQXbpIz997T/eZ337beHvk6ldoqBRMSmq3sclIAWmqArka16iRruomt6lRI6ntXbsa316+zZkjVSvlMzRLu33zjXT85bMu5bY9/bTUdSs/DwqS1isokP4AkLcfOtT03wNTMQBV0oMWgIQQYurOqQKzIOzn2Itd13YxABFZqbw8aUxLSXPh7NghfcGWNVi3JPKEnra2UgXoww9LnvpB39tvS2Nqio7HqaiYmNKrVbLwcKm9jzyi66p0cDAMf3IQKumYFBYahqKzZ6WqyOefG7ZB7nIretMPcAUFUldtjx7SAO2nny45YNjZSdWbZ5+VZj7Xn8dLHtQunzGpX+1JS5O6yu7ckbrGik48qlJJQXbIEGng/c8/SwPiY2IMP/epU1KgXbhQCkYvvih1Dcrjvpo1082zVbTaI4TUHQgUn+drwwYpbOrPoF5VGIAq6UEMQIXqQjFk7RCBWRDK2Uoxd8s7DEBEVOU0GqlrqqxuwZri0CGpMhUdLXUDvf661E1aHbZvl7oVe/XSnYXXs2fp22g0QixfLnVF/fabrlL2/PO6aRJkmzfrKkw3bkhzcn31lTQBq/zfvbFZ0W/ckEKLvb0UuopW1MorNVVXWZLPknzySak70ddXNyeXfBansck6q+trqTzf3wohhDDflcceDOnp6XB3d0daWhrc3Nws3RyT5RTk4PnNz2P1udVwygeyPpSWZ91LxNsHZuPJJk8iolGEZRtJRPQQy88H7O2lCxJ//jkwapR0IV5T7d8vXbD4xRcBW9vir1+8CNSrBzg56ZZNnaq7QPHly0BIiPF95+YCKhWgUJjenpLMng3MmiU99vKSLrh78ybg4iJdRNlSyvP9zQBkxIMagABACIHvT3+PX4+sxJaX/gYAvPDLCHx7eY30+kz+uImIHibnzgEdOgCDBwOrV5vvfa9fB86fB5o1Axo1Mt/7loYBqJIe5AAkE5mZULi6AgCc3wGy7f9dzgBERPTQSU+XqkLGqkbWpDzf3zZmahOZmaKEGmdOQY6ZW0JERNXNzY3hp7wYgKzMrfRblm4CERGRxTEAWZmb6Tct3QQiIiKLYwCyAuM7vIzu9boDAG6mMQARERExAFmBRX0WoVEtaYg+K0BEREQMQFYj0C0QACtAREREAAOQ1Qh0/zcAsQJERERk+QC0dOlSBAcHw8HBAWFhYThy5EiJ654/fx5Dhw5FcHAwFAoFFi9eXOl9WgttBYgBiIiIyLIBaO3atZg0aRJmzpyJEydOIDQ0FBEREUhKSjK6fnZ2Nho0aID58+fDz8+vSvZpLeQKEE+DJyIisnAA+uSTT/Diiy9i7NixaN68OZYvXw4nJyd89913Rtfv2LEjFi5ciBEjRkClUlXJPq1FXbe6AIDU3FRk5mdauDVERESWZbEAlJ+fj+PHjyM8PFzXGBsbhIeH4+DBg2bdZ15eHtLT0w1uDxs3lRvcVNK04BwITURE1s5iAeju3btQq9Xw9fU1WO7r64uEhASz7nPevHlwd3fX3gIDAyv0/jVdPfd6AIDY1FjLNoSIiMjCLD4IuiaYNm0a0tLStLebNx/OCklzn+YAgDOJZyzcEiIiIsuyWADy9vaGUqlEYmKiwfLExMQSBzhX1z5VKhXc3NwMbg+jtn5tAQAnE05auCVERESWZbEAZG9vj/bt2yMqKkq7TKPRICoqCp07d64x+3yYtPFrAwA4lXDKou0gIiKyNFtLvvmkSZMwevRodOjQAZ06dcLixYuRlZWFsWPHAgBGjRqFOnXqYN68eQCkQc4XLlzQPr59+zZOnToFFxcXNGrUyKR9WjO5AnQ55TIy8zPhYu9i4RYRERFZhkUD0PDhw5GcnIwZM2YgISEBbdq0wbZt27SDmOPi4mBjoytS3blzB23bttU+X7RoERYtWoSePXtiz549Ju3Tmvm6+MLfxR/xmfE4k3gGXQK7WLpJREREFqEQQghLN6KmSU9Ph7u7O9LS0h7c8UBZWYDLvxWezEzA2RkA0O/nfth6dSuW9luKVzq+YsEGEhERVa3yfH/zLDArox0IHc+B0EREZL0YgKxMW38pAB25w+ujERGR9WIAsjI9g3pCAQXOJJ7BnYw7lm4OERGRRTAAWRkfZx90rNMRALDt6jYLt4aIiMgyGICsUN9GfQEAW69utXBLiIiILIMByArJAWjHtR0oUBdYuDVERETmxwBkhToEdIC3kzfS89Jx6NYhSzeHiIjI7BiArJDSRonH6j8GANh7Y6+FW0NERGR+DEBWqnu97gCAfXH7LNwSIiIi82MAslLd6nUDABy4eQBqjdrCrSEiIjIvBiAr1ap2K7ip3JCRn4EziWcs3RwiIiKzYgCyUkobpfZiqP/E/WPh1hAREZkXA5AVk8cBMQAREZG1YQCyYo8GPwoA2HplK9Lz0i3cGiIiIvNhALJij9R9BM28myGrIAs/nv7R0s0hIiIyGwYgK6ZQKDC+w3gAwJfHvoQQwsItIiIiMg8GICs3KnQUnOyccCH5AnbH7rZ0c4iIiMyCAcjKuTu4Y0zoGADA3H/mWrYxREREZsIARJjSbQrsbOzwV8xfnBmaiIisAgMQoZ57PYxtMxYAMHbTWOyN5fXBiIjo4cYARACA93q8Bz8XP1y9dxWPfv8oK0FERPRQYwAiAECgeyDOv3Ie/UL6QUBg6dGllm4SERFRtWEAIq1ajrXwfq/3AQAbojfgfs59C7eIiIioejAAkYF2/u3QqnYr5KnzsObcGks3h4iIqFowAJEBhUKB/7b9LwBg2bFl0AiNhVtERERU9RiAqJhRoaPgpnLD2aSzWH12taWbQ0REVOUYgKiYWo61MKXrFADAe7vfQ15hnoVbREREVLUYgMioNx55AwGuAYhNjcWnhz61dHOIiIiqFAMQGeVk54R5vecBAOb8PQc3025auEVERERVhwGISvRc6+fQrV43ZBdk47Vtr/Fq8URE9NBgAKISKRQKLO23FLY2tth4cSNWnFhh6SYRERFVCQYgKlVr39b48LEPAQCvbXsNGy9utGyDiIiIqgADEJXpzS5vom+jvsgtzMXgtYMxcctESzeJiIioUhiAqEw2ChusH74e07pNg43CBkuPLsUvZ3+xdLOIiIgqjAGITOJg64APe3+IGT1mAADG/zkeF5IvWLhVREREFcMAROXybo930bluZ6TnpaPzt52x89pOSzeJiIio3BiAqFxsbWyxacQmdKvXDel56Ri8djAu3b1k6WYRERGVCwMQlZuPsw92PbcLjwY/iqyCLAz7bRhyCnIs3SwiIiKTMQBRhahsVfh5yM/wcfLBmcQzCP8xHMlZyZZuFhERkUkYgKjC/F39sX74erir3HHg5gH0XNUTablplm4WERFRmRiAqFK61euGg88fRB3XOoi+G43hvw1HoabQ0s0iIiIqFQMQVVozn2bY/MxmONo6Yvu17eixsgeu3rtq6WYRERGViAGIqkQ7/3b49elf4aZyw8FbBxG6PBTLji7jBVSJiKhGYgCiKvNE4ydw5uUzeDT4UWQXZOOVLa/g9W2vMwQREVGNwwBEVSrIIwi7Ru3CoscXAQC+OPIF2n7VFj1X9UTU9SgLt46IiEjCAERVzkZhgze7vInl/ZcDAE4nnsbfN/5GxE8R+PLolxZuHREREQMQVaOXOryEE+NOYN3T6/Bc6+egFmpM2DIBW69stXTTiIjIytlaugH0cGvr3xZt/dtiaLOhcLZzxvLjy/Hs+mfRwqcFOtftjAWPL4BCobB0M4mIyMqwAkRmoVAosDhyMToEdEBqbir239yPRQcX4duT31q6aUREZIUYgMhsVLYqbB25Fcv7L8ernV4FALy+7XX8ePpHZBdkW7h1RERkTRSC5ygXk56eDnd3d6SlpcHNzc3SzamYrCzAxUV6nJkJODtbtj1FaIQGj//4OP6K+QsA4OPkg1m9ZmFc+3GwtWHPLBERlV95vr9ZASKLsFHYYMPwDZjVcxaCPYKRnJ2MCVsmoOt3XXEq4RSEEFBr1JxDiIiIqgUrQEawAmReBeoCfH38a7z717tIy5Mupurt5I3U3FQ09W6Kv0b9BR9nHwu3koiIaroHrgK0dOlSBAcHw8HBAWFhYThy5Eip669btw5NmzaFg4MDWrVqhS1bthi8PmbMGCgUCoNbZGRkdX4EqgQ7pR0mdJqAc6+cw5BmQ2CvtMfd7Lso1BTiXNI59PulHzLzMy3dTCIieohYPACtXbsWkyZNwsyZM3HixAmEhoYiIiICSUlJRtc/cOAAnnnmGTz//PM4efIkBg0ahEGDBuHcuXMG60VGRiI+Pl57W716tTk+DlVCXbe6+H3Y77g/5T6OvngU+/+7H16OXjh25xiGrB2CnIIc3Ey7CY3QWLqpRET0gLN4F1hYWBg6duyIJUuWAAA0Gg0CAwPx6quvYurUqcXWHz58OLKysvDHH39olz3yyCNo06YNli+XZh4eM2YMUlNTsXHjxgq1iV1gNceR20fw6PfStcVUShXy1Hlo49cGU7tORb+QfnBVuVq6iUREVEM8MF1g+fn5OH78OMLDw7XLbGxsEB4ejoMHDxrd5uDBgwbrA0BERESx9ffs2YPatWujSZMmGD9+PFJSUkpsR15eHtLT0w1uVDN0qtMJvw/7HbY2tshT5wEATiWcwojfR8BrgRdafNkCE/6cgPs59y3cUiIiepBYNADdvXsXarUavr6+Bst9fX2RkJBgdJuEhIQy14+MjMQPP/yAqKgofPTRR9i7dy/69u0LtVptdJ/z5s2Du7u79hYYGFjJT0ZVKbJRJI6PO469Y/Yi4c0EvNv9XTT0bIgCTQEuJF/Al8e+RMtlLfHVsa+QlZ9l6eYSEdED4KGccGXEiBHax61atULr1q3RsGFD7NmzB7179y62/rRp0zBp0iTt8/T0dIagGqa1b2vt4w8e+wBzHp2DuLQ4nEw4iSm7puByymW8/OfL+OCfD7Bt5DaciD+BzPxMPN/uedgr7S3YciIiqoksGoC8vb2hVCqRmJhosDwxMRF+fn5Gt/Hz8yvX+gDQoEEDeHt74+rVq0YDkEqlgkqlqsAnIEtRKBQI8ghCkEcQIhpGYPmx5fjs8Ge4kXYDrZe31g6U/vLYl/hmwDd4pO4jFm4xERHVJBbtArO3t0f79u0RFRWlXabRaBAVFYXOnTsb3aZz584G6wPAzp07S1wfAG7duoWUlBT4+/tXTcOpRnG0c8T/df4/HB93HO3820EjNHCxd4GXoxfOJZ1Dl2+74I1tbyBfnW/pphIRUQ1h8dPgJ02ahG+++Qbff/89oqOjMX78eGRlZWHs2LEAgFGjRmHatGna9V9//XVs27YNH3/8MS5evIhZs2bh2LFjmDhxIgAgMzMTb731Fg4dOoTY2FhERUVh4MCBaNSoESIiIizyGck8vJy8sHv0bnz75LeInhCNixMvYlToKAgIfHb4M0T+FInLKZehERqk5qZylmkiIitm8dPgAWDJkiVYuHAhEhIS0KZNG3z++ecICwsDAPTq1QvBwcFYtWqVdv1169bhvffeQ2xsLEJCQrBgwQL069cPAJCTk4NBgwbh5MmTSE1NRUBAAPr06YM5c+YUGzxdEp4G/3D536X/4dn1z2onU1QqlFALNeq41kF4g3CENwhH7/q94e/KCiER0YOsPN/fNSIA1TQMQA+fM4lnMHnHZOyJ3YMCTYHRdVrWbom+jfpidOhotKjdwswtJCKiymIAqiQGoIdXZn4m7ufch7uDO47cPoJd13dh1/VdOBF/AgK6fwrhDcLxdPOnMaDxADjZOeHQrUMI9QuFn0vJg+2JiMiyGIAqiQHI+qRkp2Dn9Z349fyv2Hhxo0EYslfaI1+dDxd7F7zb/V282ulVONvzeBIR1TQMQJXEAGTdrt+/jrXn1mLTpU04fPswAMDL0QspOdJs4t5O3hjabCh6BvVEv5B+cHdwt2RziYjoXwxAlcQARLL4jHhk5GegUa1G+OnMT3h/7/u4dv+a9nV7pT2GNhuKoc2GIj0vHV3rdUVjr8YWbDERkfViAKokBiAqSaGmEFuvbMWe2D3YcnULLt69aPC6jcIGYXXCcDP9JkJqheCp5k9hSLMhHDtERGQGDECVxABEphBC4ET8CXxx5AucTToLlVKFg7eKX8RXAQW6B3VHeP1w2Cvt8UjdR9AjqAcUCoUFWk1E9PBiAKokBiCqqJPxJ3E68TQaejbE4duH8duF37TjiPS19m2NCR0nICkrCfEZ8Xih3Qto69/WAi0mInp4MABVEgMQVaW4tDj8fuF3nE48jZzCHPxx+Q9kF2QXW29gk4EY22YsHqv/GOyUdsgtzIWHg4f5G0xE9IBiAKokBiCqTvdz7uPbk9/il7O/wNfFF672rlh3YZ32dRuFjfZirv1C+iGsThhsbWzRMaAjutbrCic7J0s1nYioRmMAqiQGIDK3C8kX8O2Jb7Hh4gbEpMaUuJ6ngyf6hvTFmcQzUCqUaObTDH0a9EG/kH7wdTHtUi9ERA8rBqBKYgAiS4rPiIe90h73cu5h5amVuJdzDxn5Gdgbuxe3M24b3UYBBZp6N0V2QTYc7RzRqFYjjA4djUeDH4WAgJejFwddE9FDjwGokhiAqCZSa9T488qfOHr7KNr5t4O90h5H7xzFn1f+xLE7x0rd1t/FHwObDMTsR2ejtnNtM7WYiMi8GIAqiQGIHjTxGfE4nXgaHg4eyC7Ixu6Y3Vh2bJl29mqZq70r+jTsA08HTyRnJ8PZ3hnNvJthcNPBaODZAI52jgCA9Lx0CCE4yzURPVAYgCqJAYgeBhqhgVqjRoGmAPvi9mFa1DSciD9R6jb13OuhtW9r7Li2A2qNGr2Ce6G1b2u08GmBx+o/hvqe9c3UeiKi8mMAqiQGIHoYaYQGB24ewL64fcgrzIOviy8y8jKwO3Y3/or5C3nqvDL3Ud+jPnrX7412/u1wPP44XOxdMLnLZNR1q2uGT0BEVDoGoEpiACJrI4RAWl4a9sXtw+mE0+jTsA88HDyw49oOXL9/HYdvH8bh24dRqCkstq2DrQNCfUOhUCgQcz8Gdko7NPBsgCdCnsDN9JtwsHXAhI4TEOQRZIFPRkTWhAGokhiAiIrLyMvAvrh9iIqJwunE02hduzWO3jmKf+L+KXNbWxtbhNQKQRu/Nni+7fPwcPBAel46NEIDT0dP1HWry8HZRFRpDECVxABEZBohBM4lncOllEsQQqBhrYZQa9TaoNTAswGi70Zj1/VdZe6rtnNt9A/pj/4h/WGvtIePs482dLmqXNHCpwV6BffSDtQmIiqKAaiSGICIqlZsaiyupFzB79G/47cLv8FeaQ93B3fYKGxwL+ceEjMTIVD2f0WOto5o598OQR5BUGvUqONaB0EeQbBR2MDHyQeNajVCy9otobJVmeFTEVFNwwBUSQxAROaVXZCNo7eP4sczP+Js0llohAaJmYlQKBToGdQT+ep8HLh5ADfTb5a5LzsbOyhtlACABp4NoFKq4GTnhIiGEehWrxua+TSDr7MvJ4YkeggxAFUSAxBRzSOEwIXkCzideBrxGfGwUdjgRtoNxGfGQwiBOxl3cCH5Au7n3i9zX54Onmjl2woeDh44cPMA6nvUx4vtXsSj9R+FUqFETmEOmno3hY3CBgCQr86HWqOGg60DgxNRDcYAVEkMQEQPJiEE4tLiICCg1qhx/f51FGoKcTvjNrZc2YLTiacRcz/GpO42HycfhNUNAwDsur4LuYW5cLB1QDv/duhctzNa+LRAel46Gns1Rp+GfbRVJyKyHAagSmIAInp45Rbm4tLdSziZcBJ3s+8irE4Y9t/cjw0XN+BUwikooIDSRonsgmyT9+nj5AMAKNQUwtneGa19WyOvMA/xmfGIaBiBRrUa4Xb6bXg6esLX2Rc+zj5QKpRo6t0Uge6B1fVRiawOA1AlMQARWSe1Rg0bhQ0KNAU4dOsQLiRfQEZeBh5v+DgaejbEnYw7OHz7MA7dOoQr967ATeWG3TG7Tep2M0apUGJk65Go51YP+ep8CAg09GyIFrVbwMPBA79f+B0FmgI80fgJtPFrAwdbhyr+xEQPFwagSmIAIiJTZRdk43TCabjYu8BOaYf7OfdxMuGkdKabyh3rL65HdkE26rrWRWpeKpKyknA3+y5yC3Nx8e5Fk99HAQWaejdFr+BeuJF2A3mFeWhUqxGyC7LhYu+CbvW6wdfZF3Xc6qCJVxPcz72Pq/euIiU7BXXc6sBd5Y6krCQ082kGF3uXajwiRJbDAFRJDEBEZA774/bj1/O/QkDAzsYOaqHGpZRLuJB8AbfTb+Pxho/DTeWGHdd2IDU31eT9uqvckZaXZvQ1lVKFHkE90Nq3NbwcveBs7wwXexd4OXrBVeWKQk0hajvXRn2P+rwYLj1wGIAqiQGIiCxNCKE940wIgaSsJOy9sReHbh1CQ8+GcLZ3xrV71+CqckVCZgIO3TqEtLw0XL9/HbmFuQCAum51UcuxFm6k3kB2QTbcHdxxN/uuyW3wcPCAq70rbG1sYae0Q7BHMJp7N4e/qz9sbWzhbOeMzoGd4WLvgrzCPKhsVVApVXCwdYCDrQOc7fn/DpkXA1AlMQAR0YMqtzAX0cnRCPIIQi3HWgCkACU7n3weB24eQHRyNNLy0pBdkI3M/EwkZycjMz8TSoUS8Znx5QpKJWng2QB9G/VFWJ0w5KvzEZ8Zr33NwdYBjWo1go+TD9wd3NHYqzE0QoOs/Cx4OXlV+r3JOjEAVRIDEBFZu4y8DMSlxSGnMAeFmkLkFebhUsolXEm5gsQsaeZuufKkERqolCrkq/ORp84zetHcstjZ2KFQUwgBgTZ+bVDfoz6yCrKQlZ+FzPxM7WMXexcEugci0C0Qdd3qwsHWAQdvHYQCCrTwaYHeDXrjkbqPwE31gP7fTZXCAFRJDEBERBWn1qiRkZ+BPbF78FfMXziZcBLOds6o41pHO19SZn4mrty7gtRcaWB4el56lbbB0dZROy1BbefayC3MlcKTWyBsFDZwsXfRzgjuZOcEPxc/+Ln4wcnOCUII1HauDU9HT9jZ2MFOaQc3lRvcVe6cCLOGYwCqJAYgIiLzkSewdLRzhI3CBluvbEVmfqZ2gLaznTOc7Z3hZOeE9Lx03Ey7iZvpN3Ez7SbS89PRMaAjVEoVjt05hu3XtuN2xu1qaaejrSNc7F1Qy7EW6nvWh73SHln5WUjLS4O/iz8aejZEkEcQcgpyYKe0QxOvJsgqyIK90h4dAzoiLi0OGfkZaFm7JZztnKEWaqg1au3EnAoo4OPso52BnMqPAaiSGICIiB5cGXkZSM5Ohp2NHTLzM5GUlQRHO0ek5aZpw1F6XjqSspIASNWohMwEJGQmIKcwBwCQmJmItLw0FKgLUKApQL463yxtd7ZzRlv/tujToA9upN3ArfRbqOtWF/Xc68HL0QsFmgLt4PT7uffhbOcMXxdf1HaujbpudZFTkIOd13dqB6Wn5abBw8EDjWo1Qlv/tg/9XFIMQJXEAERERPqyC7KRkJmA7IJsJGYmIjY1FhqhgaOdI9xUbridfhvX7l9DXFocnO2dkZWfhav3rsJN5YZ7OfdwNuks/Fz84OHggcspl6ERGu2+Ffj3bD8TLtFSGfZKe3Sq0wmNazXG9dTrsFHYwMfJB7Wda8PHyQc+zj7a524qN6TnpUMt1EjNTcX+uP1wd3BHeINw1PeoD28nbyhtlEjNTdWe9afWqJGZnwkBAQ8Hj2r9LCVhAKokBiAiIqpKuYW5UClVUCgU2kHiSoXSYExRoaYQV1KuSGOnYv9CkHsQmnk3w52MO4hLi8P93PuwV9rjXs49ZORnwNPBE1kFWUjKSkJCZgLu5dwDAHQM6AhfF1/kFebB3cEd93Pu41zSOSRmJVbZ51EqlHCyc0JGfgZsbWwR5B6Em+k3tZWyDgEd0M6vHdRCjUJNIQo0BVBAgZBaIfB39YcCCrTxa4OOdTpWWZsABqBKYwAiIqIHTXZBNvIK8+Dp6FnsNSEErt67in1x+3Aj7QYaejaEjcIGydnJSM5KRlJWkvQ4W3qckZcBN5Wbdg6oR+o8gqTsJBy8eRBJWUlVUq2a1m0aPuz9YaX3o68839+2VfrOREREZBFOdk5wsnMy+ppCoUCIVwhCvEIq/T4F6gIkZycjLTcN9dzrISUnBdfuXUOwRzACXAOQlpeGTRc3ISEzAbY2ttoQla/OR/TdaNzPuQ8BgWbezSrdlspgBcgIVoCIiIgePOX5/ua5dkRERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKyOraUbQNXEyQnIzNQ9JiIiIi0GoIeVQgE4O1u6FURERDVSjegCW7p0KYKDg+Hg4ICwsDAcOXKk1PXXrVuHpk2bwsHBAa1atcKWLVsMXhdCYMaMGfD394ejoyPCw8Nx5cqV6vwIRERE9ACxeABau3YtJk2ahJkzZ+LEiRMIDQ1FREQEkpKSjK5/4MABPPPMM3j++edx8uRJDBo0CIMGDcK5c+e06yxYsACff/45li9fjsOHD8PZ2RkRERHIzc0118ciIiKiGkwhhBCWbEBYWBg6duyIJUuWAAA0Gg0CAwPx6quvYurUqcXWHz58OLKysvDHH39olz3yyCNo06YNli9fDiEEAgIC8Oabb2Ly5MkAgLS0NPj6+mLVqlUYMWJEmW1KT0+Hu7s70tLS4ObmVkWflIiIiKpTeb6/LVoBys/Px/HjxxEeHq5dZmNjg/DwcBw8eNDoNgcPHjRYHwAiIiK068fExCAhIcFgHXd3d4SFhZW4z7y8PKSnpxvciIiI6OFl0QB09+5dqNVq+Pr6Giz39fVFQkKC0W0SEhJKXV++L88+582bB3d3d+0tMDCwQp+HiIiIHgwWHwNUE0ybNg1paWna282bNy3dJCIiIqpGFg1A3t7eUCqVSExMNFiemJgIPz8/o9v4+fmVur58X559qlQquLm5GdyIiIjo4WXRAGRvb4/27dsjKipKu0yj0SAqKgqdO3c2uk3nzp0N1geAnTt3atevX78+/Pz8DNZJT0/H4cOHS9wnERERWReLT4Q4adIkjB49Gh06dECnTp2wePFiZGVlYezYsQCAUaNGoU6dOpg3bx4A4PXXX0fPnj3x8ccfo3///lizZg2OHTuGr7/+GgCgUCjwxhtv4IMPPkBISAjq16+P6dOnIyAgAIMGDbLUxyQiIqIaxOIBaPjw4UhOTsaMGTOQkJCANm3aYNu2bdpBzHFxcbCx0RWqunTpgl9++QXvvfce3nnnHYSEhGDjxo1o2bKldp23334bWVlZGDduHFJTU9GtWzds27YNDg4OZv98REREVPNYfB6gmojzABERET14Hph5gIiIiIgsgQGIiIiIrI7FxwDVRHKvIGeEJiIienDI39umjO5hADIiIyMDADgjNBER0QMoIyMD7u7upa7DQdBGaDQa3LlzB66urlAoFFWyz/T0dAQGBuLmzZscWF0GHqvy4fEyHY9V+fB4mY7HynTVeayEEMjIyEBAQIDBGeTGsAJkhI2NDerWrVst++ZM06bjsSofHi/T8ViVD4+X6XisTFddx6qsyo+Mg6CJiIjI6jAAERERkdVhADITlUqFmTNnQqVSWbopNR6PVfnweJmOx6p8eLxMx2NluppyrDgImoiIiKwOK0BERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8MAZCZLly5FcHAwHBwcEBYWhiNHjli6SRY3a9YsKBQKg1vTpk21r+fm5mLChAnw8vKCi4sLhg4disTERAu22Hz+/vtvDBgwAAEBAVAoFNi4caPB60IIzJgxA/7+/nB0dER4eDiuXLlisM69e/cwcuRIuLm5wcPDA88//zwyMzPN+CnMp6zjNWbMmGK/a5GRkQbrWMvxmjdvHjp27AhXV1fUrl0bgwYNwqVLlwzWMeXfXlxcHPr37w8nJyfUrl0bb731FgoLC835UaqdKceqV69exX63Xn75ZYN1rOFYLVu2DK1bt9ZObti5c2ds3bpV+3pN/J1iADKDtWvXYtKkSZg5cyZOnDiB0NBQREREICkpydJNs7gWLVogPj5ee9u3b5/2tf/7v//D//73P6xbtw579+7FnTt3MGTIEAu21nyysrIQGhqKpUuXGn19wYIF+Pzzz7F8+XIcPnwYzs7OiIiIQG5urnadkSNH4vz589i5cyf++OMP/P333xg3bpy5PoJZlXW8ACAyMtLgd2316tUGr1vL8dq7dy8mTJiAQ4cOYefOnSgoKECfPn2QlZWlXaesf3tqtRr9+/dHfn4+Dhw4gO+//x6rVq3CjBkzLPGRqo0pxwoAXnzxRYPfrQULFmhfs5ZjVbduXcyfPx/Hjx/HsWPH8Nhjj2HgwIE4f/48gBr6OyWo2nXq1ElMmDBB+1ytVouAgAAxb948C7bK8mbOnClCQ0ONvpaamirs7OzEunXrtMuio6MFAHHw4EEztbBmACA2bNigfa7RaISfn59YuHChdllqaqpQqVRi9erVQgghLly4IACIo0ePatfZunWrUCgU4vbt22ZruyUUPV5CCDF69GgxcODAErex5uOVlJQkAIi9e/cKIUz7t7dlyxZhY2MjEhIStOssW7ZMuLm5iby8PPN+ADMqeqyEEKJnz57i9ddfL3Ebaz1WQgjh6ekpVqxYUWN/p1gBqmb5+fk4fvw4wsPDtctsbGwQHh6OgwcPWrBlNcOVK1cQEBCABg0aYOTIkYiLiwMAHD9+HAUFBQbHrWnTpqhXr57VH7eYmBgkJCQYHBt3d3eEhYVpj83Bgwfh4eGBDh06aNcJDw+HjY0NDh8+bPY21wR79uxB7dq10aRJE4wfPx4pKSna16z5eKWlpQEAatWqBcC0f3sHDx5Eq1at4Ovrq10nIiIC6enp2r/4H0ZFj5Xs559/hre3N1q2bIlp06YhOztb+5o1Hiu1Wo01a9YgKysLnTt3rrG/U7wYajW7e/cu1Gq1wQ8VAHx9fXHx4kULtapmCAsLw6pVq9CkSRPEx8dj9uzZ6N69O86dO4eEhATY29vDw8PDYBtfX18kJCRYpsE1hPz5jf1Oya8lJCSgdu3aBq/b2tqiVq1aVnn8IiMjMWTIENSvXx/Xrl3DO++8g759++LgwYNQKpVWe7w0Gg3eeOMNdO3aFS1btgQAk/7tJSQkGP39k197GBk7VgDw7LPPIigoCAEBAThz5gymTJmCS5cuYf369QCs61idPXsWnTt3Rm5uLlxcXLBhwwY0b94cp06dqpG/UwxAZDF9+/bVPm7dujXCwsIQFBSEX3/9FY6OjhZsGT1sRowYoX3cqlUrtG7dGg0bNsSePXvQu3dvC7bMsiZMmIBz584ZjL0j40o6VvrjxFq1agV/f3/07t0b165dQ8OGDc3dTItq0qQJTp06hbS0NPz2228YPXo09u7da+lmlYhdYNXM29sbSqWy2Gj3xMRE+Pn5WahVNZOHhwcaN26Mq1evws/PD/n5+UhNTTVYh8cN2s9f2u+Un59fsUH2hYWFuHfvntUfPwBo0KABvL29cfXqVQDWebwmTpyIP/74A7t370bdunW1y035t+fn52f0909+7WFT0rEyJiwsDAAMfres5VjZ29ujUaNGaN++PebNm4fQ0FB89tlnNfZ3igGomtnb26N9+/aIiorSLtNoNIiKikLnzp0t2LKaJzMzE9euXYO/vz/at28POzs7g+N26dIlxMXFWf1xq1+/Pvz8/AyOTXp6Og4fPqw9Np07d0ZqaiqOHz+uXeevv/6CRqPR/gdtzW7duoWUlBT4+/sDsK7jJYTAxIkTsWHDBvz111+oX7++weum/Nvr3Lkzzp49axAad+7cCTc3NzRv3tw8H8QMyjpWxpw6dQoADH63rOFYGaPRaJCXl1dzf6eqZWg1GVizZo1QqVRi1apV4sKFC2LcuHHCw8PDYLS7NXrzzTfFnj17RExMjNi/f78IDw8X3t7eIikpSQghxMsvvyzq1asn/vrrL3Hs2DHRuXNn0blzZwu32jwyMjLEyZMnxcmTJwUA8cknn4iTJ0+KGzduCCGEmD9/vvDw8BCbNm0SZ86cEQMHDhT169cXOTk52n1ERkaKtm3bisOHD4t9+/aJkJAQ8cwzz1jqI1Wr0o5XRkaGmDx5sjh48KCIiYkRu3btEu3atRMhISEiNzdXuw9rOV7jx48X7u7uYs+ePSI+Pl57y87O1q5T1r+9wsJC0bJlS9GnTx9x6tQpsW3bNuHj4yOmTZtmiY9Ubco6VlevXhXvv/++OHbsmIiJiRGbNm0SDRo0ED169NDuw1qO1dSpU8XevXtFTEyMOHPmjJg6dapQKBRix44dQoia+TvFAGQmX3zxhahXr56wt7cXnTp1EocOHbJ0kyxu+PDhwt/fX9jb24s6deqI4cOHi6tXr2pfz8nJEa+88orw9PQUTk5OYvDgwSI+Pt6CLTaf3bt3CwDFbqNHjxZCSKfCT58+Xfj6+gqVSiV69+4tLl26ZLCPlJQU8cwzzwgXFxfh5uYmxo4dKzIyMizwaapfaccrOztb9OnTR/j4+Ag7OzsRFBQkXnzxxWJ/gFjL8TJ2nACIlStXatcx5d9ebGys6Nu3r3B0dBTe3t7izTffFAUFBWb+NNWrrGMVFxcnevToIWrVqiVUKpVo1KiReOutt0RaWprBfqzhWP33v/8VQUFBwt7eXvj4+IjevXtrw48QNfN3SiGEENVTWyIiIiKqmTgGiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBERFQChUKBjRs3WroZRFQNGICIqEYaM2YMFApFsVtkZKSlm0ZEDwFbSzeAiKgkkZGRWLlypcEylUplodYQ0cOEFSAiqrFUKhX8/PwMbp6engCk7qlly5ahb9++cHR0RIMGDfDbb78ZbH/27Fk89thjcHR0hJeXF8aNG4fMzEyDdb777ju0aNECKpUK/v7+mDhxosHrd+/exeDBg+Hk5ISQkBBs3rxZ+9r9+/cxcuRI+Pj4wNHRESEhIcUCGxHVTAxARPTAmj59OoYOHYrTp09j5MiRGDFiBKKjowEAWVlZiIiIgKenJ44ePYp169Zh165dBgFn2bJlmDBhAsaNG4ezZ89i8+bNaNSokcF7zJ49G8OGDcOZM2fQr18/jBw5Evfu3dO+/4ULF7B161ZER0dj2bJl8Pb2Nt8BIKKKq7bLrBIRVcLo0aOFUqkUzs7OBre5c+cKIaQrdb/88ssG24SFhYnx48cLIYT4+uuvhaenp8jMzNS+/ueffwobGxvtleADAgLEu+++W2IbAIj33ntP+zwzM1MAEFu3bhVCCDFgwAAxduzYqvnARGRWHANERDXWo48+imXLlhksq1WrlvZx586dDV7r3LkzTp06BQCIjo5GaGgonJ2dta937doVGo0Gly5dgkKhwJ07d9C7d+9S29C6dWvtY2dnZ7i5uSEpKQkAMH78eAwdOhQnTpxAnz59MGjQIHTp0qVCn5WIzIsBiIhqLGdn52JdUlXF0dHRpPXs7OwMnisUCmg0GgBA3759cePGDWzZsgU7d+5E7969MWHCBCxatKjK20tEVYtjgIjogXXo0KFiz5s1awYAaNasGU6fPo2srCzt6/v374eNjQ2aNGkCV1dXBAcHIyoqqlJt8PHxwejRo/HTTz9h8eLF+Prrryu1PyIyD1aAiKjGysvLQ0JCgsEyW1tb7UDjdevWoUOHDujWrRt+/vlnHDlyBN9++y0AYOTIkZg5cyZGjx6NWbNmITk5Ga+++iqee+45+Pr6AgBmzZqFl19+GbVr10bfvn2RkZGB/fv349VXXzWpfTNmzED79u3RokUL5OXl4Y8//tAGMCKq2RiAiKjG2rZtG/z9/Q2WNWnSBBcvXgQgnaG1Zs0avPLKK/D398fq1avRvHlzAICTkxO2b9+O119/HR07doSTkxOGDh2KTz75RLuv0aNHIzc3F59++ikmT54Mb29vPPXUUya3z97eHtOmTUNsbCwcHR3RvXt3rFmzpgo+ORFVN4UQQli6EURE5aVQKLBhwwYMGjTI0k0hogcQxwARERGR1WEAIiIiIqvDMUBE9EBi7z0RVQYrQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1/h9k3Xe2me8hQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model_history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = model_history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.plot(epochs[0:300], loss[0:300], 'g', label= 'Training Loss')\n",
    "plt.plot(epochs[0:300], val_loss[0:300], 'b', label= 'Validation Loss')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/{model_name}/loss_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 10s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "#unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "#compile_model(unet, learning_rate)\n",
    "\n",
    "# Prognose mit Hilfe des geladenen besten Modells\n",
    "prediction = unet.predict(test_data_generator)\n",
    "\n",
    "# Erstellung einer binären Maske aus den wahrscheinlichkeiten, Schwellwert 0.5\n",
    "out = (prediction > 0.5).astype(np.uint8)\n",
    "\n",
    "# lediglich halbe Batch Size in eine Abbildung wegen Übersichtlichkeit\n",
    "rows = int(batch_size / 2)\n",
    "columns = 3\n",
    "\n",
    "# Anzahl verfügbarer Batches des Data-Generators\n",
    "no_of_batches = test_data_generator.__len__()\n",
    "\n",
    "# Prognose kommt als Tensor mit der Länge der Anzahl der Beispiele\n",
    "out_idx = 0\n",
    "\n",
    "# Erstellen des Prognosen-Ordners\n",
    "if not os.path.isdir(f'../output/predictions/{model_name}'):\n",
    "    os.makedirs(f'../output/predictions/{model_name}')\n",
    "\n",
    "# Input und Masken kommen als Batches, über die iteriert wird\n",
    "for batch_no in range(0, no_of_batches):\n",
    "\n",
    "    # iterieren über erste Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_I.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # iterieren über zweite Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][rows + i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][rows + i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_II.png', bbox_inches='tight', dpi= 400)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives', 'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', 'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', 'val_precision', 'val_recall'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives',\n",
    "                    'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', \n",
    "                    'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', \n",
    "                    'val_precision', 'val_recall']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(20):\n",
    "        writer.writerow({'loss': dict_data['loss'][i], 'accuracy': dict_data['accuracy'][i], 'binary_iou': dict_data['binary_iou'][i], 'true_positives': dict_data['true_positives'][i],\n",
    "                        'false_positives': dict_data['false_positives'][i], 'true_negatives': dict_data['true_negatives'][i], 'false_negatives': dict_data['false_negatives'][i],\n",
    "                        'precision': dict_data['precision'][i], 'recall': dict_data['recall'][i], 'val_loss': dict_data['val_loss'][i], 'val_accuracy': dict_data['val_accuracy'][i],\n",
    "                        'val_binary_iou': dict_data['val_binary_iou'][i], 'val_true_positives': dict_data['val_true_positives'][i], 'val_false_positives': dict_data['val_false_positives'][i],\n",
    "                        'val_true_negatives': dict_data['val_true_negatives'][i], 'val_false_negatives': dict_data['val_false_negatives'][i], 'val_precision': dict_data['val_precision'][i],\n",
    "                        'val_recall': dict_data['val_recall'][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': '0.25298193097114563', 'accuracy': '0.7866721749305725', 'binary_iou': '0.6463431119918823', 'true_positives': '111043808.0', 'false_positives': '48262192.0', 'true_negatives': '140314272.0', 'false_negatives': '19900488.0', 'precision': '0.697047233581543', 'recall': '0.8480232357978821', 'val_loss': '0.21770402789115906', 'val_accuracy': '0.8242917656898499', 'val_binary_iou': '0.6967154741287231', 'val_true_positives': '36183816.0', 'val_false_positives': '9768367.0', 'val_true_negatives': '51167764.0', 'val_false_negatives': '8851754.0', 'val_precision': '0.7874231934547424', 'val_recall': '0.8034497499465942'}\n",
      "{'loss': '0.17970937490463257', 'accuracy': '0.8502960205078125', 'binary_iou': '0.7348068356513977', 'true_positives': '111206328.0', 'false_positives': '27865604.0', 'true_negatives': '160480896.0', 'false_negatives': '19967952.0', 'precision': '0.7996317148208618', 'recall': '0.847775399684906', 'val_loss': '0.17682895064353943', 'val_accuracy': '0.8498079180717468', 'val_binary_iou': '0.7352555990219116', 'val_true_positives': '37936588.0', 'val_false_positives': '8678695.0', 'val_true_negatives': '52119008.0', 'val_false_negatives': '7237421.0', 'val_precision': '0.8138229250907898', 'val_recall': '0.8397879600524902'}\n",
      "{'loss': '0.16944220662117004', 'accuracy': '0.8586176633834839', 'binary_iou': '0.747620701789856', 'true_positives': '112447392.0', 'false_positives': '26535964.0', 'true_negatives': '161898704.0', 'false_negatives': '18638656.0', 'precision': '0.809070885181427', 'recall': '0.8578135967254639', 'val_loss': '0.16960737109184265', 'val_accuracy': '0.8433647751808167', 'val_binary_iou': '0.7283757328987122', 'val_true_positives': '41406300.0', 'val_false_positives': '12919748.0', 'val_true_negatives': '47966524.0', 'val_false_negatives': '3679141.0', 'val_precision': '0.7621813416481018', 'val_recall': '0.9183962941169739'}\n",
      "{'loss': '0.15938016772270203', 'accuracy': '0.8675968050956726', 'binary_iou': '0.7613716125488281', 'true_positives': '112991728.0', 'false_positives': '24180304.0', 'true_negatives': '164223536.0', 'false_negatives': '18125208.0', 'precision': '0.823722779750824', 'recall': '0.8617630004882812', 'val_loss': '0.18082629144191742', 'val_accuracy': '0.8287520408630371', 'val_binary_iou': '0.7072028517723083', 'val_true_positives': '41683936.0', 'val_false_positives': '14784452.0', 'val_true_negatives': '46140320.0', 'val_false_negatives': '3362991.0', 'val_precision': '0.7381817698478699', 'val_recall': '0.925344705581665'}\n",
      "{'loss': '0.15386037528514862', 'accuracy': '0.8729592561721802', 'binary_iou': '0.7696713209152222', 'true_positives': '113235904.0', 'false_positives': '22661028.0', 'true_negatives': '165692640.0', 'false_negatives': '17931140.0', 'precision': '0.8332484364509583', 'recall': '0.8632954359054565', 'val_loss': '0.20721104741096497', 'val_accuracy': '0.8287599682807922', 'val_binary_iou': '0.701651930809021', 'val_true_positives': '35156024.0', 'val_false_positives': '8233098.0', 'val_true_negatives': '52669072.0', 'val_false_negatives': '9913514.0', 'val_precision': '0.8102497458457947', 'val_recall': '0.7800396084785461'}\n",
      "{'loss': '0.14730830490589142', 'accuracy': '0.8784143328666687', 'binary_iou': '0.7784072160720825', 'true_positives': '114011392.0', 'false_positives': '21770962.0', 'true_negatives': '166660272.0', 'false_negatives': '17078148.0', 'precision': '0.8396627902984619', 'recall': '0.869721531867981', 'val_loss': '0.16745591163635254', 'val_accuracy': '0.8436726331710815', 'val_binary_iou': '0.7289546728134155', 'val_true_positives': '41680636.0', 'val_false_positives': '13103984.0', 'val_true_negatives': '47724816.0', 'val_false_negatives': '3462292.0', 'val_precision': '0.760809063911438', 'val_recall': '0.9233037829399109'}\n",
      "{'loss': '0.14401723444461823', 'accuracy': '0.8810575008392334', 'binary_iou': '0.7826745510101318', 'true_positives': '114393776.0', 'false_positives': '21271064.0', 'true_negatives': '167122240.0', 'false_negatives': '16733604.0', 'precision': '0.8432087898254395', 'recall': '0.8723866939544678', 'val_loss': '0.16687346994876862', 'val_accuracy': '0.8602073192596436', 'val_binary_iou': '0.7504729628562927', 'val_true_positives': '37713636.0', 'val_false_positives': '7516429.0', 'val_true_negatives': '53444012.0', 'val_false_negatives': '7297637.0', 'val_precision': '0.8338178992271423', 'val_recall': '0.8378708958625793'}\n",
      "{'loss': '0.13967755436897278', 'accuracy': '0.8848918080329895', 'binary_iou': '0.7889226675033569', 'true_positives': '114999336.0', 'false_positives': '20679376.0', 'true_negatives': '167741888.0', 'false_negatives': '16100101.0', 'precision': '0.8475856781005859', 'recall': '0.8771916627883911', 'val_loss': '0.1353950798511505', 'val_accuracy': '0.8823829293251038', 'val_binary_iou': '0.7869912385940552', 'val_true_positives': '40299460.0', 'val_false_positives': '7671211.0', 'val_true_negatives': '53208184.0', 'val_false_negatives': '4792872.0', 'val_precision': '0.8400853872299194', 'val_recall': '0.8937098383903503'}\n",
      "{'loss': '0.1352715641260147', 'accuracy': '0.8892213702201843', 'binary_iou': '0.7956593036651611', 'true_positives': '114638944.0', 'false_positives': '18970384.0', 'true_negatives': '169485760.0', 'false_negatives': '16425623.0', 'precision': '0.8580160140991211', 'recall': '0.8746753334999084', 'val_loss': '0.1568543165922165', 'val_accuracy': '0.8584086894989014', 'val_binary_iou': '0.7504804134368896', 'val_true_positives': '40856560.0', 'val_false_positives': '10655894.0', 'val_true_negatives': '50110464.0', 'val_false_negatives': '4348781.0', 'val_precision': '0.7931394577026367', 'val_recall': '0.9037994146347046'}\n",
      "{'loss': '0.12936197221279144', 'accuracy': '0.893817663192749', 'binary_iou': '0.8033660054206848', 'true_positives': '115608840.0', 'false_positives': '18361112.0', 'true_negatives': '169984368.0', 'false_negatives': '15566396.0', 'precision': '0.8629460334777832', 'recall': '0.8813313245773315', 'val_loss': '0.256801575422287', 'val_accuracy': '0.813231885433197', 'val_binary_iou': '0.6692835092544556', 'val_true_positives': '29273444.0', 'val_false_positives': '3966531.0', 'val_true_negatives': '56906144.0', 'val_false_negatives': '15825595.0', 'val_precision': '0.8806698322296143', 'val_recall': '0.6490923762321472'}\n",
      "{'loss': '0.12777672708034515', 'accuracy': '0.8952571153640747', 'binary_iou': '0.8057264089584351', 'true_positives': '115722160.0', 'false_positives': '18096608.0', 'true_negatives': '170331008.0', 'false_negatives': '15370898.0', 'precision': '0.8647677898406982', 'recall': '0.8827481865882874', 'val_loss': '0.13223814964294434', 'val_accuracy': '0.8917816877365112', 'val_binary_iou': '0.799962043762207', 'val_true_positives': '38216200.0', 'val_false_positives': '4436075.0', 'val_true_negatives': '56287440.0', 'val_false_negatives': '7032006.0', 'val_precision': '0.8959943652153015', 'val_recall': '0.8445903658866882'}\n",
      "{'loss': '0.12335705757141113', 'accuracy': '0.8994724750518799', 'binary_iou': '0.8126584887504578', 'true_positives': '115993240.0', 'false_positives': '17039420.0', 'true_negatives': '171406992.0', 'false_negatives': '15081117.0', 'precision': '0.8719155192375183', 'recall': '0.8849422335624695', 'val_loss': '0.13863824307918549', 'val_accuracy': '0.87993323802948', 'val_binary_iou': '0.7830523252487183', 'val_true_positives': '40182664.0', 'val_false_positives': '7800029.0', 'val_true_negatives': '53065372.0', 'val_false_negatives': '4923645.0', 'val_precision': '0.8374407887458801', 'val_recall': '0.8908435702323914'}\n",
      "{'loss': '0.12128963321447372', 'accuracy': '0.9008952975273132', 'binary_iou': '0.8151732683181763', 'true_positives': '116559416.0', 'false_positives': '17118276.0', 'true_negatives': '171295424.0', 'false_negatives': '14547673.0', 'precision': '0.8719436526298523', 'recall': '0.8890397548675537', 'val_loss': '0.1420867145061493', 'val_accuracy': '0.874578595161438', 'val_binary_iou': '0.7750580310821533', 'val_true_positives': '40642440.0', 'val_false_positives': '8783600.0', 'val_true_negatives': '52038120.0', 'val_false_negatives': '4507543.0', 'val_precision': '0.8222880363464355', 'val_recall': '0.9001650810241699'}\n",
      "{'loss': '0.11935042589902878', 'accuracy': '0.9026272892951965', 'binary_iou': '0.8180391788482666', 'true_positives': '116646776.0', 'false_positives': '16637965.0', 'true_negatives': '171761392.0', 'false_negatives': '14474606.0', 'precision': '0.8751697540283203', 'recall': '0.8896090984344482', 'val_loss': '0.16962216794490814', 'val_accuracy': '0.8450703620910645', 'val_binary_iou': '0.7304768562316895', 'val_true_positives': '40641952.0', 'val_false_positives': '11934879.0', 'val_true_negatives': '48911596.0', 'val_false_negatives': '4483273.0', 'val_precision': '0.7730011343955994', 'val_recall': '0.9006481766700745'}\n",
      "{'loss': '0.11748106777667999', 'accuracy': '0.9039813876152039', 'binary_iou': '0.8203401565551758', 'true_positives': '116874728.0', 'false_positives': '16479334.0', 'true_negatives': '171966000.0', 'false_negatives': '14200654.0', 'precision': '0.8764241933822632', 'recall': '0.8916603922843933', 'val_loss': '0.16435684263706207', 'val_accuracy': '0.8604539036750793', 'val_binary_iou': '0.7515079975128174', 'val_true_positives': '38347908.0', 'val_false_positives': '7986545.0', 'val_true_negatives': '52835852.0', 'val_false_negatives': '6801397.0', 'val_precision': '0.8276327252388', 'val_recall': '0.8493576645851135'}\n",
      "{'loss': '0.11296495795249939', 'accuracy': '0.9077730774879456', 'binary_iou': '0.8267014622688293', 'true_positives': '117159816.0', 'false_positives': '15511851.0', 'true_negatives': '172892432.0', 'false_negatives': '13956604.0', 'precision': '0.8830808997154236', 'recall': '0.8935556411743164', 'val_loss': '0.17737410962581635', 'val_accuracy': '0.8445158004760742', 'val_binary_iou': '0.7282230257987976', 'val_true_positives': '38698016.0', 'val_false_positives': '10038660.0', 'val_true_negatives': '50796784.0', 'val_false_negatives': '6438257.0', 'val_precision': '0.7940225005149841', 'val_recall': '0.8573595881462097'}\n",
      "{'loss': '0.1116277351975441', 'accuracy': '0.9087814092636108', 'binary_iou': '0.8284687399864197', 'true_positives': '117442272.0', 'false_positives': '15450539.0', 'true_negatives': '172932256.0', 'false_negatives': '13695691.0', 'precision': '0.8837368488311768', 'recall': '0.8955627679824829', 'val_loss': '0.22158901393413544', 'val_accuracy': '0.8260716795921326', 'val_binary_iou': '0.6940493583679199', 'val_true_positives': '32733368.0', 'val_false_positives': '6001649.0', 'val_true_negatives': '54806864.0', 'val_false_negatives': '12429828.0', 'val_precision': '0.8450588583946228', 'val_recall': '0.7247797250747681'}\n",
      "{'loss': '0.11073320358991623', 'accuracy': '0.9101096987724304', 'binary_iou': '0.8306362628936768', 'true_positives': '117300144.0', 'false_positives': '14963131.0', 'true_negatives': '173498800.0', 'false_negatives': '13758712.0', 'precision': '0.8868685960769653', 'recall': '0.8950188159942627', 'val_loss': '0.1295718252658844', 'val_accuracy': '0.8888552188873291', 'val_binary_iou': '0.7969772815704346', 'val_true_positives': '39977888.0', 'val_false_positives': '6724283.0', 'val_true_negatives': '54215616.0', 'val_false_negatives': '5053912.0', 'val_precision': '0.8560177683830261', 'val_recall': '0.8877701759338379'}\n",
      "{'loss': '0.11055346578359604', 'accuracy': '0.9099255800247192', 'binary_iou': '0.8303505182266235', 'true_positives': '117366416.0', 'false_positives': '14966230.0', 'true_negatives': '173373680.0', 'false_negatives': '13814412.0', 'precision': '0.8869044780731201', 'recall': '0.8946918249130249', 'val_loss': '0.1266525238752365', 'val_accuracy': '0.8892303705215454', 'val_binary_iou': '0.7984521389007568', 'val_true_positives': '41107320.0', 'val_false_positives': '7720637.0', 'val_true_negatives': '53125932.0', 'val_false_negatives': '4017818.0', 'val_precision': '0.8418807983398438', 'val_recall': '0.9109628200531006'}\n",
      "{'loss': '0.10677679628133774', 'accuracy': '0.9130255579948425', 'binary_iou': '0.8356871604919434', 'true_positives': '117830272.0', 'false_positives': '14455578.0', 'true_negatives': '173900384.0', 'false_negatives': '13334564.0', 'precision': '0.8907247185707092', 'recall': '0.8983373641967773', 'val_loss': '0.15511789917945862', 'val_accuracy': '0.8591651320457458', 'val_binary_iou': '0.7518163919448853', 'val_true_positives': '41172792.0', 'val_false_positives': '10981330.0', 'val_true_negatives': '49874412.0', 'val_false_negatives': '3943181.0', 'val_precision': '0.7894446849822998', 'val_recall': '0.9125990271568298'}\n"
     ]
    }
   ],
   "source": [
    "complete_csv = {}\n",
    "\n",
    "path = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "with open('../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log', 'r') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log') as f:\n",
    "    file_data = csv.reader(f)\n",
    "    headers = next(file_data)\n",
    "    new_dict = [dict(zip(headers,i)) for i in file_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': '0.25298193097114563',\n",
       "  'accuracy': '0.7866721749305725',\n",
       "  'binary_iou': '0.6463431119918823',\n",
       "  'true_positives': '111043808.0',\n",
       "  'false_positives': '48262192.0',\n",
       "  'true_negatives': '140314272.0',\n",
       "  'false_negatives': '19900488.0',\n",
       "  'precision': '0.697047233581543',\n",
       "  'recall': '0.8480232357978821',\n",
       "  'val_loss': '0.21770402789115906',\n",
       "  'val_accuracy': '0.8242917656898499',\n",
       "  'val_binary_iou': '0.6967154741287231',\n",
       "  'val_true_positives': '36183816.0',\n",
       "  'val_false_positives': '9768367.0',\n",
       "  'val_true_negatives': '51167764.0',\n",
       "  'val_false_negatives': '8851754.0',\n",
       "  'val_precision': '0.7874231934547424',\n",
       "  'val_recall': '0.8034497499465942'},\n",
       " {'loss': '0.17970937490463257',\n",
       "  'accuracy': '0.8502960205078125',\n",
       "  'binary_iou': '0.7348068356513977',\n",
       "  'true_positives': '111206328.0',\n",
       "  'false_positives': '27865604.0',\n",
       "  'true_negatives': '160480896.0',\n",
       "  'false_negatives': '19967952.0',\n",
       "  'precision': '0.7996317148208618',\n",
       "  'recall': '0.847775399684906',\n",
       "  'val_loss': '0.17682895064353943',\n",
       "  'val_accuracy': '0.8498079180717468',\n",
       "  'val_binary_iou': '0.7352555990219116',\n",
       "  'val_true_positives': '37936588.0',\n",
       "  'val_false_positives': '8678695.0',\n",
       "  'val_true_negatives': '52119008.0',\n",
       "  'val_false_negatives': '7237421.0',\n",
       "  'val_precision': '0.8138229250907898',\n",
       "  'val_recall': '0.8397879600524902'},\n",
       " {'loss': '0.16944220662117004',\n",
       "  'accuracy': '0.8586176633834839',\n",
       "  'binary_iou': '0.747620701789856',\n",
       "  'true_positives': '112447392.0',\n",
       "  'false_positives': '26535964.0',\n",
       "  'true_negatives': '161898704.0',\n",
       "  'false_negatives': '18638656.0',\n",
       "  'precision': '0.809070885181427',\n",
       "  'recall': '0.8578135967254639',\n",
       "  'val_loss': '0.16960737109184265',\n",
       "  'val_accuracy': '0.8433647751808167',\n",
       "  'val_binary_iou': '0.7283757328987122',\n",
       "  'val_true_positives': '41406300.0',\n",
       "  'val_false_positives': '12919748.0',\n",
       "  'val_true_negatives': '47966524.0',\n",
       "  'val_false_negatives': '3679141.0',\n",
       "  'val_precision': '0.7621813416481018',\n",
       "  'val_recall': '0.9183962941169739'},\n",
       " {'loss': '0.15938016772270203',\n",
       "  'accuracy': '0.8675968050956726',\n",
       "  'binary_iou': '0.7613716125488281',\n",
       "  'true_positives': '112991728.0',\n",
       "  'false_positives': '24180304.0',\n",
       "  'true_negatives': '164223536.0',\n",
       "  'false_negatives': '18125208.0',\n",
       "  'precision': '0.823722779750824',\n",
       "  'recall': '0.8617630004882812',\n",
       "  'val_loss': '0.18082629144191742',\n",
       "  'val_accuracy': '0.8287520408630371',\n",
       "  'val_binary_iou': '0.7072028517723083',\n",
       "  'val_true_positives': '41683936.0',\n",
       "  'val_false_positives': '14784452.0',\n",
       "  'val_true_negatives': '46140320.0',\n",
       "  'val_false_negatives': '3362991.0',\n",
       "  'val_precision': '0.7381817698478699',\n",
       "  'val_recall': '0.925344705581665'},\n",
       " {'loss': '0.15386037528514862',\n",
       "  'accuracy': '0.8729592561721802',\n",
       "  'binary_iou': '0.7696713209152222',\n",
       "  'true_positives': '113235904.0',\n",
       "  'false_positives': '22661028.0',\n",
       "  'true_negatives': '165692640.0',\n",
       "  'false_negatives': '17931140.0',\n",
       "  'precision': '0.8332484364509583',\n",
       "  'recall': '0.8632954359054565',\n",
       "  'val_loss': '0.20721104741096497',\n",
       "  'val_accuracy': '0.8287599682807922',\n",
       "  'val_binary_iou': '0.701651930809021',\n",
       "  'val_true_positives': '35156024.0',\n",
       "  'val_false_positives': '8233098.0',\n",
       "  'val_true_negatives': '52669072.0',\n",
       "  'val_false_negatives': '9913514.0',\n",
       "  'val_precision': '0.8102497458457947',\n",
       "  'val_recall': '0.7800396084785461'},\n",
       " {'loss': '0.14730830490589142',\n",
       "  'accuracy': '0.8784143328666687',\n",
       "  'binary_iou': '0.7784072160720825',\n",
       "  'true_positives': '114011392.0',\n",
       "  'false_positives': '21770962.0',\n",
       "  'true_negatives': '166660272.0',\n",
       "  'false_negatives': '17078148.0',\n",
       "  'precision': '0.8396627902984619',\n",
       "  'recall': '0.869721531867981',\n",
       "  'val_loss': '0.16745591163635254',\n",
       "  'val_accuracy': '0.8436726331710815',\n",
       "  'val_binary_iou': '0.7289546728134155',\n",
       "  'val_true_positives': '41680636.0',\n",
       "  'val_false_positives': '13103984.0',\n",
       "  'val_true_negatives': '47724816.0',\n",
       "  'val_false_negatives': '3462292.0',\n",
       "  'val_precision': '0.760809063911438',\n",
       "  'val_recall': '0.9233037829399109'},\n",
       " {'loss': '0.14401723444461823',\n",
       "  'accuracy': '0.8810575008392334',\n",
       "  'binary_iou': '0.7826745510101318',\n",
       "  'true_positives': '114393776.0',\n",
       "  'false_positives': '21271064.0',\n",
       "  'true_negatives': '167122240.0',\n",
       "  'false_negatives': '16733604.0',\n",
       "  'precision': '0.8432087898254395',\n",
       "  'recall': '0.8723866939544678',\n",
       "  'val_loss': '0.16687346994876862',\n",
       "  'val_accuracy': '0.8602073192596436',\n",
       "  'val_binary_iou': '0.7504729628562927',\n",
       "  'val_true_positives': '37713636.0',\n",
       "  'val_false_positives': '7516429.0',\n",
       "  'val_true_negatives': '53444012.0',\n",
       "  'val_false_negatives': '7297637.0',\n",
       "  'val_precision': '0.8338178992271423',\n",
       "  'val_recall': '0.8378708958625793'},\n",
       " {'loss': '0.13967755436897278',\n",
       "  'accuracy': '0.8848918080329895',\n",
       "  'binary_iou': '0.7889226675033569',\n",
       "  'true_positives': '114999336.0',\n",
       "  'false_positives': '20679376.0',\n",
       "  'true_negatives': '167741888.0',\n",
       "  'false_negatives': '16100101.0',\n",
       "  'precision': '0.8475856781005859',\n",
       "  'recall': '0.8771916627883911',\n",
       "  'val_loss': '0.1353950798511505',\n",
       "  'val_accuracy': '0.8823829293251038',\n",
       "  'val_binary_iou': '0.7869912385940552',\n",
       "  'val_true_positives': '40299460.0',\n",
       "  'val_false_positives': '7671211.0',\n",
       "  'val_true_negatives': '53208184.0',\n",
       "  'val_false_negatives': '4792872.0',\n",
       "  'val_precision': '0.8400853872299194',\n",
       "  'val_recall': '0.8937098383903503'},\n",
       " {'loss': '0.1352715641260147',\n",
       "  'accuracy': '0.8892213702201843',\n",
       "  'binary_iou': '0.7956593036651611',\n",
       "  'true_positives': '114638944.0',\n",
       "  'false_positives': '18970384.0',\n",
       "  'true_negatives': '169485760.0',\n",
       "  'false_negatives': '16425623.0',\n",
       "  'precision': '0.8580160140991211',\n",
       "  'recall': '0.8746753334999084',\n",
       "  'val_loss': '0.1568543165922165',\n",
       "  'val_accuracy': '0.8584086894989014',\n",
       "  'val_binary_iou': '0.7504804134368896',\n",
       "  'val_true_positives': '40856560.0',\n",
       "  'val_false_positives': '10655894.0',\n",
       "  'val_true_negatives': '50110464.0',\n",
       "  'val_false_negatives': '4348781.0',\n",
       "  'val_precision': '0.7931394577026367',\n",
       "  'val_recall': '0.9037994146347046'},\n",
       " {'loss': '0.12936197221279144',\n",
       "  'accuracy': '0.893817663192749',\n",
       "  'binary_iou': '0.8033660054206848',\n",
       "  'true_positives': '115608840.0',\n",
       "  'false_positives': '18361112.0',\n",
       "  'true_negatives': '169984368.0',\n",
       "  'false_negatives': '15566396.0',\n",
       "  'precision': '0.8629460334777832',\n",
       "  'recall': '0.8813313245773315',\n",
       "  'val_loss': '0.256801575422287',\n",
       "  'val_accuracy': '0.813231885433197',\n",
       "  'val_binary_iou': '0.6692835092544556',\n",
       "  'val_true_positives': '29273444.0',\n",
       "  'val_false_positives': '3966531.0',\n",
       "  'val_true_negatives': '56906144.0',\n",
       "  'val_false_negatives': '15825595.0',\n",
       "  'val_precision': '0.8806698322296143',\n",
       "  'val_recall': '0.6490923762321472'},\n",
       " {'loss': '0.12777672708034515',\n",
       "  'accuracy': '0.8952571153640747',\n",
       "  'binary_iou': '0.8057264089584351',\n",
       "  'true_positives': '115722160.0',\n",
       "  'false_positives': '18096608.0',\n",
       "  'true_negatives': '170331008.0',\n",
       "  'false_negatives': '15370898.0',\n",
       "  'precision': '0.8647677898406982',\n",
       "  'recall': '0.8827481865882874',\n",
       "  'val_loss': '0.13223814964294434',\n",
       "  'val_accuracy': '0.8917816877365112',\n",
       "  'val_binary_iou': '0.799962043762207',\n",
       "  'val_true_positives': '38216200.0',\n",
       "  'val_false_positives': '4436075.0',\n",
       "  'val_true_negatives': '56287440.0',\n",
       "  'val_false_negatives': '7032006.0',\n",
       "  'val_precision': '0.8959943652153015',\n",
       "  'val_recall': '0.8445903658866882'},\n",
       " {'loss': '0.12335705757141113',\n",
       "  'accuracy': '0.8994724750518799',\n",
       "  'binary_iou': '0.8126584887504578',\n",
       "  'true_positives': '115993240.0',\n",
       "  'false_positives': '17039420.0',\n",
       "  'true_negatives': '171406992.0',\n",
       "  'false_negatives': '15081117.0',\n",
       "  'precision': '0.8719155192375183',\n",
       "  'recall': '0.8849422335624695',\n",
       "  'val_loss': '0.13863824307918549',\n",
       "  'val_accuracy': '0.87993323802948',\n",
       "  'val_binary_iou': '0.7830523252487183',\n",
       "  'val_true_positives': '40182664.0',\n",
       "  'val_false_positives': '7800029.0',\n",
       "  'val_true_negatives': '53065372.0',\n",
       "  'val_false_negatives': '4923645.0',\n",
       "  'val_precision': '0.8374407887458801',\n",
       "  'val_recall': '0.8908435702323914'},\n",
       " {'loss': '0.12128963321447372',\n",
       "  'accuracy': '0.9008952975273132',\n",
       "  'binary_iou': '0.8151732683181763',\n",
       "  'true_positives': '116559416.0',\n",
       "  'false_positives': '17118276.0',\n",
       "  'true_negatives': '171295424.0',\n",
       "  'false_negatives': '14547673.0',\n",
       "  'precision': '0.8719436526298523',\n",
       "  'recall': '0.8890397548675537',\n",
       "  'val_loss': '0.1420867145061493',\n",
       "  'val_accuracy': '0.874578595161438',\n",
       "  'val_binary_iou': '0.7750580310821533',\n",
       "  'val_true_positives': '40642440.0',\n",
       "  'val_false_positives': '8783600.0',\n",
       "  'val_true_negatives': '52038120.0',\n",
       "  'val_false_negatives': '4507543.0',\n",
       "  'val_precision': '0.8222880363464355',\n",
       "  'val_recall': '0.9001650810241699'},\n",
       " {'loss': '0.11935042589902878',\n",
       "  'accuracy': '0.9026272892951965',\n",
       "  'binary_iou': '0.8180391788482666',\n",
       "  'true_positives': '116646776.0',\n",
       "  'false_positives': '16637965.0',\n",
       "  'true_negatives': '171761392.0',\n",
       "  'false_negatives': '14474606.0',\n",
       "  'precision': '0.8751697540283203',\n",
       "  'recall': '0.8896090984344482',\n",
       "  'val_loss': '0.16962216794490814',\n",
       "  'val_accuracy': '0.8450703620910645',\n",
       "  'val_binary_iou': '0.7304768562316895',\n",
       "  'val_true_positives': '40641952.0',\n",
       "  'val_false_positives': '11934879.0',\n",
       "  'val_true_negatives': '48911596.0',\n",
       "  'val_false_negatives': '4483273.0',\n",
       "  'val_precision': '0.7730011343955994',\n",
       "  'val_recall': '0.9006481766700745'},\n",
       " {'loss': '0.11748106777667999',\n",
       "  'accuracy': '0.9039813876152039',\n",
       "  'binary_iou': '0.8203401565551758',\n",
       "  'true_positives': '116874728.0',\n",
       "  'false_positives': '16479334.0',\n",
       "  'true_negatives': '171966000.0',\n",
       "  'false_negatives': '14200654.0',\n",
       "  'precision': '0.8764241933822632',\n",
       "  'recall': '0.8916603922843933',\n",
       "  'val_loss': '0.16435684263706207',\n",
       "  'val_accuracy': '0.8604539036750793',\n",
       "  'val_binary_iou': '0.7515079975128174',\n",
       "  'val_true_positives': '38347908.0',\n",
       "  'val_false_positives': '7986545.0',\n",
       "  'val_true_negatives': '52835852.0',\n",
       "  'val_false_negatives': '6801397.0',\n",
       "  'val_precision': '0.8276327252388',\n",
       "  'val_recall': '0.8493576645851135'},\n",
       " {'loss': '0.11296495795249939',\n",
       "  'accuracy': '0.9077730774879456',\n",
       "  'binary_iou': '0.8267014622688293',\n",
       "  'true_positives': '117159816.0',\n",
       "  'false_positives': '15511851.0',\n",
       "  'true_negatives': '172892432.0',\n",
       "  'false_negatives': '13956604.0',\n",
       "  'precision': '0.8830808997154236',\n",
       "  'recall': '0.8935556411743164',\n",
       "  'val_loss': '0.17737410962581635',\n",
       "  'val_accuracy': '0.8445158004760742',\n",
       "  'val_binary_iou': '0.7282230257987976',\n",
       "  'val_true_positives': '38698016.0',\n",
       "  'val_false_positives': '10038660.0',\n",
       "  'val_true_negatives': '50796784.0',\n",
       "  'val_false_negatives': '6438257.0',\n",
       "  'val_precision': '0.7940225005149841',\n",
       "  'val_recall': '0.8573595881462097'},\n",
       " {'loss': '0.1116277351975441',\n",
       "  'accuracy': '0.9087814092636108',\n",
       "  'binary_iou': '0.8284687399864197',\n",
       "  'true_positives': '117442272.0',\n",
       "  'false_positives': '15450539.0',\n",
       "  'true_negatives': '172932256.0',\n",
       "  'false_negatives': '13695691.0',\n",
       "  'precision': '0.8837368488311768',\n",
       "  'recall': '0.8955627679824829',\n",
       "  'val_loss': '0.22158901393413544',\n",
       "  'val_accuracy': '0.8260716795921326',\n",
       "  'val_binary_iou': '0.6940493583679199',\n",
       "  'val_true_positives': '32733368.0',\n",
       "  'val_false_positives': '6001649.0',\n",
       "  'val_true_negatives': '54806864.0',\n",
       "  'val_false_negatives': '12429828.0',\n",
       "  'val_precision': '0.8450588583946228',\n",
       "  'val_recall': '0.7247797250747681'},\n",
       " {'loss': '0.11073320358991623',\n",
       "  'accuracy': '0.9101096987724304',\n",
       "  'binary_iou': '0.8306362628936768',\n",
       "  'true_positives': '117300144.0',\n",
       "  'false_positives': '14963131.0',\n",
       "  'true_negatives': '173498800.0',\n",
       "  'false_negatives': '13758712.0',\n",
       "  'precision': '0.8868685960769653',\n",
       "  'recall': '0.8950188159942627',\n",
       "  'val_loss': '0.1295718252658844',\n",
       "  'val_accuracy': '0.8888552188873291',\n",
       "  'val_binary_iou': '0.7969772815704346',\n",
       "  'val_true_positives': '39977888.0',\n",
       "  'val_false_positives': '6724283.0',\n",
       "  'val_true_negatives': '54215616.0',\n",
       "  'val_false_negatives': '5053912.0',\n",
       "  'val_precision': '0.8560177683830261',\n",
       "  'val_recall': '0.8877701759338379'},\n",
       " {'loss': '0.11055346578359604',\n",
       "  'accuracy': '0.9099255800247192',\n",
       "  'binary_iou': '0.8303505182266235',\n",
       "  'true_positives': '117366416.0',\n",
       "  'false_positives': '14966230.0',\n",
       "  'true_negatives': '173373680.0',\n",
       "  'false_negatives': '13814412.0',\n",
       "  'precision': '0.8869044780731201',\n",
       "  'recall': '0.8946918249130249',\n",
       "  'val_loss': '0.1266525238752365',\n",
       "  'val_accuracy': '0.8892303705215454',\n",
       "  'val_binary_iou': '0.7984521389007568',\n",
       "  'val_true_positives': '41107320.0',\n",
       "  'val_false_positives': '7720637.0',\n",
       "  'val_true_negatives': '53125932.0',\n",
       "  'val_false_negatives': '4017818.0',\n",
       "  'val_precision': '0.8418807983398438',\n",
       "  'val_recall': '0.9109628200531006'},\n",
       " {'loss': '0.10677679628133774',\n",
       "  'accuracy': '0.9130255579948425',\n",
       "  'binary_iou': '0.8356871604919434',\n",
       "  'true_positives': '117830272.0',\n",
       "  'false_positives': '14455578.0',\n",
       "  'true_negatives': '173900384.0',\n",
       "  'false_negatives': '13334564.0',\n",
       "  'precision': '0.8907247185707092',\n",
       "  'recall': '0.8983373641967773',\n",
       "  'val_loss': '0.15511789917945862',\n",
       "  'val_accuracy': '0.8591651320457458',\n",
       "  'val_binary_iou': '0.7518163919448853',\n",
       "  'val_true_positives': '41172792.0',\n",
       "  'val_false_positives': '10981330.0',\n",
       "  'val_true_negatives': '49874412.0',\n",
       "  'val_false_negatives': '3943181.0',\n",
       "  'val_precision': '0.7894446849822998',\n",
       "  'val_recall': '0.9125990271568298'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': ['0.21770402789115906',\n",
       "  '0.17682895064353943',\n",
       "  '0.16960737109184265',\n",
       "  '0.18082629144191742',\n",
       "  '0.20721104741096497',\n",
       "  '0.16745591163635254',\n",
       "  '0.16687346994876862',\n",
       "  '0.1353950798511505',\n",
       "  '0.1568543165922165',\n",
       "  '0.256801575422287',\n",
       "  '0.13223814964294434',\n",
       "  '0.13863824307918549',\n",
       "  '0.1420867145061493',\n",
       "  '0.16962216794490814',\n",
       "  '0.16435684263706207',\n",
       "  '0.17737410962581635',\n",
       "  '0.22158901393413544',\n",
       "  '0.1295718252658844',\n",
       "  '0.1266525238752365',\n",
       "  '0.15511789917945862',\n",
       "  '0.1532878875732422',\n",
       "  '0.16470210254192352',\n",
       "  '0.15835809707641602',\n",
       "  '0.19020085036754608',\n",
       "  '0.17323553562164307',\n",
       "  '0.16869047284126282',\n",
       "  '0.16905471682548523',\n",
       "  '0.15957488119602203',\n",
       "  '0.17302271723747253',\n",
       "  '0.1479262411594391',\n",
       "  '0.14105425775051117',\n",
       "  '0.1601693034172058',\n",
       "  '0.14341682195663452',\n",
       "  '0.15757280588150024',\n",
       "  '0.15655525028705597',\n",
       "  '0.14383921027183533',\n",
       "  '0.1519373208284378',\n",
       "  '0.15273939073085785',\n",
       "  '0.13735027611255646',\n",
       "  '0.14573928713798523',\n",
       "  '0.15171602368354797',\n",
       "  '0.15392346680164337',\n",
       "  '0.16573938727378845',\n",
       "  '0.1597735434770584',\n",
       "  '0.13420899212360382',\n",
       "  '0.15384750068187714',\n",
       "  '0.15482977032661438',\n",
       "  '0.15159671008586884',\n",
       "  '0.14477665722370148',\n",
       "  '0.12236810475587845',\n",
       "  '0.14028839766979218',\n",
       "  '0.13311035931110382',\n",
       "  '0.1331200748682022',\n",
       "  '0.12476728856563568',\n",
       "  '0.12796032428741455',\n",
       "  '0.14442332088947296',\n",
       "  '0.1294504702091217',\n",
       "  '0.1249454990029335',\n",
       "  '0.13955040276050568',\n",
       "  '0.14369337260723114',\n",
       "  '0.13317513465881348',\n",
       "  '0.12440110743045807',\n",
       "  '0.12849245965480804',\n",
       "  '0.13226884603500366',\n",
       "  '0.1242087259888649',\n",
       "  '0.12489843368530273',\n",
       "  '0.12735304236412048',\n",
       "  '0.12549789249897003',\n",
       "  '0.13851229846477509',\n",
       "  '0.1473730504512787',\n",
       "  '0.1362791657447815',\n",
       "  '0.13168039917945862',\n",
       "  '0.126186341047287',\n",
       "  '0.12581415474414825',\n",
       "  '0.13660959899425507',\n",
       "  '0.13213157653808594',\n",
       "  '0.13012538850307465',\n",
       "  '0.13274507224559784',\n",
       "  '0.13762229681015015',\n",
       "  '0.12109001725912094',\n",
       "  '0.1188807338476181',\n",
       "  '0.13117694854736328',\n",
       "  '0.12731844186782837',\n",
       "  '0.1247730702161789',\n",
       "  '0.13369794189929962',\n",
       "  '0.11847555637359619',\n",
       "  '0.11922792345285416',\n",
       "  '0.1173231229186058',\n",
       "  '0.12573279440402985',\n",
       "  '0.14296342432498932',\n",
       "  '0.12769436836242676',\n",
       "  '0.13821688294410706',\n",
       "  '0.1270095407962799',\n",
       "  '0.12398946285247803',\n",
       "  '0.12144827097654343',\n",
       "  '0.12075302004814148',\n",
       "  '0.11783315986394882',\n",
       "  '0.12379972636699677',\n",
       "  '0.11779506504535675',\n",
       "  '0.12219167500734329',\n",
       "  '0.12229105830192566',\n",
       "  '0.12620393931865692',\n",
       "  '0.1147293820977211',\n",
       "  '0.11959604173898697',\n",
       "  '0.1166437640786171',\n",
       "  '0.11983519047498703',\n",
       "  '0.12043052911758423',\n",
       "  '0.11732880026102066',\n",
       "  '0.12237317860126495',\n",
       "  '0.12248948216438293',\n",
       "  '0.1247672438621521',\n",
       "  '0.12426847219467163',\n",
       "  '0.12358038127422333',\n",
       "  '0.11900582909584045',\n",
       "  '0.12076747417449951',\n",
       "  '0.1199825257062912',\n",
       "  '0.1199617087841034',\n",
       "  '0.12244444340467453',\n",
       "  '0.11729475110769272',\n",
       "  '0.1220301017165184',\n",
       "  '0.11887235939502716',\n",
       "  '0.11579880863428116',\n",
       "  '0.11833526939153671',\n",
       "  '0.11629320681095123',\n",
       "  '0.12073512375354767',\n",
       "  '0.12064170837402344',\n",
       "  '0.11893913894891739',\n",
       "  '0.11864928156137466',\n",
       "  '0.1191859245300293',\n",
       "  '0.11809110641479492',\n",
       "  '0.12140107899904251',\n",
       "  '0.11622099578380585',\n",
       "  '0.11712513864040375',\n",
       "  '0.11704415827989578',\n",
       "  '0.11579082161188126',\n",
       "  '0.11940192431211472',\n",
       "  '0.11721847206354141',\n",
       "  '0.11930017918348312',\n",
       "  '0.12150349467992783',\n",
       "  '0.12000486999750137',\n",
       "  '0.11688486486673355',\n",
       "  '0.12043492496013641',\n",
       "  '0.11513802409172058',\n",
       "  '0.11638107150793076',\n",
       "  '0.1149480938911438',\n",
       "  '0.1178000196814537',\n",
       "  '0.11645808815956116',\n",
       "  '0.11759473383426666',\n",
       "  '0.12082542479038239',\n",
       "  '0.11767257750034332',\n",
       "  '0.11661818623542786',\n",
       "  '0.11676521599292755',\n",
       "  '0.11694347858428955',\n",
       "  '0.11652178317308426',\n",
       "  '0.11690908670425415',\n",
       "  '0.11815569549798965',\n",
       "  '0.11460810154676437',\n",
       "  '0.11440238356590271',\n",
       "  '0.11823490262031555',\n",
       "  '0.11763251572847366',\n",
       "  '0.11677468568086624',\n",
       "  '0.11830823123455048',\n",
       "  '0.12119510769844055',\n",
       "  '0.11619402468204498',\n",
       "  '0.11396702378988266',\n",
       "  '0.11789123713970184',\n",
       "  '0.12078561633825302',\n",
       "  '0.11906962096691132',\n",
       "  '0.1156567633152008',\n",
       "  '0.11936014890670776',\n",
       "  '0.11512753367424011',\n",
       "  '0.11443984508514404',\n",
       "  '0.1159466952085495',\n",
       "  '0.11403097212314606',\n",
       "  '0.1165010929107666',\n",
       "  '0.11725557595491409',\n",
       "  '0.11765151470899582',\n",
       "  '0.11462093144655228',\n",
       "  '0.11723525822162628',\n",
       "  '0.11727699637413025',\n",
       "  '0.1169344112277031',\n",
       "  '0.11783318966627121',\n",
       "  '0.11990607529878616',\n",
       "  '0.1172911673784256',\n",
       "  '0.11439813673496246',\n",
       "  '0.11680661886930466',\n",
       "  '0.11593670397996902',\n",
       "  '0.11325681209564209',\n",
       "  '0.11605221778154373',\n",
       "  '0.11778043955564499',\n",
       "  '0.12012208998203278',\n",
       "  '0.11470621824264526',\n",
       "  '0.11317934840917587',\n",
       "  '0.11376090347766876',\n",
       "  '0.11499509960412979',\n",
       "  '0.11758579313755035',\n",
       "  '0.114342600107193',\n",
       "  '0.11828690767288208',\n",
       "  '0.11599338054656982',\n",
       "  '0.11690444499254227',\n",
       "  '0.1180187314748764',\n",
       "  '0.11817086488008499',\n",
       "  '0.11539346724748611',\n",
       "  '0.11245646327733994',\n",
       "  '0.1132143884897232',\n",
       "  '0.11324066668748856',\n",
       "  '0.11788246780633926',\n",
       "  '0.11375032365322113',\n",
       "  '0.1165195107460022',\n",
       "  '0.11665957421064377',\n",
       "  '0.11553255468606949',\n",
       "  '0.1156017929315567',\n",
       "  '0.11280359327793121',\n",
       "  '0.1146276444196701',\n",
       "  '0.11525095254182816',\n",
       "  '0.12001452594995499',\n",
       "  '0.11563926935195923',\n",
       "  '0.11840638518333435',\n",
       "  '0.11456241458654404',\n",
       "  '0.11544135212898254',\n",
       "  '0.11569689214229584',\n",
       "  '0.11408401280641556',\n",
       "  '0.11816465854644775',\n",
       "  '0.1149558499455452',\n",
       "  '0.11554516851902008',\n",
       "  '0.1133972704410553',\n",
       "  '0.11669003963470459',\n",
       "  '0.12003932893276215',\n",
       "  '0.11462179571390152',\n",
       "  '0.11765571683645248',\n",
       "  '0.1160205826163292',\n",
       "  '0.1159721165895462',\n",
       "  '0.11221522092819214',\n",
       "  '0.11429080367088318',\n",
       "  '0.11230839043855667',\n",
       "  '0.11320412904024124',\n",
       "  '0.11715869605541229',\n",
       "  '0.11401700973510742',\n",
       "  '0.11329974234104156',\n",
       "  '0.11398975551128387',\n",
       "  '0.11479958891868591',\n",
       "  '0.11706393212080002',\n",
       "  '0.11529475450515747',\n",
       "  '0.11355168372392654',\n",
       "  '0.11431055516004562',\n",
       "  '0.11417941004037857',\n",
       "  '0.11306194216012955',\n",
       "  '0.11349113285541534',\n",
       "  '0.11603450030088425',\n",
       "  '0.1160237118601799',\n",
       "  '0.11194554716348648',\n",
       "  '0.11267965286970139',\n",
       "  '0.11156198382377625',\n",
       "  '0.11465377360582352',\n",
       "  '0.11431556940078735',\n",
       "  '0.11516668647527695',\n",
       "  '0.11326157301664352',\n",
       "  '0.11290623992681503',\n",
       "  '0.11337651312351227',\n",
       "  '0.1122761145234108',\n",
       "  '0.11302945017814636',\n",
       "  '0.11160043627023697',\n",
       "  '0.11289632320404053',\n",
       "  '0.11282484233379364',\n",
       "  '0.11320070922374725',\n",
       "  '0.11408361047506332',\n",
       "  '0.11183971166610718',\n",
       "  '0.11375568062067032',\n",
       "  '0.11217398941516876',\n",
       "  '0.11428642272949219',\n",
       "  '0.11035120487213135',\n",
       "  '0.11318475008010864',\n",
       "  '0.11404812335968018',\n",
       "  '0.11345578730106354',\n",
       "  '0.11391288042068481',\n",
       "  '0.11250997334718704',\n",
       "  '0.11197409778833389',\n",
       "  '0.11286426335573196',\n",
       "  '0.11300475895404816',\n",
       "  '0.1131753921508789',\n",
       "  '0.11340207606554031',\n",
       "  '0.11346419155597687',\n",
       "  '0.11457433551549911',\n",
       "  '0.11424950510263443',\n",
       "  '0.11337873339653015',\n",
       "  '0.11325903981924057',\n",
       "  '0.1132345199584961',\n",
       "  '0.11304116249084473',\n",
       "  '0.11380644142627716',\n",
       "  '0.11117787659168243',\n",
       "  '0.11097700148820877',\n",
       "  '0.1133204773068428',\n",
       "  '0.1117781326174736',\n",
       "  '0.11514399200677872',\n",
       "  '0.11479592323303223',\n",
       "  '0.11253302544355392',\n",
       "  '0.11566536128520966',\n",
       "  '0.11490102112293243',\n",
       "  '0.11388024687767029',\n",
       "  '0.11300020664930344',\n",
       "  '0.11575763672590256'],\n",
       " 'val_recall': ['0.8034497499465942',\n",
       "  '0.8397879600524902',\n",
       "  '0.9183962941169739',\n",
       "  '0.925344705581665',\n",
       "  '0.7800396084785461',\n",
       "  '0.9233037829399109',\n",
       "  '0.8378708958625793',\n",
       "  '0.8937098383903503',\n",
       "  '0.9037994146347046',\n",
       "  '0.6490923762321472',\n",
       "  '0.8445903658866882',\n",
       "  '0.8908435702323914',\n",
       "  '0.9001650810241699',\n",
       "  '0.9006481766700745',\n",
       "  '0.8493576645851135',\n",
       "  '0.8573595881462097',\n",
       "  '0.7247797250747681',\n",
       "  '0.8877701759338379',\n",
       "  '0.9109628200531006',\n",
       "  '0.9125990271568298',\n",
       "  '0.8681316375732422',\n",
       "  '0.8698943257331848',\n",
       "  '0.8648158311843872',\n",
       "  '0.8132686018943787',\n",
       "  '0.8367692828178406',\n",
       "  '0.8379760384559631',\n",
       "  '0.8239779472351074',\n",
       "  '0.8643971681594849',\n",
       "  '0.8218018412590027',\n",
       "  '0.8505344986915588',\n",
       "  '0.8805814385414124',\n",
       "  '0.8445643186569214',\n",
       "  '0.8804050087928772',\n",
       "  '0.8525071740150452',\n",
       "  '0.854682445526123',\n",
       "  '0.8626556992530823',\n",
       "  '0.8526890277862549',\n",
       "  '0.8534736037254333',\n",
       "  '0.8964869976043701',\n",
       "  '0.8732181787490845',\n",
       "  '0.8408482670783997',\n",
       "  '0.8741795420646667',\n",
       "  '0.8412203788757324',\n",
       "  '0.8402198553085327',\n",
       "  '0.8770241141319275',\n",
       "  '0.8366045355796814',\n",
       "  '0.8409819602966309',\n",
       "  '0.8393517136573792',\n",
       "  '0.9027755260467529',\n",
       "  '0.9095205664634705',\n",
       "  '0.8910811543464661',\n",
       "  '0.9084098935127258',\n",
       "  '0.8921440839767456',\n",
       "  '0.9045875668525696',\n",
       "  '0.9000638127326965',\n",
       "  '0.879349410533905',\n",
       "  '0.9103804230690002',\n",
       "  '0.9021161794662476',\n",
       "  '0.8844022750854492',\n",
       "  '0.877945601940155',\n",
       "  '0.8918641805648804',\n",
       "  '0.8956597447395325',\n",
       "  '0.9074963331222534',\n",
       "  '0.8828051686286926',\n",
       "  '0.8963316679000854',\n",
       "  '0.9023861289024353',\n",
       "  '0.8917412161827087',\n",
       "  '0.9056563973426819',\n",
       "  '0.881592869758606',\n",
       "  '0.8533007502555847',\n",
       "  '0.8720873594284058',\n",
       "  '0.8910010457038879',\n",
       "  '0.9054935574531555',\n",
       "  '0.8927657008171082',\n",
       "  '0.8877168893814087',\n",
       "  '0.8862788081169128',\n",
       "  '0.8924893736839294',\n",
       "  '0.8921104073524475',\n",
       "  '0.8734277486801147',\n",
       "  '0.9031172394752502',\n",
       "  '0.8922602534294128',\n",
       "  '0.8810566067695618',\n",
       "  '0.892907977104187',\n",
       "  '0.900300920009613',\n",
       "  '0.8822528123855591',\n",
       "  '0.9056819081306458',\n",
       "  '0.9041309356689453',\n",
       "  '0.9083422422409058',\n",
       "  '0.8951994776725769',\n",
       "  '0.8586760759353638',\n",
       "  '0.8993447422981262',\n",
       "  '0.8885667324066162',\n",
       "  '0.9025124907493591',\n",
       "  '0.9057181477546692',\n",
       "  '0.8952162265777588',\n",
       "  '0.9096670746803284',\n",
       "  '0.9114355444908142',\n",
       "  '0.9151189923286438',\n",
       "  '0.9161510467529297',\n",
       "  '0.893447756767273',\n",
       "  '0.9091493487358093',\n",
       "  '0.893306314945221',\n",
       "  '0.9013187885284424',\n",
       "  '0.9130269289016724',\n",
       "  '0.9009261131286621',\n",
       "  '0.9115952253341675',\n",
       "  '0.9108734726905823',\n",
       "  '0.9069623947143555',\n",
       "  '0.9052621722221375',\n",
       "  '0.9025774598121643',\n",
       "  '0.8897026181221008',\n",
       "  '0.9080055952072144',\n",
       "  '0.8930554986000061',\n",
       "  '0.9010698199272156',\n",
       "  '0.8974961638450623',\n",
       "  '0.90845787525177',\n",
       "  '0.9101932048797607',\n",
       "  '0.901776134967804',\n",
       "  '0.9028364419937134',\n",
       "  '0.8952406048774719',\n",
       "  '0.9039737582206726',\n",
       "  '0.9086753129959106',\n",
       "  '0.9046904444694519',\n",
       "  '0.9024057984352112',\n",
       "  '0.8908393383026123',\n",
       "  '0.908892810344696',\n",
       "  '0.9170272350311279',\n",
       "  '0.9047291874885559',\n",
       "  '0.8967289328575134',\n",
       "  '0.914959728717804',\n",
       "  '0.9145568609237671',\n",
       "  '0.9000033736228943',\n",
       "  '0.9140010476112366',\n",
       "  '0.9076323509216309',\n",
       "  '0.9123165607452393',\n",
       "  '0.9133268594741821',\n",
       "  '0.9193007349967957',\n",
       "  '0.9053952693939209',\n",
       "  '0.9078467488288879',\n",
       "  '0.9072677493095398',\n",
       "  '0.9049867391586304',\n",
       "  '0.895412802696228',\n",
       "  '0.9160388708114624',\n",
       "  '0.9104902744293213',\n",
       "  '0.9093319177627563',\n",
       "  '0.9099108576774597',\n",
       "  '0.9077826738357544',\n",
       "  '0.9196755886077881',\n",
       "  '0.9097458124160767',\n",
       "  '0.905867338180542',\n",
       "  '0.9109106063842773',\n",
       "  '0.9099176526069641',\n",
       "  '0.9133888483047485',\n",
       "  '0.9110626578330994',\n",
       "  '0.9133310317993164',\n",
       "  '0.9092443585395813',\n",
       "  '0.9149479269981384',\n",
       "  '0.9091638922691345',\n",
       "  '0.9156341552734375',\n",
       "  '0.9077345132827759',\n",
       "  '0.9120107889175415',\n",
       "  '0.9134351015090942',\n",
       "  '0.9132845401763916',\n",
       "  '0.9185037016868591',\n",
       "  '0.9165863394737244',\n",
       "  '0.913665771484375',\n",
       "  '0.9122361540794373',\n",
       "  '0.912835419178009',\n",
       "  '0.9134685397148132',\n",
       "  '0.9062337279319763',\n",
       "  '0.918868899345398',\n",
       "  '0.9063910245895386',\n",
       "  '0.9154727458953857',\n",
       "  '0.9153134226799011',\n",
       "  '0.9098594784736633',\n",
       "  '0.9106874465942383',\n",
       "  '0.9148927927017212',\n",
       "  '0.9120746850967407',\n",
       "  '0.920434832572937',\n",
       "  '0.9064165353775024',\n",
       "  '0.9162482023239136',\n",
       "  '0.9025009870529175',\n",
       "  '0.9099728465080261',\n",
       "  '0.9164579510688782',\n",
       "  '0.9148892164230347',\n",
       "  '0.9177864789962769',\n",
       "  '0.9119742512702942',\n",
       "  '0.915755569934845',\n",
       "  '0.9154274463653564',\n",
       "  '0.9201580882072449',\n",
       "  '0.9202529191970825',\n",
       "  '0.9153046607971191',\n",
       "  '0.9187358021736145',\n",
       "  '0.9147254824638367',\n",
       "  '0.9126228094100952',\n",
       "  '0.9139297604560852',\n",
       "  '0.9130886197090149',\n",
       "  '0.9108365774154663',\n",
       "  '0.9209015965461731',\n",
       "  '0.9181728959083557',\n",
       "  '0.9201520085334778',\n",
       "  '0.9101868867874146',\n",
       "  '0.9192184209823608',\n",
       "  '0.9076467752456665',\n",
       "  '0.9145250916481018',\n",
       "  '0.911400556564331',\n",
       "  '0.9127548336982727',\n",
       "  '0.9115918874740601',\n",
       "  '0.9182314872741699',\n",
       "  '0.9117229580879211',\n",
       "  '0.9165856838226318',\n",
       "  '0.918455183506012',\n",
       "  '0.910864531993866',\n",
       "  '0.9106550812721252',\n",
       "  '0.9091745615005493',\n",
       "  '0.9162465333938599',\n",
       "  '0.9127001762390137',\n",
       "  '0.9112803936004639',\n",
       "  '0.9170609712600708',\n",
       "  '0.9181414246559143',\n",
       "  '0.9221186637878418',\n",
       "  '0.9176177978515625',\n",
       "  '0.9097387194633484',\n",
       "  '0.9179956316947937',\n",
       "  '0.9127970933914185',\n",
       "  '0.9115978479385376',\n",
       "  '0.9081261157989502',\n",
       "  '0.9224645495414734',\n",
       "  '0.9129247069358826',\n",
       "  '0.9157043099403381',\n",
       "  '0.9089363217353821',\n",
       "  '0.9156010746955872',\n",
       "  '0.9083479046821594',\n",
       "  '0.9186058640480042',\n",
       "  '0.9111701250076294',\n",
       "  '0.9235313534736633',\n",
       "  '0.9173887372016907',\n",
       "  '0.9153755307197571',\n",
       "  '0.9166662693023682',\n",
       "  '0.9118124842643738',\n",
       "  '0.9124084711074829',\n",
       "  '0.920568585395813',\n",
       "  '0.9169029593467712',\n",
       "  '0.9185730814933777',\n",
       "  '0.9142057299613953',\n",
       "  '0.9119232892990112',\n",
       "  '0.9176174998283386',\n",
       "  '0.9206912517547607',\n",
       "  '0.9150436520576477',\n",
       "  '0.918765127658844',\n",
       "  '0.9212852716445923',\n",
       "  '0.920566201210022',\n",
       "  '0.914833664894104',\n",
       "  '0.9178637862205505',\n",
       "  '0.9196422696113586',\n",
       "  '0.913414478302002',\n",
       "  '0.9197643995285034',\n",
       "  '0.9200530052185059',\n",
       "  '0.9145254492759705',\n",
       "  '0.9177091717720032',\n",
       "  '0.9191275238990784',\n",
       "  '0.9205524921417236',\n",
       "  '0.9197447896003723',\n",
       "  '0.9203625321388245',\n",
       "  '0.9207009673118591',\n",
       "  '0.91944819688797',\n",
       "  '0.91544508934021',\n",
       "  '0.920981228351593',\n",
       "  '0.9119866490364075',\n",
       "  '0.919940710067749',\n",
       "  '0.9109920263290405',\n",
       "  '0.9177347421646118',\n",
       "  '0.9137817025184631',\n",
       "  '0.92356938123703',\n",
       "  '0.923754870891571',\n",
       "  '0.9191481471061707',\n",
       "  '0.9194711446762085',\n",
       "  '0.9197134375572205',\n",
       "  '0.9179508686065674',\n",
       "  '0.9179187417030334',\n",
       "  '0.9200094938278198',\n",
       "  '0.916538655757904',\n",
       "  '0.9200593829154968',\n",
       "  '0.9162121415138245',\n",
       "  '0.9179103374481201',\n",
       "  '0.9202543497085571',\n",
       "  '0.9191972613334656',\n",
       "  '0.9140179753303528',\n",
       "  '0.9194062948226929',\n",
       "  '0.9162887930870056',\n",
       "  '0.9187495708465576',\n",
       "  '0.9178752303123474',\n",
       "  '0.9178215861320496',\n",
       "  '0.9242412447929382',\n",
       "  '0.9206775426864624',\n",
       "  '0.9150415658950806',\n",
       "  '0.9188150763511658',\n",
       "  '0.9216482639312744',\n",
       "  '0.9180718064308167',\n",
       "  '0.9219462275505066',\n",
       "  '0.921051025390625'],\n",
       " 'val_false_positives': ['9768367.0',\n",
       "  '8678695.0',\n",
       "  '12919748.0',\n",
       "  '14784452.0',\n",
       "  '8233098.0',\n",
       "  '13103984.0',\n",
       "  '7516429.0',\n",
       "  '7671211.0',\n",
       "  '10655894.0',\n",
       "  '3966531.0',\n",
       "  '4436075.0',\n",
       "  '7800029.0',\n",
       "  '8783600.0',\n",
       "  '11934879.0',\n",
       "  '7986545.0',\n",
       "  '10038660.0',\n",
       "  '6001649.0',\n",
       "  '6724283.0',\n",
       "  '7720637.0',\n",
       "  '10981330.0',\n",
       "  '7995532.0',\n",
       "  '9388413.0',\n",
       "  '8310546.0',\n",
       "  '8564972.0',\n",
       "  '8171298.0',\n",
       "  '7846076.0',\n",
       "  '6882977.0',\n",
       "  '8430896.0',\n",
       "  '7301166.0',\n",
       "  '6451831.0',\n",
       "  '7515209.0',\n",
       "  '7337428.0',\n",
       "  '7793475.0',\n",
       "  '7554219.0',\n",
       "  '7472669.0',\n",
       "  '6708055.0',\n",
       "  '6990396.0',\n",
       "  '7111299.0',\n",
       "  '8003803.0',\n",
       "  '7511030.0',\n",
       "  '6186966.0',\n",
       "  '8510896.0',\n",
       "  '7752052.0',\n",
       "  '7051738.0',\n",
       "  '6547396.0',\n",
       "  '6182531.0',\n",
       "  '6595123.0',\n",
       "  '6008902.0',\n",
       "  '9089778.0',\n",
       "  '7188811.0',\n",
       "  '7955312.0',\n",
       "  '8270205.0',\n",
       "  '7313449.0',\n",
       "  '7144993.0',\n",
       "  '7241171.0',\n",
       "  '7789454.0',\n",
       "  '7990725.0',\n",
       "  '7059497.0',\n",
       "  '7650451.0',\n",
       "  '7570976.0',\n",
       "  '7133141.0',\n",
       "  '6587527.0',\n",
       "  '7736609.0',\n",
       "  '6661618.0',\n",
       "  '6696174.0',\n",
       "  '7040544.0',\n",
       "  '6751547.0',\n",
       "  '7320436.0',\n",
       "  '7306383.0',\n",
       "  '6493311.0',\n",
       "  '6473311.0',\n",
       "  '7147035.0',\n",
       "  '7349679.0',\n",
       "  '6541107.0',\n",
       "  '7431242.0',\n",
       "  '6848179.0',\n",
       "  '7076109.0',\n",
       "  '7286132.0',\n",
       "  '6671738.0',\n",
       "  '6655291.0',\n",
       "  '5827465.0',\n",
       "  '6454110.0',\n",
       "  '6693823.0',\n",
       "  '6863397.0',\n",
       "  '6837606.0',\n",
       "  '6608031.0',\n",
       "  '6512216.0',\n",
       "  '6562191.0',\n",
       "  '6745363.0',\n",
       "  '6268144.0',\n",
       "  '7164729.0',\n",
       "  '7683408.0',\n",
       "  '7237269.0',\n",
       "  '7231613.0',\n",
       "  '6310184.0',\n",
       "  '7017896.0',\n",
       "  '6882456.0',\n",
       "  '7650375.0',\n",
       "  '7093535.0',\n",
       "  '6169027.0',\n",
       "  '7182040.0',\n",
       "  '6688132.0',\n",
       "  '6000315.0',\n",
       "  '7072328.0',\n",
       "  '6111206.0',\n",
       "  '7022818.0',\n",
       "  '7072027.0',\n",
       "  '6507236.0',\n",
       "  '6969499.0',\n",
       "  '6833923.0',\n",
       "  '6287806.0',\n",
       "  '7340763.0',\n",
       "  '6302173.0',\n",
       "  '6338738.0',\n",
       "  '6356568.0',\n",
       "  '6884398.0',\n",
       "  '7049656.0',\n",
       "  '6850225.0',\n",
       "  '6249336.0',\n",
       "  '6321843.0',\n",
       "  '6491146.0',\n",
       "  '6519950.0',\n",
       "  '6468702.0',\n",
       "  '6143717.0',\n",
       "  '5999407.0',\n",
       "  '6977920.0',\n",
       "  '7258941.0',\n",
       "  '6435423.0',\n",
       "  '6178631.0',\n",
       "  '7060847.0',\n",
       "  '7356539.0',\n",
       "  '6004807.0',\n",
       "  '6831848.0',\n",
       "  '6549019.0',\n",
       "  '6663939.0',\n",
       "  '7066731.0',\n",
       "  '7189002.0',\n",
       "  '6604726.0',\n",
       "  '6973299.0',\n",
       "  '6762992.0',\n",
       "  '6432876.0',\n",
       "  '6188659.0',\n",
       "  '6840811.0',\n",
       "  '6617569.0',\n",
       "  '6352211.0',\n",
       "  '6731872.0',\n",
       "  '6457385.0',\n",
       "  '7238208.0',\n",
       "  '7063887.0',\n",
       "  '6421701.0',\n",
       "  '6626373.0',\n",
       "  '6592848.0',\n",
       "  '6831751.0',\n",
       "  '6621291.0',\n",
       "  '6852340.0',\n",
       "  '6685736.0',\n",
       "  '6643525.0',\n",
       "  '6355423.0',\n",
       "  '7083548.0',\n",
       "  '6533151.0',\n",
       "  '6693123.0',\n",
       "  '7045977.0',\n",
       "  '7271796.0',\n",
       "  '7010789.0',\n",
       "  '6741147.0',\n",
       "  '7013738.0',\n",
       "  '7138950.0',\n",
       "  '7029609.0',\n",
       "  '6702185.0',\n",
       "  '6682764.0',\n",
       "  '6892815.0',\n",
       "  '6184756.0',\n",
       "  '6786822.0',\n",
       "  '6625081.0',\n",
       "  '6627620.0',\n",
       "  '6701753.0',\n",
       "  '6990843.0',\n",
       "  '6602763.0',\n",
       "  '7271121.0',\n",
       "  '6503394.0',\n",
       "  '6920385.0',\n",
       "  '6346590.0',\n",
       "  '6883486.0',\n",
       "  '7073157.0',\n",
       "  '6565922.0',\n",
       "  '7056995.0',\n",
       "  '6652428.0',\n",
       "  '6575537.0',\n",
       "  '6851404.0',\n",
       "  '7365267.0',\n",
       "  '7605111.0',\n",
       "  '6719768.0',\n",
       "  '6826572.0',\n",
       "  '6564801.0',\n",
       "  '6627336.0',\n",
       "  '6971668.0',\n",
       "  '6543941.0',\n",
       "  '6871320.0',\n",
       "  '7089894.0',\n",
       "  '7079218.0',\n",
       "  '7243105.0',\n",
       "  '6815943.0',\n",
       "  '6899521.0',\n",
       "  '6058089.0',\n",
       "  '6542881.0',\n",
       "  '6322329.0',\n",
       "  '6746400.0',\n",
       "  '6380405.0',\n",
       "  '7049475.0',\n",
       "  '6688924.0',\n",
       "  '6847416.0',\n",
       "  '6927529.0',\n",
       "  '6315100.0',\n",
       "  '6464787.0',\n",
       "  '6408100.0',\n",
       "  '7292969.0',\n",
       "  '6680109.0',\n",
       "  '6819014.0',\n",
       "  '6799947.0',\n",
       "  '6883265.0',\n",
       "  '7138391.0',\n",
       "  '6784169.0',\n",
       "  '6748843.0',\n",
       "  '6876187.0',\n",
       "  '6637981.0',\n",
       "  '6337296.0',\n",
       "  '6532334.0',\n",
       "  '7647113.0',\n",
       "  '6549969.0',\n",
       "  '7080541.0',\n",
       "  '6481059.0',\n",
       "  '6887706.0',\n",
       "  '6073201.0',\n",
       "  '6841121.0',\n",
       "  '6227347.0',\n",
       "  '7090025.0',\n",
       "  '7134353.0',\n",
       "  '6647790.0',\n",
       "  '6663395.0',\n",
       "  '6413070.0',\n",
       "  '6631169.0',\n",
       "  '7198609.0',\n",
       "  '6905649.0',\n",
       "  '6761663.0',\n",
       "  '6651015.0',\n",
       "  '6499834.0',\n",
       "  '6658399.0',\n",
       "  '6949805.0',\n",
       "  '6820235.0',\n",
       "  '6988728.0',\n",
       "  '6830655.0',\n",
       "  '6854208.0',\n",
       "  '6326229.0',\n",
       "  '6750144.0',\n",
       "  '6853814.0',\n",
       "  '6657131.0',\n",
       "  '6852045.0',\n",
       "  '6848949.0',\n",
       "  '6512282.0',\n",
       "  '6632358.0',\n",
       "  '6814214.0',\n",
       "  '6704797.0',\n",
       "  '6816795.0',\n",
       "  '6779581.0',\n",
       "  '6799552.0',\n",
       "  '6842265.0',\n",
       "  '6430027.0',\n",
       "  '6910828.0',\n",
       "  '6272876.0',\n",
       "  '6925499.0',\n",
       "  '6007034.0',\n",
       "  '6679837.0',\n",
       "  '6499658.0',\n",
       "  '7028003.0',\n",
       "  '7053894.0',\n",
       "  '6674978.0',\n",
       "  '6655624.0',\n",
       "  '6752666.0',\n",
       "  '6647952.0',\n",
       "  '6671173.0',\n",
       "  '6846696.0',\n",
       "  '6654268.0',\n",
       "  '6900936.0',\n",
       "  '6777069.0',\n",
       "  '6727720.0',\n",
       "  '6860239.0',\n",
       "  '6808160.0',\n",
       "  '6450340.0',\n",
       "  '6794321.0',\n",
       "  '6436595.0',\n",
       "  '6572012.0',\n",
       "  '6752783.0',\n",
       "  '6633046.0',\n",
       "  '7235276.0',\n",
       "  '6958019.0',\n",
       "  '6478292.0',\n",
       "  '6958231.0',\n",
       "  '7072367.0',\n",
       "  '6793908.0',\n",
       "  '6906495.0',\n",
       "  '7202194.0'],\n",
       " 'false_positives': ['48262192.0',\n",
       "  '27865604.0',\n",
       "  '26535964.0',\n",
       "  '24180304.0',\n",
       "  '22661028.0',\n",
       "  '21770962.0',\n",
       "  '21271064.0',\n",
       "  '20679376.0',\n",
       "  '18970384.0',\n",
       "  '18361112.0',\n",
       "  '18096608.0',\n",
       "  '17039420.0',\n",
       "  '17118276.0',\n",
       "  '16637965.0',\n",
       "  '16479334.0',\n",
       "  '15511851.0',\n",
       "  '15450539.0',\n",
       "  '14963131.0',\n",
       "  '14966230.0',\n",
       "  '14455578.0',\n",
       "  '14923478.0',\n",
       "  '13476758.0',\n",
       "  '12346751.0',\n",
       "  '11795770.0',\n",
       "  '11190987.0',\n",
       "  '10688978.0',\n",
       "  '10302724.0',\n",
       "  '10085414.0',\n",
       "  '9757199.0',\n",
       "  '9446453.0',\n",
       "  '9056807.0',\n",
       "  '8896953.0',\n",
       "  '8745585.0',\n",
       "  '8491503.0',\n",
       "  '8436640.0',\n",
       "  '8213388.0',\n",
       "  '8102850.0',\n",
       "  '7931892.0',\n",
       "  '7859627.0',\n",
       "  '7685584.0',\n",
       "  '7598116.0',\n",
       "  '7551386.0',\n",
       "  '7305634.0',\n",
       "  '7193699.0',\n",
       "  '7295953.0',\n",
       "  '6977136.0',\n",
       "  '7033529.0',\n",
       "  '6925606.0',\n",
       "  '6757289.0',\n",
       "  '6691404.0',\n",
       "  '6805104.0',\n",
       "  '6662078.0',\n",
       "  '6480976.0',\n",
       "  '6523479.0',\n",
       "  '6408760.0',\n",
       "  '6377012.0',\n",
       "  '6317833.0',\n",
       "  '6252158.0',\n",
       "  '6166478.0',\n",
       "  '6008575.0',\n",
       "  '6153825.0',\n",
       "  '6058574.0',\n",
       "  '5936787.0',\n",
       "  '5856439.0',\n",
       "  '5799776.0',\n",
       "  '5794920.0',\n",
       "  '5726393.0',\n",
       "  '5695700.0',\n",
       "  '5638060.0',\n",
       "  '5670895.0',\n",
       "  '5535413.0',\n",
       "  '5511531.0',\n",
       "  '5464186.0',\n",
       "  '5453836.0',\n",
       "  '5499757.0',\n",
       "  '5360537.0',\n",
       "  '5336545.0',\n",
       "  '5306695.0',\n",
       "  '5185485.0',\n",
       "  '5214493.0',\n",
       "  '5149075.0',\n",
       "  '5218970.0',\n",
       "  '5151220.0',\n",
       "  '5149368.0',\n",
       "  '5017609.0',\n",
       "  '5043673.0',\n",
       "  '4980750.0',\n",
       "  '4942512.0',\n",
       "  '4950957.0',\n",
       "  '4895951.0',\n",
       "  '4800330.0',\n",
       "  '4785030.0',\n",
       "  '4797218.0',\n",
       "  '4743315.0',\n",
       "  '4774565.0',\n",
       "  '4776206.0',\n",
       "  '4638195.0',\n",
       "  '4674102.0',\n",
       "  '4633043.0',\n",
       "  '4689436.0',\n",
       "  '4636033.0',\n",
       "  '4573718.0',\n",
       "  '4558592.0',\n",
       "  '4524074.0',\n",
       "  '4507274.0',\n",
       "  '4483441.0',\n",
       "  '4453989.0',\n",
       "  '4422716.0',\n",
       "  '4353448.0',\n",
       "  '4406292.0',\n",
       "  '4321262.0',\n",
       "  '4319419.0',\n",
       "  '4309674.0',\n",
       "  '4312104.0',\n",
       "  '4276012.0',\n",
       "  '4291189.0',\n",
       "  '4201263.0',\n",
       "  '4209346.0',\n",
       "  '4148367.0',\n",
       "  '4167234.0',\n",
       "  '4125654.0',\n",
       "  '4076635.0',\n",
       "  '4112492.0',\n",
       "  '4100056.0',\n",
       "  '4061460.0',\n",
       "  '4029320.0',\n",
       "  '3986961.0',\n",
       "  '4055427.0',\n",
       "  '3926520.0',\n",
       "  '3931477.0',\n",
       "  '3925494.0',\n",
       "  '3956162.0',\n",
       "  '3913470.0',\n",
       "  '3867753.0',\n",
       "  '3856483.0',\n",
       "  '3848838.0',\n",
       "  '3882576.0',\n",
       "  '3844139.0',\n",
       "  '3828746.0',\n",
       "  '3787471.0',\n",
       "  '3766693.0',\n",
       "  '3760504.0',\n",
       "  '3789311.0',\n",
       "  '3744909.0',\n",
       "  '3725566.0',\n",
       "  '3745761.0',\n",
       "  '3696886.0',\n",
       "  '3701427.0',\n",
       "  '3670820.0',\n",
       "  '3640265.0',\n",
       "  '3627322.0',\n",
       "  '3574210.0',\n",
       "  '3663855.0',\n",
       "  '3591113.0',\n",
       "  '3538539.0',\n",
       "  '3572413.0',\n",
       "  '3524928.0',\n",
       "  '3522666.0',\n",
       "  '3498442.0',\n",
       "  '3523648.0',\n",
       "  '3503752.0',\n",
       "  '3471980.0',\n",
       "  '3457734.0',\n",
       "  '3405003.0',\n",
       "  '3420937.0',\n",
       "  '3400371.0',\n",
       "  '3408320.0',\n",
       "  '3417672.0',\n",
       "  '3350895.0',\n",
       "  '3392186.0',\n",
       "  '3342055.0',\n",
       "  '3387724.0',\n",
       "  '3364236.0',\n",
       "  '3285680.0',\n",
       "  '3272809.0',\n",
       "  '3303584.0',\n",
       "  '3226868.0',\n",
       "  '3250217.0',\n",
       "  '3296341.0',\n",
       "  '3256854.0',\n",
       "  '3214578.0',\n",
       "  '3199457.0',\n",
       "  '3214982.0',\n",
       "  '3166264.0',\n",
       "  '3190944.0',\n",
       "  '3153454.0',\n",
       "  '3161783.0',\n",
       "  '3124180.0',\n",
       "  '3147553.0',\n",
       "  '3151528.0',\n",
       "  '3144492.0',\n",
       "  '3160958.0',\n",
       "  '3089482.0',\n",
       "  '3077849.0',\n",
       "  '3078480.0',\n",
       "  '3050934.0',\n",
       "  '3052508.0',\n",
       "  '3055503.0',\n",
       "  '3028320.0',\n",
       "  '3039186.0',\n",
       "  '3008838.0',\n",
       "  '3019790.0',\n",
       "  '2981492.0',\n",
       "  '2971915.0',\n",
       "  '2969834.0',\n",
       "  '2948257.0',\n",
       "  '2930083.0',\n",
       "  '2948914.0',\n",
       "  '2919696.0',\n",
       "  '2935377.0',\n",
       "  '2890336.0',\n",
       "  '2870986.0',\n",
       "  '2870278.0',\n",
       "  '2881179.0',\n",
       "  '2872737.0',\n",
       "  '2871438.0',\n",
       "  '2854257.0',\n",
       "  '2790112.0',\n",
       "  '2824485.0',\n",
       "  '2814743.0',\n",
       "  '2802968.0',\n",
       "  '2799793.0',\n",
       "  '2814145.0',\n",
       "  '2851942.0',\n",
       "  '2800065.0',\n",
       "  '2785106.0',\n",
       "  '2780180.0',\n",
       "  '2780619.0',\n",
       "  '2791923.0',\n",
       "  '2732154.0',\n",
       "  '2733607.0',\n",
       "  '2737083.0',\n",
       "  '2717650.0',\n",
       "  '2697423.0',\n",
       "  '2706938.0',\n",
       "  '2707609.0',\n",
       "  '2681006.0',\n",
       "  '2683420.0',\n",
       "  '2679773.0',\n",
       "  '2671078.0',\n",
       "  '2648008.0',\n",
       "  '2657006.0',\n",
       "  '2657097.0',\n",
       "  '2627216.0',\n",
       "  '2619869.0',\n",
       "  '2620297.0',\n",
       "  '2598437.0',\n",
       "  '2610172.0',\n",
       "  '2597846.0',\n",
       "  '2588350.0',\n",
       "  '2571593.0',\n",
       "  '2585270.0',\n",
       "  '2547578.0',\n",
       "  '2556228.0',\n",
       "  '2537565.0',\n",
       "  '2536045.0',\n",
       "  '2531201.0',\n",
       "  '2541572.0',\n",
       "  '2544261.0',\n",
       "  '2525410.0',\n",
       "  '2549737.0',\n",
       "  '2488910.0',\n",
       "  '2472894.0',\n",
       "  '2502730.0',\n",
       "  '2488037.0',\n",
       "  '2465519.0',\n",
       "  '2482039.0',\n",
       "  '2459343.0',\n",
       "  '2467060.0',\n",
       "  '2446806.0',\n",
       "  '2453907.0',\n",
       "  '2423557.0',\n",
       "  '2472127.0',\n",
       "  '2461035.0',\n",
       "  '2464759.0',\n",
       "  '2467648.0',\n",
       "  '2420361.0',\n",
       "  '2393306.0',\n",
       "  '2420212.0',\n",
       "  '2391623.0',\n",
       "  '2375937.0',\n",
       "  '2362100.0',\n",
       "  '2343349.0',\n",
       "  '2353676.0',\n",
       "  '2354418.0',\n",
       "  '2363764.0',\n",
       "  '2374772.0',\n",
       "  '2321844.0',\n",
       "  '2335339.0',\n",
       "  '2318334.0',\n",
       "  '2328175.0',\n",
       "  '2299515.0',\n",
       "  '2330644.0',\n",
       "  '2324739.0',\n",
       "  '2308411.0',\n",
       "  '2285841.0',\n",
       "  '2282146.0',\n",
       "  '2305035.0',\n",
       "  '2269177.0',\n",
       "  '2262741.0',\n",
       "  '2256550.0'],\n",
       " 'val_false_negatives': ['8851754.0',\n",
       "  '7237421.0',\n",
       "  '3679141.0',\n",
       "  '3362991.0',\n",
       "  '9913514.0',\n",
       "  '3462292.0',\n",
       "  '7297637.0',\n",
       "  '4792872.0',\n",
       "  '4348781.0',\n",
       "  '15825595.0',\n",
       "  '7032006.0',\n",
       "  '4923645.0',\n",
       "  '4507543.0',\n",
       "  '4483273.0',\n",
       "  '6801397.0',\n",
       "  '6438257.0',\n",
       "  '12429828.0',\n",
       "  '5053912.0',\n",
       "  '4017818.0',\n",
       "  '3943181.0',\n",
       "  '5944726.0',\n",
       "  '5869113.0',\n",
       "  '6079232.0',\n",
       "  '8435806.0',\n",
       "  '7374033.0',\n",
       "  '7312886.0',\n",
       "  '7922662.0',\n",
       "  '6120405.0',\n",
       "  '8034445.0',\n",
       "  '6742119.0',\n",
       "  '5381316.0',\n",
       "  '7004659.0',\n",
       "  '5397325.0',\n",
       "  '6646050.0',\n",
       "  '6559521.0',\n",
       "  '6200927.0',\n",
       "  '6651964.0',\n",
       "  '6606818.0',\n",
       "  '4672042.0',\n",
       "  '5724489.0',\n",
       "  '7192793.0',\n",
       "  '5665198.0',\n",
       "  '7167131.0',\n",
       "  '7211865.0',\n",
       "  '5555375.0',\n",
       "  '7374142.0',\n",
       "  '7175543.0',\n",
       "  '7238884.0',\n",
       "  '4391015.0',\n",
       "  '4083851.0',\n",
       "  '4909676.0',\n",
       "  '4137891.0',\n",
       "  '4873532.0',\n",
       "  '4311807.0',\n",
       "  '4515256.0',\n",
       "  '5443997.0',\n",
       "  '4037752.0',\n",
       "  '4417087.0',\n",
       "  '5212937.0',\n",
       "  '5509264.0',\n",
       "  '4880562.0',\n",
       "  '4717113.0',\n",
       "  '4174647.0',\n",
       "  '5284727.0',\n",
       "  '4678049.0',\n",
       "  '4404009.0',\n",
       "  '4882457.0',\n",
       "  '4256534.0',\n",
       "  '5328217.0',\n",
       "  '6620081.0',\n",
       "  '5779911.0',\n",
       "  '4922173.0',\n",
       "  '4263487.0',\n",
       "  '4831756.0',\n",
       "  '5068548.0',\n",
       "  '5134937.0',\n",
       "  '4849707.0',\n",
       "  '4871201.0',\n",
       "  '5709995.0',\n",
       "  '4364945.0',\n",
       "  '4859781.0',\n",
       "  '5362147.0',\n",
       "  '4827539.0',\n",
       "  '4485626.0',\n",
       "  '5307799.0',\n",
       "  '4255472.0',\n",
       "  '4323036.0',\n",
       "  '4140038.0',\n",
       "  '4725118.0',\n",
       "  '6366061.0',\n",
       "  '4541184.0',\n",
       "  '5019541.0',\n",
       "  '4398084.0',\n",
       "  '4260752.0',\n",
       "  '4731966.0',\n",
       "  '4077258.0',\n",
       "  '3997543.0',\n",
       "  '3828801.0',\n",
       "  '3779963.0',\n",
       "  '4805478.0',\n",
       "  '4099892.0',\n",
       "  '4816332.0',\n",
       "  '4448775.0',\n",
       "  '3923283.0',\n",
       "  '4466386.0',\n",
       "  '3983785.0',\n",
       "  '4019699.0',\n",
       "  '4195031.0',\n",
       "  '4277085.0',\n",
       "  '4398924.0',\n",
       "  '4972009.0',\n",
       "  '4151176.0',\n",
       "  '4817497.0',\n",
       "  '4454201.0',\n",
       "  '4622399.0',\n",
       "  '4133972.0',\n",
       "  '4059752.0',\n",
       "  '4425233.0',\n",
       "  '4386014.0',\n",
       "  '4723219.0',\n",
       "  '4323671.0',\n",
       "  '4125756.0',\n",
       "  '4299205.0',\n",
       "  '4408369.0',\n",
       "  '4919555.0',\n",
       "  '4104398.0',\n",
       "  '3745912.0',\n",
       "  '4293373.0',\n",
       "  '4662822.0',\n",
       "  '3834225.0',\n",
       "  '3854301.0',\n",
       "  '4505818.0',\n",
       "  '3873416.0',\n",
       "  '4174883.0',\n",
       "  '3956546.0',\n",
       "  '3903798.0',\n",
       "  '3640779.0',\n",
       "  '4269425.0',\n",
       "  '4158451.0',\n",
       "  '4181506.0',\n",
       "  '4285346.0',\n",
       "  '4721465.0',\n",
       "  '3782813.0',\n",
       "  '4042456.0',\n",
       "  '4083054.0',\n",
       "  '4067203.0',\n",
       "  '4159970.0',\n",
       "  '3627388.0',\n",
       "  '4073743.0',\n",
       "  '4248326.0',\n",
       "  '4022974.0',\n",
       "  '4068191.0',\n",
       "  '3910098.0',\n",
       "  '4006225.0',\n",
       "  '3910667.0',\n",
       "  '4093077.0',\n",
       "  '3832406.0',\n",
       "  '4093079.0',\n",
       "  '3807113.0',\n",
       "  '4156799.0',\n",
       "  '3975219.0',\n",
       "  '3906967.0',\n",
       "  '3915282.0',\n",
       "  '3672975.0',\n",
       "  '3757701.0',\n",
       "  '3885812.0',\n",
       "  '3951036.0',\n",
       "  '3942104.0',\n",
       "  '3907745.0',\n",
       "  '4217597.0',\n",
       "  '3659413.0',\n",
       "  '4226772.0',\n",
       "  '3809376.0',\n",
       "  '3826343.0',\n",
       "  '4065343.0',\n",
       "  '4035276.0',\n",
       "  '3836654.0',\n",
       "  '3964954.0',\n",
       "  '3593952.0',\n",
       "  '4222464.0',\n",
       "  '3779069.0',\n",
       "  '4403358.0',\n",
       "  '4055663.0',\n",
       "  '3770166.0',\n",
       "  '3833913.0',\n",
       "  '3715323.0',\n",
       "  '3976984.0',\n",
       "  '3802905.0',\n",
       "  '3815686.0',\n",
       "  '3602536.0',\n",
       "  '3600022.0',\n",
       "  '3819738.0',\n",
       "  '3667189.0',\n",
       "  '3847634.0',\n",
       "  '3945320.0',\n",
       "  '3882817.0',\n",
       "  '3914452.0',\n",
       "  '4022807.0',\n",
       "  '3570578.0',\n",
       "  '3684307.0',\n",
       "  '3598006.0',\n",
       "  '4053576.0',\n",
       "  '3641939.0',\n",
       "  '4165202.0',\n",
       "  '3856103.0',\n",
       "  '4002054.0',\n",
       "  '3932562.0',\n",
       "  '3981526.0',\n",
       "  '3685156.0',\n",
       "  '3985841.0',\n",
       "  '3765053.0',\n",
       "  '3681856.0',\n",
       "  '4017687.0',\n",
       "  '4030852.0',\n",
       "  '4097469.0',\n",
       "  '3776639.0',\n",
       "  '3934714.0',\n",
       "  '4005198.0',\n",
       "  '3735626.0',\n",
       "  '3681517.0',\n",
       "  '3512221.0',\n",
       "  '3727722.0',\n",
       "  '4069980.0',\n",
       "  '3693351.0',\n",
       "  '3930117.0',\n",
       "  '3991730.0',\n",
       "  '4141527.0',\n",
       "  '3495998.0',\n",
       "  '3920567.0',\n",
       "  '3805576.0',\n",
       "  '4101306.0',\n",
       "  '3812515.0',\n",
       "  '4135232.0',\n",
       "  '3674059.0',\n",
       "  '4009458.0',\n",
       "  '3446657.0',\n",
       "  '3725783.0',\n",
       "  '3821632.0',\n",
       "  '3756677.0',\n",
       "  '3977635.0',\n",
       "  '3953346.0',\n",
       "  '3588100.0',\n",
       "  '3740698.0',\n",
       "  '3667972.0',\n",
       "  '3875219.0',\n",
       "  '3971746.0',\n",
       "  '3717691.0',\n",
       "  '3585060.0',\n",
       "  '3833637.0',\n",
       "  '3664065.0',\n",
       "  '3549449.0',\n",
       "  '3582448.0',\n",
       "  '3837162.0',\n",
       "  '3707448.0',\n",
       "  '3625418.0',\n",
       "  '3906031.0',\n",
       "  '3624403.0',\n",
       "  '3613424.0',\n",
       "  '3854231.0',\n",
       "  '3714308.0',\n",
       "  '3651075.0',\n",
       "  '3587633.0',\n",
       "  '3612929.0',\n",
       "  '3585531.0',\n",
       "  '3584905.0',\n",
       "  '3637206.0',\n",
       "  '3815304.0',\n",
       "  '3561362.0',\n",
       "  '3974073.0',\n",
       "  '3607607.0',\n",
       "  '4006192.0',\n",
       "  '3713291.0',\n",
       "  '3880041.0',\n",
       "  '3441981.0',\n",
       "  '3432880.0',\n",
       "  '3649593.0',\n",
       "  '3639290.0',\n",
       "  '3614906.0',\n",
       "  '3700470.0',\n",
       "  '3695401.0',\n",
       "  '3612131.0',\n",
       "  '3764174.0',\n",
       "  '3603080.0',\n",
       "  '3782310.0',\n",
       "  '3704335.0',\n",
       "  '3598604.0',\n",
       "  '3639829.0',\n",
       "  '3875966.0',\n",
       "  '3627405.0',\n",
       "  '3775872.0',\n",
       "  '3670300.0',\n",
       "  '3704838.0',\n",
       "  '3708258.0',\n",
       "  '3419039.0',\n",
       "  '3572159.0',\n",
       "  '3835599.0',\n",
       "  '3652833.0',\n",
       "  '3525975.0',\n",
       "  '3701828.0',\n",
       "  '3522083.0',\n",
       "  '3566638.0'],\n",
       " 'false_negatives': ['19900488.0',\n",
       "  '19967952.0',\n",
       "  '18638656.0',\n",
       "  '18125208.0',\n",
       "  '17931140.0',\n",
       "  '17078148.0',\n",
       "  '16733604.0',\n",
       "  '16100101.0',\n",
       "  '16425623.0',\n",
       "  '15566396.0',\n",
       "  '15370898.0',\n",
       "  '15081117.0',\n",
       "  '14547673.0',\n",
       "  '14474606.0',\n",
       "  '14200654.0',\n",
       "  '13956604.0',\n",
       "  '13695691.0',\n",
       "  '13758712.0',\n",
       "  '13814412.0',\n",
       "  '13334564.0',\n",
       "  '13774491.0',\n",
       "  '12456214.0',\n",
       "  '11824045.0',\n",
       "  '11292713.0',\n",
       "  '10695585.0',\n",
       "  '10409802.0',\n",
       "  '10179642.0',\n",
       "  '10076909.0',\n",
       "  '9755018.0',\n",
       "  '9449476.0',\n",
       "  '9256750.0',\n",
       "  '9079421.0',\n",
       "  '8936645.0',\n",
       "  '8805240.0',\n",
       "  '8580699.0',\n",
       "  '8422407.0',\n",
       "  '8313276.0',\n",
       "  '8098081.0',\n",
       "  '7992009.0',\n",
       "  '7895927.0',\n",
       "  '7721942.0',\n",
       "  '7698929.0',\n",
       "  '7716311.0',\n",
       "  '7479139.0',\n",
       "  '7439621.0',\n",
       "  '7292541.0',\n",
       "  '7151389.0',\n",
       "  '7075720.0',\n",
       "  '6998804.0',\n",
       "  '6994768.0',\n",
       "  '6944451.0',\n",
       "  '6756795.0',\n",
       "  '6601561.0',\n",
       "  '6641210.0',\n",
       "  '6585380.0',\n",
       "  '6545674.0',\n",
       "  '6551179.0',\n",
       "  '6399873.0',\n",
       "  '6344825.0',\n",
       "  '6221096.0',\n",
       "  '6222892.0',\n",
       "  '6152393.0',\n",
       "  '6047171.0',\n",
       "  '5962358.0',\n",
       "  '5916113.0',\n",
       "  '5889951.0',\n",
       "  '5907227.0',\n",
       "  '5842164.0',\n",
       "  '5812179.0',\n",
       "  '5704159.0',\n",
       "  '5708037.0',\n",
       "  '5666645.0',\n",
       "  '5637824.0',\n",
       "  '5695352.0',\n",
       "  '5507007.0',\n",
       "  '5490982.0',\n",
       "  '5424925.0',\n",
       "  '5399117.0',\n",
       "  '5354359.0',\n",
       "  '5380905.0',\n",
       "  '5296792.0',\n",
       "  '5265047.0',\n",
       "  '5258341.0',\n",
       "  '5179859.0',\n",
       "  '5157383.0',\n",
       "  '5112826.0',\n",
       "  '5079390.0',\n",
       "  '4976309.0',\n",
       "  '5058277.0',\n",
       "  '4981623.0',\n",
       "  '4930250.0',\n",
       "  '4907744.0',\n",
       "  '4887910.0',\n",
       "  '4840680.0',\n",
       "  '4824698.0',\n",
       "  '4757637.0',\n",
       "  '4771950.0',\n",
       "  '4786496.0',\n",
       "  '4753429.0',\n",
       "  '4672542.0',\n",
       "  '4633946.0',\n",
       "  '4669383.0',\n",
       "  '4650407.0',\n",
       "  '4586364.0',\n",
       "  '4597953.0',\n",
       "  '4578510.0',\n",
       "  '4426219.0',\n",
       "  '4387830.0',\n",
       "  '4437575.0',\n",
       "  '4431659.0',\n",
       "  '4398581.0',\n",
       "  '4354285.0',\n",
       "  '4283788.0',\n",
       "  '4409442.0',\n",
       "  '4331404.0',\n",
       "  '4292143.0',\n",
       "  '4306548.0',\n",
       "  '4212304.0',\n",
       "  '4218108.0',\n",
       "  '4254941.0',\n",
       "  '4141013.0',\n",
       "  '4136190.0',\n",
       "  '4129769.0',\n",
       "  '4155481.0',\n",
       "  '4090377.0',\n",
       "  '4174135.0',\n",
       "  '4085929.0',\n",
       "  '3971176.0',\n",
       "  '3973600.0',\n",
       "  '3974138.0',\n",
       "  '3979753.0',\n",
       "  '3948602.0',\n",
       "  '3937098.0',\n",
       "  '3896461.0',\n",
       "  '3884075.0',\n",
       "  '3880238.0',\n",
       "  '3888314.0',\n",
       "  '3881591.0',\n",
       "  '3849760.0',\n",
       "  '3814971.0',\n",
       "  '3825096.0',\n",
       "  '3801381.0',\n",
       "  '3775301.0',\n",
       "  '3778853.0',\n",
       "  '3757482.0',\n",
       "  '3729971.0',\n",
       "  '3730972.0',\n",
       "  '3733321.0',\n",
       "  '3682265.0',\n",
       "  '3664363.0',\n",
       "  '3622166.0',\n",
       "  '3625748.0',\n",
       "  '3600609.0',\n",
       "  '3571582.0',\n",
       "  '3543061.0',\n",
       "  '3523531.0',\n",
       "  '3501227.0',\n",
       "  '3489810.0',\n",
       "  '3579801.0',\n",
       "  '3551397.0',\n",
       "  '3507038.0',\n",
       "  '3476990.0',\n",
       "  '3505537.0',\n",
       "  '3434011.0',\n",
       "  '3420299.0',\n",
       "  '3441011.0',\n",
       "  '3379333.0',\n",
       "  '3420794.0',\n",
       "  '3382089.0',\n",
       "  '3397677.0',\n",
       "  '3411008.0',\n",
       "  '3324052.0',\n",
       "  '3350064.0',\n",
       "  '3280082.0',\n",
       "  '3306630.0',\n",
       "  '3271547.0',\n",
       "  '3286013.0',\n",
       "  '3214479.0',\n",
       "  '3283885.0',\n",
       "  '3242600.0',\n",
       "  '3238921.0',\n",
       "  '3160728.0',\n",
       "  '3204691.0',\n",
       "  '3199423.0',\n",
       "  '3199192.0',\n",
       "  '3168139.0',\n",
       "  '3144432.0',\n",
       "  '3118269.0',\n",
       "  '3161487.0',\n",
       "  '3177523.0',\n",
       "  '3155487.0',\n",
       "  '3154906.0',\n",
       "  '3136134.0',\n",
       "  '3089563.0',\n",
       "  '3078381.0',\n",
       "  '3070897.0',\n",
       "  '3060126.0',\n",
       "  '3061035.0',\n",
       "  '3028634.0',\n",
       "  '3013764.0',\n",
       "  '3030603.0',\n",
       "  '3011872.0',\n",
       "  '2976513.0',\n",
       "  '2965596.0',\n",
       "  '2974227.0',\n",
       "  '2952696.0',\n",
       "  '2967524.0',\n",
       "  '2935602.0',\n",
       "  '2969994.0',\n",
       "  '2924641.0',\n",
       "  '2901695.0',\n",
       "  '2863919.0',\n",
       "  '2887874.0',\n",
       "  '2895362.0',\n",
       "  '2870677.0',\n",
       "  '2834042.0',\n",
       "  '2842906.0',\n",
       "  '2857141.0',\n",
       "  '2844481.0',\n",
       "  '2784641.0',\n",
       "  '2799859.0',\n",
       "  '2790885.0',\n",
       "  '2836969.0',\n",
       "  '2779580.0',\n",
       "  '2808618.0',\n",
       "  '2798226.0',\n",
       "  '2761038.0',\n",
       "  '2812276.0',\n",
       "  '2776870.0',\n",
       "  '2735230.0',\n",
       "  '2712106.0',\n",
       "  '2723699.0',\n",
       "  '2710047.0',\n",
       "  '2727516.0',\n",
       "  '2667492.0',\n",
       "  '2693101.0',\n",
       "  '2677470.0',\n",
       "  '2694406.0',\n",
       "  '2652483.0',\n",
       "  '2646931.0',\n",
       "  '2665805.0',\n",
       "  '2622465.0',\n",
       "  '2629733.0',\n",
       "  '2634946.0',\n",
       "  '2613577.0',\n",
       "  '2600066.0',\n",
       "  '2581945.0',\n",
       "  '2600954.0',\n",
       "  '2609746.0',\n",
       "  '2589062.0',\n",
       "  '2557613.0',\n",
       "  '2560945.0',\n",
       "  '2562371.0',\n",
       "  '2570496.0',\n",
       "  '2522806.0',\n",
       "  '2566710.0',\n",
       "  '2536195.0',\n",
       "  '2526659.0',\n",
       "  '2520332.0',\n",
       "  '2543439.0',\n",
       "  '2502508.0',\n",
       "  '2516789.0',\n",
       "  '2454100.0',\n",
       "  '2480853.0',\n",
       "  '2477781.0',\n",
       "  '2462479.0',\n",
       "  '2466692.0',\n",
       "  '2446730.0',\n",
       "  '2455142.0',\n",
       "  '2460500.0',\n",
       "  '2422895.0',\n",
       "  '2423496.0',\n",
       "  '2465940.0',\n",
       "  '2449502.0',\n",
       "  '2467842.0',\n",
       "  '2424521.0',\n",
       "  '2399873.0',\n",
       "  '2375769.0',\n",
       "  '2379899.0',\n",
       "  '2390066.0',\n",
       "  '2385008.0',\n",
       "  '2373792.0',\n",
       "  '2351293.0',\n",
       "  '2328959.0',\n",
       "  '2350035.0',\n",
       "  '2321748.0',\n",
       "  '2381085.0',\n",
       "  '2360157.0',\n",
       "  '2308323.0',\n",
       "  '2315825.0',\n",
       "  '2319660.0',\n",
       "  '2294015.0',\n",
       "  '2320784.0',\n",
       "  '2333152.0',\n",
       "  '2262419.0',\n",
       "  '2266169.0',\n",
       "  '2299723.0',\n",
       "  '2270489.0',\n",
       "  '2249524.0',\n",
       "  '2260259.0',\n",
       "  '2241727.0'],\n",
       " 'binary_iou': ['0.6463431119918823',\n",
       "  '0.7348068356513977',\n",
       "  '0.747620701789856',\n",
       "  '0.7613716125488281',\n",
       "  '0.7696713209152222',\n",
       "  '0.7784072160720825',\n",
       "  '0.7826745510101318',\n",
       "  '0.7889226675033569',\n",
       "  '0.7956593036651611',\n",
       "  '0.8033660054206848',\n",
       "  '0.8057264089584351',\n",
       "  '0.8126584887504578',\n",
       "  '0.8151732683181763',\n",
       "  '0.8180391788482666',\n",
       "  '0.8203401565551758',\n",
       "  '0.8267014622688293',\n",
       "  '0.8284687399864197',\n",
       "  '0.8306362628936768',\n",
       "  '0.8303505182266235',\n",
       "  '0.8356871604919434',\n",
       "  '0.8307786583900452',\n",
       "  '0.8457794785499573',\n",
       "  '0.8553969860076904',\n",
       "  '0.8614142537117004',\n",
       "  '0.868125319480896',\n",
       "  '0.8725545406341553',\n",
       "  '0.8760201334953308',\n",
       "  '0.8778135776519775',\n",
       "  '0.8815160393714905',\n",
       "  '0.8850257396697998',\n",
       "  '0.888355553150177',\n",
       "  '0.8903061151504517',\n",
       "  '0.8920028209686279',\n",
       "  '0.8941923379898071',\n",
       "  '0.8958249688148499',\n",
       "  '0.8980337381362915',\n",
       "  '0.8993145227432251',\n",
       "  '0.9015920758247375',\n",
       "  '0.9026288986206055',\n",
       "  '0.9041920304298401',\n",
       "  '0.9057389497756958',\n",
       "  '0.9061377048492432',\n",
       "  '0.907437801361084',\n",
       "  '0.9095010757446289',\n",
       "  '0.9091638326644897',\n",
       "  '0.9118812084197998',\n",
       "  '0.9123821258544922',\n",
       "  '0.9134726524353027',\n",
       "  '0.914912223815918',\n",
       "  '0.9153347015380859',\n",
       "  '0.9149683713912964',\n",
       "  '0.9169280529022217',\n",
       "  '0.9189176559448242',\n",
       "  '0.9184274673461914',\n",
       "  '0.9194422960281372',\n",
       "  '0.9198662042617798',\n",
       "  '0.9201915860176086',\n",
       "  '0.9214795827865601',\n",
       "  '0.9223148226737976',\n",
       "  '0.9239821434020996',\n",
       "  '0.9231289625167847',\n",
       "  '0.9241070747375488',\n",
       "  '0.925462007522583',\n",
       "  '0.9264479875564575',\n",
       "  '0.9270750284194946',\n",
       "  '0.9272448420524597',\n",
       "  '0.9275543689727783',\n",
       "  '0.9281450510025024',\n",
       "  '0.9286621809005737',\n",
       "  '0.9291150569915771',\n",
       "  '0.9299004077911377',\n",
       "  '0.9303044080734253',\n",
       "  '0.9307574033737183',\n",
       "  '0.9304519891738892',\n",
       "  '0.9313454627990723',\n",
       "  '0.9322675466537476',\n",
       "  '0.9328056573867798',\n",
       "  '0.9331461191177368',\n",
       "  '0.9341280460357666',\n",
       "  '0.9338160157203674',\n",
       "  '0.9347089529037476',\n",
       "  '0.9344909191131592',\n",
       "  '0.9349321722984314',\n",
       "  '0.9354203939437866',\n",
       "  '0.9363428354263306',\n",
       "  '0.9364622831344604',\n",
       "  '0.9370462894439697',\n",
       "  '0.9379115104675293',\n",
       "  '0.9373600482940674',\n",
       "  '0.9381507039070129',\n",
       "  '0.9390319585800171',\n",
       "  '0.9392772316932678',\n",
       "  '0.9393184185028076',\n",
       "  '0.9399396181106567',\n",
       "  '0.9398436546325684',\n",
       "  '0.9402405023574829',\n",
       "  '0.9409937262535095',\n",
       "  '0.9406806230545044',\n",
       "  '0.9411288499832153',\n",
       "  '0.9412825703620911',\n",
       "  '0.9418526887893677',\n",
       "  '0.9420011043548584',\n",
       "  '0.942203164100647',\n",
       "  '0.9428107142448425',\n",
       "  '0.9428485035896301',\n",
       "  '0.9431092143058777',\n",
       "  '0.9442176818847656',\n",
       "  '0.944657564163208',\n",
       "  '0.9447546005249023',\n",
       "  '0.9444881677627563',\n",
       "  '0.9451987147331238',\n",
       "  '0.9454934597015381',\n",
       "  '0.9459710121154785',\n",
       "  '0.9451897740364075',\n",
       "  '0.9458852410316467',\n",
       "  '0.946039080619812',\n",
       "  '0.9464861154556274',\n",
       "  '0.9470257759094238',\n",
       "  '0.9473624229431152',\n",
       "  '0.9470081329345703',\n",
       "  '0.9479737281799316',\n",
       "  '0.9483059644699097',\n",
       "  '0.9481172561645508',\n",
       "  '0.9480379819869995',\n",
       "  '0.9486700892448425',\n",
       "  '0.9483453631401062',\n",
       "  '0.9491568803787231',\n",
       "  '0.9494479298591614',\n",
       "  '0.9502225518226624',\n",
       "  '0.9501833319664001',\n",
       "  '0.9501864910125732',\n",
       "  '0.950194776058197',\n",
       "  '0.9505174160003662',\n",
       "  '0.9510514140129089',\n",
       "  '0.9512079358100891',\n",
       "  '0.9512725472450256',\n",
       "  '0.951006293296814',\n",
       "  '0.9512829780578613',\n",
       "  '0.9515807628631592',\n",
       "  '0.9520518779754639',\n",
       "  '0.9521178007125854',\n",
       "  '0.952293336391449',\n",
       "  '0.9522887468338013',\n",
       "  '0.9525346755981445',\n",
       "  '0.9527779221534729',\n",
       "  '0.9528325796127319',\n",
       "  '0.9531174302101135',\n",
       "  '0.9530863165855408',\n",
       "  '0.9535777568817139',\n",
       "  '0.953882098197937',\n",
       "  '0.9542238116264343',\n",
       "  '0.9545319676399231',\n",
       "  '0.9541395902633667',\n",
       "  '0.954757034778595',\n",
       "  '0.955251932144165',\n",
       "  '0.9551671743392944',\n",
       "  '0.9555932283401489',\n",
       "  '0.9556859731674194',\n",
       "  '0.9552804231643677',\n",
       "  '0.9552948474884033',\n",
       "  '0.9556993246078491',\n",
       "  '0.9560810327529907',\n",
       "  '0.9559879899024963',\n",
       "  '0.956756591796875',\n",
       "  '0.956744909286499',\n",
       "  '0.9567466974258423',\n",
       "  '0.95708167552948',\n",
       "  '0.9567611217498779',\n",
       "  '0.9574123620986938',\n",
       "  '0.9570596218109131',\n",
       "  '0.9572944641113281',\n",
       "  '0.9575443267822266',\n",
       "  '0.9575228691101074',\n",
       "  '0.9584395289421082',\n",
       "  '0.9583616852760315',\n",
       "  '0.9583941102027893',\n",
       "  '0.9587695002555847',\n",
       "  '0.9590719938278198',\n",
       "  '0.9583548307418823',\n",
       "  '0.9588630199432373',\n",
       "  '0.9591360688209534',\n",
       "  '0.9597306251525879',\n",
       "  '0.9593549966812134',\n",
       "  '0.9596807956695557',\n",
       "  '0.9595361948013306',\n",
       "  '0.9599641561508179',\n",
       "  '0.9600595235824585',\n",
       "  '0.9604499340057373',\n",
       "  '0.9600396156311035',\n",
       "  '0.9599118232727051',\n",
       "  '0.9600924253463745',\n",
       "  '0.959997832775116',\n",
       "  '0.9605569839477539',\n",
       "  '0.9609225988388062',\n",
       "  '0.9609907269477844',\n",
       "  '0.9612011909484863',\n",
       "  '0.9612506628036499',\n",
       "  '0.9612300992012024',\n",
       "  '0.9616038203239441',\n",
       "  '0.9616371989250183',\n",
       "  '0.9617115259170532',\n",
       "  '0.9617648124694824',\n",
       "  '0.9622265100479126',\n",
       "  '0.9623495936393738',\n",
       "  '0.962309718132019',\n",
       "  '0.9625685214996338',\n",
       "  '0.9625928401947021',\n",
       "  '0.9626742601394653',\n",
       "  '0.9626451134681702',\n",
       "  '0.9628369212150574',\n",
       "  '0.9632529020309448',\n",
       "  '0.9636056423187256',\n",
       "  '0.9634585380554199',\n",
       "  '0.9633501768112183',\n",
       "  '0.9635521769523621',\n",
       "  '0.963796079158783',\n",
       "  '0.9638373851776123',\n",
       "  '0.9641528129577637',\n",
       "  '0.9640124440193176',\n",
       "  '0.9644572138786316',\n",
       "  '0.9644287824630737',\n",
       "  '0.9645090103149414',\n",
       "  '0.9641269445419312',\n",
       "  '0.9642531871795654',\n",
       "  '0.9643934965133667',\n",
       "  '0.9645569324493408',\n",
       "  '0.9648051261901855',\n",
       "  '0.9644951820373535',\n",
       "  '0.9646401405334473',\n",
       "  '0.9652748107910156',\n",
       "  '0.965410590171814',\n",
       "  '0.9653187990188599',\n",
       "  '0.9655271768569946',\n",
       "  '0.9655369520187378',\n",
       "  '0.9658544063568115',\n",
       "  '0.9656943678855896',\n",
       "  '0.9659565687179565',\n",
       "  '0.9658337235450745',\n",
       "  '0.9661163091659546',\n",
       "  '0.9662092924118042',\n",
       "  '0.9662353992462158',\n",
       "  '0.9664489030838013',\n",
       "  '0.9664077758789062',\n",
       "  '0.9665595889091492',\n",
       "  '0.9667350053787231',\n",
       "  '0.9668211936950684',\n",
       "  '0.9670693874359131',\n",
       "  '0.9668775796890259',\n",
       "  '0.9668961763381958',\n",
       "  '0.967085599899292',\n",
       "  '0.9673880934715271',\n",
       "  '0.967279314994812',\n",
       "  '0.9675093293190002',\n",
       "  '0.9673990607261658',\n",
       "  '0.9678204655647278',\n",
       "  '0.9675456285476685',\n",
       "  '0.9677739143371582',\n",
       "  '0.9677676558494568',\n",
       "  '0.9677947759628296',\n",
       "  '0.9677653908729553',\n",
       "  '0.9678707122802734',\n",
       "  '0.9681564569473267',\n",
       "  '0.968650758266449',\n",
       "  '0.9682900309562683',\n",
       "  '0.9684078693389893',\n",
       "  '0.9686489105224609',\n",
       "  '0.9685139656066895',\n",
       "  '0.968783438205719',\n",
       "  '0.9686816930770874',\n",
       "  '0.9687737226486206',\n",
       "  '0.9689664840698242',\n",
       "  '0.969149112701416',\n",
       "  '0.9685797691345215',\n",
       "  '0.9687550067901611',\n",
       "  '0.9686169624328613',\n",
       "  '0.9688738584518433',\n",
       "  '0.9693179130554199',\n",
       "  '0.9696440100669861',\n",
       "  '0.9694465398788452',\n",
       "  '0.9695612192153931',\n",
       "  '0.9696956872940063',\n",
       "  '0.9698456525802612',\n",
       "  '0.9701052904129028',\n",
       "  '0.970186710357666',\n",
       "  '0.9700493216514587',\n",
       "  '0.9701622724533081',\n",
       "  '0.9697232246398926',\n",
       "  '0.97017902135849',\n",
       "  '0.9704197645187378',\n",
       "  '0.9704894423484802',\n",
       "  '0.9704045057296753',\n",
       "  '0.9707427024841309',\n",
       "  '0.9703803062438965',\n",
       "  '0.9703353643417358',\n",
       "  '0.9708892107009888',\n",
       "  '0.971001148223877',\n",
       "  '0.9708172082901001',\n",
       "  '0.9708541631698608',\n",
       "  '0.9712101221084595',\n",
       "  '0.9711898565292358',\n",
       "  '0.9713348150253296'],\n",
       " 'loss': ['0.25298193097114563',\n",
       "  '0.17970937490463257',\n",
       "  '0.16944220662117004',\n",
       "  '0.15938016772270203',\n",
       "  '0.15386037528514862',\n",
       "  '0.14730830490589142',\n",
       "  '0.14401723444461823',\n",
       "  '0.13967755436897278',\n",
       "  '0.1352715641260147',\n",
       "  '0.12936197221279144',\n",
       "  '0.12777672708034515',\n",
       "  '0.12335705757141113',\n",
       "  '0.12128963321447372',\n",
       "  '0.11935042589902878',\n",
       "  '0.11748106777667999',\n",
       "  '0.11296495795249939',\n",
       "  '0.1116277351975441',\n",
       "  '0.11073320358991623',\n",
       "  '0.11055346578359604',\n",
       "  '0.10677679628133774',\n",
       "  '0.11020775139331818',\n",
       "  '0.09975660592317581',\n",
       "  '0.0935378223657608',\n",
       "  '0.0894191786646843',\n",
       "  '0.08441867679357529',\n",
       "  '0.08155381679534912',\n",
       "  '0.07915724068880081',\n",
       "  '0.07844380289316177',\n",
       "  '0.07533737272024155',\n",
       "  '0.07316134124994278',\n",
       "  '0.07119274884462357',\n",
       "  '0.06957931816577911',\n",
       "  '0.06880433857440948',\n",
       "  '0.06713059544563293',\n",
       "  '0.06614269316196442',\n",
       "  '0.06454344838857651',\n",
       "  '0.06352739781141281',\n",
       "  '0.06210588291287422',\n",
       "  '0.06124335527420044',\n",
       "  '0.0604797787964344',\n",
       "  '0.05925912410020828',\n",
       "  '0.059359148144721985',\n",
       "  '0.058401912450790405',\n",
       "  '0.05686119571328163',\n",
       "  '0.05698848143219948',\n",
       "  '0.055322013795375824',\n",
       "  '0.05488469824194908',\n",
       "  '0.05423285439610481',\n",
       "  '0.05342765152454376',\n",
       "  '0.05310150235891342',\n",
       "  '0.053259093314409256',\n",
       "  '0.05196375772356987',\n",
       "  '0.050651054829359055',\n",
       "  '0.05102226510643959',\n",
       "  '0.05042153224349022',\n",
       "  '0.05005910247564316',\n",
       "  '0.04988605156540871',\n",
       "  '0.049086082726716995',\n",
       "  '0.04858037456870079',\n",
       "  '0.04743805527687073',\n",
       "  '0.048179324716329575',\n",
       "  '0.047389645129442215',\n",
       "  '0.04667980968952179',\n",
       "  '0.04567601904273033',\n",
       "  '0.045331407338380814',\n",
       "  '0.04546033591032028',\n",
       "  '0.045165326446294785',\n",
       "  '0.04490531235933304',\n",
       "  '0.04451688006520271',\n",
       "  '0.044179368764162064',\n",
       "  '0.043642349541187286',\n",
       "  '0.04324305057525635',\n",
       "  '0.042909324169158936',\n",
       "  '0.04333086684346199',\n",
       "  '0.042637646198272705',\n",
       "  '0.04206259548664093',\n",
       "  '0.04178716242313385',\n",
       "  '0.04139517620205879',\n",
       "  '0.04087722301483154',\n",
       "  '0.041012492030858994',\n",
       "  '0.04040880128741264',\n",
       "  '0.04063909500837326',\n",
       "  '0.04024669900536537',\n",
       "  '0.03990807756781578',\n",
       "  '0.03947186842560768',\n",
       "  '0.03948971629142761',\n",
       "  '0.03897038474678993',\n",
       "  '0.038472533226013184',\n",
       "  '0.0388808511197567',\n",
       "  '0.038243088871240616',\n",
       "  '0.03778625279664993',\n",
       "  '0.0374939851462841',\n",
       "  '0.037650033831596375',\n",
       "  '0.03713776916265488',\n",
       "  '0.03717006742954254',\n",
       "  '0.03689578175544739',\n",
       "  '0.036380864679813385',\n",
       "  '0.03668750450015068',\n",
       "  '0.036511167883872986',\n",
       "  '0.03616529330611229',\n",
       "  '0.0358094647526741',\n",
       "  '0.035910651087760925',\n",
       "  '0.03576977550983429',\n",
       "  '0.03523630648851395',\n",
       "  '0.03528541326522827',\n",
       "  '0.03503312170505524',\n",
       "  '0.03434037044644356',\n",
       "  '0.03405272960662842',\n",
       "  '0.034186575561761856',\n",
       "  '0.034115344285964966',\n",
       "  '0.033719997853040695',\n",
       "  '0.033633362501859665',\n",
       "  '0.03327028453350067',\n",
       "  '0.03376934304833412',\n",
       "  '0.03337562084197998',\n",
       "  '0.03322942182421684',\n",
       "  '0.0329010970890522',\n",
       "  '0.03256067633628845',\n",
       "  '0.03230657801032066',\n",
       "  '0.0326424203813076',\n",
       "  '0.031988855451345444',\n",
       "  '0.03182803839445114',\n",
       "  '0.03201259672641754',\n",
       "  '0.03195665776729584',\n",
       "  '0.03154204785823822',\n",
       "  '0.03181702271103859',\n",
       "  '0.031236199662089348',\n",
       "  '0.031091155484318733',\n",
       "  '0.030587730929255486',\n",
       "  '0.030694084241986275',\n",
       "  '0.030709784477949142',\n",
       "  '0.030608592554926872',\n",
       "  '0.030400224030017853',\n",
       "  '0.02995280735194683',\n",
       "  '0.029955169185996056',\n",
       "  '0.029823295772075653',\n",
       "  '0.0301505159586668',\n",
       "  '0.02998911589384079',\n",
       "  '0.029631642624735832',\n",
       "  '0.02942471019923687',\n",
       "  '0.029456211254000664',\n",
       "  '0.02926347218453884',\n",
       "  '0.029269060119986534',\n",
       "  '0.0291194599121809',\n",
       "  '0.02887488156557083',\n",
       "  '0.028933987021446228',\n",
       "  '0.02876264415681362',\n",
       "  '0.02879377081990242',\n",
       "  '0.02842693403363228',\n",
       "  '0.028267063200473785',\n",
       "  '0.028050124645233154',\n",
       "  '0.027815895155072212',\n",
       "  '0.028151940554380417',\n",
       "  '0.027655677869915962',\n",
       "  '0.027402225881814957',\n",
       "  '0.02753579244017601',\n",
       "  '0.027193043380975723',\n",
       "  '0.027035370469093323',\n",
       "  '0.02741950750350952',\n",
       "  '0.027362549677491188',\n",
       "  '0.027141286060214043',\n",
       "  '0.02684197761118412',\n",
       "  '0.026949914172291756',\n",
       "  '0.026453619822859764',\n",
       "  '0.02653789333999157',\n",
       "  '0.026512756943702698',\n",
       "  '0.02627013996243477',\n",
       "  '0.02649555914103985',\n",
       "  '0.026049574837088585',\n",
       "  '0.026223544031381607',\n",
       "  '0.026102259755134583',\n",
       "  '0.02601204253733158',\n",
       "  '0.026011519134044647',\n",
       "  '0.025400273501873016',\n",
       "  '0.025432514026761055',\n",
       "  '0.025453517213463783',\n",
       "  '0.025237347930669785',\n",
       "  '0.025057435035705566',\n",
       "  '0.025517495349049568',\n",
       "  '0.025136135518550873',\n",
       "  '0.024966491386294365',\n",
       "  '0.024614546447992325',\n",
       "  '0.024860525503754616',\n",
       "  '0.02466304786503315',\n",
       "  '0.024760419502854347',\n",
       "  '0.0244610533118248',\n",
       "  '0.024419482797384262',\n",
       "  '0.024113750085234642',\n",
       "  '0.024364639073610306',\n",
       "  '0.024472786113619804',\n",
       "  '0.024284522980451584',\n",
       "  '0.02442179247736931',\n",
       "  '0.024051785469055176',\n",
       "  '0.023845814168453217',\n",
       "  '0.0238355565816164',\n",
       "  '0.0237477645277977',\n",
       "  '0.023641664534807205',\n",
       "  '0.023671846836805344',\n",
       "  '0.02347804605960846',\n",
       "  '0.023367898538708687',\n",
       "  '0.02338794432580471',\n",
       "  '0.023331087082624435',\n",
       "  '0.023118793964385986',\n",
       "  '0.02300393208861351',\n",
       "  '0.023024188354611397',\n",
       "  '0.022737283259630203',\n",
       "  '0.022799182683229446',\n",
       "  '0.022743115201592445',\n",
       "  '0.022742096334695816',\n",
       "  '0.022695431485772133',\n",
       "  '0.022346075624227524',\n",
       "  '0.022098196670413017',\n",
       "  '0.022262483835220337',\n",
       "  '0.022295206785202026',\n",
       "  '0.022260960191488266',\n",
       "  '0.022079939022660255',\n",
       "  '0.02204226702451706',\n",
       "  '0.02181226946413517',\n",
       "  '0.02198566310107708',\n",
       "  '0.02160509303212166',\n",
       "  '0.021674975752830505',\n",
       "  '0.021771440282464027',\n",
       "  '0.021848324686288834',\n",
       "  '0.021814528852701187',\n",
       "  '0.021694783121347427',\n",
       "  '0.021509965881705284',\n",
       "  '0.02141561172902584',\n",
       "  '0.021715613082051277',\n",
       "  '0.021523291245102882',\n",
       "  '0.021186692640185356',\n",
       "  '0.021051986142992973',\n",
       "  '0.021091332659125328',\n",
       "  '0.020963270217180252',\n",
       "  '0.02101760171353817',\n",
       "  '0.020862434059381485',\n",
       "  '0.02087472938001156',\n",
       "  '0.020755549892783165',\n",
       "  '0.02076469361782074',\n",
       "  '0.020626451820135117',\n",
       "  '0.020545991137623787',\n",
       "  '0.02056698314845562',\n",
       "  '0.020442644134163857',\n",
       "  '0.020444365218281746',\n",
       "  '0.020397920161485672',\n",
       "  '0.02027166076004505',\n",
       "  '0.020236508920788765',\n",
       "  '0.020067749544978142',\n",
       "  '0.02007519267499447',\n",
       "  '0.020170187577605247',\n",
       "  '0.020037593320012093',\n",
       "  '0.019843928515911102',\n",
       "  '0.019932905212044716',\n",
       "  '0.019728975370526314',\n",
       "  '0.01984328404068947',\n",
       "  '0.019544079899787903',\n",
       "  '0.019800538197159767',\n",
       "  '0.01957654394209385',\n",
       "  '0.01961866393685341',\n",
       "  '0.01960464008152485',\n",
       "  '0.01957906037569046',\n",
       "  '0.019605927169322968',\n",
       "  '0.019392583519220352',\n",
       "  '0.019025709480047226',\n",
       "  '0.01934180222451687',\n",
       "  '0.019213715568184853',\n",
       "  '0.019065704196691513',\n",
       "  '0.01910104975104332',\n",
       "  '0.018979066982865334',\n",
       "  '0.0190699715167284',\n",
       "  '0.01899358071386814',\n",
       "  '0.018863290548324585',\n",
       "  '0.01872098445892334',\n",
       "  '0.019087815657258034',\n",
       "  '0.01901715062558651',\n",
       "  '0.01909731887280941',\n",
       "  '0.018950389698147774',\n",
       "  '0.018677333369851112',\n",
       "  '0.018390804529190063',\n",
       "  '0.01858551613986492',\n",
       "  '0.018494045361876488',\n",
       "  '0.01839270442724228',\n",
       "  '0.018283557146787643',\n",
       "  '0.01821291074156761',\n",
       "  '0.0180937759578228',\n",
       "  '0.018169986084103584',\n",
       "  '0.018149053677916527',\n",
       "  '0.01845473423600197',\n",
       "  '0.01811436004936695',\n",
       "  '0.017980244010686874',\n",
       "  '0.017887592315673828',\n",
       "  '0.018056198954582214',\n",
       "  '0.017805663868784904',\n",
       "  '0.017993444576859474',\n",
       "  '0.018040742725133896',\n",
       "  '0.01764015667140484',\n",
       "  '0.017645591869950294',\n",
       "  '0.017720764502882957',\n",
       "  '0.017698783427476883',\n",
       "  '0.017493467777967453',\n",
       "  '0.01749074086546898',\n",
       "  '0.01736176572740078'],\n",
       " 'val_true_positives': ['36183816.0',\n",
       "  '37936588.0',\n",
       "  '41406300.0',\n",
       "  '41683936.0',\n",
       "  '35156024.0',\n",
       "  '41680636.0',\n",
       "  '37713636.0',\n",
       "  '40299460.0',\n",
       "  '40856560.0',\n",
       "  '29273444.0',\n",
       "  '38216200.0',\n",
       "  '40182664.0',\n",
       "  '40642440.0',\n",
       "  '40641952.0',\n",
       "  '38347908.0',\n",
       "  '38698016.0',\n",
       "  '32733368.0',\n",
       "  '39977888.0',\n",
       "  '41107320.0',\n",
       "  '41172792.0',\n",
       "  '39136048.0',\n",
       "  '39241244.0',\n",
       "  '38890768.0',\n",
       "  '36740352.0',\n",
       "  '37801488.0',\n",
       "  '37821720.0',\n",
       "  '37086832.0',\n",
       "  '39014384.0',\n",
       "  '37052692.0',\n",
       "  '38366088.0',\n",
       "  '39681324.0',\n",
       "  '38060028.0',\n",
       "  '39732704.0',\n",
       "  '38414088.0',\n",
       "  '38579700.0',\n",
       "  '38947864.0',\n",
       "  '38503968.0',\n",
       "  '38482804.0',\n",
       "  '40462768.0',\n",
       "  '39427800.0',\n",
       "  '38001772.0',\n",
       "  '39360844.0',\n",
       "  '37971728.0',\n",
       "  '37924304.0',\n",
       "  '39619136.0',\n",
       "  '37756504.0',\n",
       "  '37948540.0',\n",
       "  '37821568.0',\n",
       "  '40772680.0',\n",
       "  '41051852.0',\n",
       "  '40166796.0',\n",
       "  '41040476.0',\n",
       "  '40312048.0',\n",
       "  '40879444.0',\n",
       "  '40666132.0',\n",
       "  '39678008.0',\n",
       "  '41016612.0',\n",
       "  '40708744.0',\n",
       "  '39882548.0',\n",
       "  '39628516.0',\n",
       "  '40253084.0',\n",
       "  '40491824.0',\n",
       "  '40954904.0',\n",
       "  '39808800.0',\n",
       "  '40447092.0',\n",
       "  '40712612.0',\n",
       "  '40217396.0',\n",
       "  '40860812.0',\n",
       "  '39670904.0',\n",
       "  '38506796.0',\n",
       "  '39406496.0',\n",
       "  '40235800.0',\n",
       "  '40849704.0',\n",
       "  '40226168.0',\n",
       "  '40072232.0',\n",
       "  '40018788.0',\n",
       "  '40259408.0',\n",
       "  '40278660.0',\n",
       "  '39402556.0',\n",
       "  '40688928.0',\n",
       "  '40246868.0',\n",
       "  '39719364.0',\n",
       "  '40250888.0',\n",
       "  '40506000.0',\n",
       "  '39770140.0',\n",
       "  '40862840.0',\n",
       "  '40770092.0',\n",
       "  '41028432.0',\n",
       "  '40361652.0',\n",
       "  '38679812.0',\n",
       "  '40575024.0',\n",
       "  '40025704.0',\n",
       "  '40716256.0',\n",
       "  '40930880.0',\n",
       "  '40427384.0',\n",
       "  '41058668.0',\n",
       "  '41139564.0',\n",
       "  '41279044.0',\n",
       "  '41300664.0',\n",
       "  '40294264.0',\n",
       "  '41027936.0',\n",
       "  '40325340.0',\n",
       "  '40633532.0',\n",
       "  '41185892.0',\n",
       "  '40614952.0',\n",
       "  '41079212.0',\n",
       "  '41081364.0',\n",
       "  '40894608.0',\n",
       "  '40869436.0',\n",
       "  '40754128.0',\n",
       "  '40106208.0',\n",
       "  '40973048.0',\n",
       "  '40229208.0',\n",
       "  '40569468.0',\n",
       "  '40472488.0',\n",
       "  '41025252.0',\n",
       "  '41145660.0',\n",
       "  '40627280.0',\n",
       "  '40754492.0',\n",
       "  '40363136.0',\n",
       "  '40702264.0',\n",
       "  '41051032.0',\n",
       "  '40808588.0',\n",
       "  '40762016.0',\n",
       "  '40147552.0',\n",
       "  '40945824.0',\n",
       "  '41400384.0',\n",
       "  '40771548.0',\n",
       "  '40488488.0',\n",
       "  '41252936.0',\n",
       "  '41255220.0',\n",
       "  '40553900.0',\n",
       "  '41166852.0',\n",
       "  '41023680.0',\n",
       "  '41166504.0',\n",
       "  '41136628.0',\n",
       "  '41474620.0',\n",
       "  '40859644.0',\n",
       "  '40966956.0',\n",
       "  '40910736.0',\n",
       "  '40817276.0',\n",
       "  '40422340.0',\n",
       "  '41271528.0',\n",
       "  '41119728.0',\n",
       "  '40949936.0',\n",
       "  '41079236.0',\n",
       "  '40950520.0',\n",
       "  '41531848.0',\n",
       "  '41062588.0',\n",
       "  '40882960.0',\n",
       "  '41133632.0',\n",
       "  '41092612.0',\n",
       "  '41235320.0',\n",
       "  '41039228.0',\n",
       "  '41211216.0',\n",
       "  '41006880.0',\n",
       "  '41227084.0',\n",
       "  '40966972.0',\n",
       "  '41319120.0',\n",
       "  '40895800.0',\n",
       "  '41203288.0',\n",
       "  '41226444.0',\n",
       "  '41235644.0',\n",
       "  '41396272.0',\n",
       "  '41291284.0',\n",
       "  '41123112.0',\n",
       "  '41067920.0',\n",
       "  '41283888.0',\n",
       "  '41252068.0',\n",
       "  '40762280.0',\n",
       "  '41445524.0',\n",
       "  '40926720.0',\n",
       "  '41257456.0',\n",
       "  '41356084.0',\n",
       "  '41034720.0',\n",
       "  '41146240.0',\n",
       "  '41243624.0',\n",
       "  '41129644.0',\n",
       "  '41575972.0',\n",
       "  '40897308.0',\n",
       "  '41343176.0',\n",
       "  '40759760.0',\n",
       "  '40993664.0',\n",
       "  '41358824.0',\n",
       "  '41212236.0',\n",
       "  '41475832.0',\n",
       "  '41202804.0',\n",
       "  '41338408.0',\n",
       "  '41301604.0',\n",
       "  '41518312.0',\n",
       "  '41542956.0',\n",
       "  '41279984.0',\n",
       "  '41459544.0',\n",
       "  '41272912.0',\n",
       "  '41207412.0',\n",
       "  '41229376.0',\n",
       "  '41125112.0',\n",
       "  '41094436.0',\n",
       "  '41570352.0',\n",
       "  '41341228.0',\n",
       "  '41462712.0',\n",
       "  '41079872.0',\n",
       "  '41441860.0',\n",
       "  '40935580.0',\n",
       "  '41257772.0',\n",
       "  '41168108.0',\n",
       "  '41142248.0',\n",
       "  '41054212.0',\n",
       "  '41383000.0',\n",
       "  '41165656.0',\n",
       "  '41371720.0',\n",
       "  '41469468.0',\n",
       "  '41056252.0',\n",
       "  '41084784.0',\n",
       "  '41016200.0',\n",
       "  '41315712.0',\n",
       "  '41136544.0',\n",
       "  '41139272.0',\n",
       "  '41304984.0',\n",
       "  '41292596.0',\n",
       "  '41584860.0',\n",
       "  '41521412.0',\n",
       "  '41021128.0',\n",
       "  '41345120.0',\n",
       "  '41138532.0',\n",
       "  '41162456.0',\n",
       "  '40936864.0',\n",
       "  '41593056.0',\n",
       "  '41104464.0',\n",
       "  '41339968.0',\n",
       "  '40936456.0',\n",
       "  '41360056.0',\n",
       "  '40983572.0',\n",
       "  '41465048.0',\n",
       "  '41126904.0',\n",
       "  '41626148.0',\n",
       "  '41374424.0',\n",
       "  '41338272.0',\n",
       "  '41323232.0',\n",
       "  '41126668.0',\n",
       "  '41180528.0',\n",
       "  '41584196.0',\n",
       "  '41275312.0',\n",
       "  '41378220.0',\n",
       "  '41293516.0',\n",
       "  '41122408.0',\n",
       "  '41409512.0',\n",
       "  '41618788.0',\n",
       "  '41291124.0',\n",
       "  '41440504.0',\n",
       "  '41543104.0',\n",
       "  '41517344.0',\n",
       "  '41217736.0',\n",
       "  '41430336.0',\n",
       "  '41490552.0',\n",
       "  '41205800.0',\n",
       "  '41547612.0',\n",
       "  '41584316.0',\n",
       "  '41237916.0',\n",
       "  '41422060.0',\n",
       "  '41495024.0',\n",
       "  '41569632.0',\n",
       "  '41405056.0',\n",
       "  '41437632.0',\n",
       "  '41622512.0',\n",
       "  '41516388.0',\n",
       "  '41306892.0',\n",
       "  '41508476.0',\n",
       "  '41179000.0',\n",
       "  '41454112.0',\n",
       "  '41003172.0',\n",
       "  '41424740.0',\n",
       "  '41122468.0',\n",
       "  '41592052.0',\n",
       "  '41591380.0',\n",
       "  '41489672.0',\n",
       "  '41553100.0',\n",
       "  '41410120.0',\n",
       "  '41400224.0',\n",
       "  '41325852.0',\n",
       "  '41544864.0',\n",
       "  '41336620.0',\n",
       "  '41468872.0',\n",
       "  '41359216.0',\n",
       "  '41421144.0',\n",
       "  '41527412.0',\n",
       "  '41406008.0',\n",
       "  '41202840.0',\n",
       "  '41381116.0',\n",
       "  '41330056.0',\n",
       "  '41502376.0',\n",
       "  '41407480.0',\n",
       "  '41416184.0',\n",
       "  '41711576.0',\n",
       "  '41461224.0',\n",
       "  '41311176.0',\n",
       "  '41341124.0',\n",
       "  '41475908.0',\n",
       "  '41481992.0',\n",
       "  '41601732.0',\n",
       "  '41609896.0'],\n",
       " 'accuracy': ['0.7866721749305725',\n",
       "  '0.8502960205078125',\n",
       "  '0.8586176633834839',\n",
       "  '0.8675968050956726',\n",
       "  '0.8729592561721802',\n",
       "  '0.8784143328666687',\n",
       "  '0.8810575008392334',\n",
       "  '0.8848918080329895',\n",
       "  '0.8892213702201843',\n",
       "  '0.893817663192749',\n",
       "  '0.8952571153640747',\n",
       "  '0.8994724750518799',\n",
       "  '0.9008952975273132',\n",
       "  '0.9026272892951965',\n",
       "  '0.9039813876152039',\n",
       "  '0.9077730774879456',\n",
       "  '0.9087814092636108',\n",
       "  '0.9101096987724304',\n",
       "  '0.9099255800247192',\n",
       "  '0.9130255579948425',\n",
       "  '0.9101842641830444',\n",
       "  '0.9188379645347595',\n",
       "  '0.9243528842926025',\n",
       "  '0.9277404546737671',\n",
       "  '0.9315019249916077',\n",
       "  '0.9339674115180969',\n",
       "  '0.9358965754508972',\n",
       "  '0.9368982911109924',\n",
       "  '0.9389329552650452',\n",
       "  '0.9408616423606873',\n",
       "  '0.9426844716072083',\n",
       "  '0.9437398314476013',\n",
       "  '0.9446602463722229',\n",
       "  '0.9458666443824768',\n",
       "  '0.9467413425445557',\n",
       "  '0.9479352235794067',\n",
       "  '0.9486230611801147',\n",
       "  '0.9498308897018433',\n",
       "  '0.9503896236419678',\n",
       "  '0.9512351751327515',\n",
       "  '0.952052891254425',\n",
       "  '0.9522713422775269',\n",
       "  '0.9529857635498047',\n",
       "  '0.954078733921051',\n",
       "  '0.9538822174072266',\n",
       "  '0.9553405046463013',\n",
       "  '0.9556058049201965',\n",
       "  '0.9561804533004761',\n",
       "  '0.9569474458694458',\n",
       "  '0.9571662545204163',\n",
       "  '0.9569679498672485',\n",
       "  '0.9580029249191284',\n",
       "  '0.9590557813644409',\n",
       "  '0.9587987065315247',\n",
       "  '0.9593325853347778',\n",
       "  '0.9595559239387512',\n",
       "  '0.9597237706184387',\n",
       "  '0.9604030847549438',\n",
       "  '0.9608437418937683',\n",
       "  '0.9617250561714172',\n",
       "  '0.9612649083137512',\n",
       "  '0.961783766746521',\n",
       "  '0.9624940156936646',\n",
       "  '0.9630106091499329',\n",
       "  '0.9633328914642334',\n",
       "  '0.9634300470352173',\n",
       "  '0.9635903835296631',\n",
       "  '0.9638897180557251',\n",
       "  '0.9641643166542053',\n",
       "  '0.9643999934196472',\n",
       "  '0.9648113250732422',\n",
       "  '0.9650158882141113',\n",
       "  '0.9652544856071472',\n",
       "  '0.9651066660881042',\n",
       "  '0.9655526280403137',\n",
       "  '0.9660382270812988',\n",
       "  '0.9663198590278625',\n",
       "  '0.9664940237998962',\n",
       "  '0.9670131802558899',\n",
       "  '0.966839611530304',\n",
       "  '0.9673075675964355',\n",
       "  '0.9671878814697266',\n",
       "  '0.9674212336540222',\n",
       "  '0.9676727652549744',\n",
       "  '0.9681555032730103',\n",
       "  '0.9682132005691528',\n",
       "  '0.9685147404670715',\n",
       "  '0.9689568877220154',\n",
       "  '0.9686740636825562',\n",
       "  '0.969086229801178',\n",
       "  '0.9695460796356201',\n",
       "  '0.9696651697158813',\n",
       "  '0.9696887135505676',\n",
       "  '0.9700053930282593',\n",
       "  '0.9699566960334778',\n",
       "  '0.9701620936393738',\n",
       "  '0.9705491065979004',\n",
       "  '0.9703913331031799',\n",
       "  '0.9706234335899353',\n",
       "  '0.9706999063491821',\n",
       "  '0.9709877371788025',\n",
       "  '0.9710717797279358',\n",
       "  '0.9711788296699524',\n",
       "  '0.9714871048927307',\n",
       "  '0.9715031981468201',\n",
       "  '0.9716389179229736',\n",
       "  '0.97220778465271',\n",
       "  '0.9724256992340088',\n",
       "  '0.9724870920181274',\n",
       "  '0.9723404049873352',\n",
       "  '0.9727097153663635',\n",
       "  '0.97285395860672',\n",
       "  '0.9731056094169617',\n",
       "  '0.9727044105529785',\n",
       "  '0.9730615615844727',\n",
       "  '0.9731366634368896',\n",
       "  '0.9733731150627136',\n",
       "  '0.9736427068710327',\n",
       "  '0.9738155603408813',\n",
       "  '0.9736412167549133',\n",
       "  '0.9741281270980835',\n",
       "  '0.974296510219574',\n",
       "  '0.9742044806480408',\n",
       "  '0.9741623997688293',\n",
       "  '0.9744873046875',\n",
       "  '0.9743252396583557',\n",
       "  '0.9747347831726074',\n",
       "  '0.9748795032501221',\n",
       "  '0.9752750992774963',\n",
       "  '0.9752578735351562',\n",
       "  '0.9752590656280518',\n",
       "  '0.9752612709999084',\n",
       "  '0.9754300117492676',\n",
       "  '0.975700318813324',\n",
       "  '0.9757744073867798',\n",
       "  '0.975810170173645',\n",
       "  '0.9756794571876526',\n",
       "  '0.9758206605911255',\n",
       "  '0.9759688973426819',\n",
       "  '0.9762064814567566',\n",
       "  '0.9762402176856995',\n",
       "  '0.9763335585594177',\n",
       "  '0.9763255715370178',\n",
       "  '0.9764530062675476',\n",
       "  '0.9765798449516296',\n",
       "  '0.9766028523445129',\n",
       "  '0.9767524600028992',\n",
       "  '0.9767316579818726',\n",
       "  '0.976987361907959',\n",
       "  '0.9771389365196228',\n",
       "  '0.9773113131523132',\n",
       "  '0.9774660468101501',\n",
       "  '0.9772643446922302',\n",
       "  '0.977583110332489',\n",
       "  '0.9778372049331665',\n",
       "  '0.977791965007782',\n",
       "  '0.9780105948448181',\n",
       "  '0.9780532121658325',\n",
       "  '0.9778478145599365',\n",
       "  '0.9778573513031006',\n",
       "  '0.9780583381652832',\n",
       "  '0.9782520532608032',\n",
       "  '0.978206992149353',\n",
       "  '0.9785961508750916',\n",
       "  '0.9785886406898499',\n",
       "  '0.9785885214805603',\n",
       "  '0.9787567853927612',\n",
       "  '0.9785975217819214',\n",
       "  '0.9789280295372009',\n",
       "  '0.9787497520446777',\n",
       "  '0.9788649678230286',\n",
       "  '0.9789945483207703',\n",
       "  '0.9789864420890808',\n",
       "  '0.9794509410858154',\n",
       "  '0.9794080853462219',\n",
       "  '0.9794222116470337',\n",
       "  '0.9796169996261597',\n",
       "  '0.9797673225402832',\n",
       "  '0.97940593957901',\n",
       "  '0.9796585440635681',\n",
       "  '0.9798025488853455',\n",
       "  '0.9800949096679688',\n",
       "  '0.9799081087112427',\n",
       "  '0.9800771474838257',\n",
       "  '0.9800007343292236',\n",
       "  '0.9802155494689941',\n",
       "  '0.9802635312080383',\n",
       "  '0.9804631471633911',\n",
       "  '0.9802547097206116',\n",
       "  '0.980192244052887',\n",
       "  '0.9802829623222351',\n",
       "  '0.9802334904670715',\n",
       "  '0.9805155992507935',\n",
       "  '0.9806979894638062',\n",
       "  '0.9807311296463013',\n",
       "  '0.9808405041694641',\n",
       "  '0.9808690547943115',\n",
       "  '0.980857253074646',\n",
       "  '0.9810439944267273',\n",
       "  '0.9810562133789062',\n",
       "  '0.9810981750488281',\n",
       "  '0.9811225533485413',\n",
       "  '0.9813528656959534',\n",
       "  '0.9814172983169556',\n",
       "  '0.9813969135284424',\n",
       "  '0.9815321564674377',\n",
       "  '0.9815422296524048',\n",
       "  '0.9815832376480103',\n",
       "  '0.9815673828125',\n",
       "  '0.9816599488258362',\n",
       "  '0.9818724393844604',\n",
       "  '0.9820517301559448',\n",
       "  '0.9819785952568054',\n",
       "  '0.9819213151931763',\n",
       "  '0.9820252060890198',\n",
       "  '0.9821434617042542',\n",
       "  '0.9821696877479553',\n",
       "  '0.9823258519172668',\n",
       "  '0.9822579026222229',\n",
       "  '0.9824756383895874',\n",
       "  '0.9824650287628174',\n",
       "  '0.9825031161308289',\n",
       "  '0.9823139309883118',\n",
       "  '0.9823747873306274',\n",
       "  '0.9824464321136475',\n",
       "  '0.9825255274772644',\n",
       "  '0.9826576113700867',\n",
       "  '0.9824960827827454',\n",
       "  '0.9825716018676758',\n",
       "  '0.9828890562057495',\n",
       "  '0.9829562902450562',\n",
       "  '0.9829095005989075',\n",
       "  '0.983012855052948',\n",
       "  '0.9830217957496643',\n",
       "  '0.9831798076629639',\n",
       "  '0.9830976128578186',\n",
       "  '0.9832297563552856',\n",
       "  '0.9831690788269043',\n",
       "  '0.9833117127418518',\n",
       "  '0.9833559989929199',\n",
       "  '0.9833694100379944',\n",
       "  '0.9834769368171692',\n",
       "  '0.9834538102149963',\n",
       "  '0.98353111743927',\n",
       "  '0.9836212992668152',\n",
       "  '0.983661949634552',\n",
       "  '0.9837870001792908',\n",
       "  '0.9836908578872681',\n",
       "  '0.9837017059326172',\n",
       "  '0.9837964177131653',\n",
       "  '0.9839473366737366',\n",
       "  '0.9838942885398865',\n",
       "  '0.9840072393417358',\n",
       "  '0.9839548468589783',\n",
       "  '0.9841625690460205',\n",
       "  '0.9840300679206848',\n",
       "  '0.9841405749320984',\n",
       "  '0.9841382503509521',\n",
       "  '0.9841493368148804',\n",
       "  '0.984136164188385',\n",
       "  '0.9841880202293396',\n",
       "  '0.9843336343765259',\n",
       "  '0.9845798015594482',\n",
       "  '0.9844028353691101',\n",
       "  '0.9844589233398438',\n",
       "  '0.9845772981643677',\n",
       "  '0.9845120906829834',\n",
       "  '0.9846457242965698',\n",
       "  '0.9845951199531555',\n",
       "  '0.9846413731575012',\n",
       "  '0.9847368597984314',\n",
       "  '0.9848296642303467',\n",
       "  '0.9845450520515442',\n",
       "  '0.984631359577179',\n",
       "  '0.9845625758171082',\n",
       "  '0.9846891760826111',\n",
       "  '0.9849144220352173',\n",
       "  '0.985074520111084',\n",
       "  '0.9849773049354553',\n",
       "  '0.9850347638130188',\n",
       "  '0.9850997924804688',\n",
       "  '0.985178530216217',\n",
       "  '0.9853072166442871',\n",
       "  '0.9853448271751404',\n",
       "  '0.9852765798568726',\n",
       "  '0.9853355288505554',\n",
       "  '0.9851157069206238',\n",
       "  '0.9853466749191284',\n",
       "  '0.985466718673706',\n",
       "  '0.9854965806007385',\n",
       "  '0.9854538440704346',\n",
       "  '0.9856242537498474',\n",
       "  '0.9854425191879272',\n",
       "  '0.9854223728179932',\n",
       "  '0.9856945872306824',\n",
       "  '0.9857537746429443',\n",
       "  '0.9856598973274231',\n",
       "  '0.9856796264648438',\n",
       "  '0.9858578443527222',\n",
       "  '0.9858441948890686',\n",
       "  '0.9859217405319214'],\n",
       " 'recall': ['0.8480232357978821',\n",
       "  '0.847775399684906',\n",
       "  '0.8578135967254639',\n",
       "  '0.8617630004882812',\n",
       "  '0.8632954359054565',\n",
       "  '0.869721531867981',\n",
       "  '0.8723866939544678',\n",
       "  '0.8771916627883911',\n",
       "  '0.8746753334999084',\n",
       "  '0.8813313245773315',\n",
       "  '0.8827481865882874',\n",
       "  '0.8849422335624695',\n",
       "  '0.8890397548675537',\n",
       "  '0.8896090984344482',\n",
       "  '0.8916603922843933',\n",
       "  '0.8935556411743164',\n",
       "  '0.8955627679824829',\n",
       "  '0.8950188159942627',\n",
       "  '0.8946918249130249',\n",
       "  '0.8983373641967773',\n",
       "  '0.8949553370475769',\n",
       "  '0.9050225019454956',\n",
       "  '0.9098093509674072',\n",
       "  '0.9138765335083008',\n",
       "  '0.9183986186981201',\n",
       "  '0.9206288456916809',\n",
       "  '0.9223816394805908',\n",
       "  '0.9231461882591248',\n",
       "  '0.9256098866462708',\n",
       "  '0.9279149770736694',\n",
       "  '0.9294142127037048',\n",
       "  '0.9307874441146851',\n",
       "  '0.9318816065788269',\n",
       "  '0.9328294992446899',\n",
       "  '0.93453449010849',\n",
       "  '0.935748279094696',\n",
       "  '0.9365903735160828',\n",
       "  '0.9382877349853516',\n",
       "  '0.939081072807312',\n",
       "  '0.9397986531257629',\n",
       "  '0.9411449432373047',\n",
       "  '0.9413038492202759',\n",
       "  '0.9411420822143555',\n",
       "  '0.9429518580436707',\n",
       "  '0.9432936310768127',\n",
       "  '0.9443961381912231',\n",
       "  '0.9454336166381836',\n",
       "  '0.9460331797599792',\n",
       "  '0.9466171860694885',\n",
       "  '0.9466803669929504',\n",
       "  '0.9470500349998474',\n",
       "  '0.9484767317771912',\n",
       "  '0.949652910232544',\n",
       "  '0.9493446350097656',\n",
       "  '0.9497860074043274',\n",
       "  '0.9500853419303894',\n",
       "  '0.9500697255134583',\n",
       "  '0.9511996507644653',\n",
       "  '0.9516183733940125',\n",
       "  '0.9525389075279236',\n",
       "  '0.952553391456604',\n",
       "  '0.9530709981918335',\n",
       "  '0.9538722634315491',\n",
       "  '0.9545135498046875',\n",
       "  '0.9548915028572083',\n",
       "  '0.955052375793457',\n",
       "  '0.9549404978752136',\n",
       "  '0.9554666876792908',\n",
       "  '0.9556812644004822',\n",
       "  '0.9564850330352783',\n",
       "  '0.9564670324325562',\n",
       "  '0.956805408000946',\n",
       "  '0.9570174217224121',\n",
       "  '0.9565423130989075',\n",
       "  '0.9580205678939819',\n",
       "  '0.9581351280212402',\n",
       "  '0.9586223363876343',\n",
       "  '0.9588302373886108',\n",
       "  '0.9591415524482727',\n",
       "  '0.9589893817901611',\n",
       "  '0.9596066474914551',\n",
       "  '0.9598596692085266',\n",
       "  '0.9599018692970276',\n",
       "  '0.9604947566986084',\n",
       "  '0.9606603384017944',\n",
       "  '0.9610061049461365',\n",
       "  '0.9612671732902527',\n",
       "  '0.9620633125305176',\n",
       "  '0.9614412784576416',\n",
       "  '0.9620071649551392',\n",
       "  '0.9623833298683167',\n",
       "  '0.9625878930091858',\n",
       "  '0.9627233743667603',\n",
       "  '0.9630999565124512',\n",
       "  '0.9632080793380737',\n",
       "  '0.9637092351913452',\n",
       "  '0.963624119758606',\n",
       "  '0.9634964466094971',\n",
       "  '0.963744580745697',\n",
       "  '0.9643527865409851',\n",
       "  '0.9646713137626648',\n",
       "  '0.9643818736076355',\n",
       "  '0.964514434337616',\n",
       "  '0.9650144577026367',\n",
       "  '0.9649425745010376',\n",
       "  '0.9650852084159851',\n",
       "  '0.9662312269210815',\n",
       "  '0.9665544629096985',\n",
       "  '0.9661432504653931',\n",
       "  '0.9662235379219055',\n",
       "  '0.9664601683616638',\n",
       "  '0.9668197631835938',\n",
       "  '0.9673227667808533',\n",
       "  '0.9663830399513245',\n",
       "  '0.9669689536094666',\n",
       "  '0.9672753810882568',\n",
       "  '0.9671475887298584',\n",
       "  '0.9678800702095032',\n",
       "  '0.9678419232368469',\n",
       "  '0.9675348401069641',\n",
       "  '0.9684235453605652',\n",
       "  '0.9684708714485168',\n",
       "  '0.9684972763061523',\n",
       "  '0.9683099985122681',\n",
       "  '0.9687960743904114',\n",
       "  '0.9681534171104431',\n",
       "  '0.9688442945480347',\n",
       "  '0.9697126746177673',\n",
       "  '0.9697063565254211',\n",
       "  '0.9696900844573975',\n",
       "  '0.9696504473686218',\n",
       "  '0.9698919653892517',\n",
       "  '0.9699622988700867',\n",
       "  '0.97027987241745',\n",
       "  '0.9703974723815918',\n",
       "  '0.9704146385192871',\n",
       "  '0.9703308939933777',\n",
       "  '0.9703838229179382',\n",
       "  '0.9706404805183411',\n",
       "  '0.9709135890007019',\n",
       "  '0.970840573310852',\n",
       "  '0.9710018634796143',\n",
       "  '0.971220076084137',\n",
       "  '0.9711870551109314',\n",
       "  '0.9713342785835266',\n",
       "  '0.9715588688850403',\n",
       "  '0.9715358018875122',\n",
       "  '0.9715413451194763',\n",
       "  '0.9719045162200928',\n",
       "  '0.9720543026924133',\n",
       "  '0.972376823425293',\n",
       "  '0.972361147403717',\n",
       "  '0.9725518822669983',\n",
       "  '0.9727566242218018',\n",
       "  '0.9729651808738708',\n",
       "  '0.9731165170669556',\n",
       "  '0.9732797741889954',\n",
       "  '0.9733828902244568',\n",
       "  '0.9727092385292053',\n",
       "  '0.9729092121124268',\n",
       "  '0.9732610583305359',\n",
       "  '0.9734901189804077',\n",
       "  '0.9732670783996582',\n",
       "  '0.9738123416900635',\n",
       "  '0.9739181399345398',\n",
       "  '0.9737699627876282',\n",
       "  '0.9742390513420105',\n",
       "  '0.9739130139350891',\n",
       "  '0.974208414554596',\n",
       "  '0.9740850925445557',\n",
       "  '0.974004864692688',\n",
       "  '0.9746434092521667',\n",
       "  '0.9744377732276917',\n",
       "  '0.9749665260314941',\n",
       "  '0.9747819304466248',\n",
       "  '0.9750550985336304',\n",
       "  '0.9749324917793274',\n",
       "  '0.9754772782325745',\n",
       "  '0.9749469757080078',\n",
       "  '0.9752779006958008',\n",
       "  '0.9752854704856873',\n",
       "  '0.9759088754653931',\n",
       "  '0.975562334060669',\n",
       "  '0.9755879044532776',\n",
       "  '0.9756020307540894',\n",
       "  '0.9758456349372864',\n",
       "  '0.9760231971740723',\n",
       "  '0.9762130975723267',\n",
       "  '0.9758912324905396',\n",
       "  '0.9757624864578247',\n",
       "  '0.9759297370910645',\n",
       "  '0.9759405851364136',\n",
       "  '0.9760869741439819',\n",
       "  '0.9764476418495178',\n",
       "  '0.97653728723526',\n",
       "  '0.9765815734863281',\n",
       "  '0.9766469597816467',\n",
       "  '0.9766473770141602',\n",
       "  '0.9769013524055481',\n",
       "  '0.9770299196243286',\n",
       "  '0.9768857359886169',\n",
       "  '0.9770361185073853',\n",
       "  '0.9773139953613281',\n",
       "  '0.9773882031440735',\n",
       "  '0.9773252606391907',\n",
       "  '0.9774702787399292',\n",
       "  '0.9773671627044678',\n",
       "  '0.9776062369346619',\n",
       "  '0.9773558378219604',\n",
       "  '0.9777112603187561',\n",
       "  '0.9778733849525452',\n",
       "  '0.9781539440155029',\n",
       "  '0.9779683351516724',\n",
       "  '0.9779237508773804',\n",
       "  '0.9781017303466797',\n",
       "  '0.9783942699432373',\n",
       "  '0.97830730676651',\n",
       "  '0.9782145619392395',\n",
       "  '0.9782965779304504',\n",
       "  '0.9787717461585999',\n",
       "  '0.9786435961723328',\n",
       "  '0.9787206649780273',\n",
       "  '0.9783605933189392',\n",
       "  '0.9787992238998413',\n",
       "  '0.9785803556442261',\n",
       "  '0.9786709547042847',\n",
       "  '0.9789227843284607',\n",
       "  '0.9785611033439636',\n",
       "  '0.9788163304328918',\n",
       "  '0.9791402816772461',\n",
       "  '0.9793158769607544',\n",
       "  '0.9792325496673584',\n",
       "  '0.9793412089347839',\n",
       "  '0.9791959524154663',\n",
       "  '0.9796527624130249',\n",
       "  '0.9794673919677734',\n",
       "  '0.9795846343040466',\n",
       "  '0.97945237159729',\n",
       "  '0.9797654151916504',\n",
       "  '0.9798160195350647',\n",
       "  '0.9796754717826843',\n",
       "  '0.9799999594688416',\n",
       "  '0.9799549579620361',\n",
       "  '0.9799131155014038',\n",
       "  '0.980067253112793',\n",
       "  '0.9801781177520752',\n",
       "  '0.980313241481781',\n",
       "  '0.9801694750785828',\n",
       "  '0.9800967574119568',\n",
       "  '0.9802554845809937',\n",
       "  '0.9804967641830444',\n",
       "  '0.9804653525352478',\n",
       "  '0.9804641604423523',\n",
       "  '0.980391263961792',\n",
       "  '0.9807659983634949',\n",
       "  '0.9804145693778992',\n",
       "  '0.9806599617004395',\n",
       "  '0.9807291030883789',\n",
       "  '0.9807859063148499',\n",
       "  '0.9806069731712341',\n",
       "  '0.9809174537658691',\n",
       "  '0.9808027148246765',\n",
       "  '0.9812811613082886',\n",
       "  '0.9810635447502136',\n",
       "  '0.9811011552810669',\n",
       "  '0.981227457523346',\n",
       "  '0.9811840057373047',\n",
       "  '0.9813412427902222',\n",
       "  '0.9812755584716797',\n",
       "  '0.981234073638916',\n",
       "  '0.9815212488174438',\n",
       "  '0.9815114140510559',\n",
       "  '0.9811882376670837',\n",
       "  '0.9813189506530762',\n",
       "  '0.9811803102493286',\n",
       "  '0.981515109539032',\n",
       "  '0.9816917181015015',\n",
       "  '0.98188716173172',\n",
       "  '0.9818477630615234',\n",
       "  '0.9817715287208557',\n",
       "  '0.9818201661109924',\n",
       "  '0.9818913340568542',\n",
       "  '0.9820648431777954',\n",
       "  '0.9822453856468201',\n",
       "  '0.9820848107337952',\n",
       "  '0.9822863936424255',\n",
       "  '0.9818407893180847',\n",
       "  '0.981988251209259',\n",
       "  '0.9823799133300781',\n",
       "  '0.9823445677757263',\n",
       "  '0.9823166131973267',\n",
       "  '0.9825076460838318',\n",
       "  '0.9823046922683716',\n",
       "  '0.9822025299072266',\n",
       "  '0.9827539324760437',\n",
       "  '0.9827147722244263',\n",
       "  '0.9824684262275696',\n",
       "  '0.9826821088790894',\n",
       "  '0.9828414916992188',\n",
       "  '0.982774555683136',\n",
       "  '0.982894241809845'],\n",
       " 'val_precision': ['0.7874231934547424',\n",
       "  '0.8138229250907898',\n",
       "  '0.7621813416481018',\n",
       "  '0.7381817698478699',\n",
       "  '0.8102497458457947',\n",
       "  '0.760809063911438',\n",
       "  '0.8338178992271423',\n",
       "  '0.8400853872299194',\n",
       "  '0.7931394577026367',\n",
       "  '0.8806698322296143',\n",
       "  '0.8959943652153015',\n",
       "  '0.8374407887458801',\n",
       "  '0.8222880363464355',\n",
       "  '0.7730011343955994',\n",
       "  '0.8276327252388',\n",
       "  '0.7940225005149841',\n",
       "  '0.8450588583946228',\n",
       "  '0.8560177683830261',\n",
       "  '0.8418807983398438',\n",
       "  '0.7894446849822998',\n",
       "  '0.8303572535514832',\n",
       "  '0.8069406151771545',\n",
       "  '0.823934018611908',\n",
       "  '0.810949981212616',\n",
       "  '0.8222579956054688',\n",
       "  '0.8281923532485962',\n",
       "  '0.8434613347053528',\n",
       "  '0.8223027586936951',\n",
       "  '0.8353883028030396',\n",
       "  '0.8560434579849243',\n",
       "  '0.8407678008079529',\n",
       "  '0.838373601436615',\n",
       "  '0.8360171914100647',\n",
       "  '0.8356646299362183',\n",
       "  '0.8377354145050049',\n",
       "  '0.8530737161636353',\n",
       "  '0.8463459014892578',\n",
       "  '0.8440302610397339',\n",
       "  '0.834859311580658',\n",
       "  '0.8399825692176819',\n",
       "  '0.859987735748291',\n",
       "  '0.8222146034240723',\n",
       "  '0.8304590582847595',\n",
       "  '0.84321129322052',\n",
       "  '0.8581787347793579',\n",
       "  '0.8592929244041443',\n",
       "  '0.8519402742385864',\n",
       "  '0.8629058003425598',\n",
       "  '0.8177030086517334',\n",
       "  '0.8509802222251892',\n",
       "  '0.8346849083900452',\n",
       "  '0.8322837352752686',\n",
       "  '0.8464384078979492',\n",
       "  '0.8512217402458191',\n",
       "  '0.8488503694534302',\n",
       "  '0.8358990550041199',\n",
       "  '0.8369483947753906',\n",
       "  '0.8522136211395264',\n",
       "  '0.8390496969223022',\n",
       "  '0.8395962119102478',\n",
       "  '0.8494680523872375',\n",
       "  '0.8600760698318481',\n",
       "  '0.8411096930503845',\n",
       "  '0.8566482663154602',\n",
       "  '0.8579612374305725',\n",
       "  '0.8525637984275818',\n",
       "  '0.856255054473877',\n",
       "  '0.8480646014213562',\n",
       "  '0.8444698452949524',\n",
       "  '0.8557045459747314',\n",
       "  '0.858907163143158',\n",
       "  '0.8491640090942383',\n",
       "  '0.8475150465965271',\n",
       "  '0.8601349592208862',\n",
       "  '0.8435642719268799',\n",
       "  '0.8538804650306702',\n",
       "  '0.8505116701126099',\n",
       "  '0.8468167185783386',\n",
       "  '0.8551960587501526',\n",
       "  '0.8594275712966919',\n",
       "  '0.8735203742980957',\n",
       "  '0.8602204322814941',\n",
       "  '0.8574104905128479',\n",
       "  '0.8551090955734253',\n",
       "  '0.8532946705818176',\n",
       "  '0.860798180103302',\n",
       "  '0.8622695207595825',\n",
       "  '0.8621116876602173',\n",
       "  '0.8568076491355896',\n",
       "  '0.8605466485023499',\n",
       "  '0.8499211072921753',\n",
       "  '0.8389530181884766',\n",
       "  '0.8490774631500244',\n",
       "  '0.8498497009277344',\n",
       "  '0.8649868965148926',\n",
       "  '0.8540266752243042',\n",
       "  '0.856681227684021',\n",
       "  '0.8436446785926819',\n",
       "  '0.8534217476844788',\n",
       "  '0.8672279119491577',\n",
       "  '0.8510258793830872',\n",
       "  '0.8577401041984558',\n",
       "  '0.8713313341140747',\n",
       "  '0.853448212146759',\n",
       "  '0.86921226978302',\n",
       "  '0.8540015816688538',\n",
       "  '0.8531354069709778',\n",
       "  '0.862721860408783',\n",
       "  '0.8543132543563843',\n",
       "  '0.8563941121101379',\n",
       "  '0.8644694089889526',\n",
       "  '0.8480607867240906',\n",
       "  '0.8645608425140381',\n",
       "  '0.8648692965507507',\n",
       "  '0.864260196685791',\n",
       "  '0.8563045859336853',\n",
       "  '0.8537273406982422',\n",
       "  '0.8557164072990417',\n",
       "  '0.8670462369918823',\n",
       "  '0.8645850419998169',\n",
       "  '0.8624565601348877',\n",
       "  '0.8629426956176758',\n",
       "  '0.8631753325462341',\n",
       "  '0.8690199255943298',\n",
       "  '0.8699934482574463',\n",
       "  '0.85439532995224',\n",
       "  '0.8508211970329285',\n",
       "  '0.8636764287948608',\n",
       "  '0.8676020503044128',\n",
       "  '0.8538543581962585',\n",
       "  '0.8486675024032593',\n",
       "  '0.8710271716117859',\n",
       "  '0.8576659560203552',\n",
       "  '0.8623365759849548',\n",
       "  '0.8606757521629333',\n",
       "  '0.8533975481987',\n",
       "  '0.8522714972496033',\n",
       "  '0.8608487844467163',\n",
       "  '0.8545418977737427',\n",
       "  '0.8581400513648987',\n",
       "  '0.8638548851013184',\n",
       "  '0.8672274947166443',\n",
       "  '0.8578158617019653',\n",
       "  '0.8613753318786621',\n",
       "  '0.8657098412513733',\n",
       "  '0.8591985702514648',\n",
       "  '0.8637909889221191',\n",
       "  '0.8515849709510803',\n",
       "  '0.8532224297523499',\n",
       "  '0.8642480373382568',\n",
       "  '0.8612568974494934',\n",
       "  '0.8617430329322815',\n",
       "  '0.8578704595565796',\n",
       "  '0.8610738515853882',\n",
       "  '0.8574317097663879',\n",
       "  '0.8598161339759827',\n",
       "  '0.8612191677093506',\n",
       "  '0.8656994700431824',\n",
       "  '0.8536537885665894',\n",
       "  '0.8622539043426514',\n",
       "  '0.8602583408355713',\n",
       "  '0.8540372252464294',\n",
       "  '0.8500890731811523',\n",
       "  '0.8551701307296753',\n",
       "  '0.8596542477607727',\n",
       "  '0.8542959094047546',\n",
       "  '0.8519100546836853',\n",
       "  '0.8545001149177551',\n",
       "  '0.8602379560470581',\n",
       "  '0.8591472506523132',\n",
       "  '0.8574047684669495',\n",
       "  '0.8687208294868469',\n",
       "  '0.858738124370575',\n",
       "  '0.861923336982727',\n",
       "  '0.8609464168548584',\n",
       "  '0.8599365949630737',\n",
       "  '0.8550654053688049',\n",
       "  '0.8616712689399719',\n",
       "  '0.8511452674865723',\n",
       "  '0.8627995848655701',\n",
       "  '0.8566126227378845',\n",
       "  '0.8652709722518921',\n",
       "  '0.8562260270118713',\n",
       "  '0.853956937789917',\n",
       "  '0.8625747561454773',\n",
       "  '0.8545933365821838',\n",
       "  '0.8609884977340698',\n",
       "  '0.8627636432647705',\n",
       "  '0.8577159643173218',\n",
       "  '0.8493304252624512',\n",
       "  '0.8452612161636353',\n",
       "  '0.8600041270256042',\n",
       "  '0.8586224913597107',\n",
       "  '0.862769365310669',\n",
       "  '0.8614535331726074',\n",
       "  '0.8553627133369446',\n",
       "  '0.8627214431762695',\n",
       "  '0.8567453026771545',\n",
       "  '0.8542979955673218',\n",
       "  '0.8537968993186951',\n",
       "  '0.8512887358665466',\n",
       "  '0.857692301273346',\n",
       "  '0.8572750687599182',\n",
       "  '0.8710871338844299',\n",
       "  '0.863121509552002',\n",
       "  '0.8668715357780457',\n",
       "  '0.859123170375824',\n",
       "  '0.8654905557632446',\n",
       "  '0.8544473052024841',\n",
       "  '0.8602239489555359',\n",
       "  '0.8579937815666199',\n",
       "  '0.8568603992462158',\n",
       "  '0.8666894435882568',\n",
       "  '0.8640410900115967',\n",
       "  '0.8648772835731506',\n",
       "  '0.8499657511711121',\n",
       "  '0.860297441482544',\n",
       "  '0.8578135967254639',\n",
       "  '0.8586434125900269',\n",
       "  '0.8571221232414246',\n",
       "  '0.8534910678863525',\n",
       "  '0.8595572710037231',\n",
       "  '0.8587220311164856',\n",
       "  '0.8574035167694092',\n",
       "  '0.8610618710517883',\n",
       "  '0.8665825724601746',\n",
       "  '0.8623878955841064',\n",
       "  '0.8446977138519287',\n",
       "  '0.8625528216362',\n",
       "  '0.853769838809967',\n",
       "  '0.8633192777633667',\n",
       "  '0.857243001461029',\n",
       "  '0.8709388971328735',\n",
       "  '0.8583800196647644',\n",
       "  '0.86849445104599',\n",
       "  '0.8544626235961914',\n",
       "  '0.8529265522956848',\n",
       "  '0.8614640831947327',\n",
       "  '0.8611405491828918',\n",
       "  '0.8651009202003479',\n",
       "  '0.8613065481185913',\n",
       "  '0.8524355292320251',\n",
       "  '0.8566727042198181',\n",
       "  '0.8595413565635681',\n",
       "  '0.8612768650054932',\n",
       "  '0.8635126948356628',\n",
       "  '0.8614793419837952',\n",
       "  '0.8569074273109436',\n",
       "  '0.8582406044006348',\n",
       "  '0.8556919693946838',\n",
       "  '0.8587942123413086',\n",
       "  '0.8583008646965027',\n",
       "  '0.8669394254684448',\n",
       "  '0.8598988056182861',\n",
       "  '0.8582292795181274',\n",
       "  '0.860912561416626',\n",
       "  '0.8584278225898743',\n",
       "  '0.8585900068283081',\n",
       "  '0.8636176586151123',\n",
       "  '0.8619824051856995',\n",
       "  '0.858945906162262',\n",
       "  '0.8611108064651489',\n",
       "  '0.8586367964744568',\n",
       "  '0.8593950271606445',\n",
       "  '0.8595774173736572',\n",
       "  '0.8585100173950195',\n",
       "  '0.8653028011322021',\n",
       "  '0.8572711944580078',\n",
       "  '0.867805540561676',\n",
       "  '0.8568508625030518',\n",
       "  '0.8722184896469116',\n",
       "  '0.8611392974853516',\n",
       "  '0.8635159730911255',\n",
       "  '0.8554505109786987',\n",
       "  '0.8549932837486267',\n",
       "  '0.8614133596420288',\n",
       "  '0.8619415163993835',\n",
       "  '0.8597949743270874',\n",
       "  '0.8616398572921753',\n",
       "  '0.8610086441040039',\n",
       "  '0.858514666557312',\n",
       "  '0.8613430857658386',\n",
       "  '0.8573296666145325',\n",
       "  '0.8592108488082886',\n",
       "  '0.8602725267410278',\n",
       "  '0.8582233190536499',\n",
       "  '0.8587933778762817',\n",
       "  '0.8646398782730103',\n",
       "  '0.858967125415802',\n",
       "  '0.8652491569519043',\n",
       "  '0.8632949590682983',\n",
       "  '0.8597851395606995',\n",
       "  '0.86195307970047',\n",
       "  '0.8521809577941895',\n",
       "  '0.8562964200973511',\n",
       "  '0.8644410371780396',\n",
       "  '0.855935275554657',\n",
       "  '0.8543229699134827',\n",
       "  '0.8592691421508789',\n",
       "  '0.8576221466064453',\n",
       "  '0.8524506688117981'],\n",
       " 'val_true_negatives': ['51167764.0',\n",
       "  '52119008.0',\n",
       "  '47966524.0',\n",
       "  '46140320.0',\n",
       "  '52669072.0',\n",
       "  '47724816.0',\n",
       "  '53444012.0',\n",
       "  '53208184.0',\n",
       "  '50110464.0',\n",
       "  '56906144.0',\n",
       "  '56287440.0',\n",
       "  '53065372.0',\n",
       "  '52038120.0',\n",
       "  '48911596.0',\n",
       "  '52835852.0',\n",
       "  '50796784.0',\n",
       "  '54806864.0',\n",
       "  '54215616.0',\n",
       "  '53125932.0',\n",
       "  '49874412.0',\n",
       "  '52895400.0',\n",
       "  '51472936.0',\n",
       "  '52691164.0',\n",
       "  '52230576.0',\n",
       "  '52624892.0',\n",
       "  '52991028.0',\n",
       "  '54079244.0',\n",
       "  '52406036.0',\n",
       "  '53583392.0',\n",
       "  '54411688.0',\n",
       "  '53393864.0',\n",
       "  '53569596.0',\n",
       "  '53048208.0',\n",
       "  '53357360.0',\n",
       "  '53359820.0',\n",
       "  '54114864.0',\n",
       "  '53825388.0',\n",
       "  '53770800.0',\n",
       "  '52833096.0',\n",
       "  '53308404.0',\n",
       "  '54590168.0',\n",
       "  '52434776.0',\n",
       "  '53080808.0',\n",
       "  '53783808.0',\n",
       "  '54249804.0',\n",
       "  '54658532.0',\n",
       "  '54252516.0',\n",
       "  '54902364.0',\n",
       "  '51718232.0',\n",
       "  '53647204.0',\n",
       "  '52939928.0',\n",
       "  '52523124.0',\n",
       "  '53472680.0',\n",
       "  '53635480.0',\n",
       "  '53549152.0',\n",
       "  '53060240.0',\n",
       "  '52926616.0',\n",
       "  '53786380.0',\n",
       "  '53225792.0',\n",
       "  '53262956.0',\n",
       "  '53704920.0',\n",
       "  '54175248.0',\n",
       "  '53105536.0',\n",
       "  '54216584.0',\n",
       "  '54150400.0',\n",
       "  '53814552.0',\n",
       "  '54120324.0',\n",
       "  '53533928.0',\n",
       "  '53666224.0',\n",
       "  '54351536.0',\n",
       "  '54311988.0',\n",
       "  '53666704.0',\n",
       "  '53508840.0',\n",
       "  '54372680.0',\n",
       "  '53399696.0',\n",
       "  '53969800.0',\n",
       "  '53786484.0',\n",
       "  '53535720.0',\n",
       "  '54187432.0',\n",
       "  '54262540.0',\n",
       "  '55037596.0',\n",
       "  '54436096.0',\n",
       "  '54199444.0',\n",
       "  '54116696.0',\n",
       "  '54056176.0',\n",
       "  '54245340.0',\n",
       "  '54366352.0',\n",
       "  '54241048.0',\n",
       "  '54139580.0',\n",
       "  '54657684.0',\n",
       "  '53690784.0',\n",
       "  '53243064.0',\n",
       "  '53620108.0',\n",
       "  '53548472.0',\n",
       "  '54502188.0',\n",
       "  '53817884.0',\n",
       "  '53952144.0',\n",
       "  '53213488.0',\n",
       "  '53797556.0',\n",
       "  '54702936.0',\n",
       "  '53661840.0',\n",
       "  '54141900.0',\n",
       "  '54889100.0',\n",
       "  '53790224.0',\n",
       "  '54779160.0',\n",
       "  '53885896.0',\n",
       "  '53798608.0',\n",
       "  '54374840.0',\n",
       "  '53855688.0',\n",
       "  '53984744.0',\n",
       "  '54605688.0',\n",
       "  '53506712.0',\n",
       "  '54622848.0',\n",
       "  '54609308.0',\n",
       "  '54520264.0',\n",
       "  '53928084.0',\n",
       "  '53716640.0',\n",
       "  '54068968.0',\n",
       "  '54581868.0',\n",
       "  '54563520.0',\n",
       "  '54454612.0',\n",
       "  '54274980.0',\n",
       "  '54395220.0',\n",
       "  '54657596.0',\n",
       "  '54905200.0',\n",
       "  '53943568.0',\n",
       "  '53566468.0',\n",
       "  '54471360.0',\n",
       "  '54641768.0',\n",
       "  '53823708.0',\n",
       "  '53505660.0',\n",
       "  '54907204.0',\n",
       "  '54099592.0',\n",
       "  '54224140.0',\n",
       "  '54184724.0',\n",
       "  '53864568.0',\n",
       "  '53667312.0',\n",
       "  '54237924.0',\n",
       "  '53873016.0',\n",
       "  '54116472.0',\n",
       "  '54436216.0',\n",
       "  '54639248.0',\n",
       "  '54076548.0',\n",
       "  '54191968.0',\n",
       "  '54586504.0',\n",
       "  '54093396.0',\n",
       "  '54403836.0',\n",
       "  '53574268.0',\n",
       "  '53771504.0',\n",
       "  '54418720.0',\n",
       "  '54188732.0',\n",
       "  '54218044.0',\n",
       "  '53994548.0',\n",
       "  '54304972.0',\n",
       "  '53997484.0',\n",
       "  '54186024.0',\n",
       "  '54268696.0',\n",
       "  '54556240.0',\n",
       "  '53761936.0',\n",
       "  '54385952.0',\n",
       "  '54100088.0',\n",
       "  '53792324.0',\n",
       "  '53548988.0',\n",
       "  '53891672.0',\n",
       "  '54181572.0',\n",
       "  '53949048.0',\n",
       "  '53813808.0',\n",
       "  '53716116.0',\n",
       "  '54109704.0',\n",
       "  '54309080.0',\n",
       "  '53973952.0',\n",
       "  '54633464.0',\n",
       "  '54118056.0',\n",
       "  '54164216.0',\n",
       "  '54244028.0',\n",
       "  '54088448.0',\n",
       "  '53900584.0',\n",
       "  '54274344.0',\n",
       "  '53530672.0',\n",
       "  '54348532.0',\n",
       "  '53929080.0',\n",
       "  '54462016.0',\n",
       "  '54038896.0',\n",
       "  '53769552.0',\n",
       "  '54359640.0',\n",
       "  '53723568.0',\n",
       "  '54139496.0',\n",
       "  '54254872.0',\n",
       "  '54003020.0',\n",
       "  '53485600.0',\n",
       "  '53223612.0',\n",
       "  '54152224.0',\n",
       "  '54018408.0',\n",
       "  '54286376.0',\n",
       "  '54191636.0',\n",
       "  '53887848.0',\n",
       "  '54388200.0',\n",
       "  '53983152.0',\n",
       "  '53740884.0',\n",
       "  '53866960.0',\n",
       "  '53667888.0',\n",
       "  '54022320.0',\n",
       "  '53988396.0',\n",
       "  '54812840.0',\n",
       "  '54314956.0',\n",
       "  '54479224.0',\n",
       "  '54150504.0',\n",
       "  '54555576.0',\n",
       "  '53854088.0',\n",
       "  '54131304.0',\n",
       "  '53987532.0',\n",
       "  '53892852.0',\n",
       "  '54582672.0',\n",
       "  '54391280.0',\n",
       "  '54449944.0',\n",
       "  '53586376.0',\n",
       "  '54220336.0',\n",
       "  '54008240.0',\n",
       "  '54131156.0',\n",
       "  '54114332.0',\n",
       "  '53736236.0',\n",
       "  '53938420.0',\n",
       "  '54131744.0',\n",
       "  '54057060.0',\n",
       "  '54265084.0',\n",
       "  '54480236.0',\n",
       "  '54360984.0',\n",
       "  '53235544.0',\n",
       "  '54396712.0',\n",
       "  '53745636.0',\n",
       "  '54452896.0',\n",
       "  '53911420.0',\n",
       "  '54779708.0',\n",
       "  '53991488.0',\n",
       "  '54608020.0',\n",
       "  '53808892.0',\n",
       "  '53737164.0',\n",
       "  '54164036.0',\n",
       "  '54228412.0',\n",
       "  '54454328.0',\n",
       "  '54206668.0',\n",
       "  '53600792.0',\n",
       "  '54050048.0',\n",
       "  '54163852.0',\n",
       "  '54151960.0',\n",
       "  '54377704.0',\n",
       "  '54186120.0',\n",
       "  '53818048.0',\n",
       "  '54026720.0',\n",
       "  '53878416.0',\n",
       "  '54048488.0',\n",
       "  '54017720.0',\n",
       "  '54590596.0',\n",
       "  '54083784.0',\n",
       "  '54001928.0',\n",
       "  '54202760.0',\n",
       "  '53947664.0',\n",
       "  '53925004.0',\n",
       "  '54367280.0',\n",
       "  '54202992.0',\n",
       "  '54011384.0',\n",
       "  '54109644.0',\n",
       "  '54136928.0',\n",
       "  '54168964.0',\n",
       "  '53964752.0',\n",
       "  '53975856.0',\n",
       "  '54419496.0',\n",
       "  '53991036.0',\n",
       "  '54545760.0',\n",
       "  '53984488.0',\n",
       "  '54955320.0',\n",
       "  '54153840.0',\n",
       "  '54469528.0',\n",
       "  '53909660.0',\n",
       "  '53893552.0',\n",
       "  '54157488.0',\n",
       "  '54123708.0',\n",
       "  '54194028.0',\n",
       "  '54223072.0',\n",
       "  '54279288.0',\n",
       "  '53968028.0',\n",
       "  '54216652.0',\n",
       "  '53998820.0',\n",
       "  '54053116.0',\n",
       "  '54118508.0',\n",
       "  '53985448.0',\n",
       "  '54117728.0',\n",
       "  '54442572.0',\n",
       "  '54168864.0',\n",
       "  '54429184.0',\n",
       "  '54227028.0',\n",
       "  '54106604.0',\n",
       "  '54214216.0',\n",
       "  '53605824.0',\n",
       "  '53980316.0',\n",
       "  '54346648.0',\n",
       "  '54019520.0',\n",
       "  '53897468.0',\n",
       "  '53993988.0',\n",
       "  '53941408.0',\n",
       "  '53592992.0'],\n",
       " 'true_positives': ['111043808.0',\n",
       "  '111206328.0',\n",
       "  '112447392.0',\n",
       "  '112991728.0',\n",
       "  '113235904.0',\n",
       "  '114011392.0',\n",
       "  '114393776.0',\n",
       "  '114999336.0',\n",
       "  '114638944.0',\n",
       "  '115608840.0',\n",
       "  '115722160.0',\n",
       "  '115993240.0',\n",
       "  '116559416.0',\n",
       "  '116646776.0',\n",
       "  '116874728.0',\n",
       "  '117159816.0',\n",
       "  '117442272.0',\n",
       "  '117300144.0',\n",
       "  '117366416.0',\n",
       "  '117830272.0',\n",
       "  '117355328.0',\n",
       "  '118692888.0',\n",
       "  '119276576.0',\n",
       "  '119829672.0',\n",
       "  '120375520.0',\n",
       "  '120743664.0',\n",
       "  '120970208.0',\n",
       "  '121040984.0',\n",
       "  '121378176.0',\n",
       "  '121638552.0',\n",
       "  '121885136.0',\n",
       "  '122102336.0',\n",
       "  '122256176.0',\n",
       "  '122282704.0',\n",
       "  '122491304.0',\n",
       "  '122662144.0',\n",
       "  '122791104.0',\n",
       "  '123125144.0',\n",
       "  '123198872.0',\n",
       "  '123262672.0',\n",
       "  '123480720.0',\n",
       "  '123466816.0',\n",
       "  '123384384.0',\n",
       "  '123623008.0',\n",
       "  '123755928.0',\n",
       "  '123859272.0',\n",
       "  '123907208.0',\n",
       "  '124036728.0',\n",
       "  '124107008.0',\n",
       "  '124190864.0',\n",
       "  '124206712.0',\n",
       "  '124383808.0',\n",
       "  '124519472.0',\n",
       "  '124464448.0',\n",
       "  '124560848.0',\n",
       "  '124591528.0',\n",
       "  '124655336.0',\n",
       "  '124744160.0',\n",
       "  '124796360.0',\n",
       "  '124856752.0',\n",
       "  '124932784.0',\n",
       "  '124947544.0',\n",
       "  '125049016.0',\n",
       "  '125117640.0',\n",
       "  '125236832.0',\n",
       "  '125150472.0',\n",
       "  '125190992.0',\n",
       "  '125344096.0',\n",
       "  '125332760.0',\n",
       "  '125380920.0',\n",
       "  '125411872.0',\n",
       "  '125522208.0',\n",
       "  '125527552.0',\n",
       "  '125359712.0',\n",
       "  '125676456.0',\n",
       "  '125668784.0',\n",
       "  '125682656.0',\n",
       "  '125743640.0',\n",
       "  '125692192.0',\n",
       "  '125826584.0',\n",
       "  '125833560.0',\n",
       "  '125901040.0',\n",
       "  '125878616.0',\n",
       "  '125938240.0',\n",
       "  '125941432.0',\n",
       "  '126005840.0',\n",
       "  '126059808.0',\n",
       "  '126197784.0',\n",
       "  '126125472.0',\n",
       "  '126138448.0',\n",
       "  '126135312.0',\n",
       "  '126272896.0',\n",
       "  '126237488.0',\n",
       "  '126342984.0',\n",
       "  '126309928.0',\n",
       "  '126340080.0',\n",
       "  '126412504.0',\n",
       "  '126337528.0',\n",
       "  '126356104.0',\n",
       "  '126404904.0',\n",
       "  '126532776.0',\n",
       "  '126426304.0',\n",
       "  '126400232.0',\n",
       "  '126506848.0',\n",
       "  '126556816.0',\n",
       "  '126555448.0',\n",
       "  '126648080.0',\n",
       "  '126805408.0',\n",
       "  '126631680.0',\n",
       "  '126773728.0',\n",
       "  '126746392.0',\n",
       "  '126877072.0',\n",
       "  '126810136.0',\n",
       "  '126757632.0',\n",
       "  '126799784.0',\n",
       "  '126867360.0',\n",
       "  '126780976.0',\n",
       "  '126930632.0',\n",
       "  '126949784.0',\n",
       "  '126806992.0',\n",
       "  '127001424.0',\n",
       "  '127050280.0',\n",
       "  '126962608.0',\n",
       "  '126973488.0',\n",
       "  '126995048.0',\n",
       "  '126895880.0',\n",
       "  '127059504.0',\n",
       "  '127145520.0',\n",
       "  '127195808.0',\n",
       "  '127142512.0',\n",
       "  '127150640.0',\n",
       "  '127199000.0',\n",
       "  '127134680.0',\n",
       "  '127208888.0',\n",
       "  '127323376.0',\n",
       "  '127273752.0',\n",
       "  '127167712.0',\n",
       "  '127181704.0',\n",
       "  '127275040.0',\n",
       "  '127344912.0',\n",
       "  '127353744.0',\n",
       "  '127289176.0',\n",
       "  '127402960.0',\n",
       "  '127372464.0',\n",
       "  '127321792.0',\n",
       "  '127417072.0',\n",
       "  '127344952.0',\n",
       "  '127450744.0',\n",
       "  '127380160.0',\n",
       "  '127459984.0',\n",
       "  '127505640.0',\n",
       "  '127557152.0',\n",
       "  '127578080.0',\n",
       "  '127527616.0',\n",
       "  '127512560.0',\n",
       "  '127543024.0',\n",
       "  '127531592.0',\n",
       "  '127621552.0',\n",
       "  '127592680.0',\n",
       "  '127541160.0',\n",
       "  '127651416.0',\n",
       "  '127681488.0',\n",
       "  '127626128.0',\n",
       "  '127696808.0',\n",
       "  '127716656.0',\n",
       "  '127744656.0',\n",
       "  '127801288.0',\n",
       "  '127709456.0',\n",
       "  '127749496.0',\n",
       "  '127711536.0',\n",
       "  '127806288.0',\n",
       "  '127768096.0',\n",
       "  '127705200.0',\n",
       "  '127747752.0',\n",
       "  '127814912.0',\n",
       "  '127879320.0',\n",
       "  '127800784.0',\n",
       "  '127867272.0',\n",
       "  '127793752.0',\n",
       "  '127919408.0',\n",
       "  '127814216.0',\n",
       "  '128038000.0',\n",
       "  '127932456.0',\n",
       "  '127859384.0',\n",
       "  '127926184.0',\n",
       "  '127993776.0',\n",
       "  '128000320.0',\n",
       "  '127973736.0',\n",
       "  '127973032.0',\n",
       "  '127921728.0',\n",
       "  '127939256.0',\n",
       "  '127974712.0',\n",
       "  '128011528.0',\n",
       "  '128088728.0',\n",
       "  '128124896.0',\n",
       "  '128060624.0',\n",
       "  '127977456.0',\n",
       "  '128017808.0',\n",
       "  '128088576.0',\n",
       "  '128189872.0',\n",
       "  '128083184.0',\n",
       "  '128144936.0',\n",
       "  '128228320.0',\n",
       "  '128186712.0',\n",
       "  '128194960.0',\n",
       "  '128105040.0',\n",
       "  '128148376.0',\n",
       "  '128154472.0',\n",
       "  '128189280.0',\n",
       "  '128291304.0',\n",
       "  '128238920.0',\n",
       "  '128231512.0',\n",
       "  '128190448.0',\n",
       "  '128257208.0',\n",
       "  '128221048.0',\n",
       "  '128336712.0',\n",
       "  '128210720.0',\n",
       "  '128292192.0',\n",
       "  '128217032.0',\n",
       "  '128391344.0',\n",
       "  '128301776.0',\n",
       "  '128364120.0',\n",
       "  '128264944.0',\n",
       "  '128327544.0',\n",
       "  '128314824.0',\n",
       "  '128395000.0',\n",
       "  '128235376.0',\n",
       "  '128363824.0',\n",
       "  '128308464.0',\n",
       "  '128389704.0',\n",
       "  '128408064.0',\n",
       "  '128428536.0',\n",
       "  '128471360.0',\n",
       "  '128377568.0',\n",
       "  '128430672.0',\n",
       "  '128469040.0',\n",
       "  '128472400.0',\n",
       "  '128435648.0',\n",
       "  '128433832.0',\n",
       "  '128492984.0',\n",
       "  '128496160.0',\n",
       "  '128500416.0',\n",
       "  '128561656.0',\n",
       "  '128542400.0',\n",
       "  '128506152.0',\n",
       "  '128571360.0',\n",
       "  '128569288.0',\n",
       "  '128557976.0',\n",
       "  '128511664.0',\n",
       "  '128539136.0',\n",
       "  '128580336.0',\n",
       "  '128536624.0',\n",
       "  '128600120.0',\n",
       "  '128518968.0',\n",
       "  '128641216.0',\n",
       "  '128485280.0',\n",
       "  '128600696.0',\n",
       "  '128585984.0',\n",
       "  '128650944.0',\n",
       "  '128608912.0',\n",
       "  '128638720.0',\n",
       "  '128584624.0',\n",
       "  '128649224.0',\n",
       "  '128528488.0',\n",
       "  '128629728.0',\n",
       "  '128712024.0',\n",
       "  '128628544.0',\n",
       "  '128683480.0',\n",
       "  '128664464.0',\n",
       "  '128655080.0',\n",
       "  '128695104.0',\n",
       "  '128657064.0',\n",
       "  '128619336.0',\n",
       "  '128673088.0',\n",
       "  '128662808.0',\n",
       "  '128737696.0',\n",
       "  '128681392.0',\n",
       "  '128789304.0',\n",
       "  '128727744.0',\n",
       "  '128727048.0',\n",
       "  '128804792.0',\n",
       "  '128712336.0',\n",
       "  '128748488.0',\n",
       "  '128846128.0',\n",
       "  '128825416.0',\n",
       "  '128749456.0',\n",
       "  '128741728.0',\n",
       "  '128674112.0',\n",
       "  '128696832.0',\n",
       "  '128851760.0',\n",
       "  '128857528.0',\n",
       "  '128849904.0',\n",
       "  '128831672.0',\n",
       "  '128761456.0',\n",
       "  '128922088.0',\n",
       "  '128838072.0',\n",
       "  '128876328.0',\n",
       "  '128836184.0',\n",
       "  '128852928.0',\n",
       "  '128955920.0',\n",
       "  '128809344.0'],\n",
       " 'val_accuracy': ['0.8242917656898499',\n",
       "  '0.8498079180717468',\n",
       "  '0.8433647751808167',\n",
       "  '0.8287520408630371',\n",
       "  '0.8287599682807922',\n",
       "  '0.8436726331710815',\n",
       "  '0.8602073192596436',\n",
       "  '0.8823829293251038',\n",
       "  '0.8584086894989014',\n",
       "  '0.813231885433197',\n",
       "  '0.8917816877365112',\n",
       "  '0.87993323802948',\n",
       "  '0.874578595161438',\n",
       "  '0.8450703620910645',\n",
       "  '0.8604539036750793',\n",
       "  '0.8445158004760742',\n",
       "  '0.8260716795921326',\n",
       "  '0.8888552188873291',\n",
       "  '0.8892303705215454',\n",
       "  '0.8591651320457458',\n",
       "  '0.8684530258178711',\n",
       "  '0.8560224175453186',\n",
       "  '0.8642113208770752',\n",
       "  '0.8395726680755615',\n",
       "  '0.8533067107200623',\n",
       "  '0.8569526076316833',\n",
       "  '0.8602868914604187',\n",
       "  '0.862686812877655',\n",
       "  '0.8552858233451843',\n",
       "  '0.8754955530166626',\n",
       "  '0.8783020973205566',\n",
       "  '0.8646611571311951',\n",
       "  '0.8755253553390503',\n",
       "  '0.8659992814064026',\n",
       "  '0.8675855398178101',\n",
       "  '0.8781846165657043',\n",
       "  '0.8712639808654785',\n",
       "  '0.8705491423606873',\n",
       "  '0.8803845047950745',\n",
       "  '0.8751032948493958',\n",
       "  '0.8737421631813049',\n",
       "  '0.8662274479866028',\n",
       "  '0.8592154383659363',\n",
       "  '0.8654018044471741',\n",
       "  '0.8857923746109009',\n",
       "  '0.8720723986625671',\n",
       "  '0.8700535297393799',\n",
       "  '0.8749876022338867',\n",
       "  '0.872788667678833',\n",
       "  '0.8936258554458618',\n",
       "  '0.878600001335144',\n",
       "  '0.8829112648963928',\n",
       "  '0.8849976658821106',\n",
       "  '0.8918882608413696',\n",
       "  '0.8890605568885803',\n",
       "  '0.8751226663589478',\n",
       "  '0.8864935636520386',\n",
       "  '0.8917012810707092',\n",
       "  '0.8786147832870483',\n",
       "  '0.8765685558319092',\n",
       "  '0.886633038520813',\n",
       "  '0.8933241367340088',\n",
       "  '0.8875998854637146',\n",
       "  '0.8872687220573425',\n",
       "  '0.8926673531532288',\n",
       "  '0.8920038342475891',\n",
       "  '0.8902159333229065',\n",
       "  '0.890754222869873',\n",
       "  '0.8807737827301025',\n",
       "  '0.8762558102607727',\n",
       "  '0.8843727111816406',\n",
       "  '0.8861092329025269',\n",
       "  '0.8904123902320862',\n",
       "  '0.8926801681518555',\n",
       "  '0.8820460438728333',\n",
       "  '0.8869215250015259',\n",
       "  '0.8874621987342834',\n",
       "  '0.8852776288986206',\n",
       "  '0.8831599950790405',\n",
       "  '0.8960076570510864',\n",
       "  '0.899150013923645',\n",
       "  '0.8884961009025574',\n",
       "  '0.891278862953186',\n",
       "  '0.892905056476593',\n",
       "  '0.8853901028633118',\n",
       "  '0.8974866271018982',\n",
       "  '0.8977532386779785',\n",
       "  '0.8990088701248169',\n",
       "  '0.8917590975761414',\n",
       "  '0.8807775974273682',\n",
       "  '0.8895372152328491',\n",
       "  '0.8801289200782776',\n",
       "  '0.890203058719635',\n",
       "  '0.8915525674819946',\n",
       "  '0.8958012461662292',\n",
       "  '0.8953007459640503',\n",
       "  '0.897331178188324',\n",
       "  '0.8916771411895752',\n",
       "  '0.8973925709724426',\n",
       "  '0.8964393138885498',\n",
       "  '0.8935382962226868',\n",
       "  '0.891438364982605',\n",
       "  '0.901397168636322',\n",
       "  '0.896240234375',\n",
       "  '0.9001848101615906',\n",
       "  '0.8961367607116699',\n",
       "  '0.8953332901000977',\n",
       "  '0.8990083932876587',\n",
       "  '0.8938716650009155',\n",
       "  '0.8940012454986572',\n",
       "  '0.8937467932701111',\n",
       "  '0.8915566205978394',\n",
       "  '0.8950695991516113',\n",
       "  '0.898152768611908',\n",
       "  '0.8963971734046936',\n",
       "  '0.8960254788398743',\n",
       "  '0.8951661586761475',\n",
       "  '0.8935993313789368',\n",
       "  '0.8996397852897644',\n",
       "  '0.8957734704017639',\n",
       "  '0.8979461789131165',\n",
       "  '0.899541974067688',\n",
       "  '0.8983888626098633',\n",
       "  '0.9004254937171936',\n",
       "  '0.896963357925415',\n",
       "  '0.8954219222068787',\n",
       "  '0.8961529731750488',\n",
       "  '0.8987581133842468',\n",
       "  '0.8976947069168091',\n",
       "  '0.8971890211105347',\n",
       "  '0.8942090272903442',\n",
       "  '0.9008165597915649',\n",
       "  '0.898979902267456',\n",
       "  '0.898804247379303',\n",
       "  '0.8997799158096313',\n",
       "  '0.8964767456054688',\n",
       "  '0.8978047966957092',\n",
       "  '0.8973862528800964',\n",
       "  '0.894955575466156',\n",
       "  '0.8967226147651672',\n",
       "  '0.8988575339317322',\n",
       "  '0.8970469236373901',\n",
       "  '0.8997504711151123',\n",
       "  '0.899406909942627',\n",
       "  '0.9015278220176697',\n",
       "  '0.8980947732925415',\n",
       "  '0.8998093605041504',\n",
       "  '0.897466778755188',\n",
       "  '0.8948997259140015',\n",
       "  '0.8993126153945923',\n",
       "  '0.8995078206062317',\n",
       "  '0.8993973135948181',\n",
       "  '0.8986347317695618',\n",
       "  '0.8997136950492859',\n",
       "  '0.8984349966049194',\n",
       "  '0.8982857465744019',\n",
       "  '0.9011440873146057',\n",
       "  '0.9014029502868652',\n",
       "  '0.8972306251525879',\n",
       "  '0.8991243839263916',\n",
       "  '0.8993282318115234',\n",
       "  '0.896642804145813',\n",
       "  '0.8944332003593445',\n",
       "  '0.8991830348968506',\n",
       "  '0.9009276628494263',\n",
       "  '0.8971466422080994',\n",
       "  '0.8953496813774109',\n",
       "  '0.8964655995368958',\n",
       "  '0.8998795747756958',\n",
       "  '0.8971389532089233',\n",
       "  '0.9004243016242981',\n",
       "  '0.9017519950866699',\n",
       "  '0.9000090956687927',\n",
       "  '0.9013753533363342',\n",
       "  '0.8990960121154785',\n",
       "  '0.8986802101135254',\n",
       "  '0.8978266716003418',\n",
       "  '0.900277853012085',\n",
       "  '0.897472083568573',\n",
       "  '0.8987855911254883',\n",
       "  '0.8990347981452942',\n",
       "  '0.8985582590103149',\n",
       "  '0.8967729210853577',\n",
       "  '0.8976773023605347',\n",
       "  '0.9018622636795044',\n",
       "  '0.8983471989631653',\n",
       "  '0.8996958136558533',\n",
       "  '0.9020639061927795',\n",
       "  '0.8993401527404785',\n",
       "  '0.8965025544166565',\n",
       "  '0.8942627906799316',\n",
       "  '0.9005441665649414',\n",
       "  '0.9009757041931152',\n",
       "  '0.9017431139945984',\n",
       "  '0.9002312421798706',\n",
       "  '0.8975719213485718',\n",
       "  '0.901309609413147',\n",
       "  '0.8971978425979614',\n",
       "  '0.8994025588035583',\n",
       "  '0.898430347442627',\n",
       "  '0.8976981043815613',\n",
       "  '0.897429883480072',\n",
       "  '0.9005255103111267',\n",
       "  '0.9035282135009766',\n",
       "  '0.9018701314926147',\n",
       "  '0.9025741219520569',\n",
       "  '0.8992281556129456',\n",
       "  '0.9022198915481567',\n",
       "  '0.8987030982971191',\n",
       "  '0.899267852306366',\n",
       "  '0.899855375289917',\n",
       "  '0.899884819984436',\n",
       "  '0.9024949669837952',\n",
       "  '0.9009581804275513',\n",
       "  '0.9008644223213196',\n",
       "  '0.8955419063568115',\n",
       "  '0.8998335003852844',\n",
       "  '0.8978575468063354',\n",
       "  '0.9005813002586365',\n",
       "  '0.9003056883811951',\n",
       "  '0.899495542049408',\n",
       "  '0.9008046984672546',\n",
       "  '0.8979083299636841',\n",
       "  '0.9002606272697449',\n",
       "  '0.9002745151519775',\n",
       "  '0.9025304317474365',\n",
       "  '0.8992761969566345',\n",
       "  '0.894848108291626',\n",
       "  '0.9011947512626648',\n",
       "  '0.8972732424736023',\n",
       "  '0.9001396894454956',\n",
       "  '0.8990277051925659',\n",
       "  '0.903668224811554',\n",
       "  '0.900773823261261',\n",
       "  '0.9034006595611572',\n",
       "  '0.9005709290504456',\n",
       "  '0.8975184559822083',\n",
       "  '0.9012057185173035',\n",
       "  '0.901671290397644',\n",
       "  '0.901948094367981',\n",
       "  '0.9001194834709167',\n",
       "  '0.8982113003730774',\n",
       "  '0.8995358943939209',\n",
       "  '0.9015809297561646',\n",
       "  '0.900669515132904',\n",
       "  '0.901185154914856',\n",
       "  '0.9020863175392151',\n",
       "  '0.9005879759788513',\n",
       "  '0.8994649648666382',\n",
       "  '0.8994749784469604',\n",
       "  '0.9020484089851379',\n",
       "  '0.9015147686004639',\n",
       "  '0.9040935635566711',\n",
       "  '0.9013170599937439',\n",
       "  '0.9011128544807434',\n",
       "  '0.9003209471702576',\n",
       "  '0.9011392593383789',\n",
       "  '0.9012719392776489',\n",
       "  '0.9021766185760498',\n",
       "  '0.9023639559745789',\n",
       "  '0.9012442231178284',\n",
       "  '0.9028757214546204',\n",
       "  '0.9015802145004272',\n",
       "  '0.9021894931793213',\n",
       "  '0.9020072221755981',\n",
       "  '0.9011106491088867',\n",
       "  '0.9033202528953552',\n",
       "  '0.9011791348457336',\n",
       "  '0.9033049941062927',\n",
       "  '0.9006044864654541',\n",
       "  '0.9055103063583374',\n",
       "  '0.9019255042076111',\n",
       "  '0.9020522236824036',\n",
       "  '0.9012000560760498',\n",
       "  '0.9010416865348816',\n",
       "  '0.902572512626648',\n",
       "  '0.9028521776199341',\n",
       "  '0.9021664261817932',\n",
       "  '0.9023473858833313',\n",
       "  '0.9021760821342468',\n",
       "  '0.9013053774833679',\n",
       "  '0.9016866087913513',\n",
       "  '0.9008788466453552',\n",
       "  '0.9003567099571228',\n",
       "  '0.9015581011772156',\n",
       "  '0.9013053774833679',\n",
       "  '0.9014074206352234',\n",
       "  '0.9025560617446899',\n",
       "  '0.9016554951667786',\n",
       "  '0.9036301970481873',\n",
       "  '0.9033485651016235',\n",
       "  '0.9013168811798096',\n",
       "  '0.9024145603179932',\n",
       "  '0.8994607329368591',\n",
       "  '0.9006325602531433',\n",
       "  '0.9026731252670288',\n",
       "  '0.8998688459396362',\n",
       "  '0.8999889492988586',\n",
       "  '0.9009572863578796',\n",
       "  '0.9015909433364868',\n",
       "  '0.8983802199363708'],\n",
       " 'true_negatives': ['140314272.0',\n",
       "  '160480896.0',\n",
       "  '161898704.0',\n",
       "  '164223536.0',\n",
       "  '165692640.0',\n",
       "  '166660272.0',\n",
       "  '167122240.0',\n",
       "  '167741888.0',\n",
       "  '169485760.0',\n",
       "  '169984368.0',\n",
       "  '170331008.0',\n",
       "  '171406992.0',\n",
       "  '171295424.0',\n",
       "  '171761392.0',\n",
       "  '171966000.0',\n",
       "  '172892432.0',\n",
       "  '172932256.0',\n",
       "  '173498800.0',\n",
       "  '173373680.0',\n",
       "  '173900384.0',\n",
       "  '173467456.0',\n",
       "  '174894880.0',\n",
       "  '176073328.0',\n",
       "  '176602592.0',\n",
       "  '177258720.0',\n",
       "  '177678368.0',\n",
       "  '178068112.0',\n",
       "  '178317440.0',\n",
       "  '178630304.0',\n",
       "  '178986208.0',\n",
       "  '179322080.0',\n",
       "  '179442128.0',\n",
       "  '179582352.0',\n",
       "  '179941312.0',\n",
       "  '180012096.0',\n",
       "  '180222832.0',\n",
       "  '180313472.0',\n",
       "  '180365584.0',\n",
       "  '180470272.0',\n",
       "  '180676544.0',\n",
       "  '180720064.0',\n",
       "  '180803632.0',\n",
       "  '181114448.0',\n",
       "  '181224928.0',\n",
       "  '181029200.0',\n",
       "  '181391808.0',\n",
       "  '181428624.0',\n",
       "  '181482672.0',\n",
       "  '181657632.0',\n",
       "  '181643760.0',\n",
       "  '181564480.0',\n",
       "  '181718064.0',\n",
       "  '181918720.0',\n",
       "  '181891648.0',\n",
       "  '181965760.0',\n",
       "  '182006560.0',\n",
       "  '181996416.0',\n",
       "  '182124560.0',\n",
       "  '182213040.0',\n",
       "  '182434432.0',\n",
       "  '182211328.0',\n",
       "  '182362272.0',\n",
       "  '182487808.0',\n",
       "  '182584368.0',\n",
       "  '182567968.0',\n",
       "  '182685408.0',\n",
       "  '182696160.0',\n",
       "  '182638784.0',\n",
       "  '182737760.0',\n",
       "  '182764752.0',\n",
       "  '182865456.0',\n",
       "  '182820384.0',\n",
       "  '182891200.0',\n",
       "  '183011856.0',\n",
       "  '182837584.0',\n",
       "  '183000464.0',\n",
       "  '183076640.0',\n",
       "  '183071360.0',\n",
       "  '183288688.0',\n",
       "  '183098784.0',\n",
       "  '183241344.0',\n",
       "  '183135776.0',\n",
       "  '183232640.0',\n",
       "  '183253344.0',\n",
       "  '183404352.0',\n",
       "  '183358432.0',\n",
       "  '183400688.0',\n",
       "  '183404160.0',\n",
       "  '183386096.0',\n",
       "  '183504720.0',\n",
       "  '183654912.0',\n",
       "  '183555168.0',\n",
       "  '183598096.0',\n",
       "  '183593824.0',\n",
       "  '183611648.0',\n",
       "  '183646800.0',\n",
       "  '183698160.0',\n",
       "  '183722624.0',\n",
       "  '183778144.0',\n",
       "  '183753872.0',\n",
       "  '183718000.0',\n",
       "  '183851296.0',\n",
       "  '183911504.0',\n",
       "  '183903488.0',\n",
       "  '183858720.0',\n",
       "  '183903296.0',\n",
       "  '183992480.0',\n",
       "  '183904784.0',\n",
       "  '184098048.0',\n",
       "  '183909056.0',\n",
       "  '184054512.0',\n",
       "  '183970032.0',\n",
       "  '184117152.0',\n",
       "  '184041616.0',\n",
       "  '184113600.0',\n",
       "  '184070112.0',\n",
       "  '184232048.0',\n",
       "  '184168512.0',\n",
       "  '184204544.0',\n",
       "  '184291552.0',\n",
       "  '184252656.0',\n",
       "  '184257664.0',\n",
       "  '184315872.0',\n",
       "  '184291776.0',\n",
       "  '184373920.0',\n",
       "  '184421472.0',\n",
       "  '184388512.0',\n",
       "  '184348656.0',\n",
       "  '184424848.0',\n",
       "  '184472576.0',\n",
       "  '184464912.0',\n",
       "  '184417056.0',\n",
       "  '184535472.0',\n",
       "  '184547712.0',\n",
       "  '184456832.0',\n",
       "  '184517968.0',\n",
       "  '184582176.0',\n",
       "  '184613296.0',\n",
       "  '184567248.0',\n",
       "  '184573328.0',\n",
       "  '184575248.0',\n",
       "  '184669744.0',\n",
       "  '184553184.0',\n",
       "  '184624608.0',\n",
       "  '184715936.0',\n",
       "  '184627920.0',\n",
       "  '184747904.0',\n",
       "  '184635280.0',\n",
       "  '184787472.0',\n",
       "  '184756192.0',\n",
       "  '184765648.0',\n",
       "  '184763600.0',\n",
       "  '184678288.0',\n",
       "  '184830528.0',\n",
       "  '184926672.0',\n",
       "  '184881792.0',\n",
       "  '184963040.0',\n",
       "  '184886672.0',\n",
       "  '184849744.0',\n",
       "  '184904544.0',\n",
       "  '184858592.0',\n",
       "  '184890352.0',\n",
       "  '184931328.0',\n",
       "  '184984960.0',\n",
       "  '184962912.0',\n",
       "  '184934720.0',\n",
       "  '184931824.0',\n",
       "  '184972816.0',\n",
       "  '185038368.0',\n",
       "  '185019408.0',\n",
       "  '184961472.0',\n",
       "  '185040960.0',\n",
       "  '185101280.0',\n",
       "  '185207280.0',\n",
       "  '185126480.0',\n",
       "  '185066176.0',\n",
       "  '185207072.0',\n",
       "  '185188784.0',\n",
       "  '185146784.0',\n",
       "  '185101840.0',\n",
       "  '185253104.0',\n",
       "  '185122576.0',\n",
       "  '185168608.0',\n",
       "  '185295696.0',\n",
       "  '185204528.0',\n",
       "  '185205328.0',\n",
       "  '185214320.0',\n",
       "  '185304560.0',\n",
       "  '185238720.0',\n",
       "  '185269936.0',\n",
       "  '185281488.0',\n",
       "  '185230224.0',\n",
       "  '185283600.0',\n",
       "  '185264560.0',\n",
       "  '185239072.0',\n",
       "  '185338304.0',\n",
       "  '185430688.0',\n",
       "  '185386464.0',\n",
       "  '185375264.0',\n",
       "  '185277968.0',\n",
       "  '185398176.0',\n",
       "  '185344208.0',\n",
       "  '185334432.0',\n",
       "  '185396560.0',\n",
       "  '185381728.0',\n",
       "  '185514768.0',\n",
       "  '185474736.0',\n",
       "  '185481808.0',\n",
       "  '185441808.0',\n",
       "  '185369440.0',\n",
       "  '185489840.0',\n",
       "  '185554320.0',\n",
       "  '185572160.0',\n",
       "  '185487008.0',\n",
       "  '185556240.0',\n",
       "  '185478576.0',\n",
       "  '185612848.0',\n",
       "  '185581232.0',\n",
       "  '185634688.0',\n",
       "  '185530080.0',\n",
       "  '185616064.0',\n",
       "  '185565984.0',\n",
       "  '185604752.0',\n",
       "  '185561632.0',\n",
       "  '185597200.0',\n",
       "  '185542448.0',\n",
       "  '185744128.0',\n",
       "  '185564032.0',\n",
       "  '185643552.0',\n",
       "  '185663616.0',\n",
       "  '185666960.0',\n",
       "  '185631504.0',\n",
       "  '185621792.0',\n",
       "  '185718304.0',\n",
       "  '185715616.0',\n",
       "  '185651008.0',\n",
       "  '185689888.0',\n",
       "  '185707344.0',\n",
       "  '185754672.0',\n",
       "  '185709808.0',\n",
       "  '185710800.0',\n",
       "  '185740896.0',\n",
       "  '185672320.0',\n",
       "  '185716224.0',\n",
       "  '185781152.0',\n",
       "  '185729040.0',\n",
       "  '185771088.0',\n",
       "  '185751712.0',\n",
       "  '185801520.0',\n",
       "  '185804176.0',\n",
       "  '185811264.0',\n",
       "  '185837904.0',\n",
       "  '185810672.0',\n",
       "  '185875072.0',\n",
       "  '185819200.0',\n",
       "  '185932736.0',\n",
       "  '185852688.0',\n",
       "  '185866496.0',\n",
       "  '185805200.0',\n",
       "  '185843040.0',\n",
       "  '185829760.0',\n",
       "  '185930480.0',\n",
       "  '185944560.0',\n",
       "  '186008736.0',\n",
       "  '185925360.0',\n",
       "  '185880736.0',\n",
       "  '185943488.0',\n",
       "  '185931296.0',\n",
       "  '185934144.0',\n",
       "  '185958336.0',\n",
       "  '185948848.0',\n",
       "  '186016576.0',\n",
       "  '185963312.0',\n",
       "  '185937120.0',\n",
       "  '185925360.0',\n",
       "  '185890848.0',\n",
       "  '186019104.0',\n",
       "  '185962288.0',\n",
       "  '185992912.0',\n",
       "  '186012096.0',\n",
       "  '185955072.0',\n",
       "  '186072544.0',\n",
       "  '186077632.0',\n",
       "  '185991936.0',\n",
       "  '185990960.0',\n",
       "  '186085792.0',\n",
       "  '186023168.0',\n",
       "  '186164688.0',\n",
       "  '186180176.0',\n",
       "  '186034864.0',\n",
       "  '186015328.0',\n",
       "  '186077312.0',\n",
       "  '186037648.0',\n",
       "  '186101456.0',\n",
       "  '186027872.0',\n",
       "  '186130592.0',\n",
       "  '186062464.0',\n",
       "  '186109088.0',\n",
       "  '186149104.0',\n",
       "  '186041824.0',\n",
       "  '186213136.0'],\n",
       " 'precision': ['0.697047233581543',\n",
       "  '0.7996317148208618',\n",
       "  '0.809070885181427',\n",
       "  '0.823722779750824',\n",
       "  '0.8332484364509583',\n",
       "  '0.8396627902984619',\n",
       "  '0.8432087898254395',\n",
       "  '0.8475856781005859',\n",
       "  '0.8580160140991211',\n",
       "  '0.8629460334777832',\n",
       "  '0.8647677898406982',\n",
       "  '0.8719155192375183',\n",
       "  '0.8719436526298523',\n",
       "  '0.8751697540283203',\n",
       "  '0.8764241933822632',\n",
       "  '0.8830808997154236',\n",
       "  '0.8837368488311768',\n",
       "  '0.8868685960769653',\n",
       "  '0.8869044780731201',\n",
       "  '0.8907247185707092',\n",
       "  '0.8871816396713257',\n",
       "  '0.898034393787384',\n",
       "  '0.9061962962150574',\n",
       "  '0.9103838205337524',\n",
       "  '0.9149404764175415',\n",
       "  '0.9186733365058899',\n",
       "  '0.9215167760848999',\n",
       "  '0.9230862855911255',\n",
       "  '0.9255944490432739',\n",
       "  '0.9279364347457886',\n",
       "  '0.9308333992958069',\n",
       "  '0.9320839643478394',\n",
       "  '0.9332407116889954',\n",
       "  '0.9350674152374268',\n",
       "  '0.9355627298355103',\n",
       "  '0.9372427463531494',\n",
       "  '0.9380961060523987',\n",
       "  '0.9394775032997131',\n",
       "  '0.9400296211242676',\n",
       "  '0.9413082599639893',\n",
       "  '0.9420340061187744',\n",
       "  '0.9423638582229614',\n",
       "  '0.9440995454788208',\n",
       "  '0.9450093507766724',\n",
       "  '0.9443277716636658',\n",
       "  '0.946672797203064',\n",
       "  '0.9462846517562866',\n",
       "  '0.9471175670623779',\n",
       "  '0.9483641386032104',\n",
       "  '0.9488745927810669',\n",
       "  '0.9480573534965515',\n",
       "  '0.9491622447967529',\n",
       "  '0.9505270719528198',\n",
       "  '0.9501978754997253',\n",
       "  '0.951066792011261',\n",
       "  '0.9513087868690491',\n",
       "  '0.9517623782157898',\n",
       "  '0.9522722363471985',\n",
       "  '0.952914297580719',\n",
       "  '0.9540858268737793',\n",
       "  '0.9530552625656128',\n",
       "  '0.9537534713745117',\n",
       "  '0.9546761512756348',\n",
       "  '0.9552854895591736',\n",
       "  '0.9557392597198486',\n",
       "  '0.95574551820755',\n",
       "  '0.9562594890594482',\n",
       "  '0.9565346240997314',\n",
       "  '0.9569517970085144',\n",
       "  '0.9567278623580933',\n",
       "  '0.9577279090881348',\n",
       "  '0.9579380750656128',\n",
       "  '0.9582860469818115',\n",
       "  '0.9583082795143127',\n",
       "  '0.9580734968185425',\n",
       "  '0.9590890407562256',\n",
       "  '0.9592689871788025',\n",
       "  '0.9595064520835876',\n",
       "  '0.9603791236877441',\n",
       "  '0.9602071642875671',\n",
       "  '0.9606888890266418',\n",
       "  '0.9601970314979553',\n",
       "  '0.9606866240501404',\n",
       "  '0.9607180953025818',\n",
       "  '0.9616856575012207',\n",
       "  '0.9615132212638855',\n",
       "  '0.9619907736778259',\n",
       "  '0.9623112678527832',\n",
       "  '0.9622284770011902',\n",
       "  '0.9626361131668091',\n",
       "  '0.9633382558822632',\n",
       "  '0.9634891748428345',\n",
       "  '0.9633897542953491',\n",
       "  '0.9638153314590454',\n",
       "  '0.9635764360427856',\n",
       "  '0.9635727405548096',\n",
       "  '0.9646076560020447',\n",
       "  '0.9643229842185974',\n",
       "  '0.9646303653717041',\n",
       "  '0.9642285704612732',\n",
       "  '0.9646559953689575',\n",
       "  '0.9650861024856567',\n",
       "  '0.9651906490325928',\n",
       "  '0.9654732346534729',\n",
       "  '0.965610146522522',\n",
       "  '0.9657854437828064',\n",
       "  '0.9660265445709229',\n",
       "  '0.966297447681427',\n",
       "  '0.9667637944221497',\n",
       "  '0.9664103984832764',\n",
       "  '0.9670302867889404',\n",
       "  '0.9670767188072205',\n",
       "  '0.9671317934989929',\n",
       "  '0.9671006798744202',\n",
       "  '0.9673776030540466',\n",
       "  '0.9672824144363403',\n",
       "  '0.967924952507019',\n",
       "  '0.967901885509491',\n",
       "  '0.9683567881584167',\n",
       "  '0.9681828022003174',\n",
       "  '0.9685369729995728',\n",
       "  '0.968910813331604',\n",
       "  '0.9686248898506165',\n",
       "  '0.9687194228172302',\n",
       "  '0.9690098166465759',\n",
       "  '0.9692242741584778',\n",
       "  '0.9695760011672974',\n",
       "  '0.9690899848937988',\n",
       "  '0.9700545072555542',\n",
       "  '0.9700056314468384',\n",
       "  '0.9700517654418945',\n",
       "  '0.9698360562324524',\n",
       "  '0.9701371192932129',\n",
       "  '0.970492422580719',\n",
       "  '0.9706015586853027',\n",
       "  '0.9706470370292664',\n",
       "  '0.9703733921051025',\n",
       "  '0.9706612229347229',\n",
       "  '0.9707961082458496',\n",
       "  '0.9711171984672546',\n",
       "  '0.9712730050086975',\n",
       "  '0.9713047742843628',\n",
       "  '0.9711163640022278',\n",
       "  '0.971438467502594',\n",
       "  '0.9715708494186401',\n",
       "  '0.971441924571991',\n",
       "  '0.9717884659767151',\n",
       "  '0.971777617931366',\n",
       "  '0.9719893932342529',\n",
       "  '0.97223299741745',\n",
       "  '0.9723386168479919',\n",
       "  '0.9727432727813721',\n",
       "  '0.9720832109451294',\n",
       "  '0.9726117253303528',\n",
       "  '0.9729987978935242',\n",
       "  '0.972753643989563',\n",
       "  '0.9731037616729736',\n",
       "  '0.9731389880180359',\n",
       "  '0.9733129143714905',\n",
       "  '0.9731152057647705',\n",
       "  '0.973285436630249',\n",
       "  '0.9735273122787476',\n",
       "  '0.9736219644546509',\n",
       "  '0.9740278124809265',\n",
       "  '0.9739133715629578',\n",
       "  '0.9740716814994812',\n",
       "  '0.9740238785743713',\n",
       "  '0.9739362001419067',\n",
       "  '0.9744402170181274',\n",
       "  '0.9741259813308716',\n",
       "  '0.9745169878005981',\n",
       "  '0.9741702079772949',\n",
       "  '0.9743323922157288',\n",
       "  '0.9749248623847961',\n",
       "  '0.9750334620475769',\n",
       "  '0.9748169779777527',\n",
       "  '0.9753726720809937',\n",
       "  '0.9752114415168762',\n",
       "  '0.9748543500900269',\n",
       "  '0.9751719236373901',\n",
       "  '0.9754666686058044',\n",
       "  '0.9756208658218384',\n",
       "  '0.9754857420921326',\n",
       "  '0.9758347868919373',\n",
       "  '0.975663423538208',\n",
       "  '0.9759548306465149',\n",
       "  '0.9758940935134888',\n",
       "  '0.9761691093444824',\n",
       "  '0.9759950041770935',\n",
       "  '0.9759559631347656',\n",
       "  '0.9760116338729858',\n",
       "  '0.9758955240249634',\n",
       "  '0.9764343500137329',\n",
       "  '0.9765348434448242',\n",
       "  '0.9765365719795227',\n",
       "  '0.976730227470398',\n",
       "  '0.9767037034034729',\n",
       "  '0.9766885638237',\n",
       "  '0.9769036769866943',\n",
       "  '0.976840615272522',\n",
       "  '0.977047860622406',\n",
       "  '0.9769771099090576',\n",
       "  '0.9772769212722778',\n",
       "  '0.9773411154747009',\n",
       "  '0.9773579835891724',\n",
       "  '0.9775033593177795',\n",
       "  '0.9776463508605957',\n",
       "  '0.9775069952011108',\n",
       "  '0.9777307510375977',\n",
       "  '0.9776312708854675',\n",
       "  '0.9779581427574158',\n",
       "  '0.9781012535095215',\n",
       "  '0.9780996441841125',\n",
       "  '0.9780294895172119',\n",
       "  '0.9780864119529724',\n",
       "  '0.9781153798103333',\n",
       "  '0.9782226085662842',\n",
       "  '0.9787148237228394',\n",
       "  '0.978445827960968',\n",
       "  '0.9785471558570862',\n",
       "  '0.9786204099655151',\n",
       "  '0.9786542654037476',\n",
       "  '0.9785309433937073',\n",
       "  '0.9782592058181763',\n",
       "  '0.9786441922187805',\n",
       "  '0.9787688255310059',\n",
       "  '0.9787797927856445',\n",
       "  '0.9787973165512085',\n",
       "  '0.9787039756774902',\n",
       "  '0.9791632890701294',\n",
       "  '0.9791553020477295',\n",
       "  '0.9791326522827148',\n",
       "  '0.9792844653129578',\n",
       "  '0.9794207811355591',\n",
       "  '0.9793580770492554',\n",
       "  '0.9793590903282166',\n",
       "  '0.9795582294464111',\n",
       "  '0.9795344471931458',\n",
       "  '0.979561448097229',\n",
       "  '0.9796355962753296',\n",
       "  '0.9798083901405334',\n",
       "  '0.9797418117523193',\n",
       "  '0.9797506332397461',\n",
       "  '0.9799708724021912',\n",
       "  '0.9800202250480652',\n",
       "  '0.9800269603729248',\n",
       "  '0.9801899194717407',\n",
       "  '0.9801005721092224',\n",
       "  '0.9801856875419617',\n",
       "  '0.9802607893943787',\n",
       "  '0.9803922772407532',\n",
       "  '0.9802834391593933',\n",
       "  '0.9805747270584106',\n",
       "  '0.9804979562759399',\n",
       "  '0.9806556701660156',\n",
       "  '0.9806439876556396',\n",
       "  '0.9806972742080688',\n",
       "  '0.9806175827980042',\n",
       "  '0.9806070327758789',\n",
       "  '0.9807417988777161',\n",
       "  '0.9805643558502197',\n",
       "  '0.9810113310813904',\n",
       "  '0.9811404943466187',\n",
       "  '0.9808997511863708',\n",
       "  '0.9810243844985962',\n",
       "  '0.9812046885490417',\n",
       "  '0.9810690879821777',\n",
       "  '0.981246829032898',\n",
       "  '0.9811863899230957',\n",
       "  '0.9813365936279297',\n",
       "  '0.9812892079353333',\n",
       "  '0.9815109372138977',\n",
       "  '0.981141984462738',\n",
       "  '0.9812327027320862',\n",
       "  '0.9812033176422119',\n",
       "  '0.9811924695968628',\n",
       "  '0.9815382957458496',\n",
       "  '0.9817559123039246',\n",
       "  '0.9815459847450256',\n",
       "  '0.9817598462104797',\n",
       "  '0.9818880558013916',\n",
       "  '0.9819789528846741',\n",
       "  '0.9821243286132812',\n",
       "  '0.9820603132247925',\n",
       "  '0.9820519685745239',\n",
       "  '0.9819716215133667',\n",
       "  '0.9818881154060364',\n",
       "  '0.9822754859924316',\n",
       "  '0.9821773767471313',\n",
       "  '0.9823257327079773',\n",
       "  '0.982252836227417',\n",
       "  '0.982466459274292',\n",
       "  '0.9822307825088501',\n",
       "  '0.9822655916213989',\n",
       "  '0.9824095368385315',\n",
       "  '0.982567310333252',\n",
       "  '0.9826000928878784',\n",
       "  '0.9824233055114746',\n",
       "  '0.982694149017334',\n",
       "  '0.9827558994293213',\n",
       "  '0.9827830791473389'],\n",
       " 'val_binary_iou': ['0.6967154741287231',\n",
       "  '0.7352555990219116',\n",
       "  '0.7283757328987122',\n",
       "  '0.7072028517723083',\n",
       "  '0.701651930809021',\n",
       "  '0.7289546728134155',\n",
       "  '0.7504729628562927',\n",
       "  '0.7869912385940552',\n",
       "  '0.7504804134368896',\n",
       "  '0.6692835092544556',\n",
       "  '0.799962043762207',\n",
       "  '0.7830523252487183',\n",
       "  '0.7750580310821533',\n",
       "  '0.7304768562316895',\n",
       "  '0.7515079975128174',\n",
       "  '0.7282230257987976',\n",
       "  '0.6940493583679199',\n",
       "  '0.7969772815704346',\n",
       "  '0.7984521389007568',\n",
       "  '0.7518163919448853',\n",
       "  '0.7643896341323853',\n",
       "  '0.7456974983215332',\n",
       "  '0.7577053308486938',\n",
       "  '0.7190448045730591',\n",
       "  '0.7402808666229248',\n",
       "  '0.745721161365509',\n",
       "  '0.7498765587806702',\n",
       "  '0.7555123567581177',\n",
       "  '0.7423769235610962',\n",
       "  '0.7744722962379456',\n",
       "  '0.7800848484039307',\n",
       "  '0.7575598955154419',\n",
       "  '0.7758088707923889',\n",
       "  '0.7599557638168335',\n",
       "  '0.7625356912612915',\n",
       "  '0.779231071472168',\n",
       "  '0.7680887579917908',\n",
       "  '0.7669703960418701',\n",
       "  '0.783979594707489',\n",
       "  '0.7748888731002808',\n",
       "  '0.7713758945465088',\n",
       "  '0.7611948251724243',\n",
       "  '0.749262809753418',\n",
       "  '0.7585374712944031',\n",
       "  '0.7918010354042053',\n",
       "  '0.7685357332229614',\n",
       "  '0.7656505107879639',\n",
       "  '0.7731005549430847',\n",
       "  '0.7723791599273682',\n",
       "  '0.8054614067077637',\n",
       "  '0.7809540033340454',\n",
       "  '0.7883769273757935',\n",
       "  '0.7911272644996643',\n",
       "  '0.8025419116020203',\n",
       "  '0.7978577613830566',\n",
       "  '0.7751379013061523',\n",
       "  '0.7940295934677124',\n",
       "  '0.8021144270896912',\n",
       "  '0.7807443141937256',\n",
       "  '0.7773395776748657',\n",
       "  '0.7936707139015198',\n",
       "  '0.8045529127120972',\n",
       "  '0.7957438230514526',\n",
       "  '0.7943081259727478',\n",
       "  '0.8034619092941284',\n",
       "  '0.8026022911071777',\n",
       "  '0.7993482351303101',\n",
       "  '0.8007103800773621',\n",
       "  '0.7839406728744507',\n",
       "  '0.7757952213287354',\n",
       "  '0.7893651723861694',\n",
       "  '0.7928259372711182',\n",
       "  '0.8001554012298584',\n",
       "  '0.8033041954040527',\n",
       "  '0.7862776517868042',\n",
       "  '0.793936014175415',\n",
       "  '0.7949930429458618',\n",
       "  '0.791543185710907',\n",
       "  '0.7874499559402466',\n",
       "  '0.809036374092102',\n",
       "  '0.8137847185134888',\n",
       "  '0.7961822748184204',\n",
       "  '0.8010764718055725',\n",
       "  '0.803890585899353',\n",
       "  '0.7912968397140503',\n",
       "  '0.8115648627281189',\n",
       "  '0.8119277358055115',\n",
       "  '0.8141613602638245',\n",
       "  '0.8019356727600098',\n",
       "  '0.7830171585083008',\n",
       "  '0.798548698425293',\n",
       "  '0.7832310199737549',\n",
       "  '0.7997206449508667',\n",
       "  '0.8020412921905518',\n",
       "  '0.8084969520568848',\n",
       "  '0.8081687688827515',\n",
       "  '0.8115149736404419',\n",
       "  '0.8024887442588806',\n",
       "  '0.8117283582687378',\n",
       "  '0.8094222545623779',\n",
       "  '0.8053032159805298',\n",
       "  '0.8013923764228821',\n",
       "  '0.8177619576454163',\n",
       "  '0.8097795248031616',\n",
       "  '0.8157662153244019',\n",
       "  '0.8095352649688721',\n",
       "  '0.8082374334335327',\n",
       "  '0.8140619397163391',\n",
       "  '0.8057242631912231',\n",
       "  '0.8058465719223022',\n",
       "  '0.8049204349517822',\n",
       "  '0.8020786046981812',\n",
       "  '0.8071545362472534',\n",
       "  '0.8124215602874756',\n",
       "  '0.809497594833374',\n",
       "  '0.8093163967132568',\n",
       "  '0.808013916015625',\n",
       "  '0.8051018714904785',\n",
       "  '0.814984917640686',\n",
       "  '0.8084009885787964',\n",
       "  '0.8121891021728516',\n",
       "  '0.8150467872619629',\n",
       "  '0.8129895925521851',\n",
       "  '0.8162726163864136',\n",
       "  '0.8101503849029541',\n",
       "  '0.808282196521759',\n",
       "  '0.8097876310348511',\n",
       "  '0.8135617971420288',\n",
       "  '0.8116140365600586',\n",
       "  '0.8113645911216736',\n",
       "  '0.8065460324287415',\n",
       "  '0.816750168800354',\n",
       "  '0.814214825630188',\n",
       "  '0.8138250112533569',\n",
       "  '0.8155183792114258',\n",
       "  '0.8101277351379395',\n",
       "  '0.8125179409980774',\n",
       "  '0.8113994598388672',\n",
       "  '0.8075441122055054',\n",
       "  '0.8103611469268799',\n",
       "  '0.8137588500976562',\n",
       "  '0.8105100989341736',\n",
       "  '0.8155444860458374',\n",
       "  '0.8148764371871948',\n",
       "  '0.8182160258293152',\n",
       "  '0.8127116560935974',\n",
       "  '0.8154093027114868',\n",
       "  '0.8120075464248657',\n",
       "  '0.8075240850448608',\n",
       "  '0.8145487308502197',\n",
       "  '0.8150507211685181',\n",
       "  '0.8148412108421326',\n",
       "  '0.8137015700340271',\n",
       "  '0.8153181672096252',\n",
       "  '0.8133596181869507',\n",
       "  '0.8129698038101196',\n",
       "  '0.8177893161773682',\n",
       "  '0.818024218082428',\n",
       "  '0.8114784955978394',\n",
       "  '0.8142521381378174',\n",
       "  '0.8148083686828613',\n",
       "  '0.8104604482650757',\n",
       "  '0.8068940043449402',\n",
       "  '0.8147063255310059',\n",
       "  '0.8174810409545898',\n",
       "  '0.8112038373947144',\n",
       "  '0.8082543611526489',\n",
       "  '0.8102136850357056',\n",
       "  '0.8157415986061096',\n",
       "  '0.810924768447876',\n",
       "  '0.8167648315429688',\n",
       "  '0.8185654878616333',\n",
       "  '0.8159568309783936',\n",
       "  '0.8182584047317505',\n",
       "  '0.8143084049224854',\n",
       "  '0.8137122392654419',\n",
       "  '0.8123931884765625',\n",
       "  '0.8163043260574341',\n",
       "  '0.8120450973510742',\n",
       "  '0.8137015104293823',\n",
       "  '0.8144283294677734',\n",
       "  '0.8132280707359314',\n",
       "  '0.8105040192604065',\n",
       "  '0.8122310638427734',\n",
       "  '0.8189541697502136',\n",
       "  '0.8134002685546875',\n",
       "  '0.8154067993164062',\n",
       "  '0.8193738460540771',\n",
       "  '0.8148969411849976',\n",
       "  '0.8104338645935059',\n",
       "  '0.8068288564682007',\n",
       "  '0.8168461322784424',\n",
       "  '0.8176761269569397',\n",
       "  '0.8188024759292603',\n",
       "  '0.8162839412689209',\n",
       "  '0.8119697570800781',\n",
       "  '0.8179870843887329',\n",
       "  '0.8112662434577942',\n",
       "  '0.8151825666427612',\n",
       "  '0.8134429454803467',\n",
       "  '0.8123361468315125',\n",
       "  '0.811632513999939',\n",
       "  '0.8169282674789429',\n",
       "  '0.8214859962463379',\n",
       "  '0.8189995884895325',\n",
       "  '0.8200896978378296',\n",
       "  '0.814601480960846',\n",
       "  '0.8194261789321899',\n",
       "  '0.813915491104126',\n",
       "  '0.8146827220916748',\n",
       "  '0.8157861232757568',\n",
       "  '0.8159006834030151',\n",
       "  '0.8198785781860352',\n",
       "  '0.8173830509185791',\n",
       "  '0.8171799182891846',\n",
       "  '0.808740496635437',\n",
       "  '0.8155840635299683',\n",
       "  '0.8123694658279419',\n",
       "  '0.8169243335723877',\n",
       "  '0.8164654970169067',\n",
       "  '0.8153438568115234',\n",
       "  '0.8174383640289307',\n",
       "  '0.8123666048049927',\n",
       "  '0.8164288401603699',\n",
       "  '0.8163049221038818',\n",
       "  '0.820013701915741',\n",
       "  '0.8145298957824707',\n",
       "  '0.8078068494796753',\n",
       "  '0.8177846670150757',\n",
       "  '0.8115624189376831',\n",
       "  '0.8159373998641968',\n",
       "  '0.8144282102584839',\n",
       "  '0.8217519521713257',\n",
       "  '0.8173494338989258',\n",
       "  '0.8214167356491089',\n",
       "  '0.8171262741088867',\n",
       "  '0.8119842410087585',\n",
       "  '0.8179681301116943',\n",
       "  '0.818719744682312',\n",
       "  '0.8190338611602783',\n",
       "  '0.8160821199417114',\n",
       "  '0.8132522106170654',\n",
       "  '0.8151975870132446',\n",
       "  '0.8186101913452148',\n",
       "  '0.8170602321624756',\n",
       "  '0.8177815675735474',\n",
       "  '0.8194594383239746',\n",
       "  '0.8171494007110596',\n",
       "  '0.815092921257019',\n",
       "  '0.8152129054069519',\n",
       "  '0.8194885849952698',\n",
       "  '0.8185970783233643',\n",
       "  '0.8226210474967957',\n",
       "  '0.8182144165039062',\n",
       "  '0.81792151927948',\n",
       "  '0.8164290189743042',\n",
       "  '0.8180030584335327',\n",
       "  '0.8182449340820312',\n",
       "  '0.8194875717163086',\n",
       "  '0.8199233412742615',\n",
       "  '0.8181396722793579',\n",
       "  '0.8208634853363037',\n",
       "  '0.8186273574829102',\n",
       "  '0.8196486830711365',\n",
       "  '0.8194745779037476',\n",
       "  '0.8179353475570679',\n",
       "  '0.8214128017425537',\n",
       "  '0.8180422782897949',\n",
       "  '0.8212970495223999',\n",
       "  '0.8170655965805054',\n",
       "  '0.8248006105422974',\n",
       "  '0.8192065954208374',\n",
       "  '0.8192009925842285',\n",
       "  '0.8181326389312744',\n",
       "  '0.8178730010986328',\n",
       "  '0.8203117251396179',\n",
       "  '0.820813775062561',\n",
       "  '0.819591760635376',\n",
       "  '0.8198810815811157',\n",
       "  '0.8195486068725586',\n",
       "  '0.8182732462882996',\n",
       "  '0.8187543153762817',\n",
       "  '0.817524254322052',\n",
       "  '0.816595196723938',\n",
       "  '0.8186025023460388',\n",
       "  '0.8182612061500549',\n",
       "  '0.8183460235595703',\n",
       "  '0.8200847506523132',\n",
       "  '0.8187344670295715',\n",
       "  '0.8219387531280518',\n",
       "  '0.821594774723053',\n",
       "  '0.8181982040405273',\n",
       "  '0.8200022578239441',\n",
       "  '0.8153705596923828',\n",
       "  '0.8171155452728271',\n",
       "  '0.820353627204895',\n",
       "  '0.8157865405082703',\n",
       "  '0.8160750865936279',\n",
       "  '0.817660927772522',\n",
       "  '0.8187786340713501',\n",
       "  '0.8135436773300171']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file1 = \"C:/Users/manue/OneDrive/Desktop/THESIS_NEU/output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_I.log\"\n",
    "csv_file2 = \"C:/Users/manue/OneDrive/Desktop/THESIS_NEU/output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False.log\"\n",
    "\n",
    "def parse_csv_to_dict(file_path):\n",
    "    data = {}\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            for key, value in row.items():\n",
    "                if key in data:\n",
    "                    data[key].append(value)\n",
    "                else:\n",
    "                    data[key] = [value]\n",
    "    return data\n",
    "\n",
    "\n",
    "# CSV-Datei als Dictionary parsen\n",
    "csv_data1 = parse_csv_to_dict(csv_file1)\n",
    "csv_data2 = parse_csv_to_dict(csv_file2)\n",
    "csv_data2.pop('epoch')\n",
    "\n",
    "\n",
    "def merge_dictionaries(dict1, dict2):\n",
    "    merged_dict = {}\n",
    "    keys = set(dict1.keys()) | set(dict2.keys())\n",
    "    for key in keys:\n",
    "        merged_dict[key] = dict1.get(key, []) + dict2.get(key, [])\n",
    "    return merged_dict\n",
    "\n",
    "# Beispiel-Dictionaries\n",
    "dict1 = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "dict2 = {'A': [7, 8, 9], 'C': [10, 11, 12]}\n",
    "\n",
    "# Fusionieren der Dictionaries\n",
    "merged_dict = merge_dictionaries(csv_data1, csv_data2)\n",
    "\n",
    "# Ausgabe des fusionierten Dictionaries\n",
    "merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        headers = ['Keys'] + list(data.keys())\n",
    "        writer.writerow(headers)\n",
    "        max_len = max(len(values) for values in data.values())\n",
    "        for i in range(max_len):\n",
    "            row = [i] + [data[key][i] if i < len(data[key]) else '' for key in data.keys()]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def write_dict_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        headers = list(data.keys())\n",
    "        writer.writerow(['Keys'] + headers)\n",
    "        max_len = max(len(values) for values in data.values())\n",
    "        for i in range(max_len):\n",
    "            row = [data[key][i] if i < len(data[key]) else '' for key in headers]\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Schreibe das Dictionary in die CSV-Datei\n",
    "write_dict_to_csv(csv_file, data)\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "combi_file = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "# Schreibe das Dictionary in die CSV-Datei\n",
    "write_dict_to_csv(combi_file, merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_file = '../output/final_runs_logger/Final_AVG_rgbDrop_0.2_earlyStop_False_COMBI.log'\n",
    "\n",
    "dict_data = merged_dict\n",
    "\n",
    "with open(combi_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['loss', 'accuracy', 'binary_iou', 'true_positives', 'false_positives', 'true_negatives',\n",
    "                    'false_negatives', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_binary_iou', \n",
    "                    'val_true_positives', 'val_false_positives', 'val_true_negatives', 'val_false_negatives', \n",
    "                    'val_precision', 'val_recall']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(20):\n",
    "        writer.writerow({'loss': dict_data['loss'][i], 'accuracy': dict_data['accuracy'][i], 'binary_iou': dict_data['binary_iou'][i], 'true_positives': dict_data['true_positives'][i],\n",
    "                        'false_positives': dict_data['false_positives'][i], 'true_negatives': dict_data['true_negatives'][i], 'false_negatives': dict_data['false_negatives'][i],\n",
    "                        'precision': dict_data['precision'][i], 'recall': dict_data['recall'][i], 'val_loss': dict_data['val_loss'][i], 'val_accuracy': dict_data['val_accuracy'][i],\n",
    "                        'val_binary_iou': dict_data['val_binary_iou'][i], 'val_true_positives': dict_data['val_true_positives'][i], 'val_false_positives': dict_data['val_false_positives'][i],\n",
    "                        'val_true_negatives': dict_data['val_true_negatives'][i], 'val_false_negatives': dict_data['val_false_negatives'][i], 'val_precision': dict_data['val_precision'][i],\n",
    "                        'val_recall': dict_data['val_recall'][i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
