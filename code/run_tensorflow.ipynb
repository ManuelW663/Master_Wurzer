{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auszuführen mit Environment \"tf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importe & Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufällige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            # Transformation in \"channels_last\"-Format\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            # Erstellen einer zusätzlichen Achse um Tensor-Dimension zu erreichen\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            # Skalierung der Werte\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "# Definition des Dice-Koeffizienten\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "# Ableitung einer zu minimierenden Loss-Funktion aus Dice-Koeffzient\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Rückgängig machen der Normalisierung zur korrekten Anzeige der Bilder\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    # Speicherpfade der verschiedenen Architekturen\n",
    "    model_dict = {\n",
    "        'BASIC': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    # Auswahl der Architektur entsprechend der verwendeten Variante\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    # Laden der JSON\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    # Laden des Modells aus JSON\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulässt, werden immer die selben zufällig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    # entsprechend der Variante müssen Gewichte unterschiedlich gesetzt werden\n",
    "    if model_type == 'BASIC':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "\n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte können übernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte zufällig\n",
    "    if option == 'RNDM_IR':\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren über geladene Gewichte und zufällige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Für 1. Conv-Layer stimmt shape nicht überein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte für RGB-Channel werden übernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen überein und können übernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufügen der zufälligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zusätzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer für RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die später übersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere über Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden für diesen Layer, iteriere über diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese können daher nicht übernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # für die übrigen Layer werden die Gewichte übernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zufälligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM_IR':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind für erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'NO_TL':\n",
    "        # zufällige Gewichte für Durchlauf ohne TL\n",
    "        pass\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False, train_encoder_layers= 27):\n",
    "    # Anzahl der trainierbaren Encoder Layer rückwärts vom Bottleneck gezählt, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= train_encoder_layers\n",
    "\n",
    "    # Encoder bleibt größtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM_IR']:\n",
    "\n",
    "    # Für das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafür werden die Layer jetzt rückwärts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # für train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, output_folder_prefix, do_early_stop):\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{output_folder_prefix}_logger'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    if not os.path.isdir(logger_path):\n",
    "        os.makedirs(logger_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + f'/{model_name}.log')\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "    if do_early_stop:\n",
    "        early_stop =  tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_binary_iou',\n",
    "                    min_delta=0,\n",
    "                    patience=40,\n",
    "                    verbose=1,\n",
    "                    mode='max',\n",
    "                    )\n",
    "\n",
    "        callbacks.append(early_stop)  \n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def combine_log_files(output_folder_prefix, model_name):\n",
    "    # Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "    filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "    with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "        # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "        outfile.write('sep=,\\n')\n",
    "\n",
    "        for i, fname in enumerate(filenames):\n",
    "            with open(fname) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                for j, row in enumerate(reader):\n",
    "                    # überspringen des 2. Headers\n",
    "                    if i == 1 and j == 0:\n",
    "                        continue\n",
    "\n",
    "                    delimiter = ','\n",
    "                    list_to_string = delimiter.join(row)\n",
    "                    list_to_string += '\\n'\n",
    "\n",
    "                    outfile.write(list_to_string)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuchsreihe Freeze-From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.8022 - binary_iou: 0.6671 - true_positives: 111377872.0000 - false_positives: 43645320.0000 - true_negatives: 144931120.0000 - false_negatives: 19566386.0000 - precision: 0.7185 - recall: 0.8506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 94s 449ms/step - loss: 0.2400 - accuracy: 0.8022 - binary_iou: 0.6671 - true_positives: 111377872.0000 - false_positives: 43645320.0000 - true_negatives: 144931120.0000 - false_negatives: 19566386.0000 - precision: 0.7185 - recall: 0.8506 - val_loss: 0.2006 - val_accuracy: 0.8440 - val_binary_iou: 0.7237 - val_true_positives: 35357640.0000 - val_false_positives: 6852445.0000 - val_true_negatives: 54083696.0000 - val_false_negatives: 9677936.0000 - val_precision: 0.8377 - val_recall: 0.7851\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.8555 - binary_iou: 0.7427 - true_positives: 111802440.0000 - false_positives: 26927672.0000 - true_negatives: 161534528.0000 - false_negatives: 19256160.0000 - precision: 0.8059 - recall: 0.8531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1737 - accuracy: 0.8555 - binary_iou: 0.7427 - true_positives: 111802440.0000 - false_positives: 26927672.0000 - true_negatives: 161534528.0000 - false_negatives: 19256160.0000 - precision: 0.8059 - recall: 0.8531 - val_loss: 0.1565 - val_accuracy: 0.8635 - val_binary_iou: 0.7579 - val_true_positives: 40303392.0000 - val_false_positives: 9610437.0000 - val_true_negatives: 51207832.0000 - val_false_negatives: 4850052.0000 - val_precision: 0.8075 - val_recall: 0.8926\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.8672 - binary_iou: 0.7608 - true_positives: 113062864.0000 - false_positives: 24359546.0000 - true_negatives: 164030768.0000 - false_negatives: 18067520.0000 - precision: 0.8227 - recall: 0.8622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1601 - accuracy: 0.8672 - binary_iou: 0.7608 - true_positives: 113062864.0000 - false_positives: 24359546.0000 - true_negatives: 164030768.0000 - false_negatives: 18067520.0000 - precision: 0.8227 - recall: 0.8622 - val_loss: 0.1485 - val_accuracy: 0.8751 - val_binary_iou: 0.7742 - val_true_positives: 38699984.0000 - val_false_positives: 6808984.0000 - val_true_negatives: 54036824.0000 - val_false_negatives: 6425922.0000 - val_precision: 0.8504 - val_recall: 0.8576\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.8766 - binary_iou: 0.7755 - true_positives: 113719704.0000 - false_positives: 22027396.0000 - true_negatives: 166374912.0000 - false_negatives: 17398814.0000 - precision: 0.8377 - recall: 0.8673"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 446ms/step - loss: 0.1495 - accuracy: 0.8766 - binary_iou: 0.7755 - true_positives: 113719704.0000 - false_positives: 22027396.0000 - true_negatives: 166374912.0000 - false_negatives: 17398814.0000 - precision: 0.8377 - recall: 0.8673 - val_loss: 0.1366 - val_accuracy: 0.8823 - val_binary_iou: 0.7867 - val_true_positives: 40125768.0000 - val_false_positives: 7566010.0000 - val_true_negatives: 53372264.0000 - val_false_negatives: 4907679.0000 - val_precision: 0.8414 - val_recall: 0.8910\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.1400 - accuracy: 0.8849 - binary_iou: 0.7888 - true_positives: 114583840.0000 - false_positives: 20180960.0000 - true_negatives: 168168832.0000 - false_negatives: 16587126.0000 - precision: 0.8503 - recall: 0.8735 - val_loss: 0.1375 - val_accuracy: 0.8763 - val_binary_iou: 0.7783 - val_true_positives: 41597064.0000 - val_false_positives: 9623798.0000 - val_true_negatives: 51261432.0000 - val_false_negatives: 3489414.0000 - val_precision: 0.8121 - val_recall: 0.9226\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.8888 - binary_iou: 0.7951 - true_positives: 115265664.0000 - false_positives: 19728242.0000 - true_negatives: 168710672.0000 - false_negatives: 15816170.0000 - precision: 0.8539 - recall: 0.8793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1353 - accuracy: 0.8888 - binary_iou: 0.7951 - true_positives: 115265664.0000 - false_positives: 19728242.0000 - true_negatives: 168710672.0000 - false_negatives: 15816170.0000 - precision: 0.8539 - recall: 0.8793 - val_loss: 0.1316 - val_accuracy: 0.8888 - val_binary_iou: 0.7967 - val_true_positives: 39750280.0000 - val_false_positives: 6433953.0000 - val_true_negatives: 54437632.0000 - val_false_negatives: 5349834.0000 - val_precision: 0.8607 - val_recall: 0.8814\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.8903 - binary_iou: 0.7976 - true_positives: 115200072.0000 - false_positives: 19051996.0000 - true_negatives: 169263744.0000 - false_negatives: 16004990.0000 - precision: 0.8581 - recall: 0.8780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 452ms/step - loss: 0.1336 - accuracy: 0.8903 - binary_iou: 0.7976 - true_positives: 115200072.0000 - false_positives: 19051996.0000 - true_negatives: 169263744.0000 - false_negatives: 16004990.0000 - precision: 0.8581 - recall: 0.8780 - val_loss: 0.1286 - val_accuracy: 0.8934 - val_binary_iou: 0.8035 - val_true_positives: 39051092.0000 - val_false_positives: 5160435.0000 - val_true_negatives: 55628372.0000 - val_false_negatives: 6131805.0000 - val_precision: 0.8833 - val_recall: 0.8643\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.1253 - accuracy: 0.8976 - binary_iou: 0.8095 - true_positives: 115636968.0000 - false_positives: 17214546.0000 - true_negatives: 171176688.0000 - false_negatives: 15492618.0000 - precision: 0.8704 - recall: 0.8819 - val_loss: 0.1256 - val_accuracy: 0.8899 - val_binary_iou: 0.7996 - val_true_positives: 41209836.0000 - val_false_positives: 7741861.0000 - val_true_negatives: 53091812.0000 - val_false_negatives: 3928214.0000 - val_precision: 0.8418 - val_recall: 0.9130\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9006 - binary_iou: 0.8145 - true_positives: 116114408.0000 - false_positives: 16775546.0000 - true_negatives: 171644464.0000 - false_negatives: 14986298.0000 - precision: 0.8738 - recall: 0.8857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 92s 462ms/step - loss: 0.1219 - accuracy: 0.9006 - binary_iou: 0.8145 - true_positives: 116114408.0000 - false_positives: 16775546.0000 - true_negatives: 171644464.0000 - false_negatives: 14986298.0000 - precision: 0.8738 - recall: 0.8857 - val_loss: 0.1249 - val_accuracy: 0.8979 - val_binary_iou: 0.8101 - val_true_positives: 38469368.0000 - val_false_positives: 4279634.0000 - val_true_negatives: 56682172.0000 - val_false_negatives: 6540547.0000 - val_precision: 0.8999 - val_recall: 0.8547\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.8996 - binary_iou: 0.8131 - true_positives: 116461112.0000 - false_positives: 17430352.0000 - true_negatives: 170988576.0000 - false_negatives: 14640734.0000 - precision: 0.8698 - recall: 0.8883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1228 - accuracy: 0.8996 - binary_iou: 0.8131 - true_positives: 116461112.0000 - false_positives: 17430352.0000 - true_negatives: 170988576.0000 - false_negatives: 14640734.0000 - precision: 0.8698 - recall: 0.8883 - val_loss: 0.1213 - val_accuracy: 0.8970 - val_binary_iou: 0.8102 - val_true_positives: 40168464.0000 - val_false_positives: 5990550.0000 - val_true_negatives: 54883768.0000 - val_false_negatives: 4928941.0000 - val_precision: 0.8702 - val_recall: 0.8907\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9014 - binary_iou: 0.8159 - true_positives: 116607696.0000 - false_positives: 17090800.0000 - true_negatives: 171393328.0000 - false_negatives: 14428945.0000 - precision: 0.8722 - recall: 0.8899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 452ms/step - loss: 0.1210 - accuracy: 0.9014 - binary_iou: 0.8159 - true_positives: 116607696.0000 - false_positives: 17090800.0000 - true_negatives: 171393328.0000 - false_negatives: 14428945.0000 - precision: 0.8722 - recall: 0.8899 - val_loss: 0.1173 - val_accuracy: 0.9038 - val_binary_iou: 0.8204 - val_true_positives: 39029660.0000 - val_false_positives: 4081647.0000 - val_true_negatives: 56750732.0000 - val_false_negatives: 6109670.0000 - val_precision: 0.9053 - val_recall: 0.8646\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.1122 - accuracy: 0.9087 - binary_iou: 0.8284 - true_positives: 117420608.0000 - false_positives: 15433328.0000 - true_negatives: 172938240.0000 - false_negatives: 13728626.0000 - precision: 0.8838 - recall: 0.8953 - val_loss: 0.1210 - val_accuracy: 0.9006 - val_binary_iou: 0.8151 - val_true_positives: 39091728.0000 - val_false_positives: 4593835.0000 - val_true_negatives: 56347336.0000 - val_false_negatives: 5938806.0000 - val_precision: 0.8948 - val_recall: 0.8681\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9088 - binary_iou: 0.8286 - true_positives: 117401800.0000 - false_positives: 15336215.0000 - true_negatives: 172990944.0000 - false_negatives: 13791798.0000 - precision: 0.8845 - recall: 0.8949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 455ms/step - loss: 0.1116 - accuracy: 0.9088 - binary_iou: 0.8286 - true_positives: 117401800.0000 - false_positives: 15336215.0000 - true_negatives: 172990944.0000 - false_negatives: 13791798.0000 - precision: 0.8845 - recall: 0.8949 - val_loss: 0.1145 - val_accuracy: 0.9034 - val_binary_iou: 0.8209 - val_true_positives: 40400736.0000 - val_false_positives: 5538401.0000 - val_true_negatives: 55338104.0000 - val_false_negatives: 4694466.0000 - val_precision: 0.8794 - val_recall: 0.8959\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.1094 - accuracy: 0.9111 - binary_iou: 0.8323 - true_positives: 117309120.0000 - false_positives: 14614323.0000 - true_negatives: 173812112.0000 - false_negatives: 13785187.0000 - precision: 0.8892 - recall: 0.8948 - val_loss: 0.1193 - val_accuracy: 0.9025 - val_binary_iou: 0.8179 - val_true_positives: 38781592.0000 - val_false_positives: 3957391.0000 - val_true_negatives: 56858720.0000 - val_false_negatives: 6374010.0000 - val_precision: 0.9074 - val_recall: 0.8588\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9131 - binary_iou: 0.8358 - true_positives: 117873576.0000 - false_positives: 14501682.0000 - true_negatives: 173882944.0000 - false_negatives: 13262614.0000 - precision: 0.8905 - recall: 0.8989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 447ms/step - loss: 0.1069 - accuracy: 0.9131 - binary_iou: 0.8358 - true_positives: 117873576.0000 - false_positives: 14501682.0000 - true_negatives: 173882944.0000 - false_negatives: 13262614.0000 - precision: 0.8905 - recall: 0.8989 - val_loss: 0.1137 - val_accuracy: 0.9037 - val_binary_iou: 0.8217 - val_true_positives: 40798136.0000 - val_false_positives: 5933828.0000 - val_true_negatives: 54969904.0000 - val_false_negatives: 4269842.0000 - val_precision: 0.8730 - val_recall: 0.9053\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.1052 - accuracy: 0.9144 - binary_iou: 0.8381 - true_positives: 118135560.0000 - false_positives: 14382700.0000 - true_negatives: 174035696.0000 - false_negatives: 12966778.0000 - precision: 0.8915 - recall: 0.9011 - val_loss: 0.1232 - val_accuracy: 0.8908 - val_binary_iou: 0.8016 - val_true_positives: 41979040.0000 - val_false_positives: 8456584.0000 - val_true_negatives: 52422936.0000 - val_false_negatives: 3113146.0000 - val_precision: 0.8323 - val_recall: 0.9310\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.1027 - accuracy: 0.9165 - binary_iou: 0.8417 - true_positives: 118314384.0000 - false_positives: 13824599.0000 - true_negatives: 174535360.0000 - false_negatives: 12846381.0000 - precision: 0.8954 - recall: 0.9021 - val_loss: 0.1157 - val_accuracy: 0.9024 - val_binary_iou: 0.8189 - val_true_positives: 40152660.0000 - val_false_positives: 5370570.0000 - val_true_negatives: 55471756.0000 - val_false_negatives: 4976709.0000 - val_precision: 0.8820 - val_recall: 0.8897\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9170 - binary_iou: 0.8424 - true_positives: 118064944.0000 - false_positives: 13445368.0000 - true_negatives: 174921408.0000 - false_negatives: 13088996.0000 - precision: 0.8978 - recall: 0.9002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 88s 443ms/step - loss: 0.1024 - accuracy: 0.9170 - binary_iou: 0.8424 - true_positives: 118064944.0000 - false_positives: 13445368.0000 - true_negatives: 174921408.0000 - false_negatives: 13088996.0000 - precision: 0.8978 - recall: 0.9002 - val_loss: 0.1118 - val_accuracy: 0.9054 - val_binary_iou: 0.8244 - val_true_positives: 40711516.0000 - val_false_positives: 5614468.0000 - val_true_negatives: 55237480.0000 - val_false_negatives: 4408241.0000 - val_precision: 0.8788 - val_recall: 0.9023\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.1015 - accuracy: 0.9177 - binary_iou: 0.8437 - true_positives: 118455016.0000 - false_positives: 13531825.0000 - true_negatives: 174755648.0000 - false_negatives: 12778274.0000 - precision: 0.8975 - recall: 0.9026 - val_loss: 0.1125 - val_accuracy: 0.9052 - val_binary_iou: 0.8241 - val_true_positives: 40700396.0000 - val_false_positives: 5695036.0000 - val_true_negatives: 55225908.0000 - val_false_negatives: 4350372.0000 - val_precision: 0.8773 - val_recall: 0.9034\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9220 - binary_iou: 0.8512 - true_positives: 118882216.0000 - false_positives: 12713193.0000 - true_negatives: 175704032.0000 - false_negatives: 12221376.0000 - precision: 0.9034 - recall: 0.9068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0966 - accuracy: 0.9220 - binary_iou: 0.8512 - true_positives: 118882216.0000 - false_positives: 12713193.0000 - true_negatives: 175704032.0000 - false_negatives: 12221376.0000 - precision: 0.9034 - recall: 0.9068 - val_loss: 0.1097 - val_accuracy: 0.9074 - val_binary_iou: 0.8275 - val_true_positives: 40447432.0000 - val_false_positives: 5165293.0000 - val_true_negatives: 55711168.0000 - val_false_negatives: 4647815.0000 - val_precision: 0.8868 - val_recall: 0.8969\n",
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2  trainable:  True  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9271 - binary_iou: 0.8602 - true_positives: 119460704.0000 - false_positives: 11650622.0000 - true_negatives: 176767600.0000 - false_negatives: 11641884.0000 - precision: 0.9111 - recall: 0.9112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 96s 461ms/step - loss: 0.0900 - accuracy: 0.9271 - binary_iou: 0.8602 - true_positives: 119460704.0000 - false_positives: 11650622.0000 - true_negatives: 176767600.0000 - false_negatives: 11641884.0000 - precision: 0.9111 - recall: 0.9112 - val_loss: 0.1076 - val_accuracy: 0.9103 - val_binary_iou: 0.8325 - val_true_positives: 40545612.0000 - val_false_positives: 4957550.0000 - val_true_negatives: 55925128.0000 - val_false_negatives: 4543439.0000 - val_precision: 0.8911 - val_recall: 0.8992\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9311 - binary_iou: 0.8673 - true_positives: 120062800.0000 - false_positives: 10999991.0000 - true_negatives: 177433536.0000 - false_negatives: 11024424.0000 - precision: 0.9161 - recall: 0.9159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0853 - accuracy: 0.9311 - binary_iou: 0.8673 - true_positives: 120062800.0000 - false_positives: 10999991.0000 - true_negatives: 177433536.0000 - false_negatives: 11024424.0000 - precision: 0.9161 - recall: 0.9159 - val_loss: 0.1061 - val_accuracy: 0.9113 - val_binary_iou: 0.8337 - val_true_positives: 40098216.0000 - val_false_positives: 4524053.0000 - val_true_negatives: 56472768.0000 - val_false_negatives: 4876666.0000 - val_precision: 0.8986 - val_recall: 0.8916\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0816 - accuracy: 0.9342 - binary_iou: 0.8729 - true_positives: 120622792.0000 - false_positives: 10475593.0000 - true_negatives: 177867392.0000 - false_negatives: 10555007.0000 - precision: 0.9201 - recall: 0.9195 - val_loss: 0.1099 - val_accuracy: 0.9100 - val_binary_iou: 0.8311 - val_true_positives: 39541620.0000 - val_false_positives: 3936358.0000 - val_true_negatives: 56893012.0000 - val_false_negatives: 5600733.0000 - val_precision: 0.9095 - val_recall: 0.8759\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9366 - binary_iou: 0.8773 - true_positives: 120938744.0000 - false_positives: 10039776.0000 - true_negatives: 178327200.0000 - false_negatives: 10215038.0000 - precision: 0.9233 - recall: 0.9221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0784 - accuracy: 0.9366 - binary_iou: 0.8773 - true_positives: 120938744.0000 - false_positives: 10039776.0000 - true_negatives: 178327200.0000 - false_negatives: 10215038.0000 - precision: 0.9233 - recall: 0.9221 - val_loss: 0.1052 - val_accuracy: 0.9115 - val_binary_iou: 0.8342 - val_true_positives: 40255140.0000 - val_false_positives: 4591130.0000 - val_true_negatives: 56337352.0000 - val_false_negatives: 4788082.0000 - val_precision: 0.8976 - val_recall: 0.8937\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0769 - accuracy: 0.9380 - binary_iou: 0.8797 - true_positives: 121115280.0000 - false_positives: 9783484.0000 - true_negatives: 178584288.0000 - false_negatives: 10037746.0000 - precision: 0.9253 - recall: 0.9235 - val_loss: 0.1074 - val_accuracy: 0.9112 - val_binary_iou: 0.8335 - val_true_positives: 40038360.0000 - val_false_positives: 4306358.0000 - val_true_negatives: 56522904.0000 - val_false_negatives: 5104102.0000 - val_precision: 0.9029 - val_recall: 0.8869\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9397 - binary_iou: 0.8829 - true_positives: 121223240.0000 - false_positives: 9443425.0000 - true_negatives: 179032464.0000 - false_negatives: 9821648.0000 - precision: 0.9277 - recall: 0.9251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0748 - accuracy: 0.9397 - binary_iou: 0.8829 - true_positives: 121223240.0000 - false_positives: 9443425.0000 - true_negatives: 179032464.0000 - false_negatives: 9821648.0000 - precision: 0.9277 - recall: 0.9251 - val_loss: 0.1058 - val_accuracy: 0.9118 - val_binary_iou: 0.8348 - val_true_positives: 40300380.0000 - val_false_positives: 4505862.0000 - val_true_negatives: 56328732.0000 - val_false_negatives: 4836719.0000 - val_precision: 0.8994 - val_recall: 0.8928\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9412 - binary_iou: 0.8856 - true_positives: 121625392.0000 - false_positives: 9271599.0000 - true_negatives: 179108288.0000 - false_negatives: 9515490.0000 - precision: 0.9292 - recall: 0.9274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/FT_Tests_checkpoints\\FT_Tests_AVG_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0731 - accuracy: 0.9412 - binary_iou: 0.8856 - true_positives: 121625392.0000 - false_positives: 9271599.0000 - true_negatives: 179108288.0000 - false_negatives: 9515490.0000 - precision: 0.9292 - recall: 0.9274 - val_loss: 0.1042 - val_accuracy: 0.9131 - val_binary_iou: 0.8370 - val_true_positives: 40366080.0000 - val_false_positives: 4460972.0000 - val_true_negatives: 56399096.0000 - val_false_negatives: 4745562.0000 - val_precision: 0.9005 - val_recall: 0.8948\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0717 - accuracy: 0.9423 - binary_iou: 0.8876 - true_positives: 121817784.0000 - false_positives: 9124325.0000 - true_negatives: 179263152.0000 - false_negatives: 9315550.0000 - precision: 0.9303 - recall: 0.9290 - val_loss: 0.1056 - val_accuracy: 0.9127 - val_binary_iou: 0.8358 - val_true_positives: 39801464.0000 - val_false_positives: 3964516.0000 - val_true_negatives: 56922376.0000 - val_false_negatives: 5283371.0000 - val_precision: 0.9094 - val_recall: 0.8828\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0697 - accuracy: 0.9438 - binary_iou: 0.8903 - true_positives: 122006208.0000 - false_positives: 8844629.0000 - true_negatives: 179548384.0000 - false_negatives: 9121615.0000 - precision: 0.9324 - recall: 0.9304 - val_loss: 0.1062 - val_accuracy: 0.9128 - val_binary_iou: 0.8361 - val_true_positives: 39951960.0000 - val_false_positives: 4079290.0000 - val_true_negatives: 56777008.0000 - val_false_negatives: 5163461.0000 - val_precision: 0.9074 - val_recall: 0.8856\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 76s 380ms/step - loss: 0.0681 - accuracy: 0.9451 - binary_iou: 0.8928 - true_positives: 122226496.0000 - false_positives: 8653576.0000 - true_negatives: 179749872.0000 - false_negatives: 8890869.0000 - precision: 0.9339 - recall: 0.9322 - val_loss: 0.1060 - val_accuracy: 0.9122 - val_binary_iou: 0.8352 - val_true_positives: 40094296.0000 - val_false_positives: 4292949.0000 - val_true_negatives: 56570756.0000 - val_false_negatives: 5013705.0000 - val_precision: 0.9033 - val_recall: 0.8889\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 75s 379ms/step - loss: 0.0668 - accuracy: 0.9463 - binary_iou: 0.8950 - true_positives: 122352896.0000 - false_positives: 8402666.0000 - true_negatives: 180003248.0000 - false_negatives: 8761975.0000 - precision: 0.9357 - recall: 0.9332 - val_loss: 0.1054 - val_accuracy: 0.9127 - val_binary_iou: 0.8360 - val_true_positives: 40027588.0000 - val_false_positives: 4180473.0000 - val_true_negatives: 56691084.0000 - val_false_negatives: 5072564.0000 - val_precision: 0.9054 - val_recall: 0.8875\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0659 - accuracy: 0.9472 - binary_iou: 0.8966 - true_positives: 122399632.0000 - false_positives: 8216112.0000 - true_negatives: 180235584.0000 - false_negatives: 8669515.0000 - precision: 0.9371 - recall: 0.9339 - val_loss: 0.1068 - val_accuracy: 0.9100 - val_binary_iou: 0.8321 - val_true_positives: 40759952.0000 - val_false_positives: 5145300.0000 - val_true_negatives: 55678120.0000 - val_false_negatives: 4388334.0000 - val_precision: 0.8879 - val_recall: 0.9028\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0644 - accuracy: 0.9480 - binary_iou: 0.8982 - true_positives: 122683376.0000 - false_positives: 8140681.0000 - true_negatives: 180238192.0000 - false_negatives: 8458531.0000 - precision: 0.9378 - recall: 0.9355 - val_loss: 0.1047 - val_accuracy: 0.9116 - val_binary_iou: 0.8347 - val_true_positives: 40640420.0000 - val_false_positives: 5003170.0000 - val_true_negatives: 55963956.0000 - val_false_negatives: 4364159.0000 - val_precision: 0.8904 - val_recall: 0.9030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 76s 382ms/step - loss: 0.0631 - accuracy: 0.9491 - binary_iou: 0.9002 - true_positives: 122734872.0000 - false_positives: 7901090.0000 - true_negatives: 180519008.0000 - false_negatives: 8365847.0000 - precision: 0.9395 - recall: 0.9362 - val_loss: 0.1055 - val_accuracy: 0.9127 - val_binary_iou: 0.8359 - val_true_positives: 39989432.0000 - val_false_positives: 4227143.0000 - val_true_negatives: 56725800.0000 - val_false_negatives: 5029325.0000 - val_precision: 0.9044 - val_recall: 0.8883\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0621 - accuracy: 0.9500 - binary_iou: 0.9018 - true_positives: 122856016.0000 - false_positives: 7717607.0000 - true_negatives: 180683024.0000 - false_negatives: 8264032.0000 - precision: 0.9409 - recall: 0.9370 - val_loss: 0.1054 - val_accuracy: 0.9125 - val_binary_iou: 0.8359 - val_true_positives: 40292968.0000 - val_false_positives: 4444217.0000 - val_true_negatives: 56410956.0000 - val_false_negatives: 4823558.0000 - val_precision: 0.9007 - val_recall: 0.8931\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0611 - accuracy: 0.9509 - binary_iou: 0.9036 - true_positives: 123040392.0000 - false_positives: 7605444.0000 - true_negatives: 180801792.0000 - false_negatives: 8073094.0000 - precision: 0.9418 - recall: 0.9384 - val_loss: 0.1044 - val_accuracy: 0.9127 - val_binary_iou: 0.8362 - val_true_positives: 40369888.0000 - val_false_positives: 4479326.0000 - val_true_negatives: 56347000.0000 - val_false_negatives: 4775492.0000 - val_precision: 0.9001 - val_recall: 0.8942\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0597 - accuracy: 0.9519 - binary_iou: 0.9054 - true_positives: 123202208.0000 - false_positives: 7461871.0000 - true_negatives: 180948000.0000 - false_negatives: 7908735.0000 - precision: 0.9429 - recall: 0.9397 - val_loss: 0.1061 - val_accuracy: 0.9130 - val_binary_iou: 0.8363 - val_true_positives: 39716208.0000 - val_false_positives: 3795177.0000 - val_true_negatives: 57039188.0000 - val_false_negatives: 5421130.0000 - val_precision: 0.9128 - val_recall: 0.8799\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0589 - accuracy: 0.9526 - binary_iou: 0.9067 - true_positives: 123215616.0000 - false_positives: 7291654.0000 - true_negatives: 181158224.0000 - false_negatives: 7855264.0000 - precision: 0.9441 - recall: 0.9401 - val_loss: 0.1052 - val_accuracy: 0.9122 - val_binary_iou: 0.8355 - val_true_positives: 40377696.0000 - val_false_positives: 4554107.0000 - val_true_negatives: 56293480.0000 - val_false_negatives: 4746435.0000 - val_precision: 0.8986 - val_recall: 0.8948\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0580 - accuracy: 0.9532 - binary_iou: 0.9078 - true_positives: 123363528.0000 - false_positives: 7280005.0000 - true_negatives: 181199600.0000 - false_negatives: 7677632.0000 - precision: 0.9443 - recall: 0.9414 - val_loss: 0.1055 - val_accuracy: 0.9115 - val_binary_iou: 0.8344 - val_true_positives: 40520684.0000 - val_false_positives: 4858289.0000 - val_true_negatives: 56075660.0000 - val_false_negatives: 4517084.0000 - val_precision: 0.8929 - val_recall: 0.8997\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0570 - accuracy: 0.9540 - binary_iou: 0.9093 - true_positives: 123493752.0000 - false_positives: 7110197.0000 - true_negatives: 181323936.0000 - false_negatives: 7592935.0000 - precision: 0.9456 - recall: 0.9421 - val_loss: 0.1046 - val_accuracy: 0.9124 - val_binary_iou: 0.8358 - val_true_positives: 40331288.0000 - val_false_positives: 4420796.0000 - val_true_negatives: 56358424.0000 - val_false_negatives: 4861206.0000 - val_precision: 0.9012 - val_recall: 0.8924\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0563 - accuracy: 0.9547 - binary_iou: 0.9107 - true_positives: 123594296.0000 - false_positives: 6943928.0000 - true_negatives: 181465600.0000 - false_negatives: 7516999.0000 - precision: 0.9468 - recall: 0.9427 - val_loss: 0.1054 - val_accuracy: 0.9110 - val_binary_iou: 0.8336 - val_true_positives: 40675640.0000 - val_false_positives: 4953861.0000 - val_true_negatives: 55859928.0000 - val_false_negatives: 4482288.0000 - val_precision: 0.8914 - val_recall: 0.9007\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0557 - accuracy: 0.9551 - binary_iou: 0.9114 - true_positives: 123729664.0000 - false_positives: 6913498.0000 - true_negatives: 181439936.0000 - false_negatives: 7437701.0000 - precision: 0.9471 - recall: 0.9433 - val_loss: 0.1069 - val_accuracy: 0.9112 - val_binary_iou: 0.8334 - val_true_positives: 39996992.0000 - val_false_positives: 4278153.0000 - val_true_negatives: 56563336.0000 - val_false_negatives: 5133246.0000 - val_precision: 0.9034 - val_recall: 0.8863\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0551 - accuracy: 0.9556 - binary_iou: 0.9124 - true_positives: 123717848.0000 - false_positives: 6836269.0000 - true_negatives: 181620400.0000 - false_negatives: 7346230.0000 - precision: 0.9476 - recall: 0.9439 - val_loss: 0.1067 - val_accuracy: 0.9120 - val_binary_iou: 0.8345 - val_true_positives: 39732004.0000 - val_false_positives: 4021717.0000 - val_true_negatives: 56912136.0000 - val_false_negatives: 5305863.0000 - val_precision: 0.9081 - val_recall: 0.8822\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0551 - accuracy: 0.9557 - binary_iou: 0.9126 - true_positives: 123942792.0000 - false_positives: 6891049.0000 - true_negatives: 181433792.0000 - false_negatives: 7253034.0000 - precision: 0.9473 - recall: 0.9447 - val_loss: 0.1061 - val_accuracy: 0.9114 - val_binary_iou: 0.8342 - val_true_positives: 40529868.0000 - val_false_positives: 4846379.0000 - val_true_negatives: 56051784.0000 - val_false_negatives: 4543687.0000 - val_precision: 0.8932 - val_recall: 0.8992\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0535 - accuracy: 0.9569 - binary_iou: 0.9147 - true_positives: 123879840.0000 - false_positives: 6569554.0000 - true_negatives: 181860352.0000 - false_negatives: 7210967.0000 - precision: 0.9496 - recall: 0.9450 - val_loss: 0.1073 - val_accuracy: 0.9112 - val_binary_iou: 0.8333 - val_true_positives: 39766156.0000 - val_false_positives: 4007997.0000 - val_true_negatives: 56798228.0000 - val_false_negatives: 5399337.0000 - val_precision: 0.9084 - val_recall: 0.8805\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0529 - accuracy: 0.9575 - binary_iou: 0.9160 - true_positives: 124055448.0000 - false_positives: 6525041.0000 - true_negatives: 181892784.0000 - false_negatives: 7047497.0000 - precision: 0.9500 - recall: 0.9462 - val_loss: 0.1055 - val_accuracy: 0.9111 - val_binary_iou: 0.8337 - val_true_positives: 40579544.0000 - val_false_positives: 4905237.0000 - val_true_negatives: 55967260.0000 - val_false_negatives: 4519657.0000 - val_precision: 0.8922 - val_recall: 0.8998\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0522 - accuracy: 0.9580 - binary_iou: 0.9169 - true_positives: 124205800.0000 - false_positives: 6503211.0000 - true_negatives: 181902576.0000 - false_negatives: 6909198.0000 - precision: 0.9502 - recall: 0.9473 - val_loss: 0.1073 - val_accuracy: 0.9102 - val_binary_iou: 0.8320 - val_true_positives: 40219576.0000 - val_false_positives: 4550339.0000 - val_true_negatives: 56240064.0000 - val_false_negatives: 4961714.0000 - val_precision: 0.8984 - val_recall: 0.8902\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0513 - accuracy: 0.9585 - binary_iou: 0.9178 - true_positives: 124308648.0000 - false_positives: 6374356.0000 - true_negatives: 181950176.0000 - false_negatives: 6887623.0000 - precision: 0.9512 - recall: 0.9475 - val_loss: 0.1100 - val_accuracy: 0.9106 - val_binary_iou: 0.8320 - val_true_positives: 39508104.0000 - val_false_positives: 3840842.0000 - val_true_negatives: 56990440.0000 - val_false_negatives: 5632317.0000 - val_precision: 0.9114 - val_recall: 0.8752\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0508 - accuracy: 0.9591 - binary_iou: 0.9190 - true_positives: 124333776.0000 - false_positives: 6304370.0000 - true_negatives: 182118496.0000 - false_negatives: 6764101.0000 - precision: 0.9517 - recall: 0.9484 - val_loss: 0.1071 - val_accuracy: 0.9102 - val_binary_iou: 0.8320 - val_true_positives: 40270240.0000 - val_false_positives: 4775546.0000 - val_true_negatives: 56183496.0000 - val_false_negatives: 4742450.0000 - val_precision: 0.8940 - val_recall: 0.8946\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0505 - accuracy: 0.9594 - binary_iou: 0.9195 - true_positives: 124463584.0000 - false_positives: 6269177.0000 - true_negatives: 182070608.0000 - false_negatives: 6717374.0000 - precision: 0.9520 - recall: 0.9488 - val_loss: 0.1072 - val_accuracy: 0.9093 - val_binary_iou: 0.8310 - val_true_positives: 40870504.0000 - val_false_positives: 5364216.0000 - val_true_negatives: 55490560.0000 - val_false_negatives: 4246435.0000 - val_precision: 0.8840 - val_recall: 0.9059\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0492 - accuracy: 0.9602 - binary_iou: 0.9210 - true_positives: 124585736.0000 - false_positives: 6154409.0000 - true_negatives: 182211376.0000 - false_negatives: 6569294.0000 - precision: 0.9529 - recall: 0.9499 - val_loss: 0.1068 - val_accuracy: 0.9105 - val_binary_iou: 0.8325 - val_true_positives: 40329344.0000 - val_false_positives: 4725819.0000 - val_true_negatives: 56154072.0000 - val_false_negatives: 4762477.0000 - val_precision: 0.8951 - val_recall: 0.8944\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.0494 - accuracy: 0.9601 - binary_iou: 0.9209 - true_positives: 124466696.0000 - false_positives: 6158949.0000 - true_negatives: 182315840.0000 - false_negatives: 6579399.0000 - precision: 0.9529 - recall: 0.9498 - val_loss: 0.1052 - val_accuracy: 0.9118 - val_binary_iou: 0.8349 - val_true_positives: 40561384.0000 - val_false_positives: 4766888.0000 - val_true_negatives: 56061088.0000 - val_false_negatives: 4582346.0000 - val_precision: 0.8948 - val_recall: 0.8985\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.0490 - accuracy: 0.9605 - binary_iou: 0.9216 - true_positives: 124570520.0000 - false_positives: 6098607.0000 - true_negatives: 182323168.0000 - false_negatives: 6528447.0000 - precision: 0.9533 - recall: 0.9502 - val_loss: 0.1058 - val_accuracy: 0.9108 - val_binary_iou: 0.8333 - val_true_positives: 40659104.0000 - val_false_positives: 4984018.0000 - val_true_negatives: 55861056.0000 - val_false_negatives: 4467541.0000 - val_precision: 0.8908 - val_recall: 0.9010\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.0483 - accuracy: 0.9610 - binary_iou: 0.9227 - true_positives: 124588288.0000 - false_positives: 5976052.0000 - true_negatives: 182486528.0000 - false_negatives: 6469831.0000 - precision: 0.9542 - recall: 0.9506 - val_loss: 0.1048 - val_accuracy: 0.9113 - val_binary_iou: 0.8343 - val_true_positives: 40899864.0000 - val_false_positives: 5141151.0000 - val_true_negatives: 55668528.0000 - val_false_negatives: 4262163.0000 - val_precision: 0.8883 - val_recall: 0.9056\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0481 - accuracy: 0.9614 - binary_iou: 0.9233 - true_positives: 124625920.0000 - false_positives: 5897883.0000 - true_negatives: 182554048.0000 - false_negatives: 6442969.0000 - precision: 0.9548 - recall: 0.9508 - val_loss: 0.1075 - val_accuracy: 0.9113 - val_binary_iou: 0.8334 - val_true_positives: 39692348.0000 - val_false_positives: 4009602.0000 - val_true_negatives: 56882440.0000 - val_false_negatives: 5387317.0000 - val_precision: 0.9083 - val_recall: 0.8805\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0474 - accuracy: 0.9618 - binary_iou: 0.9241 - true_positives: 124802768.0000 - false_positives: 5886784.0000 - true_negatives: 182504112.0000 - false_negatives: 6327112.0000 - precision: 0.9550 - recall: 0.9517 - val_loss: 0.1051 - val_accuracy: 0.9119 - val_binary_iou: 0.8349 - val_true_positives: 40236328.0000 - val_false_positives: 4493678.0000 - val_true_negatives: 56402056.0000 - val_false_negatives: 4839649.0000 - val_precision: 0.8995 - val_recall: 0.8926\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0465 - accuracy: 0.9626 - binary_iou: 0.9256 - true_positives: 124897952.0000 - false_positives: 5707741.0000 - true_negatives: 182660496.0000 - false_negatives: 6254612.0000 - precision: 0.9563 - recall: 0.9523 - val_loss: 0.1058 - val_accuracy: 0.9118 - val_binary_iou: 0.8347 - val_true_positives: 40194604.0000 - val_false_positives: 4409715.0000 - val_true_negatives: 56433864.0000 - val_false_negatives: 4933540.0000 - val_precision: 0.9011 - val_recall: 0.8907\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 74s 373ms/step - loss: 0.0461 - accuracy: 0.9629 - binary_iou: 0.9262 - true_positives: 124957464.0000 - false_positives: 5736117.0000 - true_negatives: 182701296.0000 - false_negatives: 6125902.0000 - precision: 0.9561 - recall: 0.9533 - val_loss: 0.1066 - val_accuracy: 0.9095 - val_binary_iou: 0.8314 - val_true_positives: 40903704.0000 - val_false_positives: 5391561.0000 - val_true_negatives: 55480348.0000 - val_false_negatives: 4196083.0000 - val_precision: 0.8835 - val_recall: 0.9070\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 74s 372ms/step - loss: 0.0458 - accuracy: 0.9630 - binary_iou: 0.9264 - true_positives: 125054872.0000 - false_positives: 5695307.0000 - true_negatives: 182635008.0000 - false_negatives: 6135531.0000 - precision: 0.9564 - recall: 0.9532 - val_loss: 0.1053 - val_accuracy: 0.9115 - val_binary_iou: 0.8342 - val_true_positives: 40300812.0000 - val_false_positives: 4588893.0000 - val_true_negatives: 56290124.0000 - val_false_negatives: 4791871.0000 - val_precision: 0.8978 - val_recall: 0.8937\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 74s 374ms/step - loss: 0.0457 - accuracy: 0.9632 - binary_iou: 0.9268 - true_positives: 125048112.0000 - false_positives: 5706061.0000 - true_negatives: 182710736.0000 - false_negatives: 6055886.0000 - precision: 0.9564 - recall: 0.9538 - val_loss: 0.1068 - val_accuracy: 0.9111 - val_binary_iou: 0.8334 - val_true_positives: 40077080.0000 - val_false_positives: 4339950.0000 - val_true_negatives: 56478900.0000 - val_false_negatives: 5075775.0000 - val_precision: 0.9023 - val_recall: 0.8876\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 74s 374ms/step - loss: 0.0449 - accuracy: 0.9638 - binary_iou: 0.9279 - true_positives: 125122688.0000 - false_positives: 5626771.0000 - true_negatives: 182824432.0000 - false_negatives: 5946931.0000 - precision: 0.9570 - recall: 0.9546 - val_loss: 0.1065 - val_accuracy: 0.9113 - val_binary_iou: 0.8338 - val_true_positives: 40239344.0000 - val_false_positives: 4513165.0000 - val_true_negatives: 56330940.0000 - val_false_negatives: 4888256.0000 - val_precision: 0.8992 - val_recall: 0.8917\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.0447 - accuracy: 0.9640 - binary_iou: 0.9284 - true_positives: 125148128.0000 - false_positives: 5518113.0000 - true_negatives: 182879456.0000 - false_negatives: 5975099.0000 - precision: 0.9578 - recall: 0.9544 - val_loss: 0.1085 - val_accuracy: 0.9097 - val_binary_iou: 0.8310 - val_true_positives: 40029920.0000 - val_false_positives: 4473742.0000 - val_true_negatives: 56375624.0000 - val_false_negatives: 5092416.0000 - val_precision: 0.8995 - val_recall: 0.8871\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 74s 371ms/step - loss: 0.0446 - accuracy: 0.9640 - binary_iou: 0.9284 - true_positives: 125174584.0000 - false_positives: 5501757.0000 - true_negatives: 182849136.0000 - false_negatives: 5995295.0000 - precision: 0.9579 - recall: 0.9543 - val_loss: 0.1063 - val_accuracy: 0.9111 - val_binary_iou: 0.8336 - val_true_positives: 40348144.0000 - val_false_positives: 4677392.0000 - val_true_negatives: 56204960.0000 - val_false_negatives: 4741206.0000 - val_precision: 0.8961 - val_recall: 0.8948\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.0435 - accuracy: 0.9650 - binary_iou: 0.9302 - true_positives: 125317656.0000 - false_positives: 5393400.0000 - true_negatives: 183005120.0000 - false_negatives: 5804585.0000 - precision: 0.9587 - recall: 0.9557 - val_loss: 0.1090 - val_accuracy: 0.9103 - val_binary_iou: 0.8318 - val_true_positives: 39872296.0000 - val_false_positives: 4345238.0000 - val_true_negatives: 56591704.0000 - val_false_negatives: 5162471.0000 - val_precision: 0.9017 - val_recall: 0.8854\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.0435 - accuracy: 0.9649 - binary_iou: 0.9300 - true_positives: 125294664.0000 - false_positives: 5399817.0000 - true_negatives: 183008736.0000 - false_negatives: 5817524.0000 - precision: 0.9587 - recall: 0.9556 - val_loss: 0.1069 - val_accuracy: 0.9097 - val_binary_iou: 0.8317 - val_true_positives: 41023536.0000 - val_false_positives: 5442364.0000 - val_true_negatives: 55374596.0000 - val_false_negatives: 4131222.0000 - val_precision: 0.8829 - val_recall: 0.9085\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.0437 - accuracy: 0.9648 - binary_iou: 0.9298 - true_positives: 125205288.0000 - false_positives: 5406795.0000 - true_negatives: 183056352.0000 - false_negatives: 5852338.0000 - precision: 0.9586 - recall: 0.9553 - val_loss: 0.1070 - val_accuracy: 0.9099 - val_binary_iou: 0.8318 - val_true_positives: 40709632.0000 - val_false_positives: 5095948.0000 - val_true_negatives: 55712156.0000 - val_false_negatives: 4453963.0000 - val_precision: 0.8887 - val_recall: 0.9014\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 74s 370ms/step - loss: 0.0436 - accuracy: 0.9651 - binary_iou: 0.9304 - true_positives: 125219136.0000 - false_positives: 5336399.0000 - true_negatives: 183154416.0000 - false_negatives: 5810872.0000 - precision: 0.9591 - recall: 0.9557 - val_loss: 0.1068 - val_accuracy: 0.9113 - val_binary_iou: 0.8336 - val_true_positives: 40083600.0000 - val_false_positives: 4393441.0000 - val_true_negatives: 56483408.0000 - val_false_negatives: 5011268.0000 - val_precision: 0.9012 - val_recall: 0.8889\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0423 - accuracy: 0.9658 - binary_iou: 0.9318 - true_positives: 125406520.0000 - false_positives: 5267021.0000 - true_negatives: 183190352.0000 - false_negatives: 5656824.0000 - precision: 0.9597 - recall: 0.9568 - val_loss: 0.1057 - val_accuracy: 0.9103 - val_binary_iou: 0.8326 - val_true_positives: 40746424.0000 - val_false_positives: 5083191.0000 - val_true_negatives: 55722136.0000 - val_false_negatives: 4419954.0000 - val_precision: 0.8891 - val_recall: 0.9021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0423 - accuracy: 0.9659 - binary_iou: 0.9320 - true_positives: 125513856.0000 - false_positives: 5242194.0000 - true_negatives: 183109168.0000 - false_negatives: 5655491.0000 - precision: 0.9599 - recall: 0.9569 - val_loss: 0.1075 - val_accuracy: 0.9107 - val_binary_iou: 0.8326 - val_true_positives: 40127192.0000 - val_false_positives: 4538665.0000 - val_true_negatives: 56376068.0000 - val_false_negatives: 4929801.0000 - val_precision: 0.8984 - val_recall: 0.8906\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0420 - accuracy: 0.9661 - binary_iou: 0.9324 - true_positives: 125421656.0000 - false_positives: 5148469.0000 - true_negatives: 183279360.0000 - false_negatives: 5671294.0000 - precision: 0.9606 - recall: 0.9567 - val_loss: 0.1074 - val_accuracy: 0.9095 - val_binary_iou: 0.8311 - val_true_positives: 40532704.0000 - val_false_positives: 4984283.0000 - val_true_negatives: 55853820.0000 - val_false_negatives: 4600895.0000 - val_precision: 0.8905 - val_recall: 0.8981\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0418 - accuracy: 0.9663 - binary_iou: 0.9328 - true_positives: 125596472.0000 - false_positives: 5174639.0000 - true_negatives: 183167728.0000 - false_negatives: 5581929.0000 - precision: 0.9604 - recall: 0.9574 - val_loss: 0.1058 - val_accuracy: 0.9106 - val_binary_iou: 0.8328 - val_true_positives: 40503040.0000 - val_false_positives: 4787365.0000 - val_true_negatives: 55990064.0000 - val_false_negatives: 4691230.0000 - val_precision: 0.8943 - val_recall: 0.8962\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0415 - accuracy: 0.9666 - binary_iou: 0.9334 - true_positives: 125536480.0000 - false_positives: 5096631.0000 - true_negatives: 183327296.0000 - false_negatives: 5560382.0000 - precision: 0.9610 - recall: 0.9576 - val_loss: 0.1072 - val_accuracy: 0.9107 - val_binary_iou: 0.8331 - val_true_positives: 40469352.0000 - val_false_positives: 4896795.0000 - val_true_negatives: 56042092.0000 - val_false_negatives: 4563465.0000 - val_precision: 0.8921 - val_recall: 0.8987\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0412 - accuracy: 0.9668 - binary_iou: 0.9337 - true_positives: 125558280.0000 - false_positives: 5086496.0000 - true_negatives: 183350304.0000 - false_negatives: 5525741.0000 - precision: 0.9611 - recall: 0.9578 - val_loss: 0.1074 - val_accuracy: 0.9102 - val_binary_iou: 0.8321 - val_true_positives: 40408996.0000 - val_false_positives: 4710204.0000 - val_true_negatives: 56047380.0000 - val_false_negatives: 4805146.0000 - val_precision: 0.8956 - val_recall: 0.8937\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0408 - accuracy: 0.9670 - binary_iou: 0.9342 - true_positives: 125652808.0000 - false_positives: 5040952.0000 - true_negatives: 183338192.0000 - false_negatives: 5488843.0000 - precision: 0.9614 - recall: 0.9581 - val_loss: 0.1071 - val_accuracy: 0.9103 - val_binary_iou: 0.8322 - val_true_positives: 40342460.0000 - val_false_positives: 4790355.0000 - val_true_negatives: 56122872.0000 - val_false_negatives: 4716022.0000 - val_precision: 0.8939 - val_recall: 0.8953\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0401 - accuracy: 0.9675 - binary_iou: 0.9351 - true_positives: 125697936.0000 - false_positives: 4966548.0000 - true_negatives: 183453360.0000 - false_negatives: 5402874.0000 - precision: 0.9620 - recall: 0.9588 - val_loss: 0.1065 - val_accuracy: 0.9109 - val_binary_iou: 0.8331 - val_true_positives: 40157980.0000 - val_false_positives: 4466918.0000 - val_true_negatives: 56373024.0000 - val_false_negatives: 4973797.0000 - val_precision: 0.8999 - val_recall: 0.8898\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0400 - accuracy: 0.9677 - binary_iou: 0.9354 - true_positives: 125762192.0000 - false_positives: 4964125.0000 - true_negatives: 183424656.0000 - false_negatives: 5369824.0000 - precision: 0.9620 - recall: 0.9591 - val_loss: 0.1071 - val_accuracy: 0.9113 - val_binary_iou: 0.8336 - val_true_positives: 39921496.0000 - val_false_positives: 4163661.0000 - val_true_negatives: 56653596.0000 - val_false_negatives: 5232947.0000 - val_precision: 0.9056 - val_recall: 0.8841\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0396 - accuracy: 0.9680 - binary_iou: 0.9361 - true_positives: 125708792.0000 - false_positives: 4876955.0000 - true_negatives: 183594144.0000 - false_negatives: 5340780.0000 - precision: 0.9627 - recall: 0.9592 - val_loss: 0.1072 - val_accuracy: 0.9109 - val_binary_iou: 0.8329 - val_true_positives: 39832384.0000 - val_false_positives: 4173067.0000 - val_true_negatives: 56701908.0000 - val_false_negatives: 5264358.0000 - val_precision: 0.9052 - val_recall: 0.8833\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0397 - accuracy: 0.9680 - binary_iou: 0.9360 - true_positives: 125831440.0000 - false_positives: 4947453.0000 - true_negatives: 183455728.0000 - false_negatives: 5286115.0000 - precision: 0.9622 - recall: 0.9597 - val_loss: 0.1066 - val_accuracy: 0.9112 - val_binary_iou: 0.8335 - val_true_positives: 40003284.0000 - val_false_positives: 4364195.0000 - val_true_negatives: 56562176.0000 - val_false_negatives: 5042056.0000 - val_precision: 0.9016 - val_recall: 0.8881\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0391 - accuracy: 0.9685 - binary_iou: 0.9370 - true_positives: 125956776.0000 - false_positives: 4867103.0000 - true_negatives: 183498112.0000 - false_negatives: 5198688.0000 - precision: 0.9628 - recall: 0.9604 - val_loss: 0.1062 - val_accuracy: 0.9115 - val_binary_iou: 0.8341 - val_true_positives: 40131076.0000 - val_false_positives: 4387529.0000 - val_true_negatives: 56465648.0000 - val_false_negatives: 4987466.0000 - val_precision: 0.9014 - val_recall: 0.8895\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0390 - accuracy: 0.9686 - binary_iou: 0.9371 - true_positives: 125942464.0000 - false_positives: 4823245.0000 - true_negatives: 183538064.0000 - false_negatives: 5217049.0000 - precision: 0.9631 - recall: 0.9602 - val_loss: 0.1070 - val_accuracy: 0.9102 - val_binary_iou: 0.8321 - val_true_positives: 40362168.0000 - val_false_positives: 4756447.0000 - val_true_negatives: 56093900.0000 - val_false_negatives: 4759208.0000 - val_precision: 0.8946 - val_recall: 0.8945\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0388 - accuracy: 0.9687 - binary_iou: 0.9374 - true_positives: 125920416.0000 - false_positives: 4808080.0000 - true_negatives: 183600592.0000 - false_negatives: 5191683.0000 - precision: 0.9632 - recall: 0.9604 - val_loss: 0.1061 - val_accuracy: 0.9112 - val_binary_iou: 0.8337 - val_true_positives: 40292492.0000 - val_false_positives: 4620579.0000 - val_true_negatives: 56267536.0000 - val_false_negatives: 4791115.0000 - val_precision: 0.8971 - val_recall: 0.8937\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0385 - accuracy: 0.9689 - binary_iou: 0.9377 - true_positives: 126025096.0000 - false_positives: 4782766.0000 - true_negatives: 183543856.0000 - false_negatives: 5169034.0000 - precision: 0.9634 - recall: 0.9606 - val_loss: 0.1060 - val_accuracy: 0.9107 - val_binary_iou: 0.8332 - val_true_positives: 40571484.0000 - val_false_positives: 4853939.0000 - val_true_negatives: 55941208.0000 - val_false_negatives: 4605069.0000 - val_precision: 0.8931 - val_recall: 0.8981\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 75s 376ms/step - loss: 0.0377 - accuracy: 0.9695 - binary_iou: 0.9390 - true_positives: 126124200.0000 - false_positives: 4682859.0000 - true_negatives: 183662880.0000 - false_negatives: 5050749.0000 - precision: 0.9642 - recall: 0.9615 - val_loss: 0.1086 - val_accuracy: 0.9104 - val_binary_iou: 0.8319 - val_true_positives: 39787008.0000 - val_false_positives: 4195869.0000 - val_true_negatives: 56687388.0000 - val_false_negatives: 5301446.0000 - val_precision: 0.9046 - val_recall: 0.8824\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0382 - accuracy: 0.9692 - binary_iou: 0.9384 - true_positives: 125962448.0000 - false_positives: 4693446.0000 - true_negatives: 183719552.0000 - false_negatives: 5145296.0000 - precision: 0.9641 - recall: 0.9608 - val_loss: 0.1085 - val_accuracy: 0.9109 - val_binary_iou: 0.8327 - val_true_positives: 39736344.0000 - val_false_positives: 3982419.0000 - val_true_negatives: 56792456.0000 - val_false_negatives: 5460500.0000 - val_precision: 0.9089 - val_recall: 0.8792\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0380 - accuracy: 0.9693 - binary_iou: 0.9385 - true_positives: 126037088.0000 - false_positives: 4771482.0000 - true_negatives: 183665600.0000 - false_negatives: 5046633.0000 - precision: 0.9635 - recall: 0.9615 - val_loss: 0.1089 - val_accuracy: 0.9102 - val_binary_iou: 0.8317 - val_true_positives: 39986692.0000 - val_false_positives: 4370888.0000 - val_true_negatives: 56466420.0000 - val_false_negatives: 5147732.0000 - val_precision: 0.9015 - val_recall: 0.8859\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0373 - accuracy: 0.9698 - binary_iou: 0.9396 - true_positives: 126140816.0000 - false_positives: 4643910.0000 - true_negatives: 183737776.0000 - false_negatives: 4998198.0000 - precision: 0.9645 - recall: 0.9619 - val_loss: 0.1092 - val_accuracy: 0.9089 - val_binary_iou: 0.8295 - val_true_positives: 39916608.0000 - val_false_positives: 4475343.0000 - val_true_negatives: 56396008.0000 - val_false_negatives: 5183739.0000 - val_precision: 0.8992 - val_recall: 0.8851\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0374 - accuracy: 0.9698 - binary_iou: 0.9395 - true_positives: 126152232.0000 - false_positives: 4647386.0000 - true_negatives: 183709504.0000 - false_negatives: 5011741.0000 - precision: 0.9645 - recall: 0.9618 - val_loss: 0.1083 - val_accuracy: 0.9104 - val_binary_iou: 0.8319 - val_true_positives: 39783616.0000 - val_false_positives: 4189639.0000 - val_true_negatives: 56694024.0000 - val_false_negatives: 5304442.0000 - val_precision: 0.9047 - val_recall: 0.8824\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0370 - accuracy: 0.9702 - binary_iou: 0.9402 - true_positives: 126207368.0000 - false_positives: 4581666.0000 - true_negatives: 183781536.0000 - false_negatives: 4950135.0000 - precision: 0.9650 - recall: 0.9623 - val_loss: 0.1081 - val_accuracy: 0.9104 - val_binary_iou: 0.8324 - val_true_positives: 40257180.0000 - val_false_positives: 4710634.0000 - val_true_negatives: 56221808.0000 - val_false_negatives: 4782100.0000 - val_precision: 0.8952 - val_recall: 0.8938\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0371 - accuracy: 0.9701 - binary_iou: 0.9401 - true_positives: 126166256.0000 - false_positives: 4559807.0000 - true_negatives: 183808560.0000 - false_negatives: 4986197.0000 - precision: 0.9651 - recall: 0.9620 - val_loss: 0.1079 - val_accuracy: 0.9100 - val_binary_iou: 0.8318 - val_true_positives: 40315804.0000 - val_false_positives: 4735607.0000 - val_true_negatives: 56122932.0000 - val_false_negatives: 4797372.0000 - val_precision: 0.8949 - val_recall: 0.8937\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0367 - accuracy: 0.9703 - binary_iou: 0.9405 - true_positives: 126178680.0000 - false_positives: 4573871.0000 - true_negatives: 183857232.0000 - false_negatives: 4911032.0000 - precision: 0.9650 - recall: 0.9625 - val_loss: 0.1082 - val_accuracy: 0.9090 - val_binary_iou: 0.8302 - val_true_positives: 40349752.0000 - val_false_positives: 4899366.0000 - val_true_negatives: 55983368.0000 - val_false_negatives: 4739230.0000 - val_precision: 0.8917 - val_recall: 0.8949\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0363 - accuracy: 0.9707 - binary_iou: 0.9413 - true_positives: 126324184.0000 - false_positives: 4495966.0000 - true_negatives: 183844320.0000 - false_negatives: 4856289.0000 - precision: 0.9656 - recall: 0.9630 - val_loss: 0.1080 - val_accuracy: 0.9099 - val_binary_iou: 0.8315 - val_true_positives: 40131748.0000 - val_false_positives: 4594554.0000 - val_true_negatives: 56295608.0000 - val_false_negatives: 4949804.0000 - val_precision: 0.8973 - val_recall: 0.8902\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0360 - accuracy: 0.9709 - binary_iou: 0.9417 - true_positives: 126301800.0000 - false_positives: 4466072.0000 - true_negatives: 183932448.0000 - false_negatives: 4820447.0000 - precision: 0.9658 - recall: 0.9632 - val_loss: 0.1075 - val_accuracy: 0.9105 - val_binary_iou: 0.8321 - val_true_positives: 39881636.0000 - val_false_positives: 4265887.0000 - val_true_negatives: 56602812.0000 - val_false_negatives: 5221368.0000 - val_precision: 0.9034 - val_recall: 0.8842\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0358 - accuracy: 0.9711 - binary_iou: 0.9421 - true_positives: 126439192.0000 - false_positives: 4460145.0000 - true_negatives: 183850944.0000 - false_negatives: 4770575.0000 - precision: 0.9659 - recall: 0.9636 - val_loss: 0.1082 - val_accuracy: 0.9101 - val_binary_iou: 0.8317 - val_true_positives: 39970952.0000 - val_false_positives: 4361137.0000 - val_true_negatives: 56477632.0000 - val_false_negatives: 5161996.0000 - val_precision: 0.9016 - val_recall: 0.8856\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0357 - accuracy: 0.9711 - binary_iou: 0.9421 - true_positives: 126384720.0000 - false_positives: 4440552.0000 - true_negatives: 183908096.0000 - false_negatives: 4787371.0000 - precision: 0.9661 - recall: 0.9635 - val_loss: 0.1097 - val_accuracy: 0.9092 - val_binary_iou: 0.8300 - val_true_positives: 39921392.0000 - val_false_positives: 4510913.0000 - val_true_negatives: 56426932.0000 - val_false_negatives: 5112465.0000 - val_precision: 0.8985 - val_recall: 0.8865\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0357 - accuracy: 0.9712 - binary_iou: 0.9423 - true_positives: 126325168.0000 - false_positives: 4458790.0000 - true_negatives: 184003072.0000 - false_negatives: 4733682.0000 - precision: 0.9659 - recall: 0.9639 - val_loss: 0.1074 - val_accuracy: 0.9105 - val_binary_iou: 0.8323 - val_true_positives: 39943376.0000 - val_false_positives: 4347944.0000 - val_true_negatives: 56547604.0000 - val_false_negatives: 5132789.0000 - val_precision: 0.9018 - val_recall: 0.8861\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0350 - accuracy: 0.9716 - binary_iou: 0.9430 - true_positives: 126443552.0000 - false_positives: 4372154.0000 - true_negatives: 184006240.0000 - false_negatives: 4698895.0000 - precision: 0.9666 - recall: 0.9642 - val_loss: 0.1093 - val_accuracy: 0.9083 - val_binary_iou: 0.8288 - val_true_positives: 40189912.0000 - val_false_positives: 4771726.0000 - val_true_negatives: 56068256.0000 - val_false_negatives: 4941811.0000 - val_precision: 0.8939 - val_recall: 0.8905\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 75s 377ms/step - loss: 0.0351 - accuracy: 0.9717 - binary_iou: 0.9432 - true_positives: 126438896.0000 - false_positives: 4350390.0000 - true_negatives: 184039984.0000 - false_negatives: 4691558.0000 - precision: 0.9667 - recall: 0.9642 - val_loss: 0.1067 - val_accuracy: 0.9098 - val_binary_iou: 0.8315 - val_true_positives: 40612744.0000 - val_false_positives: 4987735.0000 - val_true_negatives: 55795880.0000 - val_false_negatives: 4575355.0000 - val_precision: 0.8906 - val_recall: 0.8987\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 75s 374ms/step - loss: 0.0348 - accuracy: 0.9719 - binary_iou: 0.9436 - true_positives: 126436648.0000 - false_positives: 4294822.0000 - true_negatives: 184100880.0000 - false_negatives: 4688362.0000 - precision: 0.9671 - recall: 0.9642 - val_loss: 0.1087 - val_accuracy: 0.9101 - val_binary_iou: 0.8313 - val_true_positives: 39661524.0000 - val_false_positives: 4068774.0000 - val_true_negatives: 56782200.0000 - val_false_negatives: 5459220.0000 - val_precision: 0.9070 - val_recall: 0.8790\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0347 - accuracy: 0.9720 - binary_iou: 0.9437 - true_positives: 126500352.0000 - false_positives: 4284378.0000 - true_negatives: 184061920.0000 - false_negatives: 4674185.0000 - precision: 0.9672 - recall: 0.9644 - val_loss: 0.1077 - val_accuracy: 0.9097 - val_binary_iou: 0.8311 - val_true_positives: 40191080.0000 - val_false_positives: 4670301.0000 - val_true_negatives: 56212296.0000 - val_false_negatives: 4898034.0000 - val_precision: 0.8959 - val_recall: 0.8914\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 75s 375ms/step - loss: 0.0345 - accuracy: 0.9722 - binary_iou: 0.9441 - true_positives: 126533408.0000 - false_positives: 4290247.0000 - true_negatives: 184091008.0000 - false_negatives: 4606184.0000 - precision: 0.9672 - recall: 0.9649 - val_loss: 0.1074 - val_accuracy: 0.9096 - val_binary_iou: 0.8310 - val_true_positives: 40181068.0000 - val_false_positives: 4587745.0000 - val_true_negatives: 56212228.0000 - val_false_negatives: 4990670.0000 - val_precision: 0.8975 - val_recall: 0.8895\n",
      "66/66 [==============================] - 12s 134ms/step - loss: 293.5942 - accuracy: 0.9107 - binary_iou: 0.8319 - true_positives: 39292868.0000 - false_positives: 4573902.0000 - true_negatives: 57210840.0000 - false_negatives: 4894108.0000 - precision: 0.8957 - recall: 0.8892\n",
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.7877 - binary_iou: 0.6476 - true_positives: 111040856.0000 - false_positives: 47943536.0000 - true_negatives: 140632976.0000 - false_negatives: 19903408.0000 - precision: 0.6984 - recall: 0.8480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 112\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         \u001b[39mprint\u001b[39m(i, layer\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39mtrainable weights:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(layer\u001b[39m.\u001b[39mtrainable_weights), \u001b[39m\"\u001b[39m\u001b[39mtrainable:\u001b[39m\u001b[39m\"\u001b[39m, layer\u001b[39m.\u001b[39mtrainable)\n\u001b[1;32m--> 112\u001b[0m model_history \u001b[39m=\u001b[39m unet\u001b[39m.\u001b[39;49mfit(train_data_generator, \n\u001b[0;32m    113\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mval_data_generator, \n\u001b[0;32m    114\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m callbacks, \n\u001b[0;32m    115\u001b[0m                         epochs\u001b[39m=\u001b[39;49m initial_epochs)\n\u001b[0;32m    117\u001b[0m \u001b[39m# Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\u001b[39;00m\n\u001b[0;32m    118\u001b[0m shutil\u001b[39m.\u001b[39mcopy(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../output/\u001b[39m\u001b[39m{\u001b[39;00moutput_folder_prefix\u001b[39m}\u001b[39;00m\u001b[39m_logger/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.log\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../output/\u001b[39m\u001b[39m{\u001b[39;00moutput_folder_prefix\u001b[39m}\u001b[39;00m\u001b[39m_logger/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_I.log\u001b[39m\u001b[39m'\u001b[39m, follow_symlinks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1463\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs_since_last_save \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_freq \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_model(epoch\u001b[39m=\u001b[39;49mepoch, batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1528\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave_weights(\n\u001b[0;32m   1523\u001b[0m             filepath,\n\u001b[0;32m   1524\u001b[0m             overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   1525\u001b[0m             options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options,\n\u001b[0;32m   1526\u001b[0m         )\n\u001b[0;32m   1527\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1528\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave(\n\u001b[0;32m   1529\u001b[0m             filepath,\n\u001b[0;32m   1530\u001b[0m             overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1531\u001b[0m             options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options,\n\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1534\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2698\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m   2644\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\n\u001b[0;32m   2645\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2652\u001b[0m     save_traces\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2653\u001b[0m ):\n\u001b[0;32m   2655\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \n\u001b[0;32m   2657\u001b[0m \u001b[39m    Please see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m   2696\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2698\u001b[0m     save\u001b[39m.\u001b[39;49msave_model(\n\u001b[0;32m   2699\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2700\u001b[0m         filepath,\n\u001b[0;32m   2701\u001b[0m         overwrite,\n\u001b[0;32m   2702\u001b[0m         include_optimizer,\n\u001b[0;32m   2703\u001b[0m         save_format,\n\u001b[0;32m   2704\u001b[0m         signatures,\n\u001b[0;32m   2705\u001b[0m         options,\n\u001b[0;32m   2706\u001b[0m         save_traces,\n\u001b[0;32m   2707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\save.py:166\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mwith\u001b[39;00m generic_utils\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[1;32m--> 166\u001b[0m         saved_model_save\u001b[39m.\u001b[39;49msave(\n\u001b[0;32m    167\u001b[0m             model,\n\u001b[0;32m    168\u001b[0m             filepath,\n\u001b[0;32m    169\u001b[0m             overwrite,\n\u001b[0;32m    170\u001b[0m             include_optimizer,\n\u001b[0;32m    171\u001b[0m             signatures,\n\u001b[0;32m    172\u001b[0m             options,\n\u001b[0;32m    173\u001b[0m             save_traces,\n\u001b[0;32m    174\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save.py:97\u001b[0m, in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[39m0\u001b[39m):\n\u001b[0;32m     96\u001b[0m     \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[1;32m---> 97\u001b[0m         saved_nodes, node_paths \u001b[39m=\u001b[39m save_lib\u001b[39m.\u001b[39;49msave_and_return_nodes(\n\u001b[0;32m     98\u001b[0m             model, filepath, signatures, options\n\u001b[0;32m     99\u001b[0m         )\n\u001b[0;32m    101\u001b[0m     \u001b[39m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1268\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1264\u001b[0m saved_model \u001b[39m=\u001b[39m saved_model_pb2\u001b[39m.\u001b[39mSavedModel()\n\u001b[0;32m   1265\u001b[0m meta_graph_def \u001b[39m=\u001b[39m saved_model\u001b[39m.\u001b[39mmeta_graphs\u001b[39m.\u001b[39madd()\n\u001b[0;32m   1267\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1268\u001b[0m     _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0;32m   1269\u001b[0m saved_model\u001b[39m.\u001b[39msaved_model_schema_version \u001b[39m=\u001b[39m (\n\u001b[0;32m   1270\u001b[0m     constants\u001b[39m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1272\u001b[0m \u001b[39m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[39m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1441\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \n\u001b[0;32m   1416\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[39m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \u001b[39mwith\u001b[39;00m save_context\u001b[39m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1441\u001b[0m   \u001b[39mreturn\u001b[39;00m _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1384\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1382\u001b[0m augmented_graph_view \u001b[39m=\u001b[39m _AugmentedGraphView(obj)\n\u001b[0;32m   1383\u001b[0m \u001b[39mif\u001b[39;00m signatures \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1384\u001b[0m   signatures \u001b[39m=\u001b[39m signature_serialization\u001b[39m.\u001b[39;49mfind_function_to_export(\n\u001b[0;32m   1385\u001b[0m       augmented_graph_view)\n\u001b[0;32m   1387\u001b[0m signatures, wrapped_functions \u001b[39m=\u001b[39m (\n\u001b[0;32m   1388\u001b[0m     signature_serialization\u001b[39m.\u001b[39mcanonicalize_signatures(signatures))\n\u001b[0;32m   1389\u001b[0m signature_serialization\u001b[39m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_serialization.py:103\u001b[0m, in \u001b[0;36mfind_function_to_export\u001b[1;34m(saveable_view)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m possible_signatures \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 103\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m children:\n\u001b[0;32m    104\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(child, (def_function\u001b[39m.\u001b[39mFunction, defun\u001b[39m.\u001b[39mConcreteFunction)):\n\u001b[0;32m    105\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:175\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache:\n\u001b[0;32m    173\u001b[0m   children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache[obj] \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 175\u001b[0m   \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39;49m(_AugmentedGraphView, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlist_children(\n\u001b[0;32m    176\u001b[0m       obj,\n\u001b[0;32m    177\u001b[0m       save_type\u001b[39m=\u001b[39;49mbase\u001b[39m.\u001b[39;49mSaveType\u001b[39m.\u001b[39;49mSAVEDMODEL,\n\u001b[0;32m    178\u001b[0m       cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serialization_cache):\n\u001b[0;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, defun\u001b[39m.\u001b[39mConcreteFunction):\n\u001b[0;32m    180\u001b[0m       child \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m  List of all children attached to the object.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m children \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 75\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m(ObjectGraphView,\n\u001b[0;32m     76\u001b[0m                        \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mchildren(obj, save_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     77\u001b[0m   children\u001b[39m.\u001b[39mappend(base\u001b[39m.\u001b[39mTrackableReference(name, ref))\n\u001b[0;32m     79\u001b[0m \u001b[39m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\checkpoint\\trackable_view.py:84\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[1;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m obj\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n\u001b[0;32m     83\u001b[0m children \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 84\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39m_trackable_children(save_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     85\u001b[0m   ref \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mconvert_to_trackable(ref, parent\u001b[39m=\u001b[39mobj)\n\u001b[0;32m     86\u001b[0m   children[name] \u001b[39m=\u001b[39m ref\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:459\u001b[0m, in \u001b[0;36mFunctional._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_trackable_children\u001b[39m(\u001b[39mself\u001b[39m, save_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    458\u001b[0m     dependencies \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layer_checkpoint_dependencies\n\u001b[1;32m--> 459\u001b[0m     dependencies\u001b[39m.\u001b[39mupdate(\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_trackable_children(save_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m dependencies\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:3666\u001b[0m, in \u001b[0;36mModel._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m   3663\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3664\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_tf_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 3666\u001b[0m children \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_trackable_children(save_type, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3668\u001b[0m \u001b[39mif\u001b[39;00m save_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msavedmodel\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   3669\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m train_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:3337\u001b[0m, in \u001b[0;36mLayer._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m   3333\u001b[0m     cache \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   3334\u001b[0m     \u001b[39m# TODO(b/213628533): This must be called before super() to ensure\u001b[39;00m\n\u001b[0;32m   3335\u001b[0m     \u001b[39m# that any input shape changes are applied before getting the config\u001b[39;00m\n\u001b[0;32m   3336\u001b[0m     \u001b[39m# of the model.\u001b[39;00m\n\u001b[1;32m-> 3337\u001b[0m     children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trackable_saved_model_saver\u001b[39m.\u001b[39;49mtrackable_children(\n\u001b[0;32m   3338\u001b[0m         cache\n\u001b[0;32m   3339\u001b[0m     )\n\u001b[0;32m   3340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3341\u001b[0m     children \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\base_serialization.py:61\u001b[0m, in \u001b[0;36mSavedModelSaver.trackable_children\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m utils\u001b[39m.\u001b[39mshould_save_traces():\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n\u001b[1;32m---> 61\u001b[0m children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjects_to_serialize(serialization_cache)\n\u001b[0;32m     62\u001b[0m children\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunctions_to_serialize(serialization_cache))\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m children\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:79\u001b[0m, in \u001b[0;36mLayerSavedModelSaver.objects_to_serialize\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjects_to_serialize\u001b[39m(\u001b[39mself\u001b[39m, serialization_cache):\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes(\n\u001b[0;32m     80\u001b[0m         serialization_cache\n\u001b[0;32m     81\u001b[0m     )\u001b[39m.\u001b[39mobjects_to_serialize\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m     save_impl\u001b[39m.\u001b[39mshould_skip_serialization(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m    102\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_must_restore_from_config\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m serialized_attr\n\u001b[1;32m--> 106\u001b[0m object_dict, function_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m    107\u001b[0m     serialization_cache\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[0;32m    111\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\model_serialization.py:57\u001b[0m, in \u001b[0;36mModelSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     53\u001b[0m     default_signature \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mdefault_save_signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m     55\u001b[0m \u001b[39m# Other than the default signature function, all other attributes match\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# with the ones serialized by Layer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m objects, functions \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m     58\u001b[0m     serialization_cache\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m default_signature\n\u001b[0;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m objects, functions\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m objects \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mwrap_layer_objects(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, serialization_cache)\n\u001b[1;32m--> 117\u001b[0m functions \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39;49mwrap_layer_functions(\n\u001b[0;32m    118\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, serialization_cache\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[39m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:168\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    162\u001b[0m         fn_name: \u001b[39mgetattr\u001b[39m(layer\u001b[39m.\u001b[39mkeras_api, fn_name, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m         \u001b[39mfor\u001b[39;00m fn_name \u001b[39min\u001b[39;00m serialized_attributes\u001b[39m.\u001b[39mLayerAttributes\u001b[39m.\u001b[39mall_functions\n\u001b[0;32m    164\u001b[0m     }\n\u001b[0;32m    166\u001b[0m \u001b[39m# Reset the losses of the layer and its children. The call function in each\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# child layer is replaced with tf.functions.\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m original_fns \u001b[39m=\u001b[39m _replace_child_layer_functions(layer, serialization_cache)\n\u001b[0;32m    169\u001b[0m original_losses \u001b[39m=\u001b[39m _reset_layer_losses(layer)\n\u001b[0;32m    171\u001b[0m \u001b[39m# Wrap all the layer call and activity regularizer functions.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[39m# Use LayerCallCollection to ensure that all layer call functions (__call__,\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# call with losses) are traced with the same inputs.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:307\u001b[0m, in \u001b[0;36m_replace_child_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39mif\u001b[39;00m child_layer \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m serialization_cache[constants\u001b[39m.\u001b[39mKERAS_CACHE_KEY]:\n\u001b[1;32m--> 307\u001b[0m     serialized_functions \u001b[39m=\u001b[39m child_layer\u001b[39m.\u001b[39;49m_trackable_saved_model_saver\u001b[39m.\u001b[39;49m_get_serialized_attributes(  \u001b[39m# noqa: E501\u001b[39;49;00m\n\u001b[0;32m    308\u001b[0m         serialization_cache\n\u001b[0;32m    309\u001b[0m     )\u001b[39m.\u001b[39mfunctions\n\u001b[0;32m    310\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     serialized_functions \u001b[39m=\u001b[39m serialization_cache[\n\u001b[0;32m    312\u001b[0m         constants\u001b[39m.\u001b[39mKERAS_CACHE_KEY\n\u001b[0;32m    313\u001b[0m     ][child_layer]\u001b[39m.\u001b[39mfunctions\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m     save_impl\u001b[39m.\u001b[39mshould_skip_serialization(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m    102\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_must_restore_from_config\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m serialized_attr\n\u001b[1;32m--> 106\u001b[0m object_dict, function_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m    107\u001b[0m     serialization_cache\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[0;32m    111\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m objects \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mwrap_layer_objects(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, serialization_cache)\n\u001b[1;32m--> 117\u001b[0m functions \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39;49mwrap_layer_functions(\n\u001b[0;32m    118\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, serialization_cache\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[39m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:225\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m fns\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    224\u001b[0m             \u001b[39mif\u001b[39;00m fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(fn, LayerCall):\n\u001b[1;32m--> 225\u001b[0m                 fn\u001b[39m.\u001b[39mget_concrete_function()\n\u001b[0;32m    227\u001b[0m \u001b[39m# Restore overwritten functions and losses\u001b[39;00m\n\u001b[0;32m    228\u001b[0m _restore_child_layer_functions(original_fns)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:392\u001b[0m, in \u001b[0;36mtracing_scope\u001b[1;34m()\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m training \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(training):\n\u001b[1;32m--> 392\u001b[0m         fn\u001b[39m.\u001b[39mget_concrete_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    393\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m     fn\u001b[39m.\u001b[39mget_concrete_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1239\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1238\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1240\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1219\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1219\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m   1220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m   1223\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:634\u001b[0m, in \u001b[0;36mlayer_call_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mcall_context()\u001b[39m.\u001b[39menter(\n\u001b[0;32m    625\u001b[0m     layer,\n\u001b[0;32m    626\u001b[0m     inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m     saving\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    630\u001b[0m ):\n\u001b[0;32m    631\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    632\u001b[0m         layer\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m    633\u001b[0m     ):\n\u001b[1;32m--> 634\u001b[0m         ret \u001b[39m=\u001b[39m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    635\u001b[0m _restore_layer_losses(original_losses)\n\u001b[0;32m    636\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:190\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[1;32m--> 190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    191\u001b[0m     training,\n\u001b[0;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    193\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    194\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mVariable):\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    109\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[0;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[0;32m     57\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:193\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39msmart_cond(\n\u001b[0;32m    191\u001b[0m     training,\n\u001b[0;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    194\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:188\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.replace_training_and_call\u001b[1;34m(training)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_training_and_call\u001b[39m(training):\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:720\u001b[0m, in \u001b[0;36m_extract_outputs_from_fn.<locals>.call\u001b[1;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 720\u001b[0m     \u001b[39mreturn\u001b[39;00m call_and_return_conditional_losses(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:674\u001b[0m, in \u001b[0;36mLayerCall.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    673\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_trace(args, kwargs)\n\u001b[1;32m--> 674\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrapped_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:634\u001b[0m, in \u001b[0;36mlayer_call_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mwith\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mcall_context()\u001b[39m.\u001b[39menter(\n\u001b[0;32m    625\u001b[0m     layer,\n\u001b[0;32m    626\u001b[0m     inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m     saving\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    630\u001b[0m ):\n\u001b[0;32m    631\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    632\u001b[0m         layer\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m    633\u001b[0m     ):\n\u001b[1;32m--> 634\u001b[0m         ret \u001b[39m=\u001b[39m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    635\u001b[0m _restore_layer_losses(original_losses)\n\u001b[0;32m    636\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:190\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[1;32m--> 190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    191\u001b[0m     training,\n\u001b[0;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    193\u001b[0m     \u001b[39mlambda\u001b[39;49;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    194\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mVariable):\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    109\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[0;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[0;32m     57\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:193\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_util\u001b[39m.\u001b[39msmart_cond(\n\u001b[0;32m    191\u001b[0m     training,\n\u001b[0;32m    192\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mlambda\u001b[39;00m: replace_training_and_call(\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    194\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:188\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.replace_training_and_call\u001b[1;34m(training)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_training_and_call\u001b[39m(training):\n\u001b[0;32m    185\u001b[0m     new_args, new_kwargs \u001b[39m=\u001b[39m call_spec\u001b[39m.\u001b[39mset_arg_value(\n\u001b[0;32m    186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_call(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:700\u001b[0m, in \u001b[0;36m_wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_and_return_conditional_losses\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    699\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m     call_output \u001b[39m=\u001b[39m layer_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    701\u001b[0m     \u001b[39mif\u001b[39;00m version_utils\u001b[39m.\u001b[39mis_v1_layer_or_model(layer):\n\u001b[0;32m    702\u001b[0m         conditional_losses \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mget_losses_for(\n\u001b[0;32m    703\u001b[0m             _filtered_inputs([args, kwargs])\n\u001b[0;32m    704\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:850\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m    849\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfused:\n\u001b[1;32m--> 850\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fused_batch_norm(inputs, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[0;32m    851\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvirtual_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    852\u001b[0m         \u001b[39m# Currently never reaches here since fused_batch_norm does not\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[39m# support virtual batching\u001b[39;00m\n\u001b[0;32m    854\u001b[0m         outputs \u001b[39m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:660\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fused_batch_norm_inference\u001b[39m():\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfused_batch_norm(\n\u001b[0;32m    650\u001b[0m         inputs,\n\u001b[0;32m    651\u001b[0m         gamma,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    657\u001b[0m         data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_format,\n\u001b[0;32m    658\u001b[0m     )\n\u001b[1;32m--> 660\u001b[0m output, mean, variance \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    661\u001b[0m     training, _fused_batch_norm_training, _fused_batch_norm_inference\n\u001b[0;32m    662\u001b[0m )\n\u001b[0;32m    663\u001b[0m variance \u001b[39m=\u001b[39m _maybe_add_or_remove_bessels_correction(\n\u001b[0;32m    664\u001b[0m     variance, remove\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    665\u001b[0m )\n\u001b[0;32m    667\u001b[0m training_value \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39mconstant_value(training)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mVariable):\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    109\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname\n\u001b[0;32m    110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[0;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[0;32m     57\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:649\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>._fused_batch_norm_inference\u001b[1;34m()\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fused_batch_norm_inference\u001b[39m():\n\u001b[1;32m--> 649\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfused_batch_norm(\n\u001b[0;32m    650\u001b[0m         inputs,\n\u001b[0;32m    651\u001b[0m         gamma,\n\u001b[0;32m    652\u001b[0m         beta,\n\u001b[0;32m    653\u001b[0m         mean\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_mean,\n\u001b[0;32m    654\u001b[0m         variance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_variance,\n\u001b[0;32m    655\u001b[0m         epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    656\u001b[0m         is_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_format,\n\u001b[0;32m    658\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1691\u001b[0m, in \u001b[0;36mfused_batch_norm\u001b[1;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[0;32m   1688\u001b[0m min_epsilon \u001b[39m=\u001b[39m \u001b[39m1.001e-5\u001b[39m\n\u001b[0;32m   1689\u001b[0m epsilon \u001b[39m=\u001b[39m epsilon \u001b[39mif\u001b[39;00m epsilon \u001b[39m>\u001b[39m min_epsilon \u001b[39melse\u001b[39;00m min_epsilon\n\u001b[1;32m-> 1691\u001b[0m y, running_mean, running_var, _, _, _ \u001b[39m=\u001b[39m gen_nn_ops\u001b[39m.\u001b[39;49mfused_batch_norm_v3(\n\u001b[0;32m   1692\u001b[0m     x,\n\u001b[0;32m   1693\u001b[0m     scale,\n\u001b[0;32m   1694\u001b[0m     offset,\n\u001b[0;32m   1695\u001b[0m     mean,\n\u001b[0;32m   1696\u001b[0m     variance,\n\u001b[0;32m   1697\u001b[0m     epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[0;32m   1698\u001b[0m     exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor,\n\u001b[0;32m   1699\u001b[0m     data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1700\u001b[0m     is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[0;32m   1701\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1702\u001b[0m \u001b[39mreturn\u001b[39;00m y, running_mean, running_var\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:4504\u001b[0m, in \u001b[0;36mfused_batch_norm_v3\u001b[1;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[0;32m   4502\u001b[0m   is_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   4503\u001b[0m is_training \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(is_training, \u001b[39m\"\u001b[39m\u001b[39mis_training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 4504\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   4505\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mFusedBatchNormV3\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, scale\u001b[39m=\u001b[39;49mscale, offset\u001b[39m=\u001b[39;49moffset, mean\u001b[39m=\u001b[39;49mmean,\n\u001b[0;32m   4506\u001b[0m                           variance\u001b[39m=\u001b[39;49mvariance, epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[0;32m   4507\u001b[0m                           exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor,\n\u001b[0;32m   4508\u001b[0m                           data_format\u001b[39m=\u001b[39;49mdata_format, is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[0;32m   4509\u001b[0m                           name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   4510\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   4511\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:779\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[0;32m    778\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[1;32m--> 779\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0;32m    780\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[0;32m    781\u001b[0m                            input_types)\n\u001b[0;32m    782\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[0;32m    783\u001b[0m                            default_type_attr_map, attrs)\n\u001b[0;32m    784\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:552\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[0;32m    546\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    547\u001b[0m           values,\n\u001b[0;32m    548\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[0;32m    549\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[0;32m    550\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[0;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 552\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    553\u001b[0m         values,\n\u001b[0;32m    554\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    555\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    556\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[0;32m    557\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[0;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2105\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m-> 2105\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1467\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1465\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1467\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:582\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[0;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:538\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 538\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    539\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, resource\u001b[39m=\u001b[39;49mresource, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    540\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    541\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gc\n",
    "\n",
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "\n",
    "#AVG (Mittelwert von RGB), RNDM_IR (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "pretrained_weights = 'AVG' \n",
    "\n",
    "# Art des Netzwerks, BASIC, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu reduzieren)\n",
    "conf = {\n",
    "    'AVG': 'BASIC',\n",
    "    'RNDM_IR': 'BASIC',\n",
    "    'NO_TL': 'BASIC',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    }\n",
    "\n",
    "# initiale Learning rate\n",
    "learning_rate = 0.001 \n",
    "\n",
    "# Dropout rate für RGB & IR, jeweils 0-1\n",
    "rgb_drop = 0 \n",
    "ir_drop = 0\n",
    "\n",
    "# Nutzung von Early Stopping beim Training\n",
    "early_stop = False\n",
    "\n",
    "# L1 & L2 weight decay regularizer 0-1\n",
    "l1 = 0.0005 \n",
    "l2 = 0.0005\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 80\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "\n",
    "# Durch RegEx kann aus den Layernamen der Index der Convolutional-Layer entnommen werden\n",
    "idx = 0\n",
    "conv_idx_list = []\n",
    "\n",
    "# Layer werden dafür rückwärts durchlaufen\n",
    "for layer in reversed(unet.layers):\n",
    "    # Bottleneck beginnt bei 'up_sampling2d', idx auf 0\n",
    "    if layer.name == 'up_sampling2d':\n",
    "        idx = 0\n",
    "\n",
    "    # Conv-Layer enden auf 'conv', wenn durch RegEx erkannt kommt Index von Bottleneck aus gezählt in Liste\n",
    "    if re.search(r\"conv$\", layer.name):\n",
    "        conv_idx_list.append(idx)\n",
    "\n",
    "    idx +=1 \n",
    "\n",
    "# Iteriere über Liste der Indizes mit Conv-Layern und friere jeweilige Layeranzahl im Encoder ein\n",
    "for conv_idx in conv_idx_list:\n",
    "\n",
    "    model_name = f'FT_Tests_{pretrained_weights}_Freeze_1st_conv_{train_first_layer}&{FT_train_first_layer}_{conv_idx}'\n",
    "\n",
    "    # Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "    output_folder_prefix = 'FT_Tests'\n",
    "\n",
    "    unet = load_model(conf[pretrained_weights])\n",
    "    set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "    set_weight_decay(unet, l1= l1, l2= l2)\n",
    "    set_pretrained_weights(unet, pretrained_weights)\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "    compile_model(unet, learning_rate)\n",
    "\n",
    "    train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    "    )\n",
    "\n",
    "    val_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = True,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    "    )\n",
    "\n",
    "    test_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = False,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    "    )\n",
    "\n",
    "    callbacks = get_callbacks(model_name, output_folder_prefix, early_stop)\n",
    "\n",
    "    for i, layer in enumerate(unet.layers):\n",
    "        #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        try:\n",
    "            print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "        except:\n",
    "            print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "    model_history = unet.fit(train_data_generator, \n",
    "                            validation_data=val_data_generator, \n",
    "                            callbacks= callbacks, \n",
    "                            epochs= initial_epochs)\n",
    "\n",
    "    # Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\n",
    "    shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "    total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "    # \n",
    "    if pretrained_weights != 'NO_TL':\n",
    "        set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer, conv_idx)\n",
    "\n",
    "    # erneut kompilieren, Learning Rate verringern\n",
    "    compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "    for i, layer in enumerate(unet.layers):\n",
    "        #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        try:\n",
    "            print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "        except:\n",
    "            print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "    history_fine = unet.fit(train_data_generator,\n",
    "                            validation_data= val_data_generator,\n",
    "                            callbacks= callbacks,\n",
    "                            epochs= total_epochs,\n",
    "                            initial_epoch= initial_epochs)\n",
    "\n",
    "\n",
    "    # laden des besten models\n",
    "    checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "    unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "    compile_model(unet, learning_rate)\n",
    "\n",
    "    # Evaluieren & Ergebnisse in Tabelle\n",
    "    eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "    FT_output_path = '../output/FT_Freeze_1st_conv_{train_first_layer}&{FT_train_first_layer}_Test_runs.csv'\n",
    "\n",
    "    # Anlegen der Datei für ersten Durchlauf\n",
    "    if not os.path.isfile(FT_output_path):\n",
    "        with open(FT_output_path, 'w', newline='') as f_object:\n",
    "            writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "            header = ['name', 'loss', 'accuracy', 'binary_iou', 'TP', 'FP', 'TN', 'FN', 'precision', 'recall']\n",
    "            writer_object.writerow(header)\n",
    "\n",
    "\n",
    "            row = []\n",
    "        \n",
    "            row.append(model_name)\n",
    "\n",
    "            for x in eval_out:\n",
    "                row.append(x)            \n",
    "\n",
    "            writer_object.writerow(row)\n",
    "\n",
    "    # Anhängen an Datei für weitere Durchläufe\n",
    "    else:\n",
    "        with open(FT_output_path, 'a', newline='') as f_object:\n",
    "            row = []\n",
    "            \n",
    "            row.append(model_name)\n",
    "\n",
    "            for x in eval_out:\n",
    "                row.append(x)\n",
    "\n",
    "            writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "            writer_object.writerow(row)\n",
    "\n",
    "    # Löschen des Modells und des Caches um OOM vorzubeugen beim Training in der Schleife\n",
    "    del unet\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_list = [4, 7, 11, 15, 18, 22, 26, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 64, 68, 72, 75, 79, 83, 86, 90, 94, 95, 98, 102, 106, 110,\n",
    "               114, 118, 121, 125, 129, 132, 136, 140, 141, 144, 148, 152, 156, 160, 164, 167, 171, 175, 176, 179, 183, 188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 7,\n",
       " 11,\n",
       " 15,\n",
       " 18,\n",
       " 22,\n",
       " 26,\n",
       " 27,\n",
       " 30,\n",
       " 34,\n",
       " 38,\n",
       " 42,\n",
       " 46,\n",
       " 50,\n",
       " 53,\n",
       " 57,\n",
       " 61,\n",
       " 64,\n",
       " 68,\n",
       " 72,\n",
       " 75,\n",
       " 79,\n",
       " 83,\n",
       " 86,\n",
       " 90,\n",
       " 94,\n",
       " 95,\n",
       " 98,\n",
       " 102,\n",
       " 106,\n",
       " 110,\n",
       " 114,\n",
       " 118,\n",
       " 121,\n",
       " 125,\n",
       " 129,\n",
       " 132,\n",
       " 136,\n",
       " 140,\n",
       " 141,\n",
       " 144,\n",
       " 148,\n",
       " 152,\n",
       " 156,\n",
       " 160,\n",
       " 164,\n",
       " 167,\n",
       " 171,\n",
       " 175,\n",
       " 176,\n",
       " 179,\n",
       " 183,\n",
       " 188]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_idx_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob trainable oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfigurationen, Laden & Kompilieren des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM_IR (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BASIC',\n",
    "    'RNDM_IR': 'BASIC',\n",
    "    'NO_TL': 'BASIC',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BASIC, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 480\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "model_name = f'Final_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}_e{total_epochs}'\n",
    "\n",
    "# Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "unet.save('model_RGB_SPLIT.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisieren der Data Generator & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: True\n",
      "1 split_input trainable weights: 0 trainable: True\n",
      "2 dropout_r trainable weights: 0 trainable: True\n",
      "3 dropout_g trainable weights: 0 trainable: True\n",
      "4 dropout_b trainable weights: 0 trainable: True\n",
      "5 dropout_ir trainable weights: 0 trainable: True\n",
      "6 concatenate_dropout trainable weights: 0 trainable: True\n",
      "7 conv1_pad trainable weights: 0 trainable: True\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: True\n",
      "10 pool1_pool trainable weights: 0 trainable: True\n",
      "11 conv2_block1_preact_bn trainable weights: 2 trainable: True\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: True\n",
      "13 conv2_block1_1_conv trainable weights: 1 trainable: True\n",
      "14 conv2_block1_1_bn trainable weights: 2 trainable: True\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: True\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: True\n",
      "17 conv2_block1_2_conv trainable weights: 1 trainable: True\n",
      "18 conv2_block1_2_bn trainable weights: 2 trainable: True\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: True\n",
      "20 conv2_block1_0_conv trainable weights: 2 trainable: True\n",
      "21 conv2_block1_3_conv trainable weights: 2 trainable: True\n",
      "22 conv2_block1_out trainable weights: 0 trainable: True\n",
      "23 conv2_block2_preact_bn trainable weights: 2 trainable: True\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: True\n",
      "25 conv2_block2_1_conv trainable weights: 1 trainable: True\n",
      "26 conv2_block2_1_bn trainable weights: 2 trainable: True\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: True\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: True\n",
      "29 conv2_block2_2_conv trainable weights: 1 trainable: True\n",
      "30 conv2_block2_2_bn trainable weights: 2 trainable: True\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: True\n",
      "32 conv2_block2_3_conv trainable weights: 2 trainable: True\n",
      "33 conv2_block2_out trainable weights: 0 trainable: True\n",
      "34 conv2_block3_preact_bn trainable weights: 2 trainable: True\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: True\n",
      "36 conv2_block3_1_conv trainable weights: 1 trainable: True\n",
      "37 conv2_block3_1_bn trainable weights: 2 trainable: True\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: True\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: True\n",
      "40 conv2_block3_2_conv trainable weights: 1 trainable: True\n",
      "41 conv2_block3_2_bn trainable weights: 2 trainable: True\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: True\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: True\n",
      "44 conv2_block3_3_conv trainable weights: 2 trainable: True\n",
      "45 conv2_block3_out trainable weights: 0 trainable: True\n",
      "46 conv3_block1_preact_bn trainable weights: 2 trainable: True\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: True\n",
      "48 conv3_block1_1_conv trainable weights: 1 trainable: True\n",
      "49 conv3_block1_1_bn trainable weights: 2 trainable: True\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: True\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: True\n",
      "52 conv3_block1_2_conv trainable weights: 1 trainable: True\n",
      "53 conv3_block1_2_bn trainable weights: 2 trainable: True\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: True\n",
      "55 conv3_block1_0_conv trainable weights: 2 trainable: True\n",
      "56 conv3_block1_3_conv trainable weights: 2 trainable: True\n",
      "57 conv3_block1_out trainable weights: 0 trainable: True\n",
      "58 conv3_block2_preact_bn trainable weights: 2 trainable: True\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: True\n",
      "60 conv3_block2_1_conv trainable weights: 1 trainable: True\n",
      "61 conv3_block2_1_bn trainable weights: 2 trainable: True\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: True\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: True\n",
      "64 conv3_block2_2_conv trainable weights: 1 trainable: True\n",
      "65 conv3_block2_2_bn trainable weights: 2 trainable: True\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: True\n",
      "67 conv3_block2_3_conv trainable weights: 2 trainable: True\n",
      "68 conv3_block2_out trainable weights: 0 trainable: True\n",
      "69 conv3_block3_preact_bn trainable weights: 2 trainable: True\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: True\n",
      "71 conv3_block3_1_conv trainable weights: 1 trainable: True\n",
      "72 conv3_block3_1_bn trainable weights: 2 trainable: True\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: True\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: True\n",
      "75 conv3_block3_2_conv trainable weights: 1 trainable: True\n",
      "76 conv3_block3_2_bn trainable weights: 2 trainable: True\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: True\n",
      "78 conv3_block3_3_conv trainable weights: 2 trainable: True\n",
      "79 conv3_block3_out trainable weights: 0 trainable: True\n",
      "80 conv3_block4_preact_bn trainable weights: 2 trainable: True\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: True\n",
      "82 conv3_block4_1_conv trainable weights: 1 trainable: True\n",
      "83 conv3_block4_1_bn trainable weights: 2 trainable: True\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: True\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: True\n",
      "86 conv3_block4_2_conv trainable weights: 1 trainable: True\n",
      "87 conv3_block4_2_bn trainable weights: 2 trainable: True\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: True\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: True\n",
      "90 conv3_block4_3_conv trainable weights: 2 trainable: True\n",
      "91 conv3_block4_out trainable weights: 0 trainable: True\n",
      "92 conv4_block1_preact_bn trainable weights: 2 trainable: True\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: True\n",
      "94 conv4_block1_1_conv trainable weights: 1 trainable: True\n",
      "95 conv4_block1_1_bn trainable weights: 2 trainable: True\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: True\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: True\n",
      "98 conv4_block1_2_conv trainable weights: 1 trainable: True\n",
      "99 conv4_block1_2_bn trainable weights: 2 trainable: True\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: True\n",
      "101 conv4_block1_0_conv trainable weights: 2 trainable: True\n",
      "102 conv4_block1_3_conv trainable weights: 2 trainable: True\n",
      "103 conv4_block1_out trainable weights: 0 trainable: True\n",
      "104 conv4_block2_preact_bn trainable weights: 2 trainable: True\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: True\n",
      "106 conv4_block2_1_conv trainable weights: 1 trainable: True\n",
      "107 conv4_block2_1_bn trainable weights: 2 trainable: True\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: True\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: True\n",
      "110 conv4_block2_2_conv trainable weights: 1 trainable: True\n",
      "111 conv4_block2_2_bn trainable weights: 2 trainable: True\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: True\n",
      "113 conv4_block2_3_conv trainable weights: 2 trainable: True\n",
      "114 conv4_block2_out trainable weights: 0 trainable: True\n",
      "115 conv4_block3_preact_bn trainable weights: 2 trainable: True\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: True\n",
      "117 conv4_block3_1_conv trainable weights: 1 trainable: True\n",
      "118 conv4_block3_1_bn trainable weights: 2 trainable: True\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: True\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: True\n",
      "121 conv4_block3_2_conv trainable weights: 1 trainable: True\n",
      "122 conv4_block3_2_bn trainable weights: 2 trainable: True\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: True\n",
      "124 conv4_block3_3_conv trainable weights: 2 trainable: True\n",
      "125 conv4_block3_out trainable weights: 0 trainable: True\n",
      "126 conv4_block4_preact_bn trainable weights: 2 trainable: True\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: True\n",
      "128 conv4_block4_1_conv trainable weights: 1 trainable: True\n",
      "129 conv4_block4_1_bn trainable weights: 2 trainable: True\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: True\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: True\n",
      "132 conv4_block4_2_conv trainable weights: 1 trainable: True\n",
      "133 conv4_block4_2_bn trainable weights: 2 trainable: True\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: True\n",
      "135 conv4_block4_3_conv trainable weights: 2 trainable: True\n",
      "136 conv4_block4_out trainable weights: 0 trainable: True\n",
      "137 conv4_block5_preact_bn trainable weights: 2 trainable: True\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: True\n",
      "139 conv4_block5_1_conv trainable weights: 1 trainable: True\n",
      "140 conv4_block5_1_bn trainable weights: 2 trainable: True\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: True\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: True\n",
      "143 conv4_block5_2_conv trainable weights: 1 trainable: True\n",
      "144 conv4_block5_2_bn trainable weights: 2 trainable: True\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: True\n",
      "146 conv4_block5_3_conv trainable weights: 2 trainable: True\n",
      "147 conv4_block5_out trainable weights: 0 trainable: True\n",
      "148 conv4_block6_preact_bn trainable weights: 2 trainable: True\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: True\n",
      "150 conv4_block6_1_conv trainable weights: 1 trainable: True\n",
      "151 conv4_block6_1_bn trainable weights: 2 trainable: True\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: True\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: True\n",
      "154 conv4_block6_2_conv trainable weights: 1 trainable: True\n",
      "155 conv4_block6_2_bn trainable weights: 2 trainable: True\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: True\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: True\n",
      "158 conv4_block6_3_conv trainable weights: 2 trainable: True\n",
      "159 conv4_block6_out trainable weights: 0 trainable: True\n",
      "160 conv5_block1_preact_bn trainable weights: 2 trainable: True\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: True\n",
      "162 conv5_block1_1_conv trainable weights: 1 trainable: True\n",
      "163 conv5_block1_1_bn trainable weights: 2 trainable: True\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: True\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: True\n",
      "166 conv5_block1_2_conv trainable weights: 1 trainable: True\n",
      "167 conv5_block1_2_bn trainable weights: 2 trainable: True\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: True\n",
      "169 conv5_block1_0_conv trainable weights: 2 trainable: True\n",
      "170 conv5_block1_3_conv trainable weights: 2 trainable: True\n",
      "171 conv5_block1_out trainable weights: 0 trainable: True\n",
      "172 conv5_block2_preact_bn trainable weights: 2 trainable: True\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: True\n",
      "174 conv5_block2_1_conv trainable weights: 1 trainable: True\n",
      "175 conv5_block2_1_bn trainable weights: 2 trainable: True\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: True\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: True\n",
      "178 conv5_block2_2_conv trainable weights: 1 trainable: True\n",
      "179 conv5_block2_2_bn trainable weights: 2 trainable: True\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: True\n",
      "181 conv5_block2_3_conv trainable weights: 2 trainable: True\n",
      "182 conv5_block2_out trainable weights: 0 trainable: True\n",
      "183 conv5_block3_preact_bn trainable weights: 2 trainable: True\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: True\n",
      "185 conv5_block3_1_conv trainable weights: 1 trainable: True\n",
      "186 conv5_block3_1_bn trainable weights: 2 trainable: True\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: True\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: True\n",
      "189 conv5_block3_2_conv trainable weights: 1 trainable: True\n",
      "190 conv5_block3_2_bn trainable weights: 2 trainable: True\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: True\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2 trainable: True\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.7748 - binary_iou: 0.6306 - true_positives: 110322440.0000 - false_positives: 51332968.0000 - true_negatives: 137243552.0000 - false_negatives: 20621784.0000 - precision: 0.6825 - recall: 0.8425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 113s 544ms/step - loss: 0.2635 - accuracy: 0.7748 - binary_iou: 0.6306 - true_positives: 110322440.0000 - false_positives: 51332968.0000 - true_negatives: 137243552.0000 - false_negatives: 20621784.0000 - precision: 0.6825 - recall: 0.8425 - val_loss: 0.3675 - val_accuracy: 0.5280 - val_binary_iou: 0.3294 - val_true_positives: 44283288.0000 - val_false_positives: 49263728.0000 - val_true_negatives: 11672403.0000 - val_false_negatives: 752282.0000 - val_precision: 0.4734 - val_recall: 0.9833\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.8263 - binary_iou: 0.7007 - true_positives: 112457688.0000 - false_positives: 36798728.0000 - true_negatives: 151554112.0000 - false_negatives: 18710254.0000 - precision: 0.7535 - recall: 0.8574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 534ms/step - loss: 0.2008 - accuracy: 0.8263 - binary_iou: 0.7007 - true_positives: 112457688.0000 - false_positives: 36798728.0000 - true_negatives: 151554112.0000 - false_negatives: 18710254.0000 - precision: 0.7535 - recall: 0.8574 - val_loss: 0.2619 - val_accuracy: 0.7794 - val_binary_iou: 0.6332 - val_true_positives: 33500694.0000 - val_false_positives: 11793966.0000 - val_true_negatives: 49095388.0000 - val_false_negatives: 11581671.0000 - val_precision: 0.7396 - val_recall: 0.7431\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1906 - accuracy: 0.8369 - binary_iou: 0.7158 - true_positives: 112341568.0000 - false_positives: 33268416.0000 - true_negatives: 155069904.0000 - false_negatives: 18840908.0000 - precision: 0.7715 - recall: 0.8564 - val_loss: 0.3997 - val_accuracy: 0.7414 - val_binary_iou: 0.5562 - val_true_positives: 21139908.0000 - val_false_positives: 3393639.0000 - val_true_negatives: 57425280.0000 - val_false_negatives: 24012884.0000 - val_precision: 0.8617 - val_recall: 0.4682\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1912 - accuracy: 0.8365 - binary_iou: 0.7152 - true_positives: 112326720.0000 - false_positives: 33438932.0000 - true_negatives: 154942592.0000 - false_negatives: 18812554.0000 - precision: 0.7706 - recall: 0.8565 - val_loss: 0.2664 - val_accuracy: 0.7678 - val_binary_iou: 0.6195 - val_true_positives: 34351720.0000 - val_false_positives: 13823533.0000 - val_true_negatives: 47010384.0000 - val_false_negatives: 10786068.0000 - val_precision: 0.7131 - val_recall: 0.7610\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1953 - accuracy: 0.8327 - binary_iou: 0.7094 - true_positives: 111420240.0000 - false_positives: 33771180.0000 - true_negatives: 154638288.0000 - false_negatives: 19691016.0000 - precision: 0.7674 - recall: 0.8498 - val_loss: 0.2869 - val_accuracy: 0.7753 - val_binary_iou: 0.6226 - val_true_positives: 30282234.0000 - val_false_positives: 8976267.0000 - val_true_negatives: 51875088.0000 - val_false_negatives: 14838129.0000 - val_precision: 0.7714 - val_recall: 0.6711\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1962 - accuracy: 0.8309 - binary_iou: 0.7071 - true_positives: 111882968.0000 - false_positives: 34676592.0000 - true_negatives: 153616144.0000 - false_negatives: 19345006.0000 - precision: 0.7634 - recall: 0.8526 - val_loss: 0.2936 - val_accuracy: 0.7745 - val_binary_iou: 0.6203 - val_true_positives: 29602470.0000 - val_false_positives: 8361940.0000 - val_true_negatives: 52477740.0000 - val_false_negatives: 15529559.0000 - val_precision: 0.7797 - val_recall: 0.6559\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1873 - accuracy: 0.8389 - binary_iou: 0.7188 - true_positives: 112550480.0000 - false_positives: 32924052.0000 - true_negatives: 155499392.0000 - false_negatives: 18546870.0000 - precision: 0.7737 - recall: 0.8585 - val_loss: 0.3897 - val_accuracy: 0.6852 - val_binary_iou: 0.5115 - val_true_positives: 26550394.0000 - val_false_positives: 14820179.0000 - val_true_negatives: 46056252.0000 - val_false_negatives: 18544888.0000 - val_precision: 0.6418 - val_recall: 0.5888\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.8437 - binary_iou: 0.7257 - true_positives: 112584536.0000 - false_positives: 31358590.0000 - true_negatives: 156996160.0000 - false_negatives: 18581424.0000 - precision: 0.7821 - recall: 0.8583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 532ms/step - loss: 0.1836 - accuracy: 0.8437 - binary_iou: 0.7257 - true_positives: 112584536.0000 - false_positives: 31358590.0000 - true_negatives: 156996160.0000 - false_negatives: 18581424.0000 - precision: 0.7821 - recall: 0.8583 - val_loss: 0.2714 - val_accuracy: 0.8038 - val_binary_iou: 0.6553 - val_true_positives: 28644722.0000 - val_false_positives: 4346973.0000 - val_true_negatives: 56537332.0000 - val_false_negatives: 16442703.0000 - val_precision: 0.8682 - val_recall: 0.6353\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.8516 - binary_iou: 0.7375 - true_positives: 113356000.0000 - false_positives: 29737572.0000 - true_negatives: 158746672.0000 - false_negatives: 17680482.0000 - precision: 0.7922 - recall: 0.8651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 531ms/step - loss: 0.1748 - accuracy: 0.8516 - binary_iou: 0.7375 - true_positives: 113356000.0000 - false_positives: 29737572.0000 - true_negatives: 158746672.0000 - false_negatives: 17680482.0000 - precision: 0.7922 - recall: 0.8651 - val_loss: 0.2242 - val_accuracy: 0.8094 - val_binary_iou: 0.6756 - val_true_positives: 35643324.0000 - val_false_positives: 10836788.0000 - val_true_negatives: 50132104.0000 - val_false_negatives: 9359495.0000 - val_precision: 0.7669 - val_recall: 0.7920\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.8486 - binary_iou: 0.7330 - true_positives: 113048408.0000 - false_positives: 30296512.0000 - true_negatives: 158100608.0000 - false_negatives: 18075256.0000 - precision: 0.7886 - recall: 0.8622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 533ms/step - loss: 0.1778 - accuracy: 0.8486 - binary_iou: 0.7330 - true_positives: 113048408.0000 - false_positives: 30296512.0000 - true_negatives: 158100608.0000 - false_negatives: 18075256.0000 - precision: 0.7886 - recall: 0.8622 - val_loss: 0.2042 - val_accuracy: 0.8298 - val_binary_iou: 0.7040 - val_true_positives: 35853008.0000 - val_false_positives: 8740988.0000 - val_true_negatives: 52082344.0000 - val_false_negatives: 9295368.0000 - val_precision: 0.8040 - val_recall: 0.7941\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1760 - accuracy: 0.8509 - binary_iou: 0.7363 - true_positives: 112638136.0000 - false_positives: 29141156.0000 - true_negatives: 159244352.0000 - false_negatives: 18497134.0000 - precision: 0.7945 - recall: 0.8589 - val_loss: 0.2256 - val_accuracy: 0.8246 - val_binary_iou: 0.6912 - val_true_positives: 32315060.0000 - val_false_positives: 5852351.0000 - val_true_negatives: 55068768.0000 - val_false_negatives: 12735545.0000 - val_precision: 0.8467 - val_recall: 0.7173\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1684 - accuracy: 0.8581 - binary_iou: 0.7471 - true_positives: 113337384.0000 - false_positives: 27537940.0000 - true_negatives: 160828256.0000 - false_negatives: 17817292.0000 - precision: 0.8045 - recall: 0.8642 - val_loss: 0.2417 - val_accuracy: 0.8203 - val_binary_iou: 0.6815 - val_true_positives: 30462008.0000 - val_false_positives: 4312660.0000 - val_true_negatives: 56463476.0000 - val_false_negatives: 14733559.0000 - val_precision: 0.8760 - val_recall: 0.6740\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.8573 - binary_iou: 0.7460 - true_positives: 113173344.0000 - false_positives: 27627596.0000 - true_negatives: 160764688.0000 - false_negatives: 17955152.0000 - precision: 0.8038 - recall: 0.8631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1695 - accuracy: 0.8573 - binary_iou: 0.7460 - true_positives: 113173344.0000 - false_positives: 27627596.0000 - true_negatives: 160764688.0000 - false_negatives: 17955152.0000 - precision: 0.8038 - recall: 0.8631 - val_loss: 0.1629 - val_accuracy: 0.8650 - val_binary_iou: 0.7573 - val_true_positives: 37328536.0000 - val_false_positives: 6535518.0000 - val_true_negatives: 54340628.0000 - val_false_negatives: 7767044.0000 - val_precision: 0.8510 - val_recall: 0.8278\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1673 - accuracy: 0.8594 - binary_iou: 0.7490 - true_positives: 113067384.0000 - false_positives: 26854024.0000 - true_negatives: 161514976.0000 - false_negatives: 18084364.0000 - precision: 0.8081 - recall: 0.8621 - val_loss: 0.1739 - val_accuracy: 0.8418 - val_binary_iou: 0.7255 - val_true_positives: 40302280.0000 - val_false_positives: 11974760.0000 - val_true_negatives: 48906328.0000 - val_false_negatives: 4788355.0000 - val_precision: 0.7709 - val_recall: 0.8938\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1677 - accuracy: 0.8583 - binary_iou: 0.7476 - true_positives: 113657400.0000 - false_positives: 27765652.0000 - true_negatives: 160597008.0000 - false_negatives: 17500688.0000 - precision: 0.8037 - recall: 0.8666 - val_loss: 0.1855 - val_accuracy: 0.8563 - val_binary_iou: 0.7396 - val_true_positives: 34083240.0000 - val_false_positives: 4229030.0000 - val_true_negatives: 56658240.0000 - val_false_negatives: 11001192.0000 - val_precision: 0.8896 - val_recall: 0.7560\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.8627 - binary_iou: 0.7542 - true_positives: 113758624.0000 - false_positives: 26463780.0000 - true_negatives: 161882528.0000 - false_negatives: 17415892.0000 - precision: 0.8113 - recall: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.1633 - accuracy: 0.8627 - binary_iou: 0.7542 - true_positives: 113758624.0000 - false_positives: 26463780.0000 - true_negatives: 161882528.0000 - false_negatives: 17415892.0000 - precision: 0.8113 - recall: 0.8672 - val_loss: 0.1610 - val_accuracy: 0.8649 - val_binary_iou: 0.7580 - val_true_positives: 38058832.0000 - val_false_positives: 7301977.0000 - val_true_negatives: 53600408.0000 - val_false_negatives: 7010495.0000 - val_precision: 0.8390 - val_recall: 0.8445\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1620 - accuracy: 0.8639 - binary_iou: 0.7562 - true_positives: 114037104.0000 - false_positives: 26308292.0000 - true_negatives: 162010272.0000 - false_negatives: 17165124.0000 - precision: 0.8125 - recall: 0.8692 - val_loss: 0.2081 - val_accuracy: 0.8327 - val_binary_iou: 0.7058 - val_true_positives: 34263492.0000 - val_false_positives: 6899338.0000 - val_true_negatives: 53976072.0000 - val_false_negatives: 10832817.0000 - val_precision: 0.8324 - val_recall: 0.7598\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1611 - accuracy: 0.8644 - binary_iou: 0.7569 - true_positives: 113978856.0000 - false_positives: 26158628.0000 - true_negatives: 162213872.0000 - false_negatives: 17169362.0000 - precision: 0.8133 - recall: 0.8691 - val_loss: 0.1657 - val_accuracy: 0.8614 - val_binary_iou: 0.7522 - val_true_positives: 37739996.0000 - val_false_positives: 7360672.0000 - val_true_negatives: 53540376.0000 - val_false_negatives: 7330679.0000 - val_precision: 0.8368 - val_recall: 0.8374\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1628 - accuracy: 0.8631 - binary_iou: 0.7547 - true_positives: 113562848.0000 - false_positives: 26230946.0000 - true_negatives: 162208304.0000 - false_negatives: 17518656.0000 - precision: 0.8124 - recall: 0.8664 - val_loss: 0.1807 - val_accuracy: 0.8565 - val_binary_iou: 0.7418 - val_true_positives: 35269384.0000 - val_false_positives: 5425760.0000 - val_true_negatives: 55491568.0000 - val_false_negatives: 9784984.0000 - val_precision: 0.8667 - val_recall: 0.7828\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1620 - accuracy: 0.8644 - binary_iou: 0.7566 - true_positives: 113399536.0000 - false_positives: 25598776.0000 - true_negatives: 162786144.0000 - false_negatives: 17736344.0000 - precision: 0.8158 - recall: 0.8647 - val_loss: 0.1735 - val_accuracy: 0.8609 - val_binary_iou: 0.7488 - val_true_positives: 35581408.0000 - val_false_positives: 5178787.0000 - val_true_negatives: 55648540.0000 - val_false_negatives: 9562988.0000 - val_precision: 0.8729 - val_recall: 0.7882\n",
      "0 input trainable weights: 0 trainable: True\n",
      "1 split_input trainable weights: 0 trainable: True\n",
      "2 dropout_r trainable weights: 0 trainable: True\n",
      "3 dropout_g trainable weights: 0 trainable: True\n",
      "4 dropout_b trainable weights: 0 trainable: True\n",
      "5 dropout_ir trainable weights: 0 trainable: True\n",
      "6 concatenate_dropout trainable weights: 0 trainable: True\n",
      "7 conv1_pad trainable weights: 0 trainable: True\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: True\n",
      "10 pool1_pool trainable weights: 0 trainable: True\n",
      "11 conv2_block1_preact_bn trainable weights: 2 trainable: True\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: True\n",
      "13 conv2_block1_1_conv trainable weights: 1 trainable: True\n",
      "14 conv2_block1_1_bn trainable weights: 2 trainable: True\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: True\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: True\n",
      "17 conv2_block1_2_conv trainable weights: 1 trainable: True\n",
      "18 conv2_block1_2_bn trainable weights: 2 trainable: True\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: True\n",
      "20 conv2_block1_0_conv trainable weights: 2 trainable: True\n",
      "21 conv2_block1_3_conv trainable weights: 2 trainable: True\n",
      "22 conv2_block1_out trainable weights: 0 trainable: True\n",
      "23 conv2_block2_preact_bn trainable weights: 2 trainable: True\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: True\n",
      "25 conv2_block2_1_conv trainable weights: 1 trainable: True\n",
      "26 conv2_block2_1_bn trainable weights: 2 trainable: True\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: True\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: True\n",
      "29 conv2_block2_2_conv trainable weights: 1 trainable: True\n",
      "30 conv2_block2_2_bn trainable weights: 2 trainable: True\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: True\n",
      "32 conv2_block2_3_conv trainable weights: 2 trainable: True\n",
      "33 conv2_block2_out trainable weights: 0 trainable: True\n",
      "34 conv2_block3_preact_bn trainable weights: 2 trainable: True\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: True\n",
      "36 conv2_block3_1_conv trainable weights: 1 trainable: True\n",
      "37 conv2_block3_1_bn trainable weights: 2 trainable: True\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: True\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: True\n",
      "40 conv2_block3_2_conv trainable weights: 1 trainable: True\n",
      "41 conv2_block3_2_bn trainable weights: 2 trainable: True\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: True\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: True\n",
      "44 conv2_block3_3_conv trainable weights: 2 trainable: True\n",
      "45 conv2_block3_out trainable weights: 0 trainable: True\n",
      "46 conv3_block1_preact_bn trainable weights: 2 trainable: True\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: True\n",
      "48 conv3_block1_1_conv trainable weights: 1 trainable: True\n",
      "49 conv3_block1_1_bn trainable weights: 2 trainable: True\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: True\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: True\n",
      "52 conv3_block1_2_conv trainable weights: 1 trainable: True\n",
      "53 conv3_block1_2_bn trainable weights: 2 trainable: True\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: True\n",
      "55 conv3_block1_0_conv trainable weights: 2 trainable: True\n",
      "56 conv3_block1_3_conv trainable weights: 2 trainable: True\n",
      "57 conv3_block1_out trainable weights: 0 trainable: True\n",
      "58 conv3_block2_preact_bn trainable weights: 2 trainable: True\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: True\n",
      "60 conv3_block2_1_conv trainable weights: 1 trainable: True\n",
      "61 conv3_block2_1_bn trainable weights: 2 trainable: True\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: True\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: True\n",
      "64 conv3_block2_2_conv trainable weights: 1 trainable: True\n",
      "65 conv3_block2_2_bn trainable weights: 2 trainable: True\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: True\n",
      "67 conv3_block2_3_conv trainable weights: 2 trainable: True\n",
      "68 conv3_block2_out trainable weights: 0 trainable: True\n",
      "69 conv3_block3_preact_bn trainable weights: 2 trainable: True\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: True\n",
      "71 conv3_block3_1_conv trainable weights: 1 trainable: True\n",
      "72 conv3_block3_1_bn trainable weights: 2 trainable: True\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: True\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: True\n",
      "75 conv3_block3_2_conv trainable weights: 1 trainable: True\n",
      "76 conv3_block3_2_bn trainable weights: 2 trainable: True\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: True\n",
      "78 conv3_block3_3_conv trainable weights: 2 trainable: True\n",
      "79 conv3_block3_out trainable weights: 0 trainable: True\n",
      "80 conv3_block4_preact_bn trainable weights: 2 trainable: True\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: True\n",
      "82 conv3_block4_1_conv trainable weights: 1 trainable: True\n",
      "83 conv3_block4_1_bn trainable weights: 2 trainable: True\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: True\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: True\n",
      "86 conv3_block4_2_conv trainable weights: 1 trainable: True\n",
      "87 conv3_block4_2_bn trainable weights: 2 trainable: True\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: True\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: True\n",
      "90 conv3_block4_3_conv trainable weights: 2 trainable: True\n",
      "91 conv3_block4_out trainable weights: 0 trainable: True\n",
      "92 conv4_block1_preact_bn trainable weights: 2 trainable: True\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: True\n",
      "94 conv4_block1_1_conv trainable weights: 1 trainable: True\n",
      "95 conv4_block1_1_bn trainable weights: 2 trainable: True\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: True\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: True\n",
      "98 conv4_block1_2_conv trainable weights: 1 trainable: True\n",
      "99 conv4_block1_2_bn trainable weights: 2 trainable: True\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: True\n",
      "101 conv4_block1_0_conv trainable weights: 2 trainable: True\n",
      "102 conv4_block1_3_conv trainable weights: 2 trainable: True\n",
      "103 conv4_block1_out trainable weights: 0 trainable: True\n",
      "104 conv4_block2_preact_bn trainable weights: 2 trainable: True\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: True\n",
      "106 conv4_block2_1_conv trainable weights: 1 trainable: True\n",
      "107 conv4_block2_1_bn trainable weights: 2 trainable: True\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: True\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: True\n",
      "110 conv4_block2_2_conv trainable weights: 1 trainable: True\n",
      "111 conv4_block2_2_bn trainable weights: 2 trainable: True\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: True\n",
      "113 conv4_block2_3_conv trainable weights: 2 trainable: True\n",
      "114 conv4_block2_out trainable weights: 0 trainable: True\n",
      "115 conv4_block3_preact_bn trainable weights: 2 trainable: True\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: True\n",
      "117 conv4_block3_1_conv trainable weights: 1 trainable: True\n",
      "118 conv4_block3_1_bn trainable weights: 2 trainable: True\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: True\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: True\n",
      "121 conv4_block3_2_conv trainable weights: 1 trainable: True\n",
      "122 conv4_block3_2_bn trainable weights: 2 trainable: True\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: True\n",
      "124 conv4_block3_3_conv trainable weights: 2 trainable: True\n",
      "125 conv4_block3_out trainable weights: 0 trainable: True\n",
      "126 conv4_block4_preact_bn trainable weights: 2 trainable: True\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: True\n",
      "128 conv4_block4_1_conv trainable weights: 1 trainable: True\n",
      "129 conv4_block4_1_bn trainable weights: 2 trainable: True\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: True\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: True\n",
      "132 conv4_block4_2_conv trainable weights: 1 trainable: True\n",
      "133 conv4_block4_2_bn trainable weights: 2 trainable: True\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: True\n",
      "135 conv4_block4_3_conv trainable weights: 2 trainable: True\n",
      "136 conv4_block4_out trainable weights: 0 trainable: True\n",
      "137 conv4_block5_preact_bn trainable weights: 2 trainable: True\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: True\n",
      "139 conv4_block5_1_conv trainable weights: 1 trainable: True\n",
      "140 conv4_block5_1_bn trainable weights: 2 trainable: True\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: True\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: True\n",
      "143 conv4_block5_2_conv trainable weights: 1 trainable: True\n",
      "144 conv4_block5_2_bn trainable weights: 2 trainable: True\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: True\n",
      "146 conv4_block5_3_conv trainable weights: 2 trainable: True\n",
      "147 conv4_block5_out trainable weights: 0 trainable: True\n",
      "148 conv4_block6_preact_bn trainable weights: 2 trainable: True\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: True\n",
      "150 conv4_block6_1_conv trainable weights: 1 trainable: True\n",
      "151 conv4_block6_1_bn trainable weights: 2 trainable: True\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: True\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: True\n",
      "154 conv4_block6_2_conv trainable weights: 1 trainable: True\n",
      "155 conv4_block6_2_bn trainable weights: 2 trainable: True\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: True\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: True\n",
      "158 conv4_block6_3_conv trainable weights: 2 trainable: True\n",
      "159 conv4_block6_out trainable weights: 0 trainable: True\n",
      "160 conv5_block1_preact_bn trainable weights: 2 trainable: True\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: True\n",
      "162 conv5_block1_1_conv trainable weights: 1 trainable: True\n",
      "163 conv5_block1_1_bn trainable weights: 2 trainable: True\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: True\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: True\n",
      "166 conv5_block1_2_conv trainable weights: 1 trainable: True\n",
      "167 conv5_block1_2_bn trainable weights: 2 trainable: True\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: True\n",
      "169 conv5_block1_0_conv trainable weights: 2 trainable: True\n",
      "170 conv5_block1_3_conv trainable weights: 2 trainable: True\n",
      "171 conv5_block1_out trainable weights: 0 trainable: True\n",
      "172 conv5_block2_preact_bn trainable weights: 2 trainable: True\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: True\n",
      "174 conv5_block2_1_conv trainable weights: 1 trainable: True\n",
      "175 conv5_block2_1_bn trainable weights: 2 trainable: True\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: True\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: True\n",
      "178 conv5_block2_2_conv trainable weights: 1 trainable: True\n",
      "179 conv5_block2_2_bn trainable weights: 2 trainable: True\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: True\n",
      "181 conv5_block2_3_conv trainable weights: 2 trainable: True\n",
      "182 conv5_block2_out trainable weights: 0 trainable: True\n",
      "183 conv5_block3_preact_bn trainable weights: 2 trainable: True\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: True\n",
      "185 conv5_block3_1_conv trainable weights: 1 trainable: True\n",
      "186 conv5_block3_1_bn trainable weights: 2 trainable: True\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: True\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: True\n",
      "189 conv5_block3_2_conv trainable weights: 1 trainable: True\n",
      "190 conv5_block3_2_bn trainable weights: 2 trainable: True\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: True\n",
      "192 conv5_block3_3_conv trainable weights: 2 trainable: True\n",
      "193 conv5_block3_out trainable weights: 0 trainable: True\n",
      "194 post_bn trainable weights: 2 trainable: True\n",
      "195 post_relu trainable weights: 0 trainable: True\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 21/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.8721 - binary_iou: 0.7688 - true_positives: 114374600.0000 - false_positives: 24064816.0000 - true_negatives: 164289728.0000 - false_negatives: 16791626.0000 - precision: 0.8262 - recall: 0.8720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 111s 533ms/step - loss: 0.1531 - accuracy: 0.8721 - binary_iou: 0.7688 - true_positives: 114374600.0000 - false_positives: 24064816.0000 - true_negatives: 164289728.0000 - false_negatives: 16791626.0000 - precision: 0.8262 - recall: 0.8720 - val_loss: 0.1425 - val_accuracy: 0.8774 - val_binary_iou: 0.7788 - val_true_positives: 39737536.0000 - val_false_positives: 7682701.0000 - val_true_negatives: 53246184.0000 - val_false_negatives: 5305277.0000 - val_precision: 0.8380 - val_recall: 0.8822\n",
      "Epoch 22/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.8772 - binary_iou: 0.7766 - true_positives: 114452016.0000 - false_positives: 22545824.0000 - true_negatives: 165821472.0000 - false_negatives: 16701476.0000 - precision: 0.8354 - recall: 0.8727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 529ms/step - loss: 0.1479 - accuracy: 0.8772 - binary_iou: 0.7766 - true_positives: 114452016.0000 - false_positives: 22545824.0000 - true_negatives: 165821472.0000 - false_negatives: 16701476.0000 - precision: 0.8354 - recall: 0.8727 - val_loss: 0.1397 - val_accuracy: 0.8813 - val_binary_iou: 0.7847 - val_true_positives: 39627980.0000 - val_false_positives: 7184614.0000 - val_true_negatives: 53760892.0000 - val_false_negatives: 5398219.0000 - val_precision: 0.8465 - val_recall: 0.8801\n",
      "Epoch 23/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1469 - accuracy: 0.8785 - binary_iou: 0.7788 - true_positives: 114628744.0000 - false_positives: 22331788.0000 - true_negatives: 166073136.0000 - false_negatives: 16487106.0000 - precision: 0.8369 - recall: 0.8743 - val_loss: 0.1423 - val_accuracy: 0.8740 - val_binary_iou: 0.7742 - val_true_positives: 40638968.0000 - val_false_positives: 8901861.0000 - val_true_negatives: 51980492.0000 - val_false_negatives: 4450406.0000 - val_precision: 0.8203 - val_recall: 0.9013\n",
      "Epoch 24/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1437 - accuracy: 0.8811 - binary_iou: 0.7828 - true_positives: 114657488.0000 - false_positives: 21495766.0000 - true_negatives: 166865184.0000 - false_negatives: 16502369.0000 - precision: 0.8421 - recall: 0.8742 - val_loss: 0.1418 - val_accuracy: 0.8770 - val_binary_iou: 0.7786 - val_true_positives: 40222064.0000 - val_false_positives: 8164040.0000 - val_true_negatives: 52720352.0000 - val_false_negatives: 4865256.0000 - val_precision: 0.8313 - val_recall: 0.8921\n",
      "Epoch 25/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.8815 - binary_iou: 0.7836 - true_positives: 114828312.0000 - false_positives: 21449662.0000 - true_negatives: 166844688.0000 - false_negatives: 16398106.0000 - precision: 0.8426 - recall: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 527ms/step - loss: 0.1426 - accuracy: 0.8815 - binary_iou: 0.7836 - true_positives: 114828312.0000 - false_positives: 21449662.0000 - true_negatives: 166844688.0000 - false_negatives: 16398106.0000 - precision: 0.8426 - recall: 0.8750 - val_loss: 0.1363 - val_accuracy: 0.8854 - val_binary_iou: 0.7908 - val_true_positives: 39149164.0000 - val_false_positives: 6153393.0000 - val_true_negatives: 54679104.0000 - val_false_negatives: 5990049.0000 - val_precision: 0.8642 - val_recall: 0.8673\n",
      "Epoch 26/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1427 - accuracy: 0.8824 - binary_iou: 0.7849 - true_positives: 114949248.0000 - false_positives: 21425592.0000 - true_negatives: 166989424.0000 - false_negatives: 16156539.0000 - precision: 0.8429 - recall: 0.8768 - val_loss: 0.1348 - val_accuracy: 0.8843 - val_binary_iou: 0.7894 - val_true_positives: 39633320.0000 - val_false_positives: 6743966.0000 - val_true_negatives: 54074596.0000 - val_false_negatives: 5519824.0000 - val_precision: 0.8546 - val_recall: 0.8778\n",
      "Epoch 27/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1434 - accuracy: 0.8817 - binary_iou: 0.7838 - true_positives: 114714768.0000 - false_positives: 21460736.0000 - true_negatives: 167013808.0000 - false_negatives: 16331405.0000 - precision: 0.8424 - recall: 0.8754 - val_loss: 0.1356 - val_accuracy: 0.8827 - val_binary_iou: 0.7875 - val_true_positives: 40318244.0000 - val_false_positives: 7623011.0000 - val_true_negatives: 53221076.0000 - val_false_negatives: 4809385.0000 - val_precision: 0.8410 - val_recall: 0.8934\n",
      "Epoch 28/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.8847 - binary_iou: 0.7886 - true_positives: 115002144.0000 - false_positives: 20699384.0000 - true_negatives: 167667184.0000 - false_negatives: 16152070.0000 - precision: 0.8475 - recall: 0.8768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 526ms/step - loss: 0.1395 - accuracy: 0.8847 - binary_iou: 0.7886 - true_positives: 115002144.0000 - false_positives: 20699384.0000 - true_negatives: 167667184.0000 - false_negatives: 16152070.0000 - precision: 0.8475 - recall: 0.8768 - val_loss: 0.1329 - val_accuracy: 0.8875 - val_binary_iou: 0.7944 - val_true_positives: 39511664.0000 - val_false_positives: 6295176.0000 - val_true_negatives: 54539988.0000 - val_false_negatives: 5624868.0000 - val_precision: 0.8626 - val_recall: 0.8754\n",
      "Epoch 29/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.8844 - binary_iou: 0.7883 - true_positives: 115358704.0000 - false_positives: 21113868.0000 - true_negatives: 167234000.0000 - false_negatives: 15814167.0000 - precision: 0.8453 - recall: 0.8794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1400 - accuracy: 0.8844 - binary_iou: 0.7883 - true_positives: 115358704.0000 - false_positives: 21113868.0000 - true_negatives: 167234000.0000 - false_negatives: 15814167.0000 - precision: 0.8453 - recall: 0.8794 - val_loss: 0.1308 - val_accuracy: 0.8879 - val_binary_iou: 0.7955 - val_true_positives: 40012116.0000 - val_false_positives: 6765109.0000 - val_true_negatives: 54084140.0000 - val_false_negatives: 5110345.0000 - val_precision: 0.8554 - val_recall: 0.8867\n",
      "Epoch 30/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1373 - accuracy: 0.8863 - binary_iou: 0.7913 - true_positives: 115491776.0000 - false_positives: 20704852.0000 - true_negatives: 167700448.0000 - false_negatives: 15623668.0000 - precision: 0.8480 - recall: 0.8808 - val_loss: 0.1403 - val_accuracy: 0.8769 - val_binary_iou: 0.7788 - val_true_positives: 40870224.0000 - val_false_positives: 8756466.0000 - val_true_negatives: 52056232.0000 - val_false_negatives: 4288798.0000 - val_precision: 0.8236 - val_recall: 0.9050\n",
      "Epoch 31/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1381 - accuracy: 0.8861 - binary_iou: 0.7911 - true_positives: 115500096.0000 - false_positives: 20771832.0000 - true_negatives: 167640992.0000 - false_negatives: 15607849.0000 - precision: 0.8476 - recall: 0.8810 - val_loss: 0.1336 - val_accuracy: 0.8879 - val_binary_iou: 0.7949 - val_true_positives: 39338448.0000 - val_false_positives: 6179487.0000 - val_true_negatives: 54751908.0000 - val_false_negatives: 5701860.0000 - val_precision: 0.8642 - val_recall: 0.8734\n",
      "Epoch 32/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1375 - accuracy: 0.8865 - binary_iou: 0.7915 - true_positives: 115231280.0000 - false_positives: 20465510.0000 - true_negatives: 168021248.0000 - false_negatives: 15802742.0000 - precision: 0.8492 - recall: 0.8794 - val_loss: 0.1440 - val_accuracy: 0.8825 - val_binary_iou: 0.7849 - val_true_positives: 37878144.0000 - val_false_positives: 5326072.0000 - val_true_negatives: 55646712.0000 - val_false_negatives: 7120799.0000 - val_precision: 0.8767 - val_recall: 0.8418\n",
      "Epoch 33/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.8869 - binary_iou: 0.7922 - true_positives: 115403168.0000 - false_positives: 20449240.0000 - true_negatives: 167971968.0000 - false_negatives: 15696416.0000 - precision: 0.8495 - recall: 0.8803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1371 - accuracy: 0.8869 - binary_iou: 0.7922 - true_positives: 115403168.0000 - false_positives: 20449240.0000 - true_negatives: 167971968.0000 - false_negatives: 15696416.0000 - precision: 0.8495 - recall: 0.8803 - val_loss: 0.1316 - val_accuracy: 0.8885 - val_binary_iou: 0.7961 - val_true_positives: 39605260.0000 - val_false_positives: 6320864.0000 - val_true_negatives: 54550828.0000 - val_false_negatives: 5494757.0000 - val_precision: 0.8624 - val_recall: 0.8782\n",
      "Epoch 34/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1355 - accuracy: 0.8883 - binary_iou: 0.7945 - true_positives: 115443816.0000 - false_positives: 19990426.0000 - true_negatives: 168389216.0000 - false_negatives: 15697379.0000 - precision: 0.8524 - recall: 0.8803 - val_loss: 0.1314 - val_accuracy: 0.8883 - val_binary_iou: 0.7957 - val_true_positives: 39568436.0000 - val_false_positives: 6364098.0000 - val_true_negatives: 54561160.0000 - val_false_negatives: 5478016.0000 - val_precision: 0.8614 - val_recall: 0.8784\n",
      "Epoch 35/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1351 - accuracy: 0.8889 - binary_iou: 0.7954 - true_positives: 115290064.0000 - false_positives: 19668464.0000 - true_negatives: 168744688.0000 - false_negatives: 15817548.0000 - precision: 0.8543 - recall: 0.8794 - val_loss: 0.1364 - val_accuracy: 0.8852 - val_binary_iou: 0.7905 - val_true_positives: 39209244.0000 - val_false_positives: 6211183.0000 - val_true_negatives: 54595228.0000 - val_false_negatives: 5956055.0000 - val_precision: 0.8633 - val_recall: 0.8681\n",
      "Epoch 36/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1345 - accuracy: 0.8889 - binary_iou: 0.7956 - true_positives: 115798032.0000 - false_positives: 20196996.0000 - true_negatives: 168224624.0000 - false_negatives: 15301139.0000 - precision: 0.8515 - recall: 0.8833 - val_loss: 0.1370 - val_accuracy: 0.8805 - val_binary_iou: 0.7842 - val_true_positives: 40548976.0000 - val_false_positives: 8100019.0000 - val_true_negatives: 52754732.0000 - val_false_negatives: 4567989.0000 - val_precision: 0.8335 - val_recall: 0.8988\n",
      "Epoch 37/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.8898 - binary_iou: 0.7969 - true_positives: 115460576.0000 - false_positives: 19520844.0000 - true_negatives: 168857296.0000 - false_negatives: 15682059.0000 - precision: 0.8554 - recall: 0.8804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1338 - accuracy: 0.8898 - binary_iou: 0.7969 - true_positives: 115460576.0000 - false_positives: 19520844.0000 - true_negatives: 168857296.0000 - false_negatives: 15682059.0000 - precision: 0.8554 - recall: 0.8804 - val_loss: 0.1319 - val_accuracy: 0.8886 - val_binary_iou: 0.7963 - val_true_positives: 39604712.0000 - val_false_positives: 6323530.0000 - val_true_negatives: 54562168.0000 - val_false_negatives: 5481302.0000 - val_precision: 0.8623 - val_recall: 0.8784\n",
      "Epoch 38/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.8897 - binary_iou: 0.7969 - true_positives: 115902944.0000 - false_positives: 19958216.0000 - true_negatives: 168370448.0000 - false_negatives: 15289107.0000 - precision: 0.8531 - recall: 0.8835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 530ms/step - loss: 0.1337 - accuracy: 0.8897 - binary_iou: 0.7969 - true_positives: 115902944.0000 - false_positives: 19958216.0000 - true_negatives: 168370448.0000 - false_negatives: 15289107.0000 - precision: 0.8531 - recall: 0.8835 - val_loss: 0.1273 - val_accuracy: 0.8919 - val_binary_iou: 0.8016 - val_true_positives: 39798064.0000 - val_false_positives: 6174015.0000 - val_true_negatives: 54714792.0000 - val_false_negatives: 5284841.0000 - val_precision: 0.8657 - val_recall: 0.8828\n",
      "Epoch 39/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1320 - accuracy: 0.8912 - binary_iou: 0.7992 - true_positives: 115821272.0000 - false_positives: 19431824.0000 - true_negatives: 168935680.0000 - false_negatives: 15332048.0000 - precision: 0.8563 - recall: 0.8831 - val_loss: 0.1365 - val_accuracy: 0.8866 - val_binary_iou: 0.7921 - val_true_positives: 38599476.0000 - val_false_positives: 5523147.0000 - val_true_negatives: 55357788.0000 - val_false_negatives: 6491304.0000 - val_precision: 0.8748 - val_recall: 0.8560\n",
      "Epoch 40/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1331 - accuracy: 0.8902 - binary_iou: 0.7976 - true_positives: 115807920.0000 - false_positives: 19760552.0000 - true_negatives: 168615984.0000 - false_negatives: 15336252.0000 - precision: 0.8542 - recall: 0.8831 - val_loss: 0.1314 - val_accuracy: 0.8898 - val_binary_iou: 0.7982 - val_true_positives: 39591760.0000 - val_false_positives: 6098161.0000 - val_true_negatives: 54705264.0000 - val_false_negatives: 5576537.0000 - val_precision: 0.8665 - val_recall: 0.8765\n",
      "Epoch 41/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.8913 - binary_iou: 0.7994 - true_positives: 115971960.0000 - false_positives: 19542664.0000 - true_negatives: 168807136.0000 - false_negatives: 15198976.0000 - precision: 0.8558 - recall: 0.8841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.1320 - accuracy: 0.8913 - binary_iou: 0.7994 - true_positives: 115971960.0000 - false_positives: 19542664.0000 - true_negatives: 168807136.0000 - false_negatives: 15198976.0000 - precision: 0.8558 - recall: 0.8841 - val_loss: 0.1275 - val_accuracy: 0.8921 - val_binary_iou: 0.8020 - val_true_positives: 39878712.0000 - val_false_positives: 6188811.0000 - val_true_negatives: 54654184.0000 - val_false_negatives: 5249998.0000 - val_precision: 0.8657 - val_recall: 0.8837\n",
      "Epoch 42/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1324 - accuracy: 0.8915 - binary_iou: 0.7997 - true_positives: 115553336.0000 - false_positives: 19056160.0000 - true_negatives: 169315232.0000 - false_negatives: 15596029.0000 - precision: 0.8584 - recall: 0.8811 - val_loss: 0.1321 - val_accuracy: 0.8873 - val_binary_iou: 0.7948 - val_true_positives: 40263632.0000 - val_false_positives: 7041797.0000 - val_true_negatives: 53765952.0000 - val_false_negatives: 4900342.0000 - val_precision: 0.8511 - val_recall: 0.8915\n",
      "Epoch 43/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.8925 - binary_iou: 0.8014 - true_positives: 116179240.0000 - false_positives: 19387822.0000 - true_negatives: 168987520.0000 - false_negatives: 14966206.0000 - precision: 0.8570 - recall: 0.8859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1308 - accuracy: 0.8925 - binary_iou: 0.8014 - true_positives: 116179240.0000 - false_positives: 19387822.0000 - true_negatives: 168987520.0000 - false_negatives: 14966206.0000 - precision: 0.8570 - recall: 0.8859 - val_loss: 0.1278 - val_accuracy: 0.8928 - val_binary_iou: 0.8028 - val_true_positives: 39489176.0000 - val_false_positives: 5746884.0000 - val_true_negatives: 55118252.0000 - val_false_negatives: 5617394.0000 - val_precision: 0.8730 - val_recall: 0.8755\n",
      "Epoch 44/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1301 - accuracy: 0.8927 - binary_iou: 0.8018 - true_positives: 116184864.0000 - false_positives: 19277836.0000 - true_negatives: 169052672.0000 - false_negatives: 15005422.0000 - precision: 0.8577 - recall: 0.8856 - val_loss: 0.1281 - val_accuracy: 0.8888 - val_binary_iou: 0.7974 - val_true_positives: 40611368.0000 - val_false_positives: 7222398.0000 - val_true_negatives: 53573348.0000 - val_false_negatives: 4564595.0000 - val_precision: 0.8490 - val_recall: 0.8990\n",
      "Epoch 45/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1297 - accuracy: 0.8934 - binary_iou: 0.8028 - true_positives: 116018792.0000 - false_positives: 19002116.0000 - true_negatives: 169425792.0000 - false_negatives: 15074101.0000 - precision: 0.8593 - recall: 0.8850 - val_loss: 0.1367 - val_accuracy: 0.8789 - val_binary_iou: 0.7821 - val_true_positives: 40985072.0000 - val_false_positives: 8763018.0000 - val_true_negatives: 52155924.0000 - val_false_negatives: 4067696.0000 - val_precision: 0.8239 - val_recall: 0.9097\n",
      "Epoch 46/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1300 - accuracy: 0.8929 - binary_iou: 0.8020 - true_positives: 116051640.0000 - false_positives: 19050968.0000 - true_negatives: 169240880.0000 - false_negatives: 15177320.0000 - precision: 0.8590 - recall: 0.8843 - val_loss: 0.1270 - val_accuracy: 0.8920 - val_binary_iou: 0.8022 - val_true_positives: 40111920.0000 - val_false_positives: 6429670.0000 - val_true_negatives: 54419004.0000 - val_false_negatives: 5011111.0000 - val_precision: 0.8619 - val_recall: 0.8889\n",
      "Epoch 47/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.8944 - binary_iou: 0.8044 - true_positives: 116011704.0000 - false_positives: 18641838.0000 - true_negatives: 169761392.0000 - false_negatives: 15105924.0000 - precision: 0.8616 - recall: 0.8848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1280 - accuracy: 0.8944 - binary_iou: 0.8044 - true_positives: 116011704.0000 - false_positives: 18641838.0000 - true_negatives: 169761392.0000 - false_negatives: 15105924.0000 - precision: 0.8616 - recall: 0.8848 - val_loss: 0.1294 - val_accuracy: 0.8939 - val_binary_iou: 0.8039 - val_true_positives: 38759324.0000 - val_false_positives: 4975969.0000 - val_true_negatives: 55969136.0000 - val_false_negatives: 6267292.0000 - val_precision: 0.8862 - val_recall: 0.8608\n",
      "Epoch 48/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1301 - accuracy: 0.8926 - binary_iou: 0.8016 - true_positives: 116110696.0000 - false_positives: 19306750.0000 - true_negatives: 169096320.0000 - false_negatives: 15007042.0000 - precision: 0.8574 - recall: 0.8855 - val_loss: 0.1320 - val_accuracy: 0.8898 - val_binary_iou: 0.7979 - val_true_positives: 39411576.0000 - val_false_positives: 6054511.0000 - val_true_negatives: 54877904.0000 - val_false_negatives: 5627726.0000 - val_precision: 0.8668 - val_recall: 0.8750\n",
      "Epoch 49/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1271 - accuracy: 0.8955 - binary_iou: 0.8063 - true_positives: 116443120.0000 - false_positives: 18734940.0000 - true_negatives: 169676048.0000 - false_negatives: 14666707.0000 - precision: 0.8614 - recall: 0.8881 - val_loss: 0.1270 - val_accuracy: 0.8926 - val_binary_iou: 0.8027 - val_true_positives: 39642992.0000 - val_false_positives: 5937587.0000 - val_true_negatives: 54949752.0000 - val_false_negatives: 5441373.0000 - val_precision: 0.8697 - val_recall: 0.8793\n",
      "Epoch 50/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.8951 - binary_iou: 0.8057 - true_positives: 116076832.0000 - false_positives: 18414204.0000 - true_negatives: 169941680.0000 - false_negatives: 15088078.0000 - precision: 0.8631 - recall: 0.8850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1278 - accuracy: 0.8951 - binary_iou: 0.8057 - true_positives: 116076832.0000 - false_positives: 18414204.0000 - true_negatives: 169941680.0000 - false_negatives: 15088078.0000 - precision: 0.8631 - recall: 0.8850 - val_loss: 0.1259 - val_accuracy: 0.8937 - val_binary_iou: 0.8045 - val_true_positives: 39741824.0000 - val_false_positives: 5954411.0000 - val_true_negatives: 54962232.0000 - val_false_negatives: 5313243.0000 - val_precision: 0.8697 - val_recall: 0.8821\n",
      "Epoch 51/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1270 - accuracy: 0.8955 - binary_iou: 0.8064 - true_positives: 116484592.0000 - false_positives: 18769380.0000 - true_negatives: 169659232.0000 - false_negatives: 14607561.0000 - precision: 0.8612 - recall: 0.8886 - val_loss: 0.1265 - val_accuracy: 0.8934 - val_binary_iou: 0.8038 - val_true_positives: 39525576.0000 - val_false_positives: 5742230.0000 - val_true_negatives: 55144936.0000 - val_false_negatives: 5558970.0000 - val_precision: 0.8731 - val_recall: 0.8767\n",
      "Epoch 52/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.8966 - binary_iou: 0.8082 - true_positives: 116476312.0000 - false_positives: 18373380.0000 - true_negatives: 170009824.0000 - false_negatives: 14661232.0000 - precision: 0.8637 - recall: 0.8882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1259 - accuracy: 0.8966 - binary_iou: 0.8082 - true_positives: 116476312.0000 - false_positives: 18373380.0000 - true_negatives: 170009824.0000 - false_negatives: 14661232.0000 - precision: 0.8637 - recall: 0.8882 - val_loss: 0.1271 - val_accuracy: 0.8942 - val_binary_iou: 0.8048 - val_true_positives: 39091396.0000 - val_false_positives: 5185505.0000 - val_true_negatives: 55672480.0000 - val_false_negatives: 6022333.0000 - val_precision: 0.8829 - val_recall: 0.8665\n",
      "Epoch 53/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.8969 - binary_iou: 0.8087 - true_positives: 116531368.0000 - false_positives: 18343484.0000 - true_negatives: 170057072.0000 - false_negatives: 14588889.0000 - precision: 0.8640 - recall: 0.8887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 532ms/step - loss: 0.1253 - accuracy: 0.8969 - binary_iou: 0.8087 - true_positives: 116531368.0000 - false_positives: 18343484.0000 - true_negatives: 170057072.0000 - false_negatives: 14588889.0000 - precision: 0.8640 - recall: 0.8887 - val_loss: 0.1266 - val_accuracy: 0.8946 - val_binary_iou: 0.8053 - val_true_positives: 39035264.0000 - val_false_positives: 5142402.0000 - val_true_negatives: 55762648.0000 - val_false_negatives: 6031412.0000 - val_precision: 0.8836 - val_recall: 0.8662\n",
      "Epoch 54/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.8971 - binary_iou: 0.8089 - true_positives: 116331472.0000 - false_positives: 18017808.0000 - true_negatives: 170308784.0000 - false_negatives: 14862671.0000 - precision: 0.8659 - recall: 0.8867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 530ms/step - loss: 0.1259 - accuracy: 0.8971 - binary_iou: 0.8089 - true_positives: 116331472.0000 - false_positives: 18017808.0000 - true_negatives: 170308784.0000 - false_negatives: 14862671.0000 - precision: 0.8659 - recall: 0.8867 - val_loss: 0.1229 - val_accuracy: 0.8944 - val_binary_iou: 0.8063 - val_true_positives: 40557984.0000 - val_false_positives: 6678717.0000 - val_true_negatives: 54223488.0000 - val_false_negatives: 4511533.0000 - val_precision: 0.8586 - val_recall: 0.8999\n",
      "Epoch 55/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.8980 - binary_iou: 0.8104 - true_positives: 116461576.0000 - false_positives: 17837004.0000 - true_negatives: 170469648.0000 - false_negatives: 14752549.0000 - precision: 0.8672 - recall: 0.8876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 531ms/step - loss: 0.1243 - accuracy: 0.8980 - binary_iou: 0.8104 - true_positives: 116461576.0000 - false_positives: 17837004.0000 - true_negatives: 170469648.0000 - false_negatives: 14752549.0000 - precision: 0.8672 - recall: 0.8876 - val_loss: 0.1233 - val_accuracy: 0.8947 - val_binary_iou: 0.8067 - val_true_positives: 40354648.0000 - val_false_positives: 6426491.0000 - val_true_negatives: 54457680.0000 - val_false_negatives: 4732893.0000 - val_precision: 0.8626 - val_recall: 0.8950\n",
      "Epoch 56/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.8994 - binary_iou: 0.8128 - true_positives: 116851464.0000 - false_positives: 17883732.0000 - true_negatives: 170510000.0000 - false_negatives: 14275539.0000 - precision: 0.8673 - recall: 0.8911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 530ms/step - loss: 0.1224 - accuracy: 0.8994 - binary_iou: 0.8128 - true_positives: 116851464.0000 - false_positives: 17883732.0000 - true_negatives: 170510000.0000 - false_negatives: 14275539.0000 - precision: 0.8673 - recall: 0.8911 - val_loss: 0.1221 - val_accuracy: 0.8953 - val_binary_iou: 0.8076 - val_true_positives: 40361324.0000 - val_false_positives: 6233949.0000 - val_true_negatives: 54512924.0000 - val_false_negatives: 4863508.0000 - val_precision: 0.8662 - val_recall: 0.8925\n",
      "Epoch 57/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1236 - accuracy: 0.8986 - binary_iou: 0.8115 - true_positives: 116709608.0000 - false_positives: 17946492.0000 - true_negatives: 170421792.0000 - false_negatives: 14442872.0000 - precision: 0.8667 - recall: 0.8899 - val_loss: 0.1287 - val_accuracy: 0.8930 - val_binary_iou: 0.8028 - val_true_positives: 38998500.0000 - val_false_positives: 5227598.0000 - val_true_negatives: 55636512.0000 - val_false_negatives: 6109097.0000 - val_precision: 0.8818 - val_recall: 0.8646\n",
      "Epoch 58/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.8992 - binary_iou: 0.8124 - true_positives: 116519072.0000 - false_positives: 17590176.0000 - true_negatives: 170804688.0000 - false_negatives: 14606798.0000 - precision: 0.8688 - recall: 0.8886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1229 - accuracy: 0.8992 - binary_iou: 0.8124 - true_positives: 116519072.0000 - false_positives: 17590176.0000 - true_negatives: 170804688.0000 - false_negatives: 14606798.0000 - precision: 0.8688 - recall: 0.8886 - val_loss: 0.1195 - val_accuracy: 0.8994 - val_binary_iou: 0.8138 - val_true_positives: 39684800.0000 - val_false_positives: 5343148.0000 - val_true_negatives: 55629584.0000 - val_false_negatives: 5314178.0000 - val_precision: 0.8813 - val_recall: 0.8819\n",
      "Epoch 59/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1224 - accuracy: 0.8993 - binary_iou: 0.8127 - true_positives: 116909376.0000 - false_positives: 17961444.0000 - true_negatives: 170436096.0000 - false_negatives: 14213773.0000 - precision: 0.8668 - recall: 0.8916 - val_loss: 0.1206 - val_accuracy: 0.8957 - val_binary_iou: 0.8087 - val_true_positives: 40872588.0000 - val_false_positives: 6874367.0000 - val_true_negatives: 54046844.0000 - val_false_negatives: 4177910.0000 - val_precision: 0.8560 - val_recall: 0.9073\n",
      "Epoch 60/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1210 - accuracy: 0.9010 - binary_iou: 0.8155 - true_positives: 116775256.0000 - false_positives: 17281072.0000 - true_negatives: 171122720.0000 - false_negatives: 14341691.0000 - precision: 0.8711 - recall: 0.8906 - val_loss: 0.1261 - val_accuracy: 0.8967 - val_binary_iou: 0.8086 - val_true_positives: 38829744.0000 - val_false_positives: 4712103.0000 - val_true_negatives: 56199908.0000 - val_false_negatives: 6229967.0000 - val_precision: 0.8918 - val_recall: 0.8617\n",
      "Epoch 61/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1210 - accuracy: 0.9006 - binary_iou: 0.8148 - true_positives: 116826016.0000 - false_positives: 17466702.0000 - true_negatives: 170938512.0000 - false_negatives: 14289585.0000 - precision: 0.8699 - recall: 0.8910 - val_loss: 0.1231 - val_accuracy: 0.8958 - val_binary_iou: 0.8080 - val_true_positives: 39863276.0000 - val_false_positives: 5893026.0000 - val_true_negatives: 55063356.0000 - val_false_negatives: 5152053.0000 - val_precision: 0.8712 - val_recall: 0.8855\n",
      "Epoch 62/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9001 - binary_iou: 0.8140 - true_positives: 116869728.0000 - false_positives: 17636840.0000 - true_negatives: 170728032.0000 - false_negatives: 14286153.0000 - precision: 0.8689 - recall: 0.8911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.1217 - accuracy: 0.9001 - binary_iou: 0.8140 - true_positives: 116869728.0000 - false_positives: 17636840.0000 - true_negatives: 170728032.0000 - false_negatives: 14286153.0000 - precision: 0.8689 - recall: 0.8911 - val_loss: 0.1187 - val_accuracy: 0.8997 - val_binary_iou: 0.8144 - val_true_positives: 40045140.0000 - val_false_positives: 5556860.0000 - val_true_negatives: 55293552.0000 - val_false_negatives: 5076149.0000 - val_precision: 0.8781 - val_recall: 0.8875\n",
      "Epoch 63/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1222 - accuracy: 0.9004 - binary_iou: 0.8144 - true_positives: 116735328.0000 - false_positives: 17471200.0000 - true_negatives: 170947312.0000 - false_negatives: 14366939.0000 - precision: 0.8698 - recall: 0.8904 - val_loss: 0.1215 - val_accuracy: 0.8995 - val_binary_iou: 0.8135 - val_true_positives: 39371068.0000 - val_false_positives: 4936317.0000 - val_true_negatives: 55947004.0000 - val_false_negatives: 5717331.0000 - val_precision: 0.8886 - val_recall: 0.8732\n",
      "Epoch 64/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1186 - accuracy: 0.9029 - binary_iou: 0.8186 - true_positives: 117016512.0000 - false_positives: 16916892.0000 - true_negatives: 171467296.0000 - false_negatives: 14120061.0000 - precision: 0.8737 - recall: 0.8923 - val_loss: 0.1220 - val_accuracy: 0.8992 - val_binary_iou: 0.8129 - val_true_positives: 39213872.0000 - val_false_positives: 4886796.0000 - val_true_negatives: 56070616.0000 - val_false_negatives: 5800422.0000 - val_precision: 0.8892 - val_recall: 0.8711\n",
      "Epoch 65/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1183 - accuracy: 0.9029 - binary_iou: 0.8186 - true_positives: 117115248.0000 - false_positives: 17074412.0000 - true_negatives: 171370896.0000 - false_negatives: 13960186.0000 - precision: 0.8728 - recall: 0.8935 - val_loss: 0.1235 - val_accuracy: 0.8929 - val_binary_iou: 0.8044 - val_true_positives: 41070052.0000 - val_false_positives: 7363754.0000 - val_true_negatives: 53557224.0000 - val_false_negatives: 3980669.0000 - val_precision: 0.8480 - val_recall: 0.9116\n",
      "Epoch 66/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1191 - accuracy: 0.9023 - binary_iou: 0.8176 - true_positives: 117069232.0000 - false_positives: 17087228.0000 - true_negatives: 171226160.0000 - false_negatives: 14138109.0000 - precision: 0.8726 - recall: 0.8922 - val_loss: 0.1216 - val_accuracy: 0.8994 - val_binary_iou: 0.8132 - val_true_positives: 39156836.0000 - val_false_positives: 4657971.0000 - val_true_negatives: 56155448.0000 - val_false_negatives: 6001470.0000 - val_precision: 0.8937 - val_recall: 0.8671\n",
      "Epoch 67/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9026 - binary_iou: 0.8182 - true_positives: 117023424.0000 - false_positives: 16964260.0000 - true_negatives: 171384016.0000 - false_negatives: 14149098.0000 - precision: 0.8734 - recall: 0.8921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.1190 - accuracy: 0.9026 - binary_iou: 0.8182 - true_positives: 117023424.0000 - false_positives: 16964260.0000 - true_negatives: 171384016.0000 - false_negatives: 14149098.0000 - precision: 0.8734 - recall: 0.8921 - val_loss: 0.1170 - val_accuracy: 0.9007 - val_binary_iou: 0.8164 - val_true_positives: 40453808.0000 - val_false_positives: 5830946.0000 - val_true_negatives: 54990772.0000 - val_false_negatives: 4696176.0000 - val_precision: 0.8740 - val_recall: 0.8960\n",
      "Epoch 68/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1171 - accuracy: 0.9039 - binary_iou: 0.8204 - true_positives: 117138712.0000 - false_positives: 16760151.0000 - true_negatives: 171688000.0000 - false_negatives: 13933896.0000 - precision: 0.8748 - recall: 0.8937 - val_loss: 0.1195 - val_accuracy: 0.8996 - val_binary_iou: 0.8143 - val_true_positives: 40111420.0000 - val_false_positives: 5644352.0000 - val_true_negatives: 55216632.0000 - val_false_negatives: 4999295.0000 - val_precision: 0.8766 - val_recall: 0.8892\n",
      "Epoch 69/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1197 - accuracy: 0.9022 - binary_iou: 0.8174 - true_positives: 116927064.0000 - false_positives: 17027092.0000 - true_negatives: 171338368.0000 - false_negatives: 14228156.0000 - precision: 0.8729 - recall: 0.8915 - val_loss: 0.1184 - val_accuracy: 0.8991 - val_binary_iou: 0.8138 - val_true_positives: 40319792.0000 - val_false_positives: 5955206.0000 - val_true_negatives: 54963616.0000 - val_false_negatives: 4733108.0000 - val_precision: 0.8713 - val_recall: 0.8949\n",
      "Epoch 70/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1163 - accuracy: 0.9044 - binary_iou: 0.8213 - true_positives: 117309688.0000 - false_positives: 16763494.0000 - true_negatives: 171680256.0000 - false_negatives: 13767348.0000 - precision: 0.8750 - recall: 0.8950 - val_loss: 0.1184 - val_accuracy: 0.8985 - val_binary_iou: 0.8132 - val_true_positives: 40791112.0000 - val_false_positives: 6388028.0000 - val_true_negatives: 54428960.0000 - val_false_negatives: 4363612.0000 - val_precision: 0.8646 - val_recall: 0.9034\n",
      "Epoch 71/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1175 - accuracy: 0.9037 - binary_iou: 0.8200 - true_positives: 117125560.0000 - false_positives: 16684934.0000 - true_negatives: 171630320.0000 - false_negatives: 14080020.0000 - precision: 0.8753 - recall: 0.8927 - val_loss: 0.1222 - val_accuracy: 0.8944 - val_binary_iou: 0.8065 - val_true_positives: 40845784.0000 - val_false_positives: 6978873.0000 - val_true_negatives: 53931240.0000 - val_false_negatives: 4215810.0000 - val_precision: 0.8541 - val_recall: 0.9064\n",
      "Epoch 72/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1189 - accuracy: 0.9029 - binary_iou: 0.8186 - true_positives: 117183952.0000 - false_positives: 17030374.0000 - true_negatives: 171298752.0000 - false_negatives: 14007772.0000 - precision: 0.8731 - recall: 0.8932 - val_loss: 0.1204 - val_accuracy: 0.8956 - val_binary_iou: 0.8087 - val_true_positives: 41066600.0000 - val_false_positives: 7027534.0000 - val_true_negatives: 53846108.0000 - val_false_negatives: 4031465.0000 - val_precision: 0.8539 - val_recall: 0.9106\n",
      "Epoch 73/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1146 - accuracy: 0.9059 - binary_iou: 0.8238 - true_positives: 117635392.0000 - false_positives: 16491830.0000 - true_negatives: 171833104.0000 - false_negatives: 13560475.0000 - precision: 0.8770 - recall: 0.8966 - val_loss: 0.1225 - val_accuracy: 0.8969 - val_binary_iou: 0.8099 - val_true_positives: 39922376.0000 - val_false_positives: 5742081.0000 - val_true_negatives: 55124108.0000 - val_false_negatives: 5183144.0000 - val_precision: 0.8743 - val_recall: 0.8851\n",
      "Epoch 74/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1170 - accuracy: 0.9044 - binary_iou: 0.8212 - true_positives: 117149184.0000 - false_positives: 16543347.0000 - true_negatives: 171835408.0000 - false_negatives: 13992800.0000 - precision: 0.8763 - recall: 0.8933 - val_loss: 0.1185 - val_accuracy: 0.8993 - val_binary_iou: 0.8141 - val_true_positives: 40337676.0000 - val_false_positives: 5926640.0000 - val_true_negatives: 54965072.0000 - val_false_negatives: 4742327.0000 - val_precision: 0.8719 - val_recall: 0.8948\n",
      "Epoch 75/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1161 - accuracy: 0.9050 - binary_iou: 0.8221 - true_positives: 117389056.0000 - false_positives: 16658599.0000 - true_negatives: 171763344.0000 - false_negatives: 13709678.0000 - precision: 0.8757 - recall: 0.8954 - val_loss: 0.1187 - val_accuracy: 0.8987 - val_binary_iou: 0.8133 - val_true_positives: 40446220.0000 - val_false_positives: 6116860.0000 - val_true_negatives: 54794204.0000 - val_false_negatives: 4614436.0000 - val_precision: 0.8686 - val_recall: 0.8976\n",
      "Epoch 76/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1143 - accuracy: 0.9066 - binary_iou: 0.8249 - true_positives: 117306928.0000 - false_positives: 16100107.0000 - true_negatives: 172384784.0000 - false_negatives: 13728924.0000 - precision: 0.8793 - recall: 0.8952 - val_loss: 0.1202 - val_accuracy: 0.8971 - val_binary_iou: 0.8108 - val_true_positives: 40664360.0000 - val_false_positives: 6532118.0000 - val_true_negatives: 54400676.0000 - val_false_negatives: 4374549.0000 - val_precision: 0.8616 - val_recall: 0.9029\n",
      "Epoch 77/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1163 - accuracy: 0.9051 - binary_iou: 0.8223 - true_positives: 117379224.0000 - false_positives: 16572980.0000 - true_negatives: 171806672.0000 - false_negatives: 13761889.0000 - precision: 0.8763 - recall: 0.8951 - val_loss: 0.1184 - val_accuracy: 0.9007 - val_binary_iou: 0.8160 - val_true_positives: 39955000.0000 - val_false_positives: 5355823.0000 - val_true_negatives: 55492028.0000 - val_false_negatives: 5168842.0000 - val_precision: 0.8818 - val_recall: 0.8855\n",
      "Epoch 78/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9067 - binary_iou: 0.8249 - true_positives: 117236384.0000 - false_positives: 15929059.0000 - true_negatives: 172467312.0000 - false_negatives: 13887976.0000 - precision: 0.8804 - recall: 0.8941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.1145 - accuracy: 0.9067 - binary_iou: 0.8249 - true_positives: 117236384.0000 - false_positives: 15929059.0000 - true_negatives: 172467312.0000 - false_negatives: 13887976.0000 - precision: 0.8804 - recall: 0.8941 - val_loss: 0.1162 - val_accuracy: 0.9028 - val_binary_iou: 0.8194 - val_true_positives: 39949120.0000 - val_false_positives: 5134712.0000 - val_true_negatives: 55716948.0000 - val_false_negatives: 5170948.0000 - val_precision: 0.8861 - val_recall: 0.8854\n",
      "Epoch 79/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1144 - accuracy: 0.9063 - binary_iou: 0.8244 - true_positives: 117361112.0000 - false_positives: 16148777.0000 - true_negatives: 172234896.0000 - false_negatives: 13775977.0000 - precision: 0.8790 - recall: 0.8949 - val_loss: 0.1199 - val_accuracy: 0.8984 - val_binary_iou: 0.8126 - val_true_positives: 40216036.0000 - val_false_positives: 5934816.0000 - val_true_negatives: 54989952.0000 - val_false_negatives: 4830911.0000 - val_precision: 0.8714 - val_recall: 0.8928\n",
      "Epoch 80/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1158 - accuracy: 0.9052 - binary_iou: 0.8225 - true_positives: 117288264.0000 - false_positives: 16514910.0000 - true_negatives: 171948640.0000 - false_negatives: 13769018.0000 - precision: 0.8766 - recall: 0.8949 - val_loss: 0.1151 - val_accuracy: 0.9008 - val_binary_iou: 0.8170 - val_true_positives: 40841680.0000 - val_false_positives: 6268571.0000 - val_true_negatives: 54620556.0000 - val_false_negatives: 4240908.0000 - val_precision: 0.8669 - val_recall: 0.9059\n",
      "Epoch 81/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1147 - accuracy: 0.9060 - binary_iou: 0.8238 - true_positives: 117430672.0000 - false_positives: 16375657.0000 - true_negatives: 172044048.0000 - false_negatives: 13670443.0000 - precision: 0.8776 - recall: 0.8957 - val_loss: 0.1171 - val_accuracy: 0.9022 - val_binary_iou: 0.8185 - val_true_positives: 39942884.0000 - val_false_positives: 5216256.0000 - val_true_negatives: 55664280.0000 - val_false_negatives: 5148298.0000 - val_precision: 0.8845 - val_recall: 0.8858\n",
      "Epoch 82/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1143 - accuracy: 0.9066 - binary_iou: 0.8249 - true_positives: 117517088.0000 - false_positives: 16165184.0000 - true_negatives: 172170288.0000 - false_negatives: 13668273.0000 - precision: 0.8791 - recall: 0.8958 - val_loss: 0.1152 - val_accuracy: 0.9020 - val_binary_iou: 0.8186 - val_true_positives: 40481980.0000 - val_false_positives: 5747434.0000 - val_true_negatives: 55105160.0000 - val_false_negatives: 4637137.0000 - val_precision: 0.8757 - val_recall: 0.8972\n",
      "Epoch 83/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1128 - accuracy: 0.9079 - binary_iou: 0.8270 - true_positives: 117556984.0000 - false_positives: 15923575.0000 - true_negatives: 172528080.0000 - false_negatives: 13512134.0000 - precision: 0.8807 - recall: 0.8969 - val_loss: 0.1213 - val_accuracy: 0.8972 - val_binary_iou: 0.8106 - val_true_positives: 40197580.0000 - val_false_positives: 6003472.0000 - val_true_negatives: 54883640.0000 - val_false_negatives: 4887016.0000 - val_precision: 0.8701 - val_recall: 0.8916\n",
      "Epoch 84/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.1125 - accuracy: 0.9080 - binary_iou: 0.8272 - true_positives: 117638952.0000 - false_positives: 15922442.0000 - true_negatives: 172486272.0000 - false_negatives: 13473161.0000 - precision: 0.8808 - recall: 0.8972 - val_loss: 0.1156 - val_accuracy: 0.9017 - val_binary_iou: 0.8183 - val_true_positives: 40552392.0000 - val_false_positives: 5839267.0000 - val_true_negatives: 55006584.0000 - val_false_negatives: 4573473.0000 - val_precision: 0.8741 - val_recall: 0.8987\n",
      "Epoch 85/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1125 - accuracy: 0.9081 - binary_iou: 0.8275 - true_positives: 117802240.0000 - false_positives: 16069626.0000 - true_negatives: 172354960.0000 - false_negatives: 13293934.0000 - precision: 0.8800 - recall: 0.8986 - val_loss: 0.1181 - val_accuracy: 0.9006 - val_binary_iou: 0.8160 - val_true_positives: 40059088.0000 - val_false_positives: 5420724.0000 - val_true_negatives: 55377176.0000 - val_false_negatives: 5114722.0000 - val_precision: 0.8808 - val_recall: 0.8868\n",
      "Epoch 86/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1133 - accuracy: 0.9078 - binary_iou: 0.8268 - true_positives: 117399680.0000 - false_positives: 15801533.0000 - true_negatives: 172661472.0000 - false_negatives: 13658099.0000 - precision: 0.8814 - recall: 0.8958 - val_loss: 0.1176 - val_accuracy: 0.9008 - val_binary_iou: 0.8163 - val_true_positives: 39989960.0000 - val_false_positives: 5348145.0000 - val_true_negatives: 55472288.0000 - val_false_negatives: 5161293.0000 - val_precision: 0.8820 - val_recall: 0.8857\n",
      "Epoch 87/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9085 - binary_iou: 0.8281 - true_positives: 117747224.0000 - false_positives: 15782773.0000 - true_negatives: 172531536.0000 - false_negatives: 13459262.0000 - precision: 0.8818 - recall: 0.8974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 531ms/step - loss: 0.1122 - accuracy: 0.9085 - binary_iou: 0.8281 - true_positives: 117747224.0000 - false_positives: 15782773.0000 - true_negatives: 172531536.0000 - false_negatives: 13459262.0000 - precision: 0.8818 - recall: 0.8974 - val_loss: 0.1147 - val_accuracy: 0.9049 - val_binary_iou: 0.8225 - val_true_positives: 39440320.0000 - val_false_positives: 4493195.0000 - val_true_negatives: 56453488.0000 - val_false_negatives: 5584702.0000 - val_precision: 0.8977 - val_recall: 0.8760\n",
      "Epoch 88/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1111 - accuracy: 0.9092 - binary_iou: 0.8292 - true_positives: 117776112.0000 - false_positives: 15590596.0000 - true_negatives: 172719200.0000 - false_negatives: 13434874.0000 - precision: 0.8831 - recall: 0.8976 - val_loss: 0.1164 - val_accuracy: 0.9005 - val_binary_iou: 0.8163 - val_true_positives: 40589280.0000 - val_false_positives: 6046690.0000 - val_true_negatives: 54842884.0000 - val_false_negatives: 4492850.0000 - val_precision: 0.8703 - val_recall: 0.9003\n",
      "Epoch 89/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1106 - accuracy: 0.9097 - binary_iou: 0.8302 - true_positives: 118010520.0000 - false_positives: 15787559.0000 - true_negatives: 172656176.0000 - false_negatives: 13066620.0000 - precision: 0.8820 - recall: 0.9003 - val_loss: 0.1181 - val_accuracy: 0.8998 - val_binary_iou: 0.8150 - val_true_positives: 40484344.0000 - val_false_positives: 6072425.0000 - val_true_negatives: 54865912.0000 - val_false_negatives: 4549033.0000 - val_precision: 0.8696 - val_recall: 0.8990\n",
      "Epoch 90/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1101 - accuracy: 0.9098 - binary_iou: 0.8304 - true_positives: 118100032.0000 - false_positives: 15800031.0000 - true_negatives: 172611456.0000 - false_negatives: 13009294.0000 - precision: 0.8820 - recall: 0.9008 - val_loss: 0.1146 - val_accuracy: 0.9043 - val_binary_iou: 0.8220 - val_true_positives: 39900720.0000 - val_false_positives: 4947896.0000 - val_true_negatives: 55934648.0000 - val_false_negatives: 5188462.0000 - val_precision: 0.8897 - val_recall: 0.8849\n",
      "Epoch 91/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9080 - binary_iou: 0.8273 - true_positives: 117741680.0000 - false_positives: 16064601.0000 - true_negatives: 172384176.0000 - false_negatives: 13330361.0000 - precision: 0.8799 - recall: 0.8983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 533ms/step - loss: 0.1124 - accuracy: 0.9080 - binary_iou: 0.8273 - true_positives: 117741680.0000 - false_positives: 16064601.0000 - true_negatives: 172384176.0000 - false_negatives: 13330361.0000 - precision: 0.8799 - recall: 0.8983 - val_loss: 0.1129 - val_accuracy: 0.9056 - val_binary_iou: 0.8242 - val_true_positives: 40150628.0000 - val_false_positives: 5045997.0000 - val_true_negatives: 55812144.0000 - val_false_negatives: 4962945.0000 - val_precision: 0.8884 - val_recall: 0.8900\n",
      "Epoch 92/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1096 - accuracy: 0.9105 - binary_iou: 0.8315 - true_positives: 118198520.0000 - false_positives: 15626009.0000 - true_negatives: 172711488.0000 - false_negatives: 12984706.0000 - precision: 0.8832 - recall: 0.9010 - val_loss: 0.1171 - val_accuracy: 0.9019 - val_binary_iou: 0.8179 - val_true_positives: 39747340.0000 - val_false_positives: 5023624.0000 - val_true_negatives: 55831804.0000 - val_false_negatives: 5368939.0000 - val_precision: 0.8878 - val_recall: 0.8810\n",
      "Epoch 93/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1096 - accuracy: 0.9103 - binary_iou: 0.8311 - true_positives: 117787944.0000 - false_positives: 15292214.0000 - true_negatives: 173070272.0000 - false_negatives: 13370390.0000 - precision: 0.8851 - recall: 0.8981 - val_loss: 0.1159 - val_accuracy: 0.9025 - val_binary_iou: 0.8191 - val_true_positives: 40067016.0000 - val_false_positives: 5297781.0000 - val_true_negatives: 55573808.0000 - val_false_negatives: 5033087.0000 - val_precision: 0.8832 - val_recall: 0.8884\n",
      "Epoch 94/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1091 - accuracy: 0.9113 - binary_iou: 0.8328 - true_positives: 118049896.0000 - false_positives: 15302400.0000 - true_negatives: 173125328.0000 - false_negatives: 13043202.0000 - precision: 0.8852 - recall: 0.9005 - val_loss: 0.1137 - val_accuracy: 0.9048 - val_binary_iou: 0.8228 - val_true_positives: 39968120.0000 - val_false_positives: 4908227.0000 - val_true_negatives: 55913408.0000 - val_false_negatives: 5181946.0000 - val_precision: 0.8906 - val_recall: 0.8852\n",
      "Epoch 95/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1101 - accuracy: 0.9105 - binary_iou: 0.8314 - true_positives: 117811512.0000 - false_positives: 15351606.0000 - true_negatives: 173096384.0000 - false_negatives: 13261341.0000 - precision: 0.8847 - recall: 0.8988 - val_loss: 0.1183 - val_accuracy: 0.9019 - val_binary_iou: 0.8177 - val_true_positives: 39672452.0000 - val_false_positives: 4925925.0000 - val_true_negatives: 55898136.0000 - val_false_negatives: 5475196.0000 - val_precision: 0.8895 - val_recall: 0.8787\n",
      "Epoch 96/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1100 - accuracy: 0.9104 - binary_iou: 0.8313 - true_positives: 117977480.0000 - false_positives: 15562104.0000 - true_negatives: 172911664.0000 - false_negatives: 13069541.0000 - precision: 0.8835 - recall: 0.9003 - val_loss: 0.1155 - val_accuracy: 0.9028 - val_binary_iou: 0.8197 - val_true_positives: 40116848.0000 - val_false_positives: 5377342.0000 - val_true_negatives: 55555696.0000 - val_false_negatives: 4921813.0000 - val_precision: 0.8818 - val_recall: 0.8907\n",
      "Epoch 97/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1087 - accuracy: 0.9116 - binary_iou: 0.8334 - true_positives: 118150808.0000 - false_positives: 15243949.0000 - true_negatives: 173118496.0000 - false_negatives: 13007459.0000 - precision: 0.8857 - recall: 0.9008 - val_loss: 0.1143 - val_accuracy: 0.9021 - val_binary_iou: 0.8190 - val_true_positives: 40825728.0000 - val_false_positives: 6193976.0000 - val_true_negatives: 54770424.0000 - val_false_negatives: 4181592.0000 - val_precision: 0.8683 - val_recall: 0.9071\n",
      "Epoch 98/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1082 - accuracy: 0.9117 - binary_iou: 0.8336 - true_positives: 118084408.0000 - false_positives: 15178749.0000 - true_negatives: 173237248.0000 - false_negatives: 13020325.0000 - precision: 0.8861 - recall: 0.9007 - val_loss: 0.1148 - val_accuracy: 0.9041 - val_binary_iou: 0.8218 - val_true_positives: 40127448.0000 - val_false_positives: 5187717.0000 - val_true_negatives: 55685288.0000 - val_false_negatives: 4971262.0000 - val_precision: 0.8855 - val_recall: 0.8898\n",
      "Epoch 99/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1085 - accuracy: 0.9118 - binary_iou: 0.8338 - true_positives: 118255856.0000 - false_positives: 15236001.0000 - true_negatives: 173089680.0000 - false_negatives: 12939259.0000 - precision: 0.8859 - recall: 0.9014 - val_loss: 0.1143 - val_accuracy: 0.9013 - val_binary_iou: 0.8179 - val_true_positives: 41077024.0000 - val_false_positives: 6392927.0000 - val_true_negatives: 54434880.0000 - val_false_negatives: 4066874.0000 - val_precision: 0.8653 - val_recall: 0.9099\n",
      "Epoch 100/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9124 - binary_iou: 0.8347 - true_positives: 118129648.0000 - false_positives: 14961493.0000 - true_negatives: 173388016.0000 - false_negatives: 13041644.0000 - precision: 0.8876 - recall: 0.9006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 533ms/step - loss: 0.1076 - accuracy: 0.9124 - binary_iou: 0.8347 - true_positives: 118129648.0000 - false_positives: 14961493.0000 - true_negatives: 173388016.0000 - false_negatives: 13041644.0000 - precision: 0.8876 - recall: 0.9006 - val_loss: 0.1111 - val_accuracy: 0.9055 - val_binary_iou: 0.8243 - val_true_positives: 40492508.0000 - val_false_positives: 5436465.0000 - val_true_negatives: 55459588.0000 - val_false_negatives: 4583143.0000 - val_precision: 0.8816 - val_recall: 0.8983\n",
      "Epoch 101/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1077 - accuracy: 0.9123 - binary_iou: 0.8345 - true_positives: 118135264.0000 - false_positives: 15053348.0000 - true_negatives: 173359680.0000 - false_negatives: 12972523.0000 - precision: 0.8870 - recall: 0.9011 - val_loss: 0.1131 - val_accuracy: 0.9057 - val_binary_iou: 0.8241 - val_true_positives: 39700104.0000 - val_false_positives: 4613038.0000 - val_true_negatives: 56281432.0000 - val_false_negatives: 5377147.0000 - val_precision: 0.8959 - val_recall: 0.8807\n",
      "Epoch 102/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1075 - accuracy: 0.9124 - binary_iou: 0.8347 - true_positives: 118133696.0000 - false_positives: 14925356.0000 - true_negatives: 173389472.0000 - false_negatives: 13072233.0000 - precision: 0.8878 - recall: 0.9004 - val_loss: 0.1197 - val_accuracy: 0.8981 - val_binary_iou: 0.8122 - val_true_positives: 40516960.0000 - val_false_positives: 6346648.0000 - val_true_negatives: 54651924.0000 - val_false_negatives: 4456183.0000 - val_precision: 0.8646 - val_recall: 0.9009\n",
      "Epoch 103/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1062 - accuracy: 0.9133 - binary_iou: 0.8364 - true_positives: 118298024.0000 - false_positives: 14870827.0000 - true_negatives: 173534480.0000 - false_negatives: 12817533.0000 - precision: 0.8883 - recall: 0.9022 - val_loss: 0.1146 - val_accuracy: 0.9048 - val_binary_iou: 0.8227 - val_true_positives: 39861884.0000 - val_false_positives: 4783168.0000 - val_true_negatives: 56020780.0000 - val_false_negatives: 5305884.0000 - val_precision: 0.8929 - val_recall: 0.8825\n",
      "Epoch 104/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9135 - binary_iou: 0.8367 - true_positives: 118276984.0000 - false_positives: 14775249.0000 - true_negatives: 173614720.0000 - false_negatives: 12853793.0000 - precision: 0.8890 - recall: 0.9020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1060 - accuracy: 0.9135 - binary_iou: 0.8367 - true_positives: 118276984.0000 - false_positives: 14775249.0000 - true_negatives: 173614720.0000 - false_negatives: 12853793.0000 - precision: 0.8890 - recall: 0.9020 - val_loss: 0.1122 - val_accuracy: 0.9076 - val_binary_iou: 0.8272 - val_true_positives: 39586616.0000 - val_false_positives: 4270269.0000 - val_true_negatives: 56596852.0000 - val_false_negatives: 5517959.0000 - val_precision: 0.9026 - val_recall: 0.8777\n",
      "Epoch 105/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1046 - accuracy: 0.9146 - binary_iou: 0.8384 - true_positives: 118453336.0000 - false_positives: 14601326.0000 - true_negatives: 173764672.0000 - false_negatives: 12701513.0000 - precision: 0.8903 - recall: 0.9032 - val_loss: 0.1121 - val_accuracy: 0.9063 - val_binary_iou: 0.8253 - val_true_positives: 40017640.0000 - val_false_positives: 4848640.0000 - val_true_negatives: 56020956.0000 - val_false_negatives: 5084489.0000 - val_precision: 0.8919 - val_recall: 0.8873\n",
      "Epoch 106/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1059 - accuracy: 0.9135 - binary_iou: 0.8366 - true_positives: 118350672.0000 - false_positives: 14799296.0000 - true_negatives: 173528704.0000 - false_negatives: 12842039.0000 - precision: 0.8889 - recall: 0.9021 - val_loss: 0.1115 - val_accuracy: 0.9071 - val_binary_iou: 0.8266 - val_true_positives: 39888680.0000 - val_false_positives: 4517840.0000 - val_true_negatives: 56243484.0000 - val_false_negatives: 5321715.0000 - val_precision: 0.8983 - val_recall: 0.8823\n",
      "Epoch 107/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1068 - accuracy: 0.9128 - binary_iou: 0.8355 - true_positives: 118221488.0000 - false_positives: 14973711.0000 - true_negatives: 173446176.0000 - false_negatives: 12879426.0000 - precision: 0.8876 - recall: 0.9018 - val_loss: 0.1122 - val_accuracy: 0.9062 - val_binary_iou: 0.8252 - val_true_positives: 40054492.0000 - val_false_positives: 4909337.0000 - val_true_negatives: 55976700.0000 - val_false_negatives: 5031190.0000 - val_precision: 0.8908 - val_recall: 0.8884\n",
      "Epoch 108/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1057 - accuracy: 0.9138 - binary_iou: 0.8371 - true_positives: 118323632.0000 - false_positives: 14701173.0000 - true_negatives: 173653504.0000 - false_negatives: 12842418.0000 - precision: 0.8895 - recall: 0.9021 - val_loss: 0.1118 - val_accuracy: 0.9050 - val_binary_iou: 0.8237 - val_true_positives: 40628916.0000 - val_false_positives: 5515339.0000 - val_true_negatives: 55278992.0000 - val_false_negatives: 4548466.0000 - val_precision: 0.8805 - val_recall: 0.8993\n",
      "Epoch 109/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1045 - accuracy: 0.9147 - binary_iou: 0.8387 - true_positives: 118421232.0000 - false_positives: 14535165.0000 - true_negatives: 173851120.0000 - false_negatives: 12713283.0000 - precision: 0.8907 - recall: 0.9031 - val_loss: 0.1224 - val_accuracy: 0.8969 - val_binary_iou: 0.8097 - val_true_positives: 39760440.0000 - val_false_positives: 5544647.0000 - val_true_negatives: 55286332.0000 - val_false_negatives: 5380298.0000 - val_precision: 0.8776 - val_recall: 0.8808\n",
      "Epoch 110/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9152 - binary_iou: 0.8395 - true_positives: 118502736.0000 - false_positives: 14412100.0000 - true_negatives: 173916688.0000 - false_negatives: 12689285.0000 - precision: 0.8916 - recall: 0.9033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1043 - accuracy: 0.9152 - binary_iou: 0.8395 - true_positives: 118502736.0000 - false_positives: 14412100.0000 - true_negatives: 173916688.0000 - false_negatives: 12689285.0000 - precision: 0.8916 - recall: 0.9033 - val_loss: 0.1083 - val_accuracy: 0.9086 - val_binary_iou: 0.8293 - val_true_positives: 40308140.0000 - val_false_positives: 4889523.0000 - val_true_negatives: 55972988.0000 - val_false_negatives: 4801060.0000 - val_precision: 0.8918 - val_recall: 0.8936\n",
      "Epoch 111/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.1046 - accuracy: 0.9145 - binary_iou: 0.8385 - true_positives: 118525584.0000 - false_positives: 14704010.0000 - true_negatives: 173690272.0000 - false_negatives: 12600836.0000 - precision: 0.8896 - recall: 0.9039 - val_loss: 0.1149 - val_accuracy: 0.8992 - val_binary_iou: 0.8148 - val_true_positives: 41598280.0000 - val_false_positives: 7243213.0000 - val_true_negatives: 53686724.0000 - val_false_negatives: 3443491.0000 - val_precision: 0.8517 - val_recall: 0.9235\n",
      "Epoch 112/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1040 - accuracy: 0.9151 - binary_iou: 0.8393 - true_positives: 118640184.0000 - false_positives: 14581502.0000 - true_negatives: 173738080.0000 - false_negatives: 12561060.0000 - precision: 0.8905 - recall: 0.9043 - val_loss: 0.1133 - val_accuracy: 0.9020 - val_binary_iou: 0.8193 - val_true_positives: 41273992.0000 - val_false_positives: 6584603.0000 - val_true_negatives: 54316496.0000 - val_false_negatives: 3796610.0000 - val_precision: 0.8624 - val_recall: 0.9158\n",
      "Epoch 113/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1028 - accuracy: 0.9162 - binary_iou: 0.8413 - true_positives: 118709888.0000 - false_positives: 14384009.0000 - true_negatives: 174034816.0000 - false_negatives: 12392108.0000 - precision: 0.8919 - recall: 0.9055 - val_loss: 0.1120 - val_accuracy: 0.9057 - val_binary_iou: 0.8246 - val_true_positives: 40286352.0000 - val_false_positives: 5196868.0000 - val_true_negatives: 55693296.0000 - val_false_negatives: 4795192.0000 - val_precision: 0.8857 - val_recall: 0.8936\n",
      "Epoch 114/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1027 - accuracy: 0.9163 - binary_iou: 0.8414 - true_positives: 118644208.0000 - false_positives: 14267388.0000 - true_negatives: 174124496.0000 - false_negatives: 12484735.0000 - precision: 0.8927 - recall: 0.9048 - val_loss: 0.1150 - val_accuracy: 0.9025 - val_binary_iou: 0.8194 - val_true_positives: 40369816.0000 - val_false_positives: 5555854.0000 - val_true_negatives: 55270688.0000 - val_false_negatives: 4775356.0000 - val_precision: 0.8790 - val_recall: 0.8942\n",
      "Epoch 115/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1030 - accuracy: 0.9163 - binary_iou: 0.8415 - true_positives: 118613248.0000 - false_positives: 14231035.0000 - true_negatives: 174169040.0000 - false_negatives: 12507413.0000 - precision: 0.8929 - recall: 0.9046 - val_loss: 0.1120 - val_accuracy: 0.9070 - val_binary_iou: 0.8263 - val_true_positives: 39839380.0000 - val_false_positives: 4558839.0000 - val_true_negatives: 56272888.0000 - val_false_negatives: 5300601.0000 - val_precision: 0.8973 - val_recall: 0.8826\n",
      "Epoch 116/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1019 - accuracy: 0.9168 - binary_iou: 0.8424 - true_positives: 118717752.0000 - false_positives: 14156788.0000 - true_negatives: 174227904.0000 - false_negatives: 12418299.0000 - precision: 0.8935 - recall: 0.9053 - val_loss: 0.1116 - val_accuracy: 0.9056 - val_binary_iou: 0.8246 - val_true_positives: 40472540.0000 - val_false_positives: 5400653.0000 - val_true_negatives: 55496936.0000 - val_false_negatives: 4601586.0000 - val_precision: 0.8823 - val_recall: 0.8979\n",
      "Epoch 117/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1020 - accuracy: 0.9168 - binary_iou: 0.8423 - true_positives: 118562040.0000 - false_positives: 14118417.0000 - true_negatives: 174372176.0000 - false_negatives: 12468087.0000 - precision: 0.8936 - recall: 0.9048 - val_loss: 0.1131 - val_accuracy: 0.9032 - val_binary_iou: 0.8209 - val_true_positives: 40928324.0000 - val_false_positives: 6139971.0000 - val_true_negatives: 54780096.0000 - val_false_negatives: 4123310.0000 - val_precision: 0.8696 - val_recall: 0.9085\n",
      "Epoch 118/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9165 - binary_iou: 0.8418 - true_positives: 118788144.0000 - false_positives: 14371854.0000 - true_negatives: 174040064.0000 - false_negatives: 12320712.0000 - precision: 0.8921 - recall: 0.9060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.1027 - accuracy: 0.9165 - binary_iou: 0.8418 - true_positives: 118788144.0000 - false_positives: 14371854.0000 - true_negatives: 174040064.0000 - false_negatives: 12320712.0000 - precision: 0.8921 - recall: 0.9060 - val_loss: 0.1099 - val_accuracy: 0.9090 - val_binary_iou: 0.8296 - val_true_positives: 39855656.0000 - val_false_positives: 4448616.0000 - val_true_negatives: 56471296.0000 - val_false_negatives: 5196132.0000 - val_precision: 0.8996 - val_recall: 0.8847\n",
      "Epoch 119/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1016 - accuracy: 0.9176 - binary_iou: 0.8437 - true_positives: 118587424.0000 - false_positives: 13801525.0000 - true_negatives: 174618560.0000 - false_negatives: 12513294.0000 - precision: 0.8958 - recall: 0.9046 - val_loss: 0.1122 - val_accuracy: 0.9047 - val_binary_iou: 0.8231 - val_true_positives: 40504120.0000 - val_false_positives: 5420236.0000 - val_true_negatives: 55366964.0000 - val_false_negatives: 4680395.0000 - val_precision: 0.8820 - val_recall: 0.8964\n",
      "Epoch 120/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.1026 - accuracy: 0.9165 - binary_iou: 0.8418 - true_positives: 118623064.0000 - false_positives: 14156382.0000 - true_negatives: 174219312.0000 - false_negatives: 12521990.0000 - precision: 0.8934 - recall: 0.9045 - val_loss: 0.1099 - val_accuracy: 0.9080 - val_binary_iou: 0.8283 - val_true_positives: 40091564.0000 - val_false_positives: 4746736.0000 - val_true_negatives: 56135580.0000 - val_false_negatives: 4997830.0000 - val_precision: 0.8941 - val_recall: 0.8892\n",
      "Epoch 121/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1019 - accuracy: 0.9173 - binary_iou: 0.8431 - true_positives: 118734912.0000 - false_positives: 14013578.0000 - true_negatives: 174350640.0000 - false_negatives: 12421676.0000 - precision: 0.8944 - recall: 0.9053 - val_loss: 0.1109 - val_accuracy: 0.9056 - val_binary_iou: 0.8250 - val_true_positives: 41049340.0000 - val_false_positives: 5975388.0000 - val_true_negatives: 54919552.0000 - val_false_negatives: 4027455.0000 - val_precision: 0.8729 - val_recall: 0.9107\n",
      "Epoch 122/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9169 - binary_iou: 0.8426 - true_positives: 118903408.0000 - false_positives: 14298579.0000 - true_negatives: 174065904.0000 - false_negatives: 12252941.0000 - precision: 0.8927 - recall: 0.9066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1021 - accuracy: 0.9169 - binary_iou: 0.8426 - true_positives: 118903408.0000 - false_positives: 14298579.0000 - true_negatives: 174065904.0000 - false_negatives: 12252941.0000 - precision: 0.8927 - recall: 0.9066 - val_loss: 0.1087 - val_accuracy: 0.9088 - val_binary_iou: 0.8298 - val_true_positives: 40525160.0000 - val_false_positives: 5111826.0000 - val_true_negatives: 55776784.0000 - val_false_negatives: 4557917.0000 - val_precision: 0.8880 - val_recall: 0.8989\n",
      "Epoch 123/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0996 - accuracy: 0.9188 - binary_iou: 0.8459 - true_positives: 118966816.0000 - false_positives: 13744304.0000 - true_negatives: 174619120.0000 - false_negatives: 12190565.0000 - precision: 0.8964 - recall: 0.9071 - val_loss: 0.1124 - val_accuracy: 0.9034 - val_binary_iou: 0.8215 - val_true_positives: 41229588.0000 - val_false_positives: 6358455.0000 - val_true_negatives: 54507896.0000 - val_false_negatives: 3875762.0000 - val_precision: 0.8664 - val_recall: 0.9141\n",
      "Epoch 124/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1010 - accuracy: 0.9177 - binary_iou: 0.8439 - true_positives: 118700112.0000 - false_positives: 13875691.0000 - true_negatives: 174536896.0000 - false_negatives: 12408068.0000 - precision: 0.8953 - recall: 0.9054 - val_loss: 0.1103 - val_accuracy: 0.9085 - val_binary_iou: 0.8287 - val_true_positives: 39800012.0000 - val_false_positives: 4332284.0000 - val_true_negatives: 56472136.0000 - val_false_negatives: 5367291.0000 - val_precision: 0.9018 - val_recall: 0.8812\n",
      "Epoch 125/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9180 - binary_iou: 0.8443 - true_positives: 118775960.0000 - false_positives: 13859762.0000 - true_negatives: 174534976.0000 - false_negatives: 12350061.0000 - precision: 0.8955 - recall: 0.9058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.1013 - accuracy: 0.9180 - binary_iou: 0.8443 - true_positives: 118775960.0000 - false_positives: 13859762.0000 - true_negatives: 174534976.0000 - false_negatives: 12350061.0000 - precision: 0.8955 - recall: 0.9058 - val_loss: 0.1075 - val_accuracy: 0.9107 - val_binary_iou: 0.8326 - val_true_positives: 40049820.0000 - val_false_positives: 4373601.0000 - val_true_negatives: 56455184.0000 - val_false_negatives: 5093121.0000 - val_precision: 0.9015 - val_recall: 0.8872\n",
      "Epoch 126/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.1008 - accuracy: 0.9180 - binary_iou: 0.8444 - true_positives: 118660328.0000 - false_positives: 13714848.0000 - true_negatives: 174671328.0000 - false_negatives: 12474297.0000 - precision: 0.8964 - recall: 0.9049 - val_loss: 0.1134 - val_accuracy: 0.9047 - val_binary_iou: 0.8230 - val_true_positives: 40382492.0000 - val_false_positives: 5338039.0000 - val_true_negatives: 55489352.0000 - val_false_negatives: 4761829.0000 - val_precision: 0.8832 - val_recall: 0.8945\n",
      "Epoch 127/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.1002 - accuracy: 0.9183 - binary_iou: 0.8450 - true_positives: 118788072.0000 - false_positives: 13766151.0000 - true_negatives: 174642560.0000 - false_negatives: 12324019.0000 - precision: 0.8961 - recall: 0.9060 - val_loss: 0.1104 - val_accuracy: 0.9093 - val_binary_iou: 0.8299 - val_true_positives: 39518184.0000 - val_false_positives: 4014135.0000 - val_true_negatives: 56844560.0000 - val_false_negatives: 5594812.0000 - val_precision: 0.9078 - val_recall: 0.8760\n",
      "Epoch 128/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0985 - accuracy: 0.9195 - binary_iou: 0.8471 - true_positives: 119154000.0000 - false_positives: 13654767.0000 - true_negatives: 174659232.0000 - false_negatives: 12052782.0000 - precision: 0.8972 - recall: 0.9081 - val_loss: 0.1091 - val_accuracy: 0.9068 - val_binary_iou: 0.8269 - val_true_positives: 40905384.0000 - val_false_positives: 5791726.0000 - val_true_negatives: 55191192.0000 - val_false_negatives: 4083402.0000 - val_precision: 0.8760 - val_recall: 0.9092\n",
      "Epoch 129/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0987 - accuracy: 0.9196 - binary_iou: 0.8471 - true_positives: 119068944.0000 - false_positives: 13665634.0000 - true_negatives: 174750448.0000 - false_negatives: 12035703.0000 - precision: 0.8970 - recall: 0.9082 - val_loss: 0.1093 - val_accuracy: 0.9085 - val_binary_iou: 0.8290 - val_true_positives: 40147704.0000 - val_false_positives: 4802879.0000 - val_true_negatives: 56123536.0000 - val_false_negatives: 4897586.0000 - val_precision: 0.8932 - val_recall: 0.8913\n",
      "Epoch 130/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0996 - accuracy: 0.9192 - binary_iou: 0.8465 - true_positives: 118760800.0000 - false_positives: 13437069.0000 - true_negatives: 174957360.0000 - false_negatives: 12365525.0000 - precision: 0.8984 - recall: 0.9057 - val_loss: 0.1076 - val_accuracy: 0.9081 - val_binary_iou: 0.8291 - val_true_positives: 41016244.0000 - val_false_positives: 5681651.0000 - val_true_negatives: 55214360.0000 - val_false_negatives: 4059466.0000 - val_precision: 0.8783 - val_recall: 0.9099\n",
      "Epoch 131/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0982 - accuracy: 0.9201 - binary_iou: 0.8480 - true_positives: 118982536.0000 - false_positives: 13499456.0000 - true_negatives: 174997392.0000 - false_negatives: 12041374.0000 - precision: 0.8981 - recall: 0.9081 - val_loss: 0.1079 - val_accuracy: 0.9094 - val_binary_iou: 0.8306 - val_true_positives: 40145948.0000 - val_false_positives: 4671521.0000 - val_true_negatives: 56226968.0000 - val_false_negatives: 4927258.0000 - val_precision: 0.8958 - val_recall: 0.8907\n",
      "Epoch 132/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0991 - accuracy: 0.9194 - binary_iou: 0.8468 - true_positives: 119009728.0000 - false_positives: 13631732.0000 - true_negatives: 174751344.0000 - false_negatives: 12127992.0000 - precision: 0.8972 - recall: 0.9075 - val_loss: 0.1070 - val_accuracy: 0.9079 - val_binary_iou: 0.8290 - val_true_positives: 41197076.0000 - val_false_positives: 5825457.0000 - val_true_negatives: 55018272.0000 - val_false_negatives: 3930913.0000 - val_precision: 0.8761 - val_recall: 0.9129\n",
      "Epoch 133/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0986 - accuracy: 0.9199 - binary_iou: 0.8478 - true_positives: 119156928.0000 - false_positives: 13586894.0000 - true_negatives: 174784912.0000 - false_negatives: 11992067.0000 - precision: 0.8976 - recall: 0.9086 - val_loss: 0.1120 - val_accuracy: 0.9040 - val_binary_iou: 0.8221 - val_true_positives: 40698248.0000 - val_false_positives: 5799730.0000 - val_true_negatives: 55101992.0000 - val_false_negatives: 4371743.0000 - val_precision: 0.8753 - val_recall: 0.9030\n",
      "Epoch 134/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9199 - binary_iou: 0.8476 - true_positives: 118885672.0000 - false_positives: 13293981.0000 - true_negatives: 175038336.0000 - false_negatives: 12302778.0000 - precision: 0.8994 - recall: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 527ms/step - loss: 0.0986 - accuracy: 0.9199 - binary_iou: 0.8476 - true_positives: 118885672.0000 - false_positives: 13293981.0000 - true_negatives: 175038336.0000 - false_negatives: 12302778.0000 - precision: 0.8994 - recall: 0.9062 - val_loss: 0.1048 - val_accuracy: 0.9110 - val_binary_iou: 0.8340 - val_true_positives: 41086716.0000 - val_false_positives: 5412087.0000 - val_true_negatives: 55458192.0000 - val_false_negatives: 4014718.0000 - val_precision: 0.8836 - val_recall: 0.9110\n",
      "Epoch 135/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0970 - accuracy: 0.9210 - binary_iou: 0.8496 - true_positives: 119108752.0000 - false_positives: 13280940.0000 - true_negatives: 175167344.0000 - false_negatives: 11963784.0000 - precision: 0.8997 - recall: 0.9087 - val_loss: 0.1092 - val_accuracy: 0.9091 - val_binary_iou: 0.8300 - val_true_positives: 40138576.0000 - val_false_positives: 4625554.0000 - val_true_negatives: 56198076.0000 - val_false_negatives: 5009497.0000 - val_precision: 0.8967 - val_recall: 0.8890\n",
      "Epoch 136/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0980 - accuracy: 0.9204 - binary_iou: 0.8486 - true_positives: 118866176.0000 - false_positives: 13169655.0000 - true_negatives: 175231744.0000 - false_negatives: 12253152.0000 - precision: 0.9003 - recall: 0.9065 - val_loss: 0.1098 - val_accuracy: 0.9060 - val_binary_iou: 0.8257 - val_true_positives: 41035784.0000 - val_false_positives: 5866598.0000 - val_true_negatives: 54977932.0000 - val_false_negatives: 4091420.0000 - val_precision: 0.8749 - val_recall: 0.9093\n",
      "Epoch 137/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0962 - accuracy: 0.9217 - binary_iou: 0.8508 - true_positives: 119242568.0000 - false_positives: 13097605.0000 - true_negatives: 175251264.0000 - false_negatives: 11929277.0000 - precision: 0.9010 - recall: 0.9091 - val_loss: 0.1081 - val_accuracy: 0.9063 - val_binary_iou: 0.8264 - val_true_positives: 41528692.0000 - val_false_positives: 6417409.0000 - val_true_negatives: 54509468.0000 - val_false_negatives: 3516153.0000 - val_precision: 0.8662 - val_recall: 0.9219\n",
      "Epoch 138/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0978 - accuracy: 0.9204 - binary_iou: 0.8486 - true_positives: 119123632.0000 - false_positives: 13448291.0000 - true_negatives: 174970720.0000 - false_negatives: 11978079.0000 - precision: 0.8986 - recall: 0.9086 - val_loss: 0.1090 - val_accuracy: 0.9075 - val_binary_iou: 0.8280 - val_true_positives: 40804936.0000 - val_false_positives: 5511316.0000 - val_true_negatives: 55365316.0000 - val_false_negatives: 4290139.0000 - val_precision: 0.8810 - val_recall: 0.9049\n",
      "Epoch 139/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0969 - accuracy: 0.9212 - binary_iou: 0.8501 - true_positives: 119262896.0000 - false_positives: 13311000.0000 - true_negatives: 175093936.0000 - false_negatives: 11852959.0000 - precision: 0.8996 - recall: 0.9096 - val_loss: 0.1076 - val_accuracy: 0.9111 - val_binary_iou: 0.8332 - val_true_positives: 39806120.0000 - val_false_positives: 4133891.0000 - val_true_negatives: 56749516.0000 - val_false_negatives: 5282196.0000 - val_precision: 0.9059 - val_recall: 0.8828\n",
      "Epoch 140/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0961 - accuracy: 0.9218 - binary_iou: 0.8511 - true_positives: 119289664.0000 - false_positives: 13168099.0000 - true_negatives: 175257248.0000 - false_negatives: 11805792.0000 - precision: 0.9006 - recall: 0.9099 - val_loss: 0.1083 - val_accuracy: 0.9107 - val_binary_iou: 0.8325 - val_true_positives: 39794504.0000 - val_false_positives: 4227021.0000 - val_true_negatives: 56714456.0000 - val_false_negatives: 5235736.0000 - val_precision: 0.9040 - val_recall: 0.8837\n",
      "Epoch 141/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0960 - accuracy: 0.9218 - binary_iou: 0.8511 - true_positives: 119313488.0000 - false_positives: 13206949.0000 - true_negatives: 175228800.0000 - false_negatives: 11771566.0000 - precision: 0.9003 - recall: 0.9102 - val_loss: 0.1048 - val_accuracy: 0.9112 - val_binary_iou: 0.8339 - val_true_positives: 40586564.0000 - val_false_positives: 4891027.0000 - val_true_negatives: 55975548.0000 - val_false_negatives: 4518590.0000 - val_precision: 0.8925 - val_recall: 0.8998\n",
      "Epoch 142/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0970 - accuracy: 0.9210 - binary_iou: 0.8496 - true_positives: 119094336.0000 - false_positives: 13276338.0000 - true_negatives: 175194432.0000 - false_negatives: 11955630.0000 - precision: 0.8997 - recall: 0.9088 - val_loss: 0.1081 - val_accuracy: 0.9068 - val_binary_iou: 0.8272 - val_true_positives: 41340788.0000 - val_false_positives: 6090175.0000 - val_true_negatives: 54757316.0000 - val_false_negatives: 3783432.0000 - val_precision: 0.8716 - val_recall: 0.9162\n",
      "Epoch 143/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9217 - binary_iou: 0.8508 - true_positives: 119241680.0000 - false_positives: 13117567.0000 - true_negatives: 175261872.0000 - false_negatives: 11899641.0000 - precision: 0.9009 - recall: 0.9093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0963 - accuracy: 0.9217 - binary_iou: 0.8508 - true_positives: 119241680.0000 - false_positives: 13117567.0000 - true_negatives: 175261872.0000 - false_negatives: 11899641.0000 - precision: 0.9009 - recall: 0.9093 - val_loss: 0.1059 - val_accuracy: 0.9115 - val_binary_iou: 0.8341 - val_true_positives: 40246324.0000 - val_false_positives: 4554536.0000 - val_true_negatives: 56342628.0000 - val_false_negatives: 4828222.0000 - val_precision: 0.8983 - val_recall: 0.8929\n",
      "Epoch 144/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0971 - accuracy: 0.9211 - binary_iou: 0.8498 - true_positives: 119230792.0000 - false_positives: 13342844.0000 - true_negatives: 175082992.0000 - false_negatives: 11864139.0000 - precision: 0.8994 - recall: 0.9095 - val_loss: 0.1064 - val_accuracy: 0.9088 - val_binary_iou: 0.8305 - val_true_positives: 41270752.0000 - val_false_positives: 5896124.0000 - val_true_negatives: 55040104.0000 - val_false_negatives: 3764721.0000 - val_precision: 0.8750 - val_recall: 0.9164\n",
      "Epoch 145/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0945 - accuracy: 0.9230 - binary_iou: 0.8532 - true_positives: 119447552.0000 - false_positives: 12906143.0000 - true_negatives: 175482208.0000 - false_negatives: 11684860.0000 - precision: 0.9025 - recall: 0.9109 - val_loss: 0.1063 - val_accuracy: 0.9104 - val_binary_iou: 0.8326 - val_true_positives: 40690664.0000 - val_false_positives: 5018561.0000 - val_true_negatives: 55784220.0000 - val_false_negatives: 4478284.0000 - val_precision: 0.8902 - val_recall: 0.9009\n",
      "Epoch 146/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0950 - accuracy: 0.9229 - binary_iou: 0.8530 - true_positives: 119335824.0000 - false_positives: 12837600.0000 - true_negatives: 175560880.0000 - false_negatives: 11786467.0000 - precision: 0.9029 - recall: 0.9101 - val_loss: 0.1059 - val_accuracy: 0.9100 - val_binary_iou: 0.8322 - val_true_positives: 41107720.0000 - val_false_positives: 5530926.0000 - val_true_negatives: 55321768.0000 - val_false_negatives: 4011278.0000 - val_precision: 0.8814 - val_recall: 0.9111\n",
      "Epoch 147/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0944 - accuracy: 0.9233 - binary_iou: 0.8537 - true_positives: 119302792.0000 - false_positives: 12737406.0000 - true_negatives: 175724544.0000 - false_negatives: 11756127.0000 - precision: 0.9035 - recall: 0.9103 - val_loss: 0.1138 - val_accuracy: 0.9057 - val_binary_iou: 0.8241 - val_true_positives: 39753748.0000 - val_false_positives: 4720255.0000 - val_true_negatives: 56226468.0000 - val_false_negatives: 5271232.0000 - val_precision: 0.8939 - val_recall: 0.8829\n",
      "Epoch 148/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0957 - accuracy: 0.9225 - binary_iou: 0.8522 - true_positives: 119292088.0000 - false_positives: 13022932.0000 - true_negatives: 175464416.0000 - false_negatives: 11741357.0000 - precision: 0.9016 - recall: 0.9104 - val_loss: 0.1107 - val_accuracy: 0.9088 - val_binary_iou: 0.8291 - val_true_positives: 39619264.0000 - val_false_positives: 4090102.0000 - val_true_negatives: 56688440.0000 - val_false_negatives: 5573909.0000 - val_precision: 0.9064 - val_recall: 0.8767\n",
      "Epoch 149/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0958 - accuracy: 0.9221 - binary_iou: 0.8516 - true_positives: 119395944.0000 - false_positives: 13135253.0000 - true_negatives: 175236912.0000 - false_negatives: 11752673.0000 - precision: 0.9009 - recall: 0.9104 - val_loss: 0.1068 - val_accuracy: 0.9098 - val_binary_iou: 0.8315 - val_true_positives: 40461572.0000 - val_false_positives: 4903035.0000 - val_true_negatives: 55948656.0000 - val_false_negatives: 4658436.0000 - val_precision: 0.8919 - val_recall: 0.8968\n",
      "Epoch 150/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9232 - binary_iou: 0.8535 - true_positives: 119564400.0000 - false_positives: 12935203.0000 - true_negatives: 175412352.0000 - false_negatives: 11608892.0000 - precision: 0.9024 - recall: 0.9115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0948 - accuracy: 0.9232 - binary_iou: 0.8535 - true_positives: 119564400.0000 - false_positives: 12935203.0000 - true_negatives: 175412352.0000 - false_negatives: 11608892.0000 - precision: 0.9024 - recall: 0.9115 - val_loss: 0.1043 - val_accuracy: 0.9131 - val_binary_iou: 0.8369 - val_true_positives: 40326388.0000 - val_false_positives: 4374333.0000 - val_true_negatives: 56434580.0000 - val_false_negatives: 4836414.0000 - val_precision: 0.9021 - val_recall: 0.8929\n",
      "Epoch 151/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0935 - accuracy: 0.9243 - binary_iou: 0.8554 - true_positives: 119578392.0000 - false_positives: 12593581.0000 - true_negatives: 175761440.0000 - false_negatives: 11587376.0000 - precision: 0.9047 - recall: 0.9117 - val_loss: 0.1064 - val_accuracy: 0.9121 - val_binary_iou: 0.8349 - val_true_positives: 39913920.0000 - val_false_positives: 4087519.0000 - val_true_negatives: 56745308.0000 - val_false_negatives: 5224975.0000 - val_precision: 0.9071 - val_recall: 0.8842\n",
      "Epoch 152/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0936 - accuracy: 0.9240 - binary_iou: 0.8548 - true_positives: 119495648.0000 - false_positives: 12678162.0000 - true_negatives: 175725648.0000 - false_negatives: 11621276.0000 - precision: 0.9041 - recall: 0.9114 - val_loss: 0.1059 - val_accuracy: 0.9090 - val_binary_iou: 0.8307 - val_true_positives: 41229556.0000 - val_false_positives: 5853947.0000 - val_true_negatives: 55095816.0000 - val_false_negatives: 3792388.0000 - val_precision: 0.8757 - val_recall: 0.9158\n",
      "Epoch 153/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0946 - accuracy: 0.9233 - binary_iou: 0.8537 - true_positives: 119572064.0000 - false_positives: 12934755.0000 - true_negatives: 175438640.0000 - false_negatives: 11575261.0000 - precision: 0.9024 - recall: 0.9117 - val_loss: 0.1064 - val_accuracy: 0.9101 - val_binary_iou: 0.8322 - val_true_positives: 40745116.0000 - val_false_positives: 5132599.0000 - val_true_negatives: 55700552.0000 - val_false_negatives: 4393449.0000 - val_precision: 0.8881 - val_recall: 0.9027\n",
      "Epoch 154/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0922 - accuracy: 0.9250 - binary_iou: 0.8566 - true_positives: 119745840.0000 - false_positives: 12550031.0000 - true_negatives: 175803040.0000 - false_negatives: 11421853.0000 - precision: 0.9051 - recall: 0.9129 - val_loss: 0.1040 - val_accuracy: 0.9119 - val_binary_iou: 0.8355 - val_true_positives: 41110748.0000 - val_false_positives: 5314174.0000 - val_true_negatives: 55526948.0000 - val_false_negatives: 4019822.0000 - val_precision: 0.8855 - val_recall: 0.9109\n",
      "Epoch 155/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0910 - accuracy: 0.9261 - binary_iou: 0.8586 - true_positives: 119812464.0000 - false_positives: 12237595.0000 - true_negatives: 176102032.0000 - false_negatives: 11368660.0000 - precision: 0.9073 - recall: 0.9133 - val_loss: 0.1045 - val_accuracy: 0.9106 - val_binary_iou: 0.8334 - val_true_positives: 41189316.0000 - val_false_positives: 5508277.0000 - val_true_negatives: 55308164.0000 - val_false_negatives: 3965952.0000 - val_precision: 0.8820 - val_recall: 0.9122\n",
      "Epoch 156/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9259 - binary_iou: 0.8582 - true_positives: 119660992.0000 - false_positives: 12201781.0000 - true_negatives: 176178304.0000 - false_negatives: 11479697.0000 - precision: 0.9075 - recall: 0.9125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0914 - accuracy: 0.9259 - binary_iou: 0.8582 - true_positives: 119660992.0000 - false_positives: 12201781.0000 - true_negatives: 176178304.0000 - false_negatives: 11479697.0000 - precision: 0.9075 - recall: 0.9125 - val_loss: 0.1027 - val_accuracy: 0.9141 - val_binary_iou: 0.8386 - val_true_positives: 40286044.0000 - val_false_positives: 4350245.0000 - val_true_negatives: 56587496.0000 - val_false_negatives: 4747920.0000 - val_precision: 0.9025 - val_recall: 0.8946\n",
      "Epoch 157/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0915 - accuracy: 0.9256 - binary_iou: 0.8578 - true_positives: 119807032.0000 - false_positives: 12438399.0000 - true_negatives: 175953952.0000 - false_negatives: 11321375.0000 - precision: 0.9059 - recall: 0.9137 - val_loss: 0.1070 - val_accuracy: 0.9110 - val_binary_iou: 0.8330 - val_true_positives: 39994792.0000 - val_false_positives: 4313098.0000 - val_true_negatives: 56540524.0000 - val_false_negatives: 5123313.0000 - val_precision: 0.9027 - val_recall: 0.8864\n",
      "Epoch 158/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0913 - accuracy: 0.9256 - binary_iou: 0.8576 - true_positives: 119748248.0000 - false_positives: 12355809.0000 - true_negatives: 175993264.0000 - false_negatives: 11423457.0000 - precision: 0.9065 - recall: 0.9129 - val_loss: 0.1023 - val_accuracy: 0.9138 - val_binary_iou: 0.8384 - val_true_positives: 40774200.0000 - val_false_positives: 4738413.0000 - val_true_negatives: 56059136.0000 - val_false_negatives: 4399953.0000 - val_precision: 0.8959 - val_recall: 0.9026\n",
      "Epoch 159/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0922 - accuracy: 0.9254 - binary_iou: 0.8573 - true_positives: 119614400.0000 - false_positives: 12289718.0000 - true_negatives: 176076384.0000 - false_negatives: 11540265.0000 - precision: 0.9068 - recall: 0.9120 - val_loss: 0.1033 - val_accuracy: 0.9138 - val_binary_iou: 0.8382 - val_true_positives: 40363140.0000 - val_false_positives: 4476926.0000 - val_true_negatives: 56477256.0000 - val_false_negatives: 4654390.0000 - val_precision: 0.9002 - val_recall: 0.8966\n",
      "Epoch 160/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0925 - accuracy: 0.9251 - binary_iou: 0.8568 - true_positives: 119598912.0000 - false_positives: 12384402.0000 - true_negatives: 175991520.0000 - false_negatives: 11546029.0000 - precision: 0.9062 - recall: 0.9120 - val_loss: 0.1061 - val_accuracy: 0.9086 - val_binary_iou: 0.8301 - val_true_positives: 41249952.0000 - val_false_positives: 5860743.0000 - val_true_negatives: 55038504.0000 - val_false_negatives: 3822498.0000 - val_precision: 0.8756 - val_recall: 0.9152\n",
      "Epoch 161/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0921 - accuracy: 0.9253 - binary_iou: 0.8572 - true_positives: 119772608.0000 - false_positives: 12503698.0000 - true_negatives: 175884416.0000 - false_negatives: 11360026.0000 - precision: 0.9055 - recall: 0.9134 - val_loss: 0.1196 - val_accuracy: 0.9034 - val_binary_iou: 0.8189 - val_true_positives: 38262984.0000 - val_false_positives: 3416243.0000 - val_true_negatives: 57474992.0000 - val_false_negatives: 6817489.0000 - val_precision: 0.9180 - val_recall: 0.8488\n",
      "Epoch 162/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0924 - accuracy: 0.9251 - binary_iou: 0.8569 - true_positives: 119668768.0000 - false_positives: 12516868.0000 - true_negatives: 175934704.0000 - false_negatives: 11400355.0000 - precision: 0.9053 - recall: 0.9130 - val_loss: 0.1020 - val_accuracy: 0.9134 - val_binary_iou: 0.8380 - val_true_positives: 41240120.0000 - val_false_positives: 5298615.0000 - val_true_negatives: 55550520.0000 - val_false_negatives: 3882463.0000 - val_precision: 0.8861 - val_recall: 0.9140\n",
      "Epoch 163/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0899 - accuracy: 0.9269 - binary_iou: 0.8600 - true_positives: 119922080.0000 - false_positives: 12153875.0000 - true_negatives: 176251696.0000 - false_negatives: 11193149.0000 - precision: 0.9080 - recall: 0.9146 - val_loss: 0.1021 - val_accuracy: 0.9138 - val_binary_iou: 0.8385 - val_true_positives: 40965296.0000 - val_false_positives: 4879297.0000 - val_true_negatives: 55869880.0000 - val_false_negatives: 4257251.0000 - val_precision: 0.8936 - val_recall: 0.9059\n",
      "Epoch 164/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0901 - accuracy: 0.9270 - binary_iou: 0.8602 - true_positives: 119968008.0000 - false_positives: 12168619.0000 - true_negatives: 176227104.0000 - false_negatives: 11157074.0000 - precision: 0.9079 - recall: 0.9149 - val_loss: 0.1062 - val_accuracy: 0.9113 - val_binary_iou: 0.8336 - val_true_positives: 39977156.0000 - val_false_positives: 4272896.0000 - val_true_negatives: 56597152.0000 - val_false_negatives: 5124523.0000 - val_precision: 0.9034 - val_recall: 0.8864\n",
      "Epoch 165/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0921 - accuracy: 0.9254 - binary_iou: 0.8573 - true_positives: 119675872.0000 - false_positives: 12388962.0000 - true_negatives: 176007680.0000 - false_negatives: 11448212.0000 - precision: 0.9062 - recall: 0.9127 - val_loss: 0.1155 - val_accuracy: 0.9063 - val_binary_iou: 0.8243 - val_true_positives: 38991084.0000 - val_false_positives: 3838559.0000 - val_true_negatives: 57045988.0000 - val_false_negatives: 6096071.0000 - val_precision: 0.9104 - val_recall: 0.8648\n",
      "Epoch 166/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0907 - accuracy: 0.9264 - binary_iou: 0.8592 - true_positives: 119902968.0000 - false_positives: 12306540.0000 - true_negatives: 176110784.0000 - false_negatives: 11200517.0000 - precision: 0.9069 - recall: 0.9146 - val_loss: 0.1065 - val_accuracy: 0.9106 - val_binary_iou: 0.8329 - val_true_positives: 40634644.0000 - val_false_positives: 5047468.0000 - val_true_negatives: 55862116.0000 - val_false_negatives: 4427483.0000 - val_precision: 0.8895 - val_recall: 0.9017\n",
      "Epoch 167/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0885 - accuracy: 0.9281 - binary_iou: 0.8621 - true_positives: 119982568.0000 - false_positives: 11861739.0000 - true_negatives: 176573680.0000 - false_negatives: 11102886.0000 - precision: 0.9100 - recall: 0.9153 - val_loss: 0.1054 - val_accuracy: 0.9110 - val_binary_iou: 0.8336 - val_true_positives: 40471792.0000 - val_false_positives: 4792046.0000 - val_true_negatives: 56072164.0000 - val_false_negatives: 4635704.0000 - val_precision: 0.8941 - val_recall: 0.8972\n",
      "Epoch 168/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9272 - binary_iou: 0.8605 - true_positives: 119955696.0000 - false_positives: 12109176.0000 - true_negatives: 176295168.0000 - false_negatives: 11160697.0000 - precision: 0.9083 - recall: 0.9149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0901 - accuracy: 0.9272 - binary_iou: 0.8605 - true_positives: 119955696.0000 - false_positives: 12109176.0000 - true_negatives: 176295168.0000 - false_negatives: 11160697.0000 - precision: 0.9083 - recall: 0.9149 - val_loss: 0.1013 - val_accuracy: 0.9140 - val_binary_iou: 0.8389 - val_true_positives: 40966792.0000 - val_false_positives: 5043301.0000 - val_true_negatives: 55891512.0000 - val_false_negatives: 4070109.0000 - val_precision: 0.8904 - val_recall: 0.9096\n",
      "Epoch 169/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0893 - accuracy: 0.9274 - binary_iou: 0.8609 - true_positives: 119955144.0000 - false_positives: 12068188.0000 - true_negatives: 176381152.0000 - false_negatives: 11116292.0000 - precision: 0.9086 - recall: 0.9152 - val_loss: 0.1066 - val_accuracy: 0.9118 - val_binary_iou: 0.8344 - val_true_positives: 39838380.0000 - val_false_positives: 4017017.0000 - val_true_negatives: 56791636.0000 - val_false_negatives: 5324682.0000 - val_precision: 0.9084 - val_recall: 0.8821\n",
      "Epoch 170/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0894 - accuracy: 0.9277 - binary_iou: 0.8614 - true_positives: 119933648.0000 - false_positives: 11889292.0000 - true_negatives: 176499552.0000 - false_negatives: 11198215.0000 - precision: 0.9098 - recall: 0.9146 - val_loss: 0.1036 - val_accuracy: 0.9131 - val_binary_iou: 0.8371 - val_true_positives: 40514956.0000 - val_false_positives: 4641290.0000 - val_true_negatives: 56248576.0000 - val_false_negatives: 4566891.0000 - val_precision: 0.8972 - val_recall: 0.8987\n",
      "Epoch 171/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0875 - accuracy: 0.9288 - binary_iou: 0.8633 - true_positives: 120210688.0000 - false_positives: 11850368.0000 - true_negatives: 176550464.0000 - false_negatives: 10909218.0000 - precision: 0.9103 - recall: 0.9168 - val_loss: 0.1037 - val_accuracy: 0.9131 - val_binary_iou: 0.8370 - val_true_positives: 40439592.0000 - val_false_positives: 4627062.0000 - val_true_negatives: 56324200.0000 - val_false_negatives: 4580865.0000 - val_precision: 0.8973 - val_recall: 0.8982\n",
      "Epoch 172/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0882 - accuracy: 0.9285 - binary_iou: 0.8628 - true_positives: 120109112.0000 - false_positives: 11860988.0000 - true_negatives: 176557088.0000 - false_negatives: 10993595.0000 - precision: 0.9101 - recall: 0.9161 - val_loss: 0.1040 - val_accuracy: 0.9105 - val_binary_iou: 0.8335 - val_true_positives: 41622272.0000 - val_false_positives: 5961027.0000 - val_true_negatives: 54866432.0000 - val_false_negatives: 3521968.0000 - val_precision: 0.8747 - val_recall: 0.9220\n",
      "Epoch 173/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0887 - accuracy: 0.9281 - binary_iou: 0.8622 - true_positives: 119994816.0000 - false_positives: 11840791.0000 - true_negatives: 176565696.0000 - false_negatives: 11119515.0000 - precision: 0.9102 - recall: 0.9152 - val_loss: 0.1065 - val_accuracy: 0.9115 - val_binary_iou: 0.8339 - val_true_positives: 40014728.0000 - val_false_positives: 4313485.0000 - val_true_negatives: 56575716.0000 - val_false_negatives: 5067790.0000 - val_precision: 0.9027 - val_recall: 0.8876\n",
      "Epoch 174/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9279 - binary_iou: 0.8618 - true_positives: 120001136.0000 - false_positives: 11864527.0000 - true_negatives: 176493120.0000 - false_negatives: 11161946.0000 - precision: 0.9100 - recall: 0.9149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.0893 - accuracy: 0.9279 - binary_iou: 0.8618 - true_positives: 120001136.0000 - false_positives: 11864527.0000 - true_negatives: 176493120.0000 - false_negatives: 11161946.0000 - precision: 0.9100 - recall: 0.9149 - val_loss: 0.1020 - val_accuracy: 0.9141 - val_binary_iou: 0.8390 - val_true_positives: 40745400.0000 - val_false_positives: 4855038.0000 - val_true_negatives: 56125892.0000 - val_false_negatives: 4245381.0000 - val_precision: 0.8935 - val_recall: 0.9056\n",
      "Epoch 175/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0892 - accuracy: 0.9275 - binary_iou: 0.8611 - true_positives: 120029200.0000 - false_positives: 12046016.0000 - true_negatives: 176328288.0000 - false_negatives: 11117261.0000 - precision: 0.9088 - recall: 0.9152 - val_loss: 0.1076 - val_accuracy: 0.9076 - val_binary_iou: 0.8286 - val_true_positives: 41446656.0000 - val_false_positives: 6050718.0000 - val_true_negatives: 54733984.0000 - val_false_negatives: 3740351.0000 - val_precision: 0.8726 - val_recall: 0.9172\n",
      "Epoch 176/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0899 - accuracy: 0.9272 - binary_iou: 0.8605 - true_positives: 119951880.0000 - false_positives: 12100954.0000 - true_negatives: 176312288.0000 - false_negatives: 11155671.0000 - precision: 0.9084 - recall: 0.9149 - val_loss: 0.1098 - val_accuracy: 0.9098 - val_binary_iou: 0.8307 - val_true_positives: 39540384.0000 - val_false_positives: 3987307.0000 - val_true_negatives: 56871944.0000 - val_false_negatives: 5572066.0000 - val_precision: 0.9084 - val_recall: 0.8765\n",
      "Epoch 177/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9274 - binary_iou: 0.8609 - true_positives: 119917560.0000 - false_positives: 12010745.0000 - true_negatives: 176418016.0000 - false_negatives: 11174462.0000 - precision: 0.9090 - recall: 0.9148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 531ms/step - loss: 0.0894 - accuracy: 0.9274 - binary_iou: 0.8609 - true_positives: 119917560.0000 - false_positives: 12010745.0000 - true_negatives: 176418016.0000 - false_negatives: 11174462.0000 - precision: 0.9090 - recall: 0.9148 - val_loss: 0.1013 - val_accuracy: 0.9144 - val_binary_iou: 0.8393 - val_true_positives: 40714224.0000 - val_false_positives: 4706691.0000 - val_true_negatives: 56182268.0000 - val_false_negatives: 4368539.0000 - val_precision: 0.8964 - val_recall: 0.9031\n",
      "Epoch 178/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0871 - accuracy: 0.9292 - binary_iou: 0.8641 - true_positives: 120318808.0000 - false_positives: 11813857.0000 - true_negatives: 176585280.0000 - false_negatives: 10802917.0000 - precision: 0.9106 - recall: 0.9176 - val_loss: 0.1015 - val_accuracy: 0.9142 - val_binary_iou: 0.8392 - val_true_positives: 40860280.0000 - val_false_positives: 4803635.0000 - val_true_negatives: 56023648.0000 - val_false_negatives: 4284150.0000 - val_precision: 0.8948 - val_recall: 0.9051\n",
      "Epoch 179/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0863 - accuracy: 0.9300 - binary_iou: 0.8655 - true_positives: 120294944.0000 - false_positives: 11575854.0000 - true_negatives: 176857056.0000 - false_negatives: 10792933.0000 - precision: 0.9122 - recall: 0.9177 - val_loss: 0.1029 - val_accuracy: 0.9145 - val_binary_iou: 0.8391 - val_true_positives: 40098356.0000 - val_false_positives: 4032524.0000 - val_true_negatives: 56814104.0000 - val_false_negatives: 5026728.0000 - val_precision: 0.9086 - val_recall: 0.8886\n",
      "Epoch 180/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0877 - accuracy: 0.9288 - binary_iou: 0.8634 - true_positives: 120116368.0000 - false_positives: 11775956.0000 - true_negatives: 176661472.0000 - false_negatives: 10966942.0000 - precision: 0.9107 - recall: 0.9163 - val_loss: 0.1057 - val_accuracy: 0.9098 - val_binary_iou: 0.8319 - val_true_positives: 41125560.0000 - val_false_positives: 5597331.0000 - val_true_negatives: 55282680.0000 - val_false_negatives: 3966139.0000 - val_precision: 0.8802 - val_recall: 0.9120\n",
      "Epoch 181/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0893 - accuracy: 0.9275 - binary_iou: 0.8610 - true_positives: 119915224.0000 - false_positives: 11931998.0000 - true_negatives: 176440480.0000 - false_negatives: 11232988.0000 - precision: 0.9095 - recall: 0.9143 - val_loss: 0.1065 - val_accuracy: 0.9106 - val_binary_iou: 0.8329 - val_true_positives: 40526440.0000 - val_false_positives: 4895921.0000 - val_true_negatives: 55973248.0000 - val_false_negatives: 4576095.0000 - val_precision: 0.8922 - val_recall: 0.8985\n",
      "Epoch 182/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9304 - binary_iou: 0.8662 - true_positives: 120179600.0000 - false_positives: 11358525.0000 - true_negatives: 177109792.0000 - false_negatives: 10872809.0000 - precision: 0.9136 - recall: 0.9170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.0861 - accuracy: 0.9304 - binary_iou: 0.8662 - true_positives: 120179600.0000 - false_positives: 11358525.0000 - true_negatives: 177109792.0000 - false_negatives: 10872809.0000 - precision: 0.9136 - recall: 0.9170 - val_loss: 0.0992 - val_accuracy: 0.9171 - val_binary_iou: 0.8438 - val_true_positives: 40587984.0000 - val_false_positives: 4266623.0000 - val_true_negatives: 56595032.0000 - val_false_negatives: 4522070.0000 - val_precision: 0.9049 - val_recall: 0.8998\n",
      "Epoch 183/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0854 - accuracy: 0.9307 - binary_iou: 0.8667 - true_positives: 120392344.0000 - false_positives: 11440723.0000 - true_negatives: 176986880.0000 - false_negatives: 10700760.0000 - precision: 0.9132 - recall: 0.9184 - val_loss: 0.0995 - val_accuracy: 0.9158 - val_binary_iou: 0.8418 - val_true_positives: 40902980.0000 - val_false_positives: 4758357.0000 - val_true_negatives: 56141312.0000 - val_false_negatives: 4169065.0000 - val_precision: 0.8958 - val_recall: 0.9075\n",
      "Epoch 184/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0865 - accuracy: 0.9299 - binary_iou: 0.8652 - true_positives: 120227248.0000 - false_positives: 11452128.0000 - true_negatives: 176888816.0000 - false_negatives: 10952563.0000 - precision: 0.9130 - recall: 0.9165 - val_loss: 0.1025 - val_accuracy: 0.9161 - val_binary_iou: 0.8414 - val_true_positives: 39746208.0000 - val_false_positives: 3558035.0000 - val_true_negatives: 57330104.0000 - val_false_negatives: 5337356.0000 - val_precision: 0.9178 - val_recall: 0.8816\n",
      "Epoch 185/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0858 - accuracy: 0.9305 - binary_iou: 0.8663 - true_positives: 120306592.0000 - false_positives: 11393748.0000 - true_negatives: 176992672.0000 - false_negatives: 10827746.0000 - precision: 0.9135 - recall: 0.9174 - val_loss: 0.1013 - val_accuracy: 0.9137 - val_binary_iou: 0.8387 - val_true_positives: 41248952.0000 - val_false_positives: 5288380.0000 - val_true_negatives: 55581500.0000 - val_false_negatives: 3852868.0000 - val_precision: 0.8864 - val_recall: 0.9146\n",
      "Epoch 186/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0864 - accuracy: 0.9297 - binary_iou: 0.8650 - true_positives: 120300616.0000 - false_positives: 11613530.0000 - true_negatives: 176768896.0000 - false_negatives: 10837750.0000 - precision: 0.9120 - recall: 0.9174 - val_loss: 0.1022 - val_accuracy: 0.9136 - val_binary_iou: 0.8382 - val_true_positives: 40902276.0000 - val_false_positives: 4996609.0000 - val_true_negatives: 55916300.0000 - val_false_negatives: 4156526.0000 - val_precision: 0.8911 - val_recall: 0.9078\n",
      "Epoch 187/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0874 - accuracy: 0.9293 - binary_iou: 0.8643 - true_positives: 120229800.0000 - false_positives: 11717643.0000 - true_negatives: 176707024.0000 - false_negatives: 10866252.0000 - precision: 0.9112 - recall: 0.9171 - val_loss: 0.0992 - val_accuracy: 0.9153 - val_binary_iou: 0.8414 - val_true_positives: 41306464.0000 - val_false_positives: 5188535.0000 - val_true_negatives: 55694172.0000 - val_false_negatives: 3782533.0000 - val_precision: 0.8884 - val_recall: 0.9161\n",
      "Epoch 188/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0859 - accuracy: 0.9305 - binary_iou: 0.8664 - true_positives: 120326208.0000 - false_positives: 11439323.0000 - true_negatives: 176990800.0000 - false_negatives: 10764448.0000 - precision: 0.9132 - recall: 0.9179 - val_loss: 0.0997 - val_accuracy: 0.9163 - val_binary_iou: 0.8426 - val_true_positives: 40876036.0000 - val_false_positives: 4629511.0000 - val_true_negatives: 56221232.0000 - val_false_negatives: 4244936.0000 - val_precision: 0.8983 - val_recall: 0.9059\n",
      "Epoch 189/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0841 - accuracy: 0.9316 - binary_iou: 0.8683 - true_positives: 120463024.0000 - false_positives: 11197070.0000 - true_negatives: 177197328.0000 - false_negatives: 10663301.0000 - precision: 0.9150 - recall: 0.9187 - val_loss: 0.1021 - val_accuracy: 0.9133 - val_binary_iou: 0.8381 - val_true_positives: 41313404.0000 - val_false_positives: 5398684.0000 - val_true_negatives: 55475240.0000 - val_false_negatives: 3784374.0000 - val_precision: 0.8844 - val_recall: 0.9161\n",
      "Epoch 190/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0843 - accuracy: 0.9315 - binary_iou: 0.8681 - true_positives: 120466248.0000 - false_positives: 11249892.0000 - true_negatives: 177162432.0000 - false_negatives: 10642159.0000 - precision: 0.9146 - recall: 0.9188 - val_loss: 0.1014 - val_accuracy: 0.9138 - val_binary_iou: 0.8388 - val_true_positives: 41206872.0000 - val_false_positives: 5178715.0000 - val_true_negatives: 55631552.0000 - val_false_negatives: 3954551.0000 - val_precision: 0.8884 - val_recall: 0.9124\n",
      "Epoch 191/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0847 - accuracy: 0.9314 - binary_iou: 0.8680 - true_positives: 120471712.0000 - false_positives: 11234789.0000 - true_negatives: 177136048.0000 - false_negatives: 10678219.0000 - precision: 0.9147 - recall: 0.9186 - val_loss: 0.1004 - val_accuracy: 0.9149 - val_binary_iou: 0.8405 - val_true_positives: 41005492.0000 - val_false_positives: 5005159.0000 - val_true_negatives: 55947984.0000 - val_false_negatives: 4013073.0000 - val_precision: 0.8912 - val_recall: 0.9109\n",
      "Epoch 192/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0854 - accuracy: 0.9307 - binary_iou: 0.8668 - true_positives: 120576040.0000 - false_positives: 11594346.0000 - true_negatives: 176802224.0000 - false_negatives: 10548108.0000 - precision: 0.9123 - recall: 0.9196 - val_loss: 0.1021 - val_accuracy: 0.9149 - val_binary_iou: 0.8400 - val_true_positives: 40381080.0000 - val_false_positives: 4344058.0000 - val_true_negatives: 56573008.0000 - val_false_negatives: 4673562.0000 - val_precision: 0.9029 - val_recall: 0.8963\n",
      "Epoch 193/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0854 - accuracy: 0.9306 - binary_iou: 0.8665 - true_positives: 120322696.0000 - false_positives: 11422697.0000 - true_negatives: 177020368.0000 - false_negatives: 10754965.0000 - precision: 0.9133 - recall: 0.9179 - val_loss: 0.1017 - val_accuracy: 0.9148 - val_binary_iou: 0.8400 - val_true_positives: 40629952.0000 - val_false_positives: 4521411.0000 - val_true_negatives: 56315472.0000 - val_false_negatives: 4504879.0000 - val_precision: 0.8999 - val_recall: 0.9002\n",
      "Epoch 194/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0851 - accuracy: 0.9310 - binary_iou: 0.8673 - true_positives: 120483608.0000 - false_positives: 11407093.0000 - true_negatives: 176999392.0000 - false_negatives: 10630819.0000 - precision: 0.9135 - recall: 0.9189 - val_loss: 0.1028 - val_accuracy: 0.9147 - val_binary_iou: 0.8392 - val_true_positives: 39952480.0000 - val_false_positives: 3809071.0000 - val_true_negatives: 56975208.0000 - val_false_negatives: 5234961.0000 - val_precision: 0.9130 - val_recall: 0.8842\n",
      "Epoch 195/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0842 - accuracy: 0.9317 - binary_iou: 0.8686 - true_positives: 120579032.0000 - false_positives: 11220932.0000 - true_negatives: 177128416.0000 - false_negatives: 10592339.0000 - precision: 0.9149 - recall: 0.9192 - val_loss: 0.1014 - val_accuracy: 0.9158 - val_binary_iou: 0.8413 - val_true_positives: 40129236.0000 - val_false_positives: 3956415.0000 - val_true_negatives: 56918912.0000 - val_false_negatives: 4967132.0000 - val_precision: 0.9103 - val_recall: 0.8899\n",
      "Epoch 196/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0837 - accuracy: 0.9321 - binary_iou: 0.8692 - true_positives: 120727672.0000 - false_positives: 11256270.0000 - true_negatives: 177088288.0000 - false_negatives: 10448454.0000 - precision: 0.9147 - recall: 0.9203 - val_loss: 0.0999 - val_accuracy: 0.9136 - val_binary_iou: 0.8387 - val_true_positives: 41650652.0000 - val_false_positives: 5598947.0000 - val_true_negatives: 55165844.0000 - val_false_negatives: 3556265.0000 - val_precision: 0.8815 - val_recall: 0.9213\n",
      "Epoch 197/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9322 - binary_iou: 0.8693 - true_positives: 120654248.0000 - false_positives: 11220380.0000 - true_negatives: 177187264.0000 - false_negatives: 10458829.0000 - precision: 0.9149 - recall: 0.9202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0838 - accuracy: 0.9322 - binary_iou: 0.8693 - true_positives: 120654248.0000 - false_positives: 11220380.0000 - true_negatives: 177187264.0000 - false_negatives: 10458829.0000 - precision: 0.9149 - recall: 0.9202 - val_loss: 0.0980 - val_accuracy: 0.9174 - val_binary_iou: 0.8446 - val_true_positives: 40909092.0000 - val_false_positives: 4547524.0000 - val_true_negatives: 56307144.0000 - val_false_negatives: 4207944.0000 - val_precision: 0.9000 - val_recall: 0.9067\n",
      "Epoch 198/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0853 - accuracy: 0.9309 - binary_iou: 0.8671 - true_positives: 120459160.0000 - false_positives: 11412916.0000 - true_negatives: 176979472.0000 - false_negatives: 10669178.0000 - precision: 0.9135 - recall: 0.9186 - val_loss: 0.1047 - val_accuracy: 0.9105 - val_binary_iou: 0.8331 - val_true_positives: 41061728.0000 - val_false_positives: 5444445.0000 - val_true_negatives: 55424184.0000 - val_false_negatives: 4041343.0000 - val_precision: 0.8829 - val_recall: 0.9104\n",
      "Epoch 199/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9325 - binary_iou: 0.8700 - true_positives: 120711344.0000 - false_positives: 11128460.0000 - true_negatives: 177242144.0000 - false_negatives: 10438810.0000 - precision: 0.9156 - recall: 0.9204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0836 - accuracy: 0.9325 - binary_iou: 0.8700 - true_positives: 120711344.0000 - false_positives: 11128460.0000 - true_negatives: 177242144.0000 - false_negatives: 10438810.0000 - precision: 0.9156 - recall: 0.9204 - val_loss: 0.0968 - val_accuracy: 0.9186 - val_binary_iou: 0.8467 - val_true_positives: 40903776.0000 - val_false_positives: 4449364.0000 - val_true_negatives: 56445088.0000 - val_false_negatives: 4173471.0000 - val_precision: 0.9019 - val_recall: 0.9074\n",
      "Epoch 200/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0831 - accuracy: 0.9328 - binary_iou: 0.8706 - true_positives: 120836200.0000 - false_positives: 11152419.0000 - true_negatives: 177227920.0000 - false_negatives: 10304268.0000 - precision: 0.9155 - recall: 0.9214 - val_loss: 0.1009 - val_accuracy: 0.9156 - val_binary_iou: 0.8414 - val_true_positives: 40680432.0000 - val_false_positives: 4591512.0000 - val_true_negatives: 56348088.0000 - val_false_negatives: 4351691.0000 - val_precision: 0.8986 - val_recall: 0.9034\n",
      "Epoch 201/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0830 - accuracy: 0.9327 - binary_iou: 0.8703 - true_positives: 120600632.0000 - false_positives: 10950923.0000 - true_negatives: 177424528.0000 - false_negatives: 10544722.0000 - precision: 0.9168 - recall: 0.9196 - val_loss: 0.1055 - val_accuracy: 0.9131 - val_binary_iou: 0.8369 - val_true_positives: 40236592.0000 - val_false_positives: 4257353.0000 - val_true_negatives: 56527808.0000 - val_false_negatives: 4949960.0000 - val_precision: 0.9043 - val_recall: 0.8905\n",
      "Epoch 202/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0832 - accuracy: 0.9326 - binary_iou: 0.8701 - true_positives: 120771280.0000 - false_positives: 11135543.0000 - true_negatives: 177200800.0000 - false_negatives: 10413215.0000 - precision: 0.9156 - recall: 0.9206 - val_loss: 0.0994 - val_accuracy: 0.9166 - val_binary_iou: 0.8433 - val_true_positives: 40901688.0000 - val_false_positives: 4661739.0000 - val_true_negatives: 56233196.0000 - val_false_negatives: 4175103.0000 - val_precision: 0.8977 - val_recall: 0.9074\n",
      "Epoch 203/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0828 - accuracy: 0.9328 - binary_iou: 0.8705 - true_positives: 120758184.0000 - false_positives: 11092071.0000 - true_negatives: 177297968.0000 - false_negatives: 10372635.0000 - precision: 0.9159 - recall: 0.9209 - val_loss: 0.1035 - val_accuracy: 0.9105 - val_binary_iou: 0.8335 - val_true_positives: 41658932.0000 - val_false_positives: 6099794.0000 - val_true_negatives: 54828520.0000 - val_false_negatives: 3384466.0000 - val_precision: 0.8723 - val_recall: 0.9249\n",
      "Epoch 204/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0814 - accuracy: 0.9339 - binary_iou: 0.8724 - true_positives: 120759320.0000 - false_positives: 10767801.0000 - true_negatives: 177627408.0000 - false_negatives: 10366237.0000 - precision: 0.9181 - recall: 0.9209 - val_loss: 0.0970 - val_accuracy: 0.9184 - val_binary_iou: 0.8462 - val_true_positives: 40712348.0000 - val_false_positives: 4221925.0000 - val_true_negatives: 56617224.0000 - val_false_negatives: 4420219.0000 - val_precision: 0.9060 - val_recall: 0.9021\n",
      "Epoch 205/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0822 - accuracy: 0.9334 - binary_iou: 0.8715 - true_positives: 120771048.0000 - false_positives: 10924494.0000 - true_negatives: 177457744.0000 - false_negatives: 10367497.0000 - precision: 0.9170 - recall: 0.9209 - val_loss: 0.1053 - val_accuracy: 0.9095 - val_binary_iou: 0.8316 - val_true_positives: 41192856.0000 - val_false_positives: 5601783.0000 - val_true_negatives: 55189688.0000 - val_false_negatives: 3987388.0000 - val_precision: 0.8803 - val_recall: 0.9117\n",
      "Epoch 206/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0825 - accuracy: 0.9332 - binary_iou: 0.8712 - true_positives: 120628464.0000 - false_positives: 10823888.0000 - true_negatives: 177549856.0000 - false_negatives: 10518559.0000 - precision: 0.9177 - recall: 0.9198 - val_loss: 0.1043 - val_accuracy: 0.9123 - val_binary_iou: 0.8356 - val_true_positives: 40466996.0000 - val_false_positives: 4722592.0000 - val_true_negatives: 56208004.0000 - val_false_negatives: 4574131.0000 - val_precision: 0.8955 - val_recall: 0.8984\n",
      "Epoch 207/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0829 - accuracy: 0.9330 - binary_iou: 0.8708 - true_positives: 120577768.0000 - false_positives: 10860159.0000 - true_negatives: 177524720.0000 - false_negatives: 10558119.0000 - precision: 0.9174 - recall: 0.9195 - val_loss: 0.1013 - val_accuracy: 0.9140 - val_binary_iou: 0.8390 - val_true_positives: 41097504.0000 - val_false_positives: 5076676.0000 - val_true_negatives: 55757736.0000 - val_false_negatives: 4039779.0000 - val_precision: 0.8901 - val_recall: 0.9105\n",
      "Epoch 208/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0816 - accuracy: 0.9338 - binary_iou: 0.8722 - true_positives: 120886536.0000 - false_positives: 10908031.0000 - true_negatives: 177472048.0000 - false_negatives: 10254180.0000 - precision: 0.9172 - recall: 0.9218 - val_loss: 0.1127 - val_accuracy: 0.9027 - val_binary_iou: 0.8201 - val_true_positives: 40986196.0000 - val_false_positives: 6315732.0000 - val_true_negatives: 54673032.0000 - val_false_negatives: 3996757.0000 - val_precision: 0.8665 - val_recall: 0.9111\n",
      "Epoch 209/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0833 - accuracy: 0.9327 - binary_iou: 0.8703 - true_positives: 120507096.0000 - false_positives: 10879491.0000 - true_negatives: 177510112.0000 - false_negatives: 10624010.0000 - precision: 0.9172 - recall: 0.9190 - val_loss: 0.0977 - val_accuracy: 0.9177 - val_binary_iou: 0.8451 - val_true_positives: 40895988.0000 - val_false_positives: 4482270.0000 - val_true_negatives: 56355772.0000 - val_false_negatives: 4237682.0000 - val_precision: 0.9012 - val_recall: 0.9061\n",
      "Epoch 210/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0822 - accuracy: 0.9333 - binary_iou: 0.8714 - true_positives: 120685024.0000 - false_positives: 10888543.0000 - true_negatives: 177527136.0000 - false_negatives: 10420090.0000 - precision: 0.9172 - recall: 0.9205 - val_loss: 0.1010 - val_accuracy: 0.9142 - val_binary_iou: 0.8392 - val_true_positives: 40806576.0000 - val_false_positives: 4851336.0000 - val_true_negatives: 56074168.0000 - val_false_negatives: 4239636.0000 - val_precision: 0.8937 - val_recall: 0.9059\n",
      "Epoch 211/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0827 - accuracy: 0.9332 - binary_iou: 0.8712 - true_positives: 120779232.0000 - false_positives: 10965154.0000 - true_negatives: 177388416.0000 - false_negatives: 10387996.0000 - precision: 0.9168 - recall: 0.9208 - val_loss: 0.0997 - val_accuracy: 0.9153 - val_binary_iou: 0.8411 - val_true_positives: 40974904.0000 - val_false_positives: 4809702.0000 - val_true_negatives: 56018336.0000 - val_false_negatives: 4168768.0000 - val_precision: 0.8949 - val_recall: 0.9077\n",
      "Epoch 212/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0823 - accuracy: 0.9334 - binary_iou: 0.8716 - true_positives: 120714216.0000 - false_positives: 10892256.0000 - true_negatives: 177530064.0000 - false_negatives: 10384231.0000 - precision: 0.9172 - recall: 0.9208 - val_loss: 0.1087 - val_accuracy: 0.9106 - val_binary_iou: 0.8320 - val_true_positives: 39403616.0000 - val_false_positives: 3807641.0000 - val_true_negatives: 57098352.0000 - val_false_negatives: 5662124.0000 - val_precision: 0.9119 - val_recall: 0.8744\n",
      "Epoch 213/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9343 - binary_iou: 0.8731 - true_positives: 120837296.0000 - false_positives: 10707745.0000 - true_negatives: 177677104.0000 - false_negatives: 10298608.0000 - precision: 0.9186 - recall: 0.9215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 527ms/step - loss: 0.0813 - accuracy: 0.9343 - binary_iou: 0.8731 - true_positives: 120837296.0000 - false_positives: 10707745.0000 - true_negatives: 177677104.0000 - false_negatives: 10298608.0000 - precision: 0.9186 - recall: 0.9215 - val_loss: 0.0967 - val_accuracy: 0.9194 - val_binary_iou: 0.8478 - val_true_positives: 40712560.0000 - val_false_positives: 4100342.0000 - val_true_negatives: 56712840.0000 - val_false_negatives: 4445958.0000 - val_precision: 0.9085 - val_recall: 0.9015\n",
      "Epoch 214/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0804 - accuracy: 0.9351 - binary_iou: 0.8746 - true_positives: 120917568.0000 - false_positives: 10534292.0000 - true_negatives: 177869184.0000 - false_negatives: 10199733.0000 - precision: 0.9199 - recall: 0.9222 - val_loss: 0.0985 - val_accuracy: 0.9176 - val_binary_iou: 0.8447 - val_true_positives: 40625056.0000 - val_false_positives: 4307833.0000 - val_true_negatives: 56613776.0000 - val_false_negatives: 4425038.0000 - val_precision: 0.9041 - val_recall: 0.9018\n",
      "Epoch 215/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0796 - accuracy: 0.9356 - binary_iou: 0.8755 - true_positives: 120936816.0000 - false_positives: 10360814.0000 - true_negatives: 178015648.0000 - false_negatives: 10207537.0000 - precision: 0.9211 - recall: 0.9222 - val_loss: 0.1018 - val_accuracy: 0.9162 - val_binary_iou: 0.8418 - val_true_positives: 39979776.0000 - val_false_positives: 3872130.0000 - val_true_negatives: 57110828.0000 - val_false_negatives: 5008989.0000 - val_precision: 0.9117 - val_recall: 0.8887\n",
      "Epoch 216/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0815 - accuracy: 0.9340 - binary_iou: 0.8727 - true_positives: 120969848.0000 - false_positives: 10925978.0000 - true_negatives: 177461952.0000 - false_negatives: 10163086.0000 - precision: 0.9172 - recall: 0.9225 - val_loss: 0.0994 - val_accuracy: 0.9169 - val_binary_iou: 0.8434 - val_true_positives: 40524828.0000 - val_false_positives: 4258799.0000 - val_true_negatives: 56636004.0000 - val_false_negatives: 4552087.0000 - val_precision: 0.9049 - val_recall: 0.8990\n",
      "Epoch 217/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9360 - binary_iou: 0.8763 - true_positives: 121104352.0000 - false_positives: 10419728.0000 - true_negatives: 177981440.0000 - false_negatives: 10015237.0000 - precision: 0.9208 - recall: 0.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.0789 - accuracy: 0.9360 - binary_iou: 0.8763 - true_positives: 121104352.0000 - false_positives: 10419728.0000 - true_negatives: 177981440.0000 - false_negatives: 10015237.0000 - precision: 0.9208 - recall: 0.9236 - val_loss: 0.0954 - val_accuracy: 0.9199 - val_binary_iou: 0.8487 - val_true_positives: 40756984.0000 - val_false_positives: 4078980.0000 - val_true_negatives: 56724384.0000 - val_false_negatives: 4411369.0000 - val_precision: 0.9090 - val_recall: 0.9023\n",
      "Epoch 218/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0789 - accuracy: 0.9363 - binary_iou: 0.8768 - true_positives: 121148456.0000 - false_positives: 10418219.0000 - true_negatives: 178020544.0000 - false_negatives: 9933609.0000 - precision: 0.9208 - recall: 0.9242 - val_loss: 0.1003 - val_accuracy: 0.9158 - val_binary_iou: 0.8421 - val_true_positives: 41002304.0000 - val_false_positives: 4674641.0000 - val_true_negatives: 56051808.0000 - val_false_negatives: 4242974.0000 - val_precision: 0.8977 - val_recall: 0.9062\n",
      "Epoch 219/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0815 - accuracy: 0.9340 - binary_iou: 0.8726 - true_positives: 120675728.0000 - false_positives: 10695380.0000 - true_negatives: 177764736.0000 - false_negatives: 10384935.0000 - precision: 0.9186 - recall: 0.9208 - val_loss: 0.0986 - val_accuracy: 0.9175 - val_binary_iou: 0.8446 - val_true_positives: 40836120.0000 - val_false_positives: 4481256.0000 - val_true_negatives: 56387896.0000 - val_false_negatives: 4266430.0000 - val_precision: 0.9011 - val_recall: 0.9054\n",
      "Epoch 220/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0793 - accuracy: 0.9358 - binary_iou: 0.8758 - true_positives: 121111696.0000 - false_positives: 10524068.0000 - true_negatives: 177884192.0000 - false_negatives: 10000850.0000 - precision: 0.9201 - recall: 0.9237 - val_loss: 0.1016 - val_accuracy: 0.9133 - val_binary_iou: 0.8382 - val_true_positives: 41498992.0000 - val_false_positives: 5597551.0000 - val_true_negatives: 55289420.0000 - val_false_negatives: 3585759.0000 - val_precision: 0.8811 - val_recall: 0.9205\n",
      "Epoch 221/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0798 - accuracy: 0.9353 - binary_iou: 0.8750 - true_positives: 120993720.0000 - false_positives: 10489235.0000 - true_negatives: 177861744.0000 - false_negatives: 10176014.0000 - precision: 0.9202 - recall: 0.9224 - val_loss: 0.1003 - val_accuracy: 0.9174 - val_binary_iou: 0.8441 - val_true_positives: 40179712.0000 - val_false_positives: 3809751.0000 - val_true_negatives: 57041288.0000 - val_false_negatives: 4940956.0000 - val_precision: 0.9134 - val_recall: 0.8905\n",
      "Epoch 222/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0799 - accuracy: 0.9352 - binary_iou: 0.8748 - true_positives: 121292976.0000 - false_positives: 10806352.0000 - true_negatives: 177518224.0000 - false_negatives: 9903208.0000 - precision: 0.9182 - recall: 0.9245 - val_loss: 0.1080 - val_accuracy: 0.9109 - val_binary_iou: 0.8327 - val_true_positives: 39714088.0000 - val_false_positives: 4000501.0000 - val_true_negatives: 56816508.0000 - val_false_negatives: 5440613.0000 - val_precision: 0.9085 - val_recall: 0.8795\n",
      "Epoch 223/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0793 - accuracy: 0.9360 - binary_iou: 0.8763 - true_positives: 121033752.0000 - false_positives: 10365529.0000 - true_negatives: 178049632.0000 - false_negatives: 10071805.0000 - precision: 0.9211 - recall: 0.9232 - val_loss: 0.0981 - val_accuracy: 0.9166 - val_binary_iou: 0.8436 - val_true_positives: 41437656.0000 - val_false_positives: 5127692.0000 - val_true_negatives: 55693440.0000 - val_false_negatives: 3712940.0000 - val_precision: 0.8899 - val_recall: 0.9178\n",
      "Epoch 224/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0782 - accuracy: 0.9364 - binary_iou: 0.8770 - true_positives: 121371264.0000 - false_positives: 10483441.0000 - true_negatives: 177825856.0000 - false_negatives: 9840321.0000 - precision: 0.9205 - recall: 0.9250 - val_loss: 0.0974 - val_accuracy: 0.9187 - val_binary_iou: 0.8465 - val_true_positives: 40609180.0000 - val_false_positives: 4112201.0000 - val_true_negatives: 56743772.0000 - val_false_negatives: 4506552.0000 - val_precision: 0.9080 - val_recall: 0.9001\n",
      "Epoch 225/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0785 - accuracy: 0.9363 - binary_iou: 0.8768 - true_positives: 121212368.0000 - false_positives: 10427303.0000 - true_negatives: 177953104.0000 - false_negatives: 9928025.0000 - precision: 0.9208 - recall: 0.9243 - val_loss: 0.1019 - val_accuracy: 0.9121 - val_binary_iou: 0.8363 - val_true_positives: 41768536.0000 - val_false_positives: 6061431.0000 - val_true_negatives: 54892304.0000 - val_false_negatives: 3249468.0000 - val_precision: 0.8733 - val_recall: 0.9278\n",
      "Epoch 226/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0775 - accuracy: 0.9373 - binary_iou: 0.8786 - true_positives: 121219856.0000 - false_positives: 10175605.0000 - true_negatives: 178264944.0000 - false_negatives: 9860365.0000 - precision: 0.9226 - recall: 0.9248 - val_loss: 0.1015 - val_accuracy: 0.9165 - val_binary_iou: 0.8423 - val_true_positives: 39834184.0000 - val_false_positives: 3592067.0000 - val_true_negatives: 57293880.0000 - val_false_negatives: 5251582.0000 - val_precision: 0.9173 - val_recall: 0.8835\n",
      "Epoch 227/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0804 - accuracy: 0.9349 - binary_iou: 0.8742 - true_positives: 121032616.0000 - false_positives: 10665953.0000 - true_negatives: 177672784.0000 - false_negatives: 10149484.0000 - precision: 0.9190 - recall: 0.9226 - val_loss: 0.1088 - val_accuracy: 0.9117 - val_binary_iou: 0.8335 - val_true_positives: 39106836.0000 - val_false_positives: 3270886.0000 - val_true_negatives: 57508608.0000 - val_false_negatives: 6085388.0000 - val_precision: 0.9228 - val_recall: 0.8653\n",
      "Epoch 228/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0836 - accuracy: 0.9325 - binary_iou: 0.8700 - true_positives: 120682536.0000 - false_positives: 11087086.0000 - true_negatives: 177279808.0000 - false_negatives: 10471360.0000 - precision: 0.9159 - recall: 0.9202 - val_loss: 0.1108 - val_accuracy: 0.9020 - val_binary_iou: 0.8198 - val_true_positives: 42104752.0000 - val_false_positives: 7404113.0000 - val_true_negatives: 53486600.0000 - val_false_negatives: 2976274.0000 - val_precision: 0.8504 - val_recall: 0.9340\n",
      "Epoch 229/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0782 - accuracy: 0.9365 - binary_iou: 0.8771 - true_positives: 121075632.0000 - false_positives: 10267857.0000 - true_negatives: 178145712.0000 - false_negatives: 10031482.0000 - precision: 0.9218 - recall: 0.9235 - val_loss: 0.0968 - val_accuracy: 0.9181 - val_binary_iou: 0.8458 - val_true_positives: 40949568.0000 - val_false_positives: 4567519.0000 - val_true_negatives: 56340948.0000 - val_false_negatives: 4113680.0000 - val_precision: 0.8997 - val_recall: 0.9087\n",
      "Epoch 230/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0776 - accuracy: 0.9370 - binary_iou: 0.8780 - true_positives: 121288464.0000 - false_positives: 10254748.0000 - true_negatives: 178097776.0000 - false_negatives: 9879836.0000 - precision: 0.9220 - recall: 0.9247 - val_loss: 0.0973 - val_accuracy: 0.9179 - val_binary_iou: 0.8453 - val_true_positives: 40742104.0000 - val_false_positives: 4438511.0000 - val_true_negatives: 56530336.0000 - val_false_negatives: 4260757.0000 - val_precision: 0.9018 - val_recall: 0.9053\n",
      "Epoch 231/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9375 - binary_iou: 0.8789 - true_positives: 121306728.0000 - false_positives: 10207604.0000 - true_negatives: 178230240.0000 - false_negatives: 9776282.0000 - precision: 0.9224 - recall: 0.9254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.0773 - accuracy: 0.9375 - binary_iou: 0.8789 - true_positives: 121306728.0000 - false_positives: 10207604.0000 - true_negatives: 178230240.0000 - false_negatives: 9776282.0000 - precision: 0.9224 - recall: 0.9254 - val_loss: 0.0950 - val_accuracy: 0.9199 - val_binary_iou: 0.8489 - val_true_positives: 40906924.0000 - val_false_positives: 4334830.0000 - val_true_negatives: 56578376.0000 - val_false_negatives: 4151581.0000 - val_precision: 0.9042 - val_recall: 0.9079\n",
      "Epoch 232/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0791 - accuracy: 0.9361 - binary_iou: 0.8764 - true_positives: 121089792.0000 - false_positives: 10408058.0000 - true_negatives: 178004864.0000 - false_negatives: 10018078.0000 - precision: 0.9208 - recall: 0.9236 - val_loss: 0.1021 - val_accuracy: 0.9129 - val_binary_iou: 0.8372 - val_true_positives: 41155196.0000 - val_false_positives: 5233282.0000 - val_true_negatives: 55583328.0000 - val_false_negatives: 3999896.0000 - val_precision: 0.8872 - val_recall: 0.9114\n",
      "Epoch 233/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0765 - accuracy: 0.9380 - binary_iou: 0.8798 - true_positives: 121423320.0000 - false_positives: 10128310.0000 - true_negatives: 178281056.0000 - false_negatives: 9688120.0000 - precision: 0.9230 - recall: 0.9261 - val_loss: 0.0965 - val_accuracy: 0.9183 - val_binary_iou: 0.8465 - val_true_positives: 41325928.0000 - val_false_positives: 4827770.0000 - val_true_negatives: 55992480.0000 - val_false_negatives: 3825518.0000 - val_precision: 0.8954 - val_recall: 0.9153\n",
      "Epoch 234/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0764 - accuracy: 0.9380 - binary_iou: 0.8798 - true_positives: 121290592.0000 - false_positives: 9957065.0000 - true_negatives: 178420704.0000 - false_negatives: 9852411.0000 - precision: 0.9241 - recall: 0.9249 - val_loss: 0.0977 - val_accuracy: 0.9175 - val_binary_iou: 0.8448 - val_true_positives: 40902408.0000 - val_false_positives: 4525575.0000 - val_true_negatives: 56327128.0000 - val_false_negatives: 4216588.0000 - val_precision: 0.9004 - val_recall: 0.9065\n",
      "Epoch 235/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0760 - accuracy: 0.9383 - binary_iou: 0.8805 - true_positives: 121466544.0000 - false_positives: 9997547.0000 - true_negatives: 178347840.0000 - false_negatives: 9708819.0000 - precision: 0.9240 - recall: 0.9260 - val_loss: 0.0976 - val_accuracy: 0.9181 - val_binary_iou: 0.8457 - val_true_positives: 40711532.0000 - val_false_positives: 4416356.0000 - val_true_negatives: 56582252.0000 - val_false_negatives: 4261572.0000 - val_precision: 0.9021 - val_recall: 0.9052\n",
      "Epoch 236/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0776 - accuracy: 0.9373 - binary_iou: 0.8785 - true_positives: 121124968.0000 - false_positives: 10039747.0000 - true_negatives: 178348400.0000 - false_negatives: 10007653.0000 - precision: 0.9235 - recall: 0.9237 - val_loss: 0.0963 - val_accuracy: 0.9179 - val_binary_iou: 0.8457 - val_true_positives: 41296056.0000 - val_false_positives: 4853871.0000 - val_true_negatives: 55976304.0000 - val_false_negatives: 3845485.0000 - val_precision: 0.8948 - val_recall: 0.9148\n",
      "Epoch 237/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0771 - accuracy: 0.9378 - binary_iou: 0.8795 - true_positives: 121382352.0000 - false_positives: 10082423.0000 - true_negatives: 178258320.0000 - false_negatives: 9797693.0000 - precision: 0.9233 - recall: 0.9253 - val_loss: 0.0958 - val_accuracy: 0.9190 - val_binary_iou: 0.8475 - val_true_positives: 41013296.0000 - val_false_positives: 4530066.0000 - val_true_negatives: 56379916.0000 - val_false_negatives: 4048434.0000 - val_precision: 0.9005 - val_recall: 0.9102\n",
      "Epoch 238/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0757 - accuracy: 0.9385 - binary_iou: 0.8807 - true_positives: 121356376.0000 - false_positives: 9867913.0000 - true_negatives: 178505152.0000 - false_negatives: 9791260.0000 - precision: 0.9248 - recall: 0.9253 - val_loss: 0.0984 - val_accuracy: 0.9185 - val_binary_iou: 0.8460 - val_true_positives: 40343944.0000 - val_false_positives: 3923115.0000 - val_true_negatives: 56985804.0000 - val_false_negatives: 4718840.0000 - val_precision: 0.9114 - val_recall: 0.8953\n",
      "Epoch 239/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0774 - accuracy: 0.9371 - binary_iou: 0.8782 - true_positives: 121168080.0000 - false_positives: 10108151.0000 - true_negatives: 178258848.0000 - false_negatives: 9985708.0000 - precision: 0.9230 - recall: 0.9239 - val_loss: 0.0981 - val_accuracy: 0.9188 - val_binary_iou: 0.8464 - val_true_positives: 40213344.0000 - val_false_positives: 3723532.0000 - val_true_negatives: 57151412.0000 - val_false_negatives: 4883417.0000 - val_precision: 0.9153 - val_recall: 0.8917\n",
      "Epoch 240/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0772 - accuracy: 0.9376 - binary_iou: 0.8791 - true_positives: 121133064.0000 - false_positives: 9990178.0000 - true_negatives: 178456880.0000 - false_negatives: 9940627.0000 - precision: 0.9238 - recall: 0.9242 - val_loss: 0.0967 - val_accuracy: 0.9179 - val_binary_iou: 0.8458 - val_true_positives: 41435348.0000 - val_false_positives: 5021305.0000 - val_true_negatives: 55831940.0000 - val_false_negatives: 3683110.0000 - val_precision: 0.8919 - val_recall: 0.9184\n",
      "Epoch 241/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0772 - accuracy: 0.9374 - binary_iou: 0.8789 - true_positives: 121386456.0000 - false_positives: 10230755.0000 - true_negatives: 178143568.0000 - false_negatives: 9760015.0000 - precision: 0.9223 - recall: 0.9256 - val_loss: 0.0982 - val_accuracy: 0.9187 - val_binary_iou: 0.8462 - val_true_positives: 40160192.0000 - val_false_positives: 3654995.0000 - val_true_negatives: 57192844.0000 - val_false_negatives: 4963693.0000 - val_precision: 0.9166 - val_recall: 0.8900\n",
      "Epoch 242/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0768 - accuracy: 0.9379 - binary_iou: 0.8797 - true_positives: 121331296.0000 - false_positives: 10049944.0000 - true_negatives: 178351776.0000 - false_negatives: 9787826.0000 - precision: 0.9235 - recall: 0.9254 - val_loss: 0.0974 - val_accuracy: 0.9182 - val_binary_iou: 0.8459 - val_true_positives: 40835480.0000 - val_false_positives: 4378582.0000 - val_true_negatives: 56470168.0000 - val_false_negatives: 4287470.0000 - val_precision: 0.9032 - val_recall: 0.9050\n",
      "Epoch 243/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0747 - accuracy: 0.9396 - binary_iou: 0.8828 - true_positives: 121554432.0000 - false_positives: 9792873.0000 - true_negatives: 178668528.0000 - false_negatives: 9504942.0000 - precision: 0.9254 - recall: 0.9275 - val_loss: 0.0983 - val_accuracy: 0.9176 - val_binary_iou: 0.8446 - val_true_positives: 40497452.0000 - val_false_positives: 4159625.0000 - val_true_negatives: 56738256.0000 - val_false_negatives: 4576386.0000 - val_precision: 0.9069 - val_recall: 0.8985\n",
      "Epoch 244/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0755 - accuracy: 0.9390 - binary_iou: 0.8817 - true_positives: 121514696.0000 - false_positives: 9868392.0000 - true_negatives: 178514016.0000 - false_negatives: 9623684.0000 - precision: 0.9249 - recall: 0.9266 - val_loss: 0.1011 - val_accuracy: 0.9134 - val_binary_iou: 0.8382 - val_true_positives: 41448884.0000 - val_false_positives: 5511760.0000 - val_true_negatives: 55342208.0000 - val_false_negatives: 3668863.0000 - val_precision: 0.8826 - val_recall: 0.9187\n",
      "Epoch 245/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0765 - accuracy: 0.9383 - binary_iou: 0.8804 - true_positives: 121309664.0000 - false_positives: 9897573.0000 - true_negatives: 178496832.0000 - false_negatives: 9816705.0000 - precision: 0.9246 - recall: 0.9251 - val_loss: 0.0975 - val_accuracy: 0.9187 - val_binary_iou: 0.8464 - val_true_positives: 40501448.0000 - val_false_positives: 4083477.0000 - val_true_negatives: 56851324.0000 - val_false_negatives: 4535471.0000 - val_precision: 0.9084 - val_recall: 0.8993\n",
      "Epoch 246/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0757 - accuracy: 0.9391 - binary_iou: 0.8818 - true_positives: 121432216.0000 - false_positives: 9880036.0000 - true_negatives: 178622032.0000 - false_negatives: 9586525.0000 - precision: 0.9248 - recall: 0.9268 - val_loss: 0.1004 - val_accuracy: 0.9167 - val_binary_iou: 0.8428 - val_true_positives: 39972220.0000 - val_false_positives: 3630445.0000 - val_true_negatives: 57177056.0000 - val_false_negatives: 5191996.0000 - val_precision: 0.9167 - val_recall: 0.8850\n",
      "Epoch 247/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0758 - accuracy: 0.9385 - binary_iou: 0.8808 - true_positives: 121597688.0000 - false_positives: 10106789.0000 - true_negatives: 178272688.0000 - false_negatives: 9543564.0000 - precision: 0.9233 - recall: 0.9272 - val_loss: 0.0998 - val_accuracy: 0.9173 - val_binary_iou: 0.8439 - val_true_positives: 40161476.0000 - val_false_positives: 3803094.0000 - val_true_negatives: 57048048.0000 - val_false_negatives: 4959084.0000 - val_precision: 0.9135 - val_recall: 0.8901\n",
      "Epoch 248/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0752 - accuracy: 0.9391 - binary_iou: 0.8818 - true_positives: 121642256.0000 - false_positives: 9929713.0000 - true_negatives: 178414416.0000 - false_negatives: 9534372.0000 - precision: 0.9245 - recall: 0.9273 - val_loss: 0.1037 - val_accuracy: 0.9162 - val_binary_iou: 0.8415 - val_true_positives: 39554512.0000 - val_false_positives: 3385593.0000 - val_true_negatives: 57539260.0000 - val_false_negatives: 5492364.0000 - val_precision: 0.9212 - val_recall: 0.8781\n",
      "Epoch 249/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0758 - accuracy: 0.9389 - binary_iou: 0.8815 - true_positives: 121471360.0000 - false_positives: 9849832.0000 - true_negatives: 178538992.0000 - false_negatives: 9660614.0000 - precision: 0.9250 - recall: 0.9263 - val_loss: 0.1000 - val_accuracy: 0.9166 - val_binary_iou: 0.8429 - val_true_positives: 40489956.0000 - val_false_positives: 4285769.0000 - val_true_negatives: 56640600.0000 - val_false_negatives: 4555385.0000 - val_precision: 0.9043 - val_recall: 0.8989\n",
      "Epoch 250/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9388 - binary_iou: 0.8814 - true_positives: 121507448.0000 - false_positives: 9904124.0000 - true_negatives: 178468512.0000 - false_negatives: 9640728.0000 - precision: 0.9246 - recall: 0.9265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 527ms/step - loss: 0.0756 - accuracy: 0.9388 - binary_iou: 0.8814 - true_positives: 121507448.0000 - false_positives: 9904124.0000 - true_negatives: 178468512.0000 - false_negatives: 9640728.0000 - precision: 0.9246 - recall: 0.9265 - val_loss: 0.0956 - val_accuracy: 0.9202 - val_binary_iou: 0.8491 - val_true_positives: 40541388.0000 - val_false_positives: 3886380.0000 - val_true_negatives: 56974040.0000 - val_false_negatives: 4569911.0000 - val_precision: 0.9125 - val_recall: 0.8987\n",
      "Epoch 251/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0757 - accuracy: 0.9389 - binary_iou: 0.8815 - true_positives: 121525424.0000 - false_positives: 9908704.0000 - true_negatives: 178472992.0000 - false_negatives: 9613682.0000 - precision: 0.9246 - recall: 0.9267 - val_loss: 0.1014 - val_accuracy: 0.9152 - val_binary_iou: 0.8406 - val_true_positives: 40459136.0000 - val_false_positives: 4268097.0000 - val_true_negatives: 56527740.0000 - val_false_negatives: 4716739.0000 - val_precision: 0.9046 - val_recall: 0.8956\n",
      "Epoch 252/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0728 - accuracy: 0.9411 - binary_iou: 0.8855 - true_positives: 121793016.0000 - false_positives: 9457928.0000 - true_negatives: 178912512.0000 - false_negatives: 9357368.0000 - precision: 0.9279 - recall: 0.9287 - val_loss: 0.0965 - val_accuracy: 0.9182 - val_binary_iou: 0.8463 - val_true_positives: 41258720.0000 - val_false_positives: 4892507.0000 - val_true_negatives: 56048180.0000 - val_false_negatives: 3772309.0000 - val_precision: 0.8940 - val_recall: 0.9162\n",
      "Epoch 253/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0742 - accuracy: 0.9399 - binary_iou: 0.8834 - true_positives: 121609496.0000 - false_positives: 9705376.0000 - true_negatives: 178719296.0000 - false_negatives: 9486623.0000 - precision: 0.9261 - recall: 0.9276 - val_loss: 0.1004 - val_accuracy: 0.9178 - val_binary_iou: 0.8443 - val_true_positives: 39760140.0000 - val_false_positives: 3391192.0000 - val_true_negatives: 57498808.0000 - val_false_negatives: 5321573.0000 - val_precision: 0.9214 - val_recall: 0.8820\n",
      "Epoch 254/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0744 - accuracy: 0.9397 - binary_iou: 0.8830 - true_positives: 121672976.0000 - false_positives: 9852383.0000 - true_negatives: 178593344.0000 - false_negatives: 9401990.0000 - precision: 0.9251 - recall: 0.9283 - val_loss: 0.0966 - val_accuracy: 0.9197 - val_binary_iou: 0.8484 - val_true_positives: 40820536.0000 - val_false_positives: 4286132.0000 - val_true_negatives: 56640076.0000 - val_false_negatives: 4224977.0000 - val_precision: 0.9050 - val_recall: 0.9062\n",
      "Epoch 255/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9404 - binary_iou: 0.8842 - true_positives: 121694840.0000 - false_positives: 9586472.0000 - true_negatives: 178778304.0000 - false_negatives: 9461081.0000 - precision: 0.9270 - recall: 0.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.0737 - accuracy: 0.9404 - binary_iou: 0.8842 - true_positives: 121694840.0000 - false_positives: 9586472.0000 - true_negatives: 178778304.0000 - false_negatives: 9461081.0000 - precision: 0.9270 - recall: 0.9279 - val_loss: 0.0962 - val_accuracy: 0.9203 - val_binary_iou: 0.8491 - val_true_positives: 40378880.0000 - val_false_positives: 3723408.0000 - val_true_negatives: 57147188.0000 - val_false_negatives: 4722232.0000 - val_precision: 0.9156 - val_recall: 0.8953\n",
      "Epoch 256/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0755 - accuracy: 0.9390 - binary_iou: 0.8817 - true_positives: 121521672.0000 - false_positives: 9879399.0000 - true_negatives: 178518432.0000 - false_negatives: 9601180.0000 - precision: 0.9248 - recall: 0.9268 - val_loss: 0.1031 - val_accuracy: 0.9151 - val_binary_iou: 0.8399 - val_true_positives: 39829496.0000 - val_false_positives: 3616784.0000 - val_true_negatives: 57146468.0000 - val_false_negatives: 5378962.0000 - val_precision: 0.9168 - val_recall: 0.8810\n",
      "Epoch 257/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0733 - accuracy: 0.9409 - binary_iou: 0.8852 - true_positives: 121815112.0000 - false_positives: 9584465.0000 - true_negatives: 178835120.0000 - false_negatives: 9286082.0000 - precision: 0.9271 - recall: 0.9292 - val_loss: 0.0955 - val_accuracy: 0.9192 - val_binary_iou: 0.8478 - val_true_positives: 40939864.0000 - val_false_positives: 4368867.0000 - val_true_negatives: 56474264.0000 - val_false_negatives: 4188726.0000 - val_precision: 0.9036 - val_recall: 0.9072\n",
      "Epoch 258/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0728 - accuracy: 0.9411 - binary_iou: 0.8854 - true_positives: 121838616.0000 - false_positives: 9511244.0000 - true_negatives: 178849104.0000 - false_negatives: 9321817.0000 - precision: 0.9276 - recall: 0.9289 - val_loss: 0.0989 - val_accuracy: 0.9178 - val_binary_iou: 0.8446 - val_true_positives: 40053444.0000 - val_false_positives: 3673700.0000 - val_true_negatives: 57209300.0000 - val_false_negatives: 5035277.0000 - val_precision: 0.9160 - val_recall: 0.8883\n",
      "Epoch 259/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0734 - accuracy: 0.9406 - binary_iou: 0.8846 - true_positives: 121746736.0000 - false_positives: 9645570.0000 - true_negatives: 178791184.0000 - false_negatives: 9337264.0000 - precision: 0.9266 - recall: 0.9288 - val_loss: 0.0969 - val_accuracy: 0.9199 - val_binary_iou: 0.8483 - val_true_positives: 40242848.0000 - val_false_positives: 3666011.0000 - val_true_negatives: 57238904.0000 - val_false_negatives: 4823956.0000 - val_precision: 0.9165 - val_recall: 0.8930\n",
      "Epoch 260/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0721 - accuracy: 0.9419 - binary_iou: 0.8869 - true_positives: 121948024.0000 - false_positives: 9358598.0000 - true_negatives: 178994272.0000 - false_negatives: 9219835.0000 - precision: 0.9287 - recall: 0.9297 - val_loss: 0.1008 - val_accuracy: 0.9128 - val_binary_iou: 0.8375 - val_true_positives: 41783888.0000 - val_false_positives: 5906277.0000 - val_true_negatives: 54951504.0000 - val_false_negatives: 3330051.0000 - val_precision: 0.8762 - val_recall: 0.9262\n",
      "Epoch 261/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9425 - binary_iou: 0.8880 - true_positives: 122115464.0000 - false_positives: 9384443.0000 - true_negatives: 179021712.0000 - false_negatives: 8999118.0000 - precision: 0.9286 - recall: 0.9314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0711 - accuracy: 0.9425 - binary_iou: 0.8880 - true_positives: 122115464.0000 - false_positives: 9384443.0000 - true_negatives: 179021712.0000 - false_negatives: 8999118.0000 - precision: 0.9286 - recall: 0.9314 - val_loss: 0.0950 - val_accuracy: 0.9211 - val_binary_iou: 0.8505 - val_true_positives: 40363716.0000 - val_false_positives: 3577390.0000 - val_true_negatives: 57246260.0000 - val_false_negatives: 4784335.0000 - val_precision: 0.9186 - val_recall: 0.8940\n",
      "Epoch 262/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0720 - accuracy: 0.9420 - binary_iou: 0.8871 - true_positives: 121858080.0000 - false_positives: 9332087.0000 - true_negatives: 179122672.0000 - false_negatives: 9207850.0000 - precision: 0.9289 - recall: 0.9297 - val_loss: 0.0980 - val_accuracy: 0.9183 - val_binary_iou: 0.8461 - val_true_positives: 40918904.0000 - val_false_positives: 4504598.0000 - val_true_negatives: 56391156.0000 - val_false_negatives: 4157057.0000 - val_precision: 0.9008 - val_recall: 0.9078\n",
      "Epoch 263/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0731 - accuracy: 0.9408 - binary_iou: 0.8849 - true_positives: 121810680.0000 - false_positives: 9580204.0000 - true_negatives: 178789072.0000 - false_negatives: 9340819.0000 - precision: 0.9271 - recall: 0.9288 - val_loss: 0.0972 - val_accuracy: 0.9191 - val_binary_iou: 0.8470 - val_true_positives: 40361888.0000 - val_false_positives: 3847110.0000 - val_true_negatives: 57032480.0000 - val_false_negatives: 4730226.0000 - val_precision: 0.9130 - val_recall: 0.8951\n",
      "Epoch 264/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0723 - accuracy: 0.9415 - binary_iou: 0.8862 - true_positives: 121882192.0000 - false_positives: 9418337.0000 - true_negatives: 178946000.0000 - false_negatives: 9274232.0000 - precision: 0.9283 - recall: 0.9293 - val_loss: 0.1013 - val_accuracy: 0.9144 - val_binary_iou: 0.8396 - val_true_positives: 40858968.0000 - val_false_positives: 4794077.0000 - val_true_negatives: 56044668.0000 - val_false_negatives: 4274015.0000 - val_precision: 0.8950 - val_recall: 0.9053\n",
      "Epoch 265/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0725 - accuracy: 0.9413 - binary_iou: 0.8859 - true_positives: 121765304.0000 - false_positives: 9411539.0000 - true_negatives: 179001584.0000 - false_negatives: 9342308.0000 - precision: 0.9283 - recall: 0.9287 - val_loss: 0.0959 - val_accuracy: 0.9194 - val_binary_iou: 0.8481 - val_true_positives: 40995692.0000 - val_false_positives: 4492345.0000 - val_true_negatives: 56437784.0000 - val_false_negatives: 4045897.0000 - val_precision: 0.9012 - val_recall: 0.9102\n",
      "Epoch 266/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0723 - accuracy: 0.9413 - binary_iou: 0.8859 - true_positives: 121896400.0000 - false_positives: 9535050.0000 - true_negatives: 178880720.0000 - false_negatives: 9208499.0000 - precision: 0.9275 - recall: 0.9298 - val_loss: 0.0992 - val_accuracy: 0.9168 - val_binary_iou: 0.8434 - val_true_positives: 40738984.0000 - val_false_positives: 4511688.0000 - val_true_negatives: 56414128.0000 - val_false_negatives: 4306898.0000 - val_precision: 0.9003 - val_recall: 0.9044\n",
      "Epoch 267/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0713 - accuracy: 0.9423 - binary_iou: 0.8877 - true_positives: 122058168.0000 - false_positives: 9342383.0000 - true_negatives: 179025584.0000 - false_negatives: 9094644.0000 - precision: 0.9289 - recall: 0.9307 - val_loss: 0.0990 - val_accuracy: 0.9173 - val_binary_iou: 0.8443 - val_true_positives: 40715484.0000 - val_false_positives: 4333794.0000 - val_true_negatives: 56492176.0000 - val_false_negatives: 4430260.0000 - val_precision: 0.9038 - val_recall: 0.9019\n",
      "Epoch 268/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0715 - accuracy: 0.9423 - binary_iou: 0.8876 - true_positives: 121923928.0000 - false_positives: 9277247.0000 - true_negatives: 179152064.0000 - false_negatives: 9167521.0000 - precision: 0.9293 - recall: 0.9301 - val_loss: 0.0982 - val_accuracy: 0.9163 - val_binary_iou: 0.8430 - val_true_positives: 41219836.0000 - val_false_positives: 4985005.0000 - val_true_negatives: 55884988.0000 - val_false_negatives: 3881882.0000 - val_precision: 0.8921 - val_recall: 0.9139\n",
      "Epoch 269/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0719 - accuracy: 0.9420 - binary_iou: 0.8871 - true_positives: 121896392.0000 - false_positives: 9329332.0000 - true_negatives: 179078560.0000 - false_negatives: 9216412.0000 - precision: 0.9289 - recall: 0.9297 - val_loss: 0.1190 - val_accuracy: 0.8984 - val_binary_iou: 0.8130 - val_true_positives: 40874124.0000 - val_false_positives: 6467770.0000 - val_true_negatives: 54329340.0000 - val_false_negatives: 4300482.0000 - val_precision: 0.8634 - val_recall: 0.9048\n",
      "Epoch 270/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0750 - accuracy: 0.9396 - binary_iou: 0.8827 - true_positives: 121542880.0000 - false_positives: 9785760.0000 - true_negatives: 178668928.0000 - false_negatives: 9523276.0000 - precision: 0.9255 - recall: 0.9273 - val_loss: 0.0977 - val_accuracy: 0.9176 - val_binary_iou: 0.8450 - val_true_positives: 41057872.0000 - val_false_positives: 4629528.0000 - val_true_negatives: 56177316.0000 - val_false_negatives: 4107015.0000 - val_precision: 0.8987 - val_recall: 0.9091\n",
      "Epoch 271/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0715 - accuracy: 0.9420 - binary_iou: 0.8871 - true_positives: 121992752.0000 - false_positives: 9409878.0000 - true_negatives: 178991072.0000 - false_negatives: 9127016.0000 - precision: 0.9284 - recall: 0.9304 - val_loss: 0.0947 - val_accuracy: 0.9201 - val_binary_iou: 0.8493 - val_true_positives: 40954168.0000 - val_false_positives: 4173279.0000 - val_true_negatives: 56553144.0000 - val_false_negatives: 4291110.0000 - val_precision: 0.9075 - val_recall: 0.9052\n",
      "Epoch 272/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0700 - accuracy: 0.9433 - binary_iou: 0.8895 - true_positives: 122062200.0000 - false_positives: 9137484.0000 - true_negatives: 179343072.0000 - false_negatives: 8978005.0000 - precision: 0.9304 - recall: 0.9315 - val_loss: 0.0950 - val_accuracy: 0.9206 - val_binary_iou: 0.8500 - val_true_positives: 40778700.0000 - val_false_positives: 4065765.0000 - val_true_negatives: 56780476.0000 - val_false_negatives: 4346759.0000 - val_precision: 0.9093 - val_recall: 0.9037\n",
      "Epoch 273/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0699 - accuracy: 0.9435 - binary_iou: 0.8899 - true_positives: 122113368.0000 - false_positives: 9078273.0000 - true_negatives: 179351120.0000 - false_negatives: 8978025.0000 - precision: 0.9308 - recall: 0.9315 - val_loss: 0.0971 - val_accuracy: 0.9199 - val_binary_iou: 0.8483 - val_true_positives: 40282944.0000 - val_false_positives: 3662969.0000 - val_true_negatives: 57196800.0000 - val_false_negatives: 4828988.0000 - val_precision: 0.9166 - val_recall: 0.8930\n",
      "Epoch 274/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9425 - binary_iou: 0.8881 - true_positives: 121994392.0000 - false_positives: 9216540.0000 - true_negatives: 179160688.0000 - false_negatives: 9149174.0000 - precision: 0.9298 - recall: 0.9302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 527ms/step - loss: 0.0710 - accuracy: 0.9425 - binary_iou: 0.8881 - true_positives: 121994392.0000 - false_positives: 9216540.0000 - true_negatives: 179160688.0000 - false_negatives: 9149174.0000 - precision: 0.9298 - recall: 0.9302 - val_loss: 0.0945 - val_accuracy: 0.9212 - val_binary_iou: 0.8510 - val_true_positives: 40834996.0000 - val_false_positives: 4103185.0000 - val_true_negatives: 56783872.0000 - val_false_negatives: 4249642.0000 - val_precision: 0.9087 - val_recall: 0.9057\n",
      "Epoch 275/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0697 - accuracy: 0.9438 - binary_iou: 0.8904 - true_positives: 122245152.0000 - false_positives: 9136179.0000 - true_negatives: 179306320.0000 - false_negatives: 8833124.0000 - precision: 0.9305 - recall: 0.9326 - val_loss: 0.1020 - val_accuracy: 0.9163 - val_binary_iou: 0.8419 - val_true_positives: 39841368.0000 - val_false_positives: 3562277.0000 - val_true_negatives: 57257956.0000 - val_false_negatives: 5310107.0000 - val_precision: 0.9179 - val_recall: 0.8824\n",
      "Epoch 276/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0699 - accuracy: 0.9436 - binary_iou: 0.8900 - true_positives: 122073232.0000 - false_positives: 9043420.0000 - true_negatives: 179418608.0000 - false_negatives: 8985502.0000 - precision: 0.9310 - recall: 0.9314 - val_loss: 0.0968 - val_accuracy: 0.9189 - val_binary_iou: 0.8470 - val_true_positives: 40706872.0000 - val_false_positives: 4220624.0000 - val_true_negatives: 56668080.0000 - val_false_negatives: 4376133.0000 - val_precision: 0.9061 - val_recall: 0.9029\n",
      "Epoch 277/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0707 - accuracy: 0.9429 - binary_iou: 0.8887 - true_positives: 122158768.0000 - false_positives: 9292123.0000 - true_negatives: 179105568.0000 - false_negatives: 8964274.0000 - precision: 0.9293 - recall: 0.9316 - val_loss: 0.0960 - val_accuracy: 0.9196 - val_binary_iou: 0.8483 - val_true_positives: 40907048.0000 - val_false_positives: 4365861.0000 - val_true_negatives: 56542756.0000 - val_false_negatives: 4156047.0000 - val_precision: 0.9036 - val_recall: 0.9078\n",
      "Epoch 278/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0691 - accuracy: 0.9441 - binary_iou: 0.8910 - true_positives: 122377008.0000 - false_positives: 9041244.0000 - true_negatives: 179286464.0000 - false_negatives: 8816020.0000 - precision: 0.9312 - recall: 0.9328 - val_loss: 0.0962 - val_accuracy: 0.9202 - val_binary_iou: 0.8490 - val_true_positives: 40539268.0000 - val_false_positives: 3895492.0000 - val_true_negatives: 56971240.0000 - val_false_negatives: 4565713.0000 - val_precision: 0.9123 - val_recall: 0.8988\n",
      "Epoch 279/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9431 - binary_iou: 0.8891 - true_positives: 122081848.0000 - false_positives: 9145683.0000 - true_negatives: 179246608.0000 - false_negatives: 9046606.0000 - precision: 0.9303 - recall: 0.9310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 530ms/step - loss: 0.0705 - accuracy: 0.9431 - binary_iou: 0.8891 - true_positives: 122081848.0000 - false_positives: 9145683.0000 - true_negatives: 179246608.0000 - false_negatives: 9046606.0000 - precision: 0.9303 - recall: 0.9310 - val_loss: 0.0937 - val_accuracy: 0.9218 - val_binary_iou: 0.8519 - val_true_positives: 40734072.0000 - val_false_positives: 3968057.0000 - val_true_negatives: 56948180.0000 - val_false_negatives: 4321409.0000 - val_precision: 0.9112 - val_recall: 0.9041\n",
      "Epoch 280/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0720 - accuracy: 0.9418 - binary_iou: 0.8867 - true_positives: 121943776.0000 - false_positives: 9448594.0000 - true_negatives: 178973136.0000 - false_negatives: 9155301.0000 - precision: 0.9281 - recall: 0.9302 - val_loss: 0.1035 - val_accuracy: 0.9160 - val_binary_iou: 0.8409 - val_true_positives: 39310244.0000 - val_false_positives: 3119394.0000 - val_true_negatives: 57760704.0000 - val_false_negatives: 5781384.0000 - val_precision: 0.9265 - val_recall: 0.8718\n",
      "Epoch 281/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0692 - accuracy: 0.9440 - binary_iou: 0.8907 - true_positives: 122185432.0000 - false_positives: 8964206.0000 - true_negatives: 179433968.0000 - false_negatives: 8937167.0000 - precision: 0.9316 - recall: 0.9318 - val_loss: 0.0949 - val_accuracy: 0.9196 - val_binary_iou: 0.8486 - val_true_positives: 41247916.0000 - val_false_positives: 4686773.0000 - val_true_negatives: 56207468.0000 - val_false_negatives: 3829553.0000 - val_precision: 0.8980 - val_recall: 0.9150\n",
      "Epoch 282/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0690 - accuracy: 0.9443 - binary_iou: 0.8913 - true_positives: 122299048.0000 - false_positives: 8966620.0000 - true_negatives: 179417664.0000 - false_negatives: 8837454.0000 - precision: 0.9317 - recall: 0.9326 - val_loss: 0.0949 - val_accuracy: 0.9205 - val_binary_iou: 0.8500 - val_true_positives: 41017992.0000 - val_false_positives: 4250269.0000 - val_true_negatives: 56533744.0000 - val_false_negatives: 4169730.0000 - val_precision: 0.9061 - val_recall: 0.9077\n",
      "Epoch 283/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0695 - accuracy: 0.9438 - binary_iou: 0.8904 - true_positives: 122124064.0000 - false_positives: 8983246.0000 - true_negatives: 179441216.0000 - false_negatives: 8972178.0000 - precision: 0.9315 - recall: 0.9316 - val_loss: 0.1003 - val_accuracy: 0.9162 - val_binary_iou: 0.8422 - val_true_positives: 40503388.0000 - val_false_positives: 4292139.0000 - val_true_negatives: 56583760.0000 - val_false_negatives: 4592411.0000 - val_precision: 0.9042 - val_recall: 0.8982\n",
      "Epoch 284/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0693 - accuracy: 0.9441 - binary_iou: 0.8910 - true_positives: 122284400.0000 - false_positives: 9077948.0000 - true_negatives: 179370528.0000 - false_negatives: 8787819.0000 - precision: 0.9309 - recall: 0.9330 - val_loss: 0.0935 - val_accuracy: 0.9210 - val_binary_iou: 0.8511 - val_true_positives: 41366676.0000 - val_false_positives: 4604157.0000 - val_true_negatives: 56233584.0000 - val_false_negatives: 3767318.0000 - val_precision: 0.8998 - val_recall: 0.9165\n",
      "Epoch 285/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0674 - accuracy: 0.9452 - binary_iou: 0.8930 - true_positives: 122423720.0000 - false_positives: 8769168.0000 - true_negatives: 179593168.0000 - false_negatives: 8734737.0000 - precision: 0.9332 - recall: 0.9334 - val_loss: 0.0989 - val_accuracy: 0.9168 - val_binary_iou: 0.8434 - val_true_positives: 40807532.0000 - val_false_positives: 4618200.0000 - val_true_negatives: 56342056.0000 - val_false_negatives: 4203931.0000 - val_precision: 0.8983 - val_recall: 0.9066\n",
      "Epoch 286/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0690 - accuracy: 0.9445 - binary_iou: 0.8917 - true_positives: 122306816.0000 - false_positives: 8953937.0000 - true_negatives: 179468656.0000 - false_negatives: 8791330.0000 - precision: 0.9318 - recall: 0.9329 - val_loss: 0.1015 - val_accuracy: 0.9153 - val_binary_iou: 0.8408 - val_true_positives: 40456788.0000 - val_false_positives: 4266994.0000 - val_true_negatives: 56541664.0000 - val_false_negatives: 4706264.0000 - val_precision: 0.9046 - val_recall: 0.8958\n",
      "Epoch 287/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0688 - accuracy: 0.9444 - binary_iou: 0.8916 - true_positives: 122342032.0000 - false_positives: 8934064.0000 - true_negatives: 179429008.0000 - false_negatives: 8815805.0000 - precision: 0.9319 - recall: 0.9328 - val_loss: 0.0949 - val_accuracy: 0.9204 - val_binary_iou: 0.8495 - val_true_positives: 40691020.0000 - val_false_positives: 4027592.0000 - val_true_negatives: 56845220.0000 - val_false_negatives: 4407887.0000 - val_precision: 0.9099 - val_recall: 0.9023\n",
      "Epoch 288/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0681 - accuracy: 0.9450 - binary_iou: 0.8925 - true_positives: 122314304.0000 - false_positives: 8816922.0000 - true_negatives: 179617136.0000 - false_negatives: 8772443.0000 - precision: 0.9328 - recall: 0.9331 - val_loss: 0.0969 - val_accuracy: 0.9190 - val_binary_iou: 0.8470 - val_true_positives: 40469420.0000 - val_false_positives: 3967227.0000 - val_true_negatives: 56917312.0000 - val_false_negatives: 4617766.0000 - val_precision: 0.9107 - val_recall: 0.8976\n",
      "Epoch 289/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0713 - accuracy: 0.9422 - binary_iou: 0.8876 - true_positives: 122143696.0000 - false_positives: 9423683.0000 - true_negatives: 178912208.0000 - false_negatives: 9041137.0000 - precision: 0.9284 - recall: 0.9311 - val_loss: 0.1033 - val_accuracy: 0.9104 - val_binary_iou: 0.8334 - val_true_positives: 41829188.0000 - val_false_positives: 6242063.0000 - val_true_negatives: 54642936.0000 - val_false_negatives: 3257514.0000 - val_precision: 0.8701 - val_recall: 0.9277\n",
      "Epoch 290/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0708 - accuracy: 0.9426 - binary_iou: 0.8883 - true_positives: 122034560.0000 - false_positives: 9290458.0000 - true_negatives: 179158224.0000 - false_negatives: 9037530.0000 - precision: 0.9293 - recall: 0.9310 - val_loss: 0.0968 - val_accuracy: 0.9179 - val_binary_iou: 0.8458 - val_true_positives: 41333912.0000 - val_false_positives: 4916954.0000 - val_true_negatives: 55937184.0000 - val_false_negatives: 3783669.0000 - val_precision: 0.8937 - val_recall: 0.9161\n",
      "Epoch 291/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0686 - accuracy: 0.9445 - binary_iou: 0.8917 - true_positives: 122384832.0000 - false_positives: 9005877.0000 - true_negatives: 179395376.0000 - false_negatives: 8734669.0000 - precision: 0.9315 - recall: 0.9334 - val_loss: 0.0972 - val_accuracy: 0.9188 - val_binary_iou: 0.8469 - val_true_positives: 40788428.0000 - val_false_positives: 4339726.0000 - val_true_negatives: 56578208.0000 - val_false_negatives: 4265349.0000 - val_precision: 0.9038 - val_recall: 0.9053\n",
      "Epoch 292/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0693 - accuracy: 0.9441 - binary_iou: 0.8911 - true_positives: 122302480.0000 - false_positives: 8983433.0000 - true_negatives: 179370208.0000 - false_negatives: 8864613.0000 - precision: 0.9316 - recall: 0.9324 - val_loss: 0.1003 - val_accuracy: 0.9173 - val_binary_iou: 0.8439 - val_true_positives: 40200340.0000 - val_false_positives: 3893616.0000 - val_true_negatives: 57010428.0000 - val_false_negatives: 4867323.0000 - val_precision: 0.9117 - val_recall: 0.8920\n",
      "Epoch 293/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0673 - accuracy: 0.9458 - binary_iou: 0.8940 - true_positives: 122387360.0000 - false_positives: 8673171.0000 - true_negatives: 179805104.0000 - false_negatives: 8655098.0000 - precision: 0.9338 - recall: 0.9340 - val_loss: 0.0969 - val_accuracy: 0.9167 - val_binary_iou: 0.8441 - val_true_positives: 41729864.0000 - val_false_positives: 5579572.0000 - val_true_negatives: 55418912.0000 - val_false_negatives: 3243375.0000 - val_precision: 0.8821 - val_recall: 0.9279\n",
      "Epoch 294/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0666 - accuracy: 0.9461 - binary_iou: 0.8947 - true_positives: 122519792.0000 - false_positives: 8664215.0000 - true_negatives: 179777392.0000 - false_negatives: 8559390.0000 - precision: 0.9340 - recall: 0.9347 - val_loss: 0.0954 - val_accuracy: 0.9197 - val_binary_iou: 0.8485 - val_true_positives: 40848120.0000 - val_false_positives: 4224852.0000 - val_true_negatives: 56615816.0000 - val_false_negatives: 4282922.0000 - val_precision: 0.9063 - val_recall: 0.9051\n",
      "Epoch 295/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0675 - accuracy: 0.9453 - binary_iou: 0.8932 - true_positives: 122473104.0000 - false_positives: 8853548.0000 - true_negatives: 179561472.0000 - false_negatives: 8632667.0000 - precision: 0.9326 - recall: 0.9342 - val_loss: 0.0990 - val_accuracy: 0.9179 - val_binary_iou: 0.8451 - val_true_positives: 40374124.0000 - val_false_positives: 3941170.0000 - val_true_negatives: 56898896.0000 - val_false_negatives: 4757525.0000 - val_precision: 0.9111 - val_recall: 0.8946\n",
      "Epoch 296/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0663 - accuracy: 0.9463 - binary_iou: 0.8951 - true_positives: 122611864.0000 - false_positives: 8610977.0000 - true_negatives: 179754320.0000 - false_negatives: 8543550.0000 - precision: 0.9344 - recall: 0.9349 - val_loss: 0.0947 - val_accuracy: 0.9207 - val_binary_iou: 0.8501 - val_true_positives: 40871276.0000 - val_false_positives: 4140883.0000 - val_true_negatives: 56692736.0000 - val_false_negatives: 4266822.0000 - val_precision: 0.9080 - val_recall: 0.9055\n",
      "Epoch 297/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0668 - accuracy: 0.9459 - binary_iou: 0.8943 - true_positives: 122590720.0000 - false_positives: 8738593.0000 - true_negatives: 179633792.0000 - false_negatives: 8557649.0000 - precision: 0.9335 - recall: 0.9347 - val_loss: 0.0962 - val_accuracy: 0.9202 - val_binary_iou: 0.8491 - val_true_positives: 40415184.0000 - val_false_positives: 3675960.0000 - val_true_negatives: 57105140.0000 - val_false_negatives: 4775428.0000 - val_precision: 0.9166 - val_recall: 0.8943\n",
      "Epoch 298/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0661 - accuracy: 0.9466 - binary_iou: 0.8956 - true_positives: 122670952.0000 - false_positives: 8596031.0000 - true_negatives: 179794048.0000 - false_negatives: 8459809.0000 - precision: 0.9345 - recall: 0.9355 - val_loss: 0.0934 - val_accuracy: 0.9205 - val_binary_iou: 0.8501 - val_true_positives: 41283768.0000 - val_false_positives: 4550302.0000 - val_true_negatives: 56261444.0000 - val_false_negatives: 3876199.0000 - val_precision: 0.9007 - val_recall: 0.9142\n",
      "Epoch 299/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0678 - accuracy: 0.9453 - binary_iou: 0.8932 - true_positives: 122378760.0000 - false_positives: 8732661.0000 - true_negatives: 179670288.0000 - false_negatives: 8739116.0000 - precision: 0.9334 - recall: 0.9333 - val_loss: 0.0959 - val_accuracy: 0.9198 - val_binary_iou: 0.8486 - val_true_positives: 40782032.0000 - val_false_positives: 4193817.0000 - val_true_negatives: 56694136.0000 - val_false_negatives: 4301729.0000 - val_precision: 0.9068 - val_recall: 0.9046\n",
      "Epoch 300/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0669 - accuracy: 0.9458 - binary_iou: 0.8941 - true_positives: 122588288.0000 - false_positives: 8799620.0000 - true_negatives: 179605920.0000 - false_negatives: 8526930.0000 - precision: 0.9330 - recall: 0.9350 - val_loss: 0.0983 - val_accuracy: 0.9182 - val_binary_iou: 0.8457 - val_true_positives: 40551200.0000 - val_false_positives: 4159942.0000 - val_true_negatives: 56753912.0000 - val_false_negatives: 4506669.0000 - val_precision: 0.9070 - val_recall: 0.9000\n",
      "Epoch 301/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0665 - accuracy: 0.9463 - binary_iou: 0.8951 - true_positives: 122703760.0000 - false_positives: 8704593.0000 - true_negatives: 179671696.0000 - false_negatives: 8440759.0000 - precision: 0.9338 - recall: 0.9356 - val_loss: 0.0956 - val_accuracy: 0.9186 - val_binary_iou: 0.8469 - val_true_positives: 41210872.0000 - val_false_positives: 4729645.0000 - val_true_negatives: 56138584.0000 - val_false_negatives: 3892618.0000 - val_precision: 0.8970 - val_recall: 0.9137\n",
      "Epoch 302/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0660 - accuracy: 0.9467 - binary_iou: 0.8957 - true_positives: 122601216.0000 - false_positives: 8463646.0000 - true_negatives: 179876336.0000 - false_negatives: 8579569.0000 - precision: 0.9354 - recall: 0.9346 - val_loss: 0.1030 - val_accuracy: 0.9145 - val_binary_iou: 0.8390 - val_true_positives: 40006232.0000 - val_false_positives: 3910532.0000 - val_true_negatives: 56903024.0000 - val_false_negatives: 5151922.0000 - val_precision: 0.9110 - val_recall: 0.8859\n",
      "Epoch 303/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0667 - accuracy: 0.9460 - binary_iou: 0.8945 - true_positives: 122745480.0000 - false_positives: 8828631.0000 - true_negatives: 179507744.0000 - false_negatives: 8438956.0000 - precision: 0.9329 - recall: 0.9357 - val_loss: 0.0985 - val_accuracy: 0.9187 - val_binary_iou: 0.8464 - val_true_positives: 40435924.0000 - val_false_positives: 3938697.0000 - val_true_negatives: 56919112.0000 - val_false_negatives: 4677996.0000 - val_precision: 0.9112 - val_recall: 0.8963\n",
      "Epoch 304/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0661 - accuracy: 0.9467 - binary_iou: 0.8957 - true_positives: 122555288.0000 - false_positives: 8417456.0000 - true_negatives: 179932080.0000 - false_negatives: 8615856.0000 - precision: 0.9357 - recall: 0.9343 - val_loss: 0.0949 - val_accuracy: 0.9199 - val_binary_iou: 0.8491 - val_true_positives: 41143164.0000 - val_false_positives: 4591144.0000 - val_true_negatives: 56344448.0000 - val_false_negatives: 3892951.0000 - val_precision: 0.8996 - val_recall: 0.9136\n",
      "Epoch 305/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0644 - accuracy: 0.9480 - binary_iou: 0.8981 - true_positives: 122752704.0000 - false_positives: 8291305.0000 - true_negatives: 180141008.0000 - false_negatives: 8335843.0000 - precision: 0.9367 - recall: 0.9364 - val_loss: 0.0958 - val_accuracy: 0.9199 - val_binary_iou: 0.8487 - val_true_positives: 40769032.0000 - val_false_positives: 4124524.0000 - val_true_negatives: 56709840.0000 - val_false_negatives: 4368333.0000 - val_precision: 0.9081 - val_recall: 0.9032\n",
      "Epoch 306/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0660 - accuracy: 0.9468 - binary_iou: 0.8959 - true_positives: 122761296.0000 - false_positives: 8584547.0000 - true_negatives: 179750096.0000 - false_negatives: 8424812.0000 - precision: 0.9346 - recall: 0.9358 - val_loss: 0.0983 - val_accuracy: 0.9181 - val_binary_iou: 0.8452 - val_true_positives: 40189664.0000 - val_false_positives: 3773910.0000 - val_true_negatives: 57103812.0000 - val_false_negatives: 4904331.0000 - val_precision: 0.9142 - val_recall: 0.8912\n",
      "Epoch 307/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0644 - accuracy: 0.9479 - binary_iou: 0.8981 - true_positives: 122954720.0000 - false_positives: 8405452.0000 - true_negatives: 179933136.0000 - false_negatives: 8227418.0000 - precision: 0.9360 - recall: 0.9373 - val_loss: 0.0940 - val_accuracy: 0.9215 - val_binary_iou: 0.8513 - val_true_positives: 40657396.0000 - val_false_positives: 3934050.0000 - val_true_negatives: 56991284.0000 - val_false_negatives: 4388984.0000 - val_precision: 0.9118 - val_recall: 0.9026\n",
      "Epoch 308/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0647 - accuracy: 0.9478 - binary_iou: 0.8977 - true_positives: 122813176.0000 - false_positives: 8313811.0000 - true_negatives: 180014752.0000 - false_negatives: 8379071.0000 - precision: 0.9366 - recall: 0.9361 - val_loss: 0.0940 - val_accuracy: 0.9217 - val_binary_iou: 0.8516 - val_true_positives: 40457120.0000 - val_false_positives: 3693817.0000 - val_true_negatives: 57219096.0000 - val_false_negatives: 4601668.0000 - val_precision: 0.9163 - val_recall: 0.8979\n",
      "Epoch 309/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0646 - accuracy: 0.9477 - binary_iou: 0.8977 - true_positives: 122863392.0000 - false_positives: 8439442.0000 - true_negatives: 179955232.0000 - false_negatives: 8262714.0000 - precision: 0.9357 - recall: 0.9370 - val_loss: 0.0992 - val_accuracy: 0.9176 - val_binary_iou: 0.8445 - val_true_positives: 40390672.0000 - val_false_positives: 4094673.0000 - val_true_negatives: 56848088.0000 - val_false_negatives: 4638259.0000 - val_precision: 0.9080 - val_recall: 0.8970\n",
      "Epoch 310/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0674 - accuracy: 0.9454 - binary_iou: 0.8934 - true_positives: 122424904.0000 - false_positives: 8713709.0000 - true_negatives: 179654128.0000 - false_negatives: 8728036.0000 - precision: 0.9336 - recall: 0.9335 - val_loss: 0.0999 - val_accuracy: 0.9158 - val_binary_iou: 0.8419 - val_true_positives: 40967704.0000 - val_false_positives: 4848056.0000 - val_true_negatives: 56076008.0000 - val_false_negatives: 4079941.0000 - val_precision: 0.8942 - val_recall: 0.9094\n",
      "Epoch 311/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0651 - accuracy: 0.9472 - binary_iou: 0.8968 - true_positives: 122728856.0000 - false_positives: 8457901.0000 - true_negatives: 179933488.0000 - false_negatives: 8400439.0000 - precision: 0.9355 - recall: 0.9359 - val_loss: 0.0972 - val_accuracy: 0.9165 - val_binary_iou: 0.8438 - val_true_positives: 41853352.0000 - val_false_positives: 5622718.0000 - val_true_negatives: 55274760.0000 - val_false_negatives: 3220878.0000 - val_precision: 0.8816 - val_recall: 0.9285\n",
      "Epoch 312/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0639 - accuracy: 0.9484 - binary_iou: 0.8989 - true_positives: 122817912.0000 - false_positives: 8238096.0000 - true_negatives: 180212800.0000 - false_negatives: 8251987.0000 - precision: 0.9371 - recall: 0.9370 - val_loss: 0.0945 - val_accuracy: 0.9208 - val_binary_iou: 0.8503 - val_true_positives: 40725972.0000 - val_false_positives: 3991167.0000 - val_true_negatives: 56854704.0000 - val_false_negatives: 4399870.0000 - val_precision: 0.9107 - val_recall: 0.9025\n",
      "Epoch 313/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0629 - accuracy: 0.9490 - binary_iou: 0.9000 - true_positives: 122956792.0000 - false_positives: 8179671.0000 - true_negatives: 180264608.0000 - false_negatives: 8119700.0000 - precision: 0.9376 - recall: 0.9381 - val_loss: 0.0945 - val_accuracy: 0.9191 - val_binary_iou: 0.8480 - val_true_positives: 41686244.0000 - val_false_positives: 5111979.0000 - val_true_negatives: 55711816.0000 - val_false_negatives: 3461683.0000 - val_precision: 0.8908 - val_recall: 0.9233\n",
      "Epoch 314/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0645 - accuracy: 0.9479 - binary_iou: 0.8979 - true_positives: 122757400.0000 - false_positives: 8308608.0000 - true_negatives: 180107792.0000 - false_negatives: 8346960.0000 - precision: 0.9366 - recall: 0.9363 - val_loss: 0.0964 - val_accuracy: 0.9194 - val_binary_iou: 0.8481 - val_true_positives: 40952632.0000 - val_false_positives: 4477336.0000 - val_true_negatives: 56481948.0000 - val_false_negatives: 4059797.0000 - val_precision: 0.9014 - val_recall: 0.9098\n",
      "Epoch 315/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0647 - accuracy: 0.9477 - binary_iou: 0.8976 - true_positives: 122753296.0000 - false_positives: 8346221.0000 - true_negatives: 180049408.0000 - false_negatives: 8371841.0000 - precision: 0.9363 - recall: 0.9362 - val_loss: 0.0946 - val_accuracy: 0.9200 - val_binary_iou: 0.8492 - val_true_positives: 41200508.0000 - val_false_positives: 4561781.0000 - val_true_negatives: 56289404.0000 - val_false_negatives: 3920038.0000 - val_precision: 0.9003 - val_recall: 0.9131\n",
      "Epoch 316/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0632 - accuracy: 0.9487 - binary_iou: 0.8995 - true_positives: 122936336.0000 - false_positives: 8146826.0000 - true_negatives: 180199296.0000 - false_negatives: 8238379.0000 - precision: 0.9378 - recall: 0.9372 - val_loss: 0.0986 - val_accuracy: 0.9189 - val_binary_iou: 0.8466 - val_true_positives: 40166152.0000 - val_false_positives: 3685826.0000 - val_true_negatives: 57209996.0000 - val_false_negatives: 4909729.0000 - val_precision: 0.9159 - val_recall: 0.8911\n",
      "Epoch 317/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0646 - accuracy: 0.9477 - binary_iou: 0.8977 - true_positives: 122798256.0000 - false_positives: 8351883.0000 - true_negatives: 180023232.0000 - false_negatives: 8347398.0000 - precision: 0.9363 - recall: 0.9364 - val_loss: 0.0978 - val_accuracy: 0.9186 - val_binary_iou: 0.8462 - val_true_positives: 40266740.0000 - val_false_positives: 3828648.0000 - val_true_negatives: 57081632.0000 - val_false_negatives: 4794687.0000 - val_precision: 0.9132 - val_recall: 0.8936\n",
      "Epoch 318/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0648 - accuracy: 0.9476 - binary_iou: 0.8974 - true_positives: 122751128.0000 - false_positives: 8376114.0000 - true_negatives: 180027056.0000 - false_negatives: 8366444.0000 - precision: 0.9361 - recall: 0.9362 - val_loss: 0.0977 - val_accuracy: 0.9172 - val_binary_iou: 0.8444 - val_true_positives: 41122920.0000 - val_false_positives: 4797266.0000 - val_true_negatives: 56073684.0000 - val_false_negatives: 3977843.0000 - val_precision: 0.8955 - val_recall: 0.9118\n",
      "Epoch 319/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0643 - accuracy: 0.9482 - binary_iou: 0.8985 - true_positives: 122966784.0000 - false_positives: 8313379.0000 - true_negatives: 179997248.0000 - false_negatives: 8243352.0000 - precision: 0.9367 - recall: 0.9372 - val_loss: 0.0956 - val_accuracy: 0.9190 - val_binary_iou: 0.8474 - val_true_positives: 41009320.0000 - val_false_positives: 4454007.0000 - val_true_negatives: 56379720.0000 - val_false_negatives: 4128672.0000 - val_precision: 0.9020 - val_recall: 0.9085\n",
      "Epoch 320/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0618 - accuracy: 0.9502 - binary_iou: 0.9022 - true_positives: 123151792.0000 - false_positives: 7977980.0000 - true_negatives: 180448416.0000 - false_negatives: 7942603.0000 - precision: 0.9392 - recall: 0.9394 - val_loss: 0.0985 - val_accuracy: 0.9165 - val_binary_iou: 0.8435 - val_true_positives: 41316656.0000 - val_false_positives: 5094127.0000 - val_true_negatives: 55811632.0000 - val_false_negatives: 3749302.0000 - val_precision: 0.8902 - val_recall: 0.9168\n",
      "Epoch 321/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0622 - accuracy: 0.9498 - binary_iou: 0.9016 - true_positives: 123079648.0000 - false_positives: 8013005.0000 - true_negatives: 180413616.0000 - false_negatives: 8014434.0000 - precision: 0.9389 - recall: 0.9389 - val_loss: 0.0949 - val_accuracy: 0.9201 - val_binary_iou: 0.8492 - val_true_positives: 40933972.0000 - val_false_positives: 4296621.0000 - val_true_negatives: 56571040.0000 - val_false_negatives: 4170091.0000 - val_precision: 0.9050 - val_recall: 0.9075\n",
      "Epoch 322/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0626 - accuracy: 0.9495 - binary_iou: 0.9010 - true_positives: 123161984.0000 - false_positives: 8157023.0000 - true_negatives: 180230752.0000 - false_negatives: 7971076.0000 - precision: 0.9379 - recall: 0.9392 - val_loss: 0.0946 - val_accuracy: 0.9208 - val_binary_iou: 0.8502 - val_true_positives: 40659260.0000 - val_false_positives: 3956746.0000 - val_true_negatives: 56917276.0000 - val_false_negatives: 4438436.0000 - val_precision: 0.9113 - val_recall: 0.9016\n",
      "Epoch 323/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0627 - accuracy: 0.9496 - binary_iou: 0.9011 - true_positives: 122989832.0000 - false_positives: 7992175.0000 - true_negatives: 180413872.0000 - false_negatives: 8124868.0000 - precision: 0.9390 - recall: 0.9380 - val_loss: 0.0974 - val_accuracy: 0.9178 - val_binary_iou: 0.8454 - val_true_positives: 41069412.0000 - val_false_positives: 4708666.0000 - val_true_negatives: 56193336.0000 - val_false_negatives: 4000302.0000 - val_precision: 0.8971 - val_recall: 0.9112\n",
      "Epoch 324/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0633 - accuracy: 0.9488 - binary_iou: 0.8997 - true_positives: 123013904.0000 - false_positives: 8217172.0000 - true_negatives: 180150048.0000 - false_negatives: 8139662.0000 - precision: 0.9374 - recall: 0.9379 - val_loss: 0.0989 - val_accuracy: 0.9187 - val_binary_iou: 0.8461 - val_true_positives: 40072392.0000 - val_false_positives: 3526604.0000 - val_true_negatives: 57279080.0000 - val_false_negatives: 5093654.0000 - val_precision: 0.9191 - val_recall: 0.8872\n",
      "Epoch 325/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0623 - accuracy: 0.9497 - binary_iou: 0.9013 - true_positives: 123144240.0000 - false_positives: 8008666.0000 - true_negatives: 180289552.0000 - false_negatives: 8078260.0000 - precision: 0.9389 - recall: 0.9384 - val_loss: 0.0954 - val_accuracy: 0.9204 - val_binary_iou: 0.8495 - val_true_positives: 40540608.0000 - val_false_positives: 3816479.0000 - val_true_negatives: 57000928.0000 - val_false_negatives: 4613687.0000 - val_precision: 0.9140 - val_recall: 0.8978\n",
      "Epoch 326/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0614 - accuracy: 0.9502 - binary_iou: 0.9023 - true_positives: 123146984.0000 - false_positives: 7910543.0000 - true_negatives: 180472656.0000 - false_negatives: 7990719.0000 - precision: 0.9396 - recall: 0.9391 - val_loss: 0.0939 - val_accuracy: 0.9200 - val_binary_iou: 0.8493 - val_true_positives: 41470160.0000 - val_false_positives: 4819161.0000 - val_true_negatives: 56018696.0000 - val_false_negatives: 3663698.0000 - val_precision: 0.8959 - val_recall: 0.9188\n",
      "Epoch 327/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0620 - accuracy: 0.9499 - binary_iou: 0.9017 - true_positives: 123118424.0000 - false_positives: 8025031.0000 - true_negatives: 180387232.0000 - false_negatives: 7990038.0000 - precision: 0.9388 - recall: 0.9391 - val_loss: 0.0939 - val_accuracy: 0.9219 - val_binary_iou: 0.8519 - val_true_positives: 40458248.0000 - val_false_positives: 3623914.0000 - val_true_negatives: 57236892.0000 - val_false_negatives: 4652662.0000 - val_precision: 0.9178 - val_recall: 0.8969\n",
      "Epoch 328/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0635 - accuracy: 0.9487 - binary_iou: 0.8995 - true_positives: 123029032.0000 - false_positives: 8258220.0000 - true_negatives: 180104192.0000 - false_negatives: 8129325.0000 - precision: 0.9371 - recall: 0.9380 - val_loss: 0.0979 - val_accuracy: 0.9173 - val_binary_iou: 0.8445 - val_true_positives: 41047376.0000 - val_false_positives: 4736681.0000 - val_true_negatives: 56160524.0000 - val_false_negatives: 4027146.0000 - val_precision: 0.8965 - val_recall: 0.9107\n",
      "Epoch 329/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0639 - accuracy: 0.9483 - binary_iou: 0.8987 - true_positives: 122912696.0000 - false_positives: 8257167.0000 - true_negatives: 180077168.0000 - false_negatives: 8273701.0000 - precision: 0.9370 - recall: 0.9369 - val_loss: 0.0975 - val_accuracy: 0.9170 - val_binary_iou: 0.8443 - val_true_positives: 41461376.0000 - val_false_positives: 5100510.0000 - val_true_negatives: 55715704.0000 - val_false_negatives: 3694098.0000 - val_precision: 0.8905 - val_recall: 0.9182\n",
      "Epoch 330/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0633 - accuracy: 0.9488 - binary_iou: 0.8998 - true_positives: 123136840.0000 - false_positives: 8358184.0000 - true_negatives: 180036672.0000 - false_negatives: 7989017.0000 - precision: 0.9364 - recall: 0.9391 - val_loss: 0.0972 - val_accuracy: 0.9191 - val_binary_iou: 0.8471 - val_true_positives: 40427384.0000 - val_false_positives: 3899201.0000 - val_true_negatives: 56967648.0000 - val_false_negatives: 4677484.0000 - val_precision: 0.9120 - val_recall: 0.8963\n",
      "Epoch 331/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0620 - accuracy: 0.9499 - binary_iou: 0.9017 - true_positives: 123128128.0000 - false_positives: 8033471.0000 - true_negatives: 180374752.0000 - false_negatives: 7984344.0000 - precision: 0.9388 - recall: 0.9391 - val_loss: 0.0974 - val_accuracy: 0.9188 - val_binary_iou: 0.8470 - val_true_positives: 40805396.0000 - val_false_positives: 4262748.0000 - val_true_negatives: 56565708.0000 - val_false_negatives: 4337860.0000 - val_precision: 0.9054 - val_recall: 0.9039\n",
      "Epoch 332/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0617 - accuracy: 0.9501 - binary_iou: 0.9020 - true_positives: 123227720.0000 - false_positives: 8012879.0000 - true_negatives: 180338464.0000 - false_negatives: 7941721.0000 - precision: 0.9389 - recall: 0.9395 - val_loss: 0.0950 - val_accuracy: 0.9202 - val_binary_iou: 0.8496 - val_true_positives: 41293240.0000 - val_false_positives: 4680937.0000 - val_true_negatives: 56219124.0000 - val_false_negatives: 3778396.0000 - val_precision: 0.8982 - val_recall: 0.9162\n",
      "Epoch 333/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0614 - accuracy: 0.9503 - binary_iou: 0.9025 - true_positives: 123237976.0000 - false_positives: 7928337.0000 - true_negatives: 180406656.0000 - false_negatives: 7947764.0000 - precision: 0.9396 - recall: 0.9394 - val_loss: 0.0949 - val_accuracy: 0.9200 - val_binary_iou: 0.8491 - val_true_positives: 41056416.0000 - val_false_positives: 4378216.0000 - val_true_negatives: 56437072.0000 - val_false_negatives: 4100020.0000 - val_precision: 0.9036 - val_recall: 0.9092\n",
      "Epoch 334/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9512 - binary_iou: 0.9040 - true_positives: 123213168.0000 - false_positives: 7721688.0000 - true_negatives: 180701104.0000 - false_negatives: 7884749.0000 - precision: 0.9410 - recall: 0.9399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.0604 - accuracy: 0.9512 - binary_iou: 0.9040 - true_positives: 123213168.0000 - false_positives: 7721688.0000 - true_negatives: 180701104.0000 - false_negatives: 7884749.0000 - precision: 0.9410 - recall: 0.9399 - val_loss: 0.0939 - val_accuracy: 0.9219 - val_binary_iou: 0.8520 - val_true_positives: 40460184.0000 - val_false_positives: 3627306.0000 - val_true_negatives: 57239620.0000 - val_false_negatives: 4644602.0000 - val_precision: 0.9177 - val_recall: 0.8970\n",
      "Epoch 335/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0603 - accuracy: 0.9514 - binary_iou: 0.9046 - true_positives: 123311240.0000 - false_positives: 7734491.0000 - true_negatives: 180690464.0000 - false_negatives: 7784527.0000 - precision: 0.9410 - recall: 0.9406 - val_loss: 0.0945 - val_accuracy: 0.9200 - val_binary_iou: 0.8490 - val_true_positives: 41017852.0000 - val_false_positives: 4402497.0000 - val_true_negatives: 56472848.0000 - val_false_negatives: 4078509.0000 - val_precision: 0.9031 - val_recall: 0.9096\n",
      "Epoch 336/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0614 - accuracy: 0.9505 - binary_iou: 0.9028 - true_positives: 123272416.0000 - false_positives: 7956184.0000 - true_negatives: 180421968.0000 - false_negatives: 7870198.0000 - precision: 0.9394 - recall: 0.9400 - val_loss: 0.0957 - val_accuracy: 0.9184 - val_binary_iou: 0.8469 - val_true_positives: 41693096.0000 - val_false_positives: 5218826.0000 - val_true_negatives: 55636564.0000 - val_false_negatives: 3423239.0000 - val_precision: 0.8888 - val_recall: 0.9241\n",
      "Epoch 337/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0650 - accuracy: 0.9474 - binary_iou: 0.8971 - true_positives: 122681728.0000 - false_positives: 8363799.0000 - true_negatives: 180032608.0000 - false_negatives: 8442634.0000 - precision: 0.9362 - recall: 0.9356 - val_loss: 0.1010 - val_accuracy: 0.9159 - val_binary_iou: 0.8418 - val_true_positives: 40433540.0000 - val_false_positives: 4238367.0000 - val_true_negatives: 56630104.0000 - val_false_negatives: 4669703.0000 - val_precision: 0.9051 - val_recall: 0.8965\n",
      "Epoch 338/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0611 - accuracy: 0.9505 - binary_iou: 0.9028 - true_positives: 123276032.0000 - false_positives: 7923368.0000 - true_negatives: 180418032.0000 - false_negatives: 7903341.0000 - precision: 0.9396 - recall: 0.9398 - val_loss: 0.0950 - val_accuracy: 0.9196 - val_binary_iou: 0.8484 - val_true_positives: 40889292.0000 - val_false_positives: 4366156.0000 - val_true_negatives: 56566304.0000 - val_false_negatives: 4149961.0000 - val_precision: 0.9035 - val_recall: 0.9079\n",
      "Epoch 339/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0610 - accuracy: 0.9509 - binary_iou: 0.9035 - true_positives: 123210832.0000 - false_positives: 7752696.0000 - true_negatives: 180612624.0000 - false_negatives: 7944561.0000 - precision: 0.9408 - recall: 0.9394 - val_loss: 0.0935 - val_accuracy: 0.9209 - val_binary_iou: 0.8508 - val_true_positives: 41207844.0000 - val_false_positives: 4483179.0000 - val_true_negatives: 56383048.0000 - val_false_negatives: 3897643.0000 - val_precision: 0.9019 - val_recall: 0.9136\n",
      "Epoch 340/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9517 - binary_iou: 0.9051 - true_positives: 123346360.0000 - false_positives: 7703385.0000 - true_negatives: 180741760.0000 - false_negatives: 7729360.0000 - precision: 0.9412 - recall: 0.9410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 529ms/step - loss: 0.0599 - accuracy: 0.9517 - binary_iou: 0.9051 - true_positives: 123346360.0000 - false_positives: 7703385.0000 - true_negatives: 180741760.0000 - false_negatives: 7729360.0000 - precision: 0.9412 - recall: 0.9410 - val_loss: 0.0928 - val_accuracy: 0.9225 - val_binary_iou: 0.8532 - val_true_positives: 40817236.0000 - val_false_positives: 3932824.0000 - val_true_negatives: 56938364.0000 - val_false_negatives: 4283293.0000 - val_precision: 0.9121 - val_recall: 0.9050\n",
      "Epoch 341/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9519 - binary_iou: 0.9053 - true_positives: 123291760.0000 - false_positives: 7610022.0000 - true_negatives: 180845120.0000 - false_negatives: 7773862.0000 - precision: 0.9419 - recall: 0.9407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 528ms/step - loss: 0.0595 - accuracy: 0.9519 - binary_iou: 0.9053 - true_positives: 123291760.0000 - false_positives: 7610022.0000 - true_negatives: 180845120.0000 - false_negatives: 7773862.0000 - precision: 0.9419 - recall: 0.9407 - val_loss: 0.0924 - val_accuracy: 0.9228 - val_binary_iou: 0.8538 - val_true_positives: 40782816.0000 - val_false_positives: 3913650.0000 - val_true_negatives: 57012736.0000 - val_false_negatives: 4262499.0000 - val_precision: 0.9124 - val_recall: 0.9054\n",
      "Epoch 342/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0606 - accuracy: 0.9509 - binary_iou: 0.9036 - true_positives: 123305328.0000 - false_positives: 7838672.0000 - true_negatives: 180537472.0000 - false_negatives: 7839344.0000 - precision: 0.9402 - recall: 0.9402 - val_loss: 0.0981 - val_accuracy: 0.9181 - val_binary_iou: 0.8456 - val_true_positives: 40731296.0000 - val_false_positives: 4286778.0000 - val_true_negatives: 56556400.0000 - val_false_negatives: 4397235.0000 - val_precision: 0.9048 - val_recall: 0.9026\n",
      "Epoch 343/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0612 - accuracy: 0.9506 - binary_iou: 0.9030 - true_positives: 123247888.0000 - false_positives: 7880369.0000 - true_negatives: 180479392.0000 - false_negatives: 7913149.0000 - precision: 0.9399 - recall: 0.9397 - val_loss: 0.0964 - val_accuracy: 0.9189 - val_binary_iou: 0.8472 - val_true_positives: 40977616.0000 - val_false_positives: 4561614.0000 - val_true_negatives: 56398920.0000 - val_false_negatives: 4033560.0000 - val_precision: 0.8998 - val_recall: 0.9104\n",
      "Epoch 344/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0599 - accuracy: 0.9515 - binary_iou: 0.9047 - true_positives: 123272416.0000 - false_positives: 7667878.0000 - true_negatives: 180750464.0000 - false_negatives: 7829997.0000 - precision: 0.9414 - recall: 0.9403 - val_loss: 0.0946 - val_accuracy: 0.9206 - val_binary_iou: 0.8501 - val_true_positives: 40955300.0000 - val_false_positives: 4268523.0000 - val_true_negatives: 56606848.0000 - val_false_negatives: 4141032.0000 - val_precision: 0.9056 - val_recall: 0.9082\n",
      "Epoch 345/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0584 - accuracy: 0.9526 - binary_iou: 0.9068 - true_positives: 123571504.0000 - false_positives: 7501145.0000 - true_negatives: 180817152.0000 - false_negatives: 7630992.0000 - precision: 0.9428 - recall: 0.9418 - val_loss: 0.0953 - val_accuracy: 0.9208 - val_binary_iou: 0.8504 - val_true_positives: 40801752.0000 - val_false_positives: 4044447.0000 - val_true_negatives: 56781064.0000 - val_false_negatives: 4344461.0000 - val_precision: 0.9098 - val_recall: 0.9038\n",
      "Epoch 346/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0591 - accuracy: 0.9520 - binary_iou: 0.9057 - true_positives: 123589744.0000 - false_positives: 7728794.0000 - true_negatives: 180601616.0000 - false_negatives: 7600620.0000 - precision: 0.9411 - recall: 0.9421 - val_loss: 0.0975 - val_accuracy: 0.9186 - val_binary_iou: 0.8464 - val_true_positives: 40638552.0000 - val_false_positives: 4198531.0000 - val_true_negatives: 56704272.0000 - val_false_negatives: 4430360.0000 - val_precision: 0.9064 - val_recall: 0.9017\n",
      "Epoch 347/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0608 - accuracy: 0.9508 - binary_iou: 0.9034 - true_positives: 123240000.0000 - false_positives: 7827961.0000 - true_negatives: 180570528.0000 - false_negatives: 7882245.0000 - precision: 0.9403 - recall: 0.9399 - val_loss: 0.1061 - val_accuracy: 0.9130 - val_binary_iou: 0.8362 - val_true_positives: 39656720.0000 - val_false_positives: 3705210.0000 - val_true_negatives: 57094936.0000 - val_false_negatives: 5514837.0000 - val_precision: 0.9146 - val_recall: 0.8779\n",
      "Epoch 348/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0593 - accuracy: 0.9521 - binary_iou: 0.9057 - true_positives: 123459160.0000 - false_positives: 7617796.0000 - true_negatives: 180742720.0000 - false_negatives: 7701017.0000 - precision: 0.9419 - recall: 0.9413 - val_loss: 0.0938 - val_accuracy: 0.9223 - val_binary_iou: 0.8528 - val_true_positives: 40656224.0000 - val_false_positives: 3844202.0000 - val_true_negatives: 57086448.0000 - val_false_negatives: 4384837.0000 - val_precision: 0.9136 - val_recall: 0.9026\n",
      "Epoch 349/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0611 - accuracy: 0.9506 - binary_iou: 0.9030 - true_positives: 123207448.0000 - false_positives: 7919929.0000 - true_negatives: 180522256.0000 - false_negatives: 7871182.0000 - precision: 0.9396 - recall: 0.9400 - val_loss: 0.0951 - val_accuracy: 0.9188 - val_binary_iou: 0.8474 - val_true_positives: 41526440.0000 - val_false_positives: 4985431.0000 - val_true_negatives: 55839688.0000 - val_false_negatives: 3620167.0000 - val_precision: 0.8928 - val_recall: 0.9198\n",
      "Epoch 350/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0600 - accuracy: 0.9516 - binary_iou: 0.9048 - true_positives: 123282872.0000 - false_positives: 7620721.0000 - true_negatives: 180769088.0000 - false_negatives: 7848062.0000 - precision: 0.9418 - recall: 0.9402 - val_loss: 0.1025 - val_accuracy: 0.9161 - val_binary_iou: 0.8412 - val_true_positives: 39460884.0000 - val_false_positives: 3292409.0000 - val_true_negatives: 57620820.0000 - val_false_negatives: 5597603.0000 - val_precision: 0.9230 - val_recall: 0.8758\n",
      "Epoch 351/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0587 - accuracy: 0.9525 - binary_iou: 0.9065 - true_positives: 123538136.0000 - false_positives: 7565963.0000 - true_negatives: 180796464.0000 - false_negatives: 7620240.0000 - precision: 0.9423 - recall: 0.9419 - val_loss: 0.0924 - val_accuracy: 0.9223 - val_binary_iou: 0.8531 - val_true_positives: 41131868.0000 - val_false_positives: 4249283.0000 - val_true_negatives: 56605640.0000 - val_false_negatives: 3984917.0000 - val_precision: 0.9064 - val_recall: 0.9117\n",
      "Epoch 352/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0584 - accuracy: 0.9528 - binary_iou: 0.9071 - true_positives: 123525448.0000 - false_positives: 7506592.0000 - true_negatives: 180913168.0000 - false_negatives: 7575584.0000 - precision: 0.9427 - recall: 0.9422 - val_loss: 0.0954 - val_accuracy: 0.9200 - val_binary_iou: 0.8490 - val_true_positives: 40952196.0000 - val_false_positives: 4407465.0000 - val_true_negatives: 56536944.0000 - val_false_negatives: 4075113.0000 - val_precision: 0.9028 - val_recall: 0.9095\n",
      "Epoch 353/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0577 - accuracy: 0.9533 - binary_iou: 0.9082 - true_positives: 123680992.0000 - false_positives: 7462763.0000 - true_negatives: 180933840.0000 - false_negatives: 7443183.0000 - precision: 0.9431 - recall: 0.9432 - val_loss: 0.0947 - val_accuracy: 0.9200 - val_binary_iou: 0.8494 - val_true_positives: 41393508.0000 - val_false_positives: 4673788.0000 - val_true_negatives: 56102020.0000 - val_false_negatives: 3802397.0000 - val_precision: 0.8985 - val_recall: 0.9159\n",
      "Epoch 354/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0578 - accuracy: 0.9532 - binary_iou: 0.9078 - true_positives: 123604720.0000 - false_positives: 7486447.0000 - true_negatives: 180957952.0000 - false_negatives: 7471683.0000 - precision: 0.9429 - recall: 0.9430 - val_loss: 0.0945 - val_accuracy: 0.9205 - val_binary_iou: 0.8499 - val_true_positives: 41073344.0000 - val_false_positives: 4437159.0000 - val_true_negatives: 56470516.0000 - val_false_negatives: 3990690.0000 - val_precision: 0.9025 - val_recall: 0.9114\n",
      "Epoch 355/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0582 - accuracy: 0.9529 - binary_iou: 0.9073 - true_positives: 123550024.0000 - false_positives: 7521862.0000 - true_negatives: 180922288.0000 - false_negatives: 7526647.0000 - precision: 0.9426 - recall: 0.9426 - val_loss: 0.0942 - val_accuracy: 0.9213 - val_binary_iou: 0.8512 - val_true_positives: 40826728.0000 - val_false_positives: 4096822.0000 - val_true_negatives: 56804532.0000 - val_false_negatives: 4243626.0000 - val_precision: 0.9088 - val_recall: 0.9058\n",
      "Epoch 356/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0609 - accuracy: 0.9510 - binary_iou: 0.9037 - true_positives: 123300080.0000 - false_positives: 7834268.0000 - true_negatives: 180552096.0000 - false_negatives: 7834243.0000 - precision: 0.9403 - recall: 0.9403 - val_loss: 0.1015 - val_accuracy: 0.9150 - val_binary_iou: 0.8402 - val_true_positives: 40487188.0000 - val_false_positives: 4378201.0000 - val_true_negatives: 56473096.0000 - val_false_negatives: 4633211.0000 - val_precision: 0.9024 - val_recall: 0.8973\n",
      "Epoch 357/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0614 - accuracy: 0.9504 - binary_iou: 0.9026 - true_positives: 123158512.0000 - false_positives: 7879319.0000 - true_negatives: 180505456.0000 - false_negatives: 7977471.0000 - precision: 0.9399 - recall: 0.9392 - val_loss: 0.0937 - val_accuracy: 0.9212 - val_binary_iou: 0.8509 - val_true_positives: 40792196.0000 - val_false_positives: 4050792.0000 - val_true_negatives: 56823780.0000 - val_false_negatives: 4304932.0000 - val_precision: 0.9097 - val_recall: 0.9045\n",
      "Epoch 358/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0576 - accuracy: 0.9534 - binary_iou: 0.9082 - true_positives: 123566072.0000 - false_positives: 7359175.0000 - true_negatives: 181063376.0000 - false_negatives: 7532124.0000 - precision: 0.9438 - recall: 0.9425 - val_loss: 0.0923 - val_accuracy: 0.9223 - val_binary_iou: 0.8531 - val_true_positives: 41149560.0000 - val_false_positives: 4222817.0000 - val_true_negatives: 56585008.0000 - val_false_negatives: 4014332.0000 - val_precision: 0.9069 - val_recall: 0.9111\n",
      "Epoch 359/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0573 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123678128.0000 - false_positives: 7274608.0000 - true_negatives: 181119936.0000 - false_negatives: 7448113.0000 - precision: 0.9444 - recall: 0.9432 - val_loss: 0.0997 - val_accuracy: 0.9187 - val_binary_iou: 0.8458 - val_true_positives: 39648832.0000 - val_false_positives: 3170932.0000 - val_true_negatives: 57707716.0000 - val_false_negatives: 5444232.0000 - val_precision: 0.9259 - val_recall: 0.8793\n",
      "Epoch 360/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0569 - accuracy: 0.9540 - binary_iou: 0.9094 - true_positives: 123858240.0000 - false_positives: 7335898.0000 - true_negatives: 180960064.0000 - false_negatives: 7366558.0000 - precision: 0.9441 - recall: 0.9439 - val_loss: 0.0939 - val_accuracy: 0.9212 - val_binary_iou: 0.8512 - val_true_positives: 41135612.0000 - val_false_positives: 4335675.0000 - val_true_negatives: 56485760.0000 - val_false_negatives: 4014674.0000 - val_precision: 0.9047 - val_recall: 0.9111\n",
      "Epoch 361/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0572 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123804776.0000 - false_positives: 7313881.0000 - true_negatives: 180988464.0000 - false_negatives: 7413565.0000 - precision: 0.9442 - recall: 0.9435 - val_loss: 0.0958 - val_accuracy: 0.9201 - val_binary_iou: 0.8493 - val_true_positives: 40912040.0000 - val_false_positives: 4296085.0000 - val_true_negatives: 56596872.0000 - val_false_negatives: 4166713.0000 - val_precision: 0.9050 - val_recall: 0.9076\n",
      "Epoch 362/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0578 - accuracy: 0.9533 - binary_iou: 0.9081 - true_positives: 123546848.0000 - false_positives: 7402790.0000 - true_negatives: 181063280.0000 - false_negatives: 7507793.0000 - precision: 0.9435 - recall: 0.9427 - val_loss: 0.0966 - val_accuracy: 0.9195 - val_binary_iou: 0.8481 - val_true_positives: 40828060.0000 - val_false_positives: 4226376.0000 - val_true_negatives: 56610660.0000 - val_false_negatives: 4306601.0000 - val_precision: 0.9062 - val_recall: 0.9046\n",
      "Epoch 363/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0575 - accuracy: 0.9536 - binary_iou: 0.9086 - true_positives: 123582000.0000 - false_positives: 7346045.0000 - true_negatives: 181113520.0000 - false_negatives: 7479180.0000 - precision: 0.9439 - recall: 0.9429 - val_loss: 0.0939 - val_accuracy: 0.9209 - val_binary_iou: 0.8509 - val_true_positives: 41340200.0000 - val_false_positives: 4599215.0000 - val_true_negatives: 56248668.0000 - val_false_negatives: 3783653.0000 - val_precision: 0.8999 - val_recall: 0.9161\n",
      "Epoch 364/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0575 - accuracy: 0.9538 - binary_iou: 0.9090 - true_positives: 123727776.0000 - false_positives: 7361875.0000 - true_negatives: 181027632.0000 - false_negatives: 7403547.0000 - precision: 0.9438 - recall: 0.9435 - val_loss: 0.0953 - val_accuracy: 0.9191 - val_binary_iou: 0.8476 - val_true_positives: 41162592.0000 - val_false_positives: 4661996.0000 - val_true_negatives: 56232888.0000 - val_false_negatives: 3914248.0000 - val_precision: 0.8983 - val_recall: 0.9132\n",
      "Epoch 365/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0581 - accuracy: 0.9530 - binary_iou: 0.9075 - true_positives: 123631088.0000 - false_positives: 7482292.0000 - true_negatives: 180862864.0000 - false_negatives: 7544476.0000 - precision: 0.9429 - recall: 0.9425 - val_loss: 0.0962 - val_accuracy: 0.9210 - val_binary_iou: 0.8502 - val_true_positives: 40267692.0000 - val_false_positives: 3533801.0000 - val_true_negatives: 57329388.0000 - val_false_negatives: 4840821.0000 - val_precision: 0.9193 - val_recall: 0.8927\n",
      "Epoch 366/500\n",
      "199/199 [==============================] - 91s 455ms/step - loss: 0.0573 - accuracy: 0.9538 - binary_iou: 0.9090 - true_positives: 123724480.0000 - false_positives: 7337499.0000 - true_negatives: 181040848.0000 - false_negatives: 7418043.0000 - precision: 0.9440 - recall: 0.9434 - val_loss: 0.0964 - val_accuracy: 0.9207 - val_binary_iou: 0.8496 - val_true_positives: 40175620.0000 - val_false_positives: 3526708.0000 - val_true_negatives: 57388808.0000 - val_false_negatives: 4880576.0000 - val_precision: 0.9193 - val_recall: 0.8917\n",
      "Epoch 367/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0586 - accuracy: 0.9527 - binary_iou: 0.9069 - true_positives: 123579912.0000 - false_positives: 7594204.0000 - true_negatives: 180816176.0000 - false_negatives: 7530439.0000 - precision: 0.9421 - recall: 0.9426 - val_loss: 0.0946 - val_accuracy: 0.9206 - val_binary_iou: 0.8499 - val_true_positives: 40799696.0000 - val_false_positives: 4165527.0000 - val_true_negatives: 56754136.0000 - val_false_negatives: 4252362.0000 - val_precision: 0.9074 - val_recall: 0.9056\n",
      "Epoch 368/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0564 - accuracy: 0.9544 - binary_iou: 0.9100 - true_positives: 123800312.0000 - false_positives: 7286946.0000 - true_negatives: 181135264.0000 - false_negatives: 7298289.0000 - precision: 0.9444 - recall: 0.9443 - val_loss: 0.0947 - val_accuracy: 0.9213 - val_binary_iou: 0.8509 - val_true_positives: 40496212.0000 - val_false_positives: 3752439.0000 - val_true_negatives: 57130960.0000 - val_false_negatives: 4592101.0000 - val_precision: 0.9152 - val_recall: 0.8982\n",
      "Epoch 369/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0557 - accuracy: 0.9551 - binary_iou: 0.9114 - true_positives: 123909128.0000 - false_positives: 7148163.0000 - true_negatives: 181252560.0000 - false_negatives: 7210891.0000 - precision: 0.9455 - recall: 0.9450 - val_loss: 0.0920 - val_accuracy: 0.9227 - val_binary_iou: 0.8538 - val_true_positives: 41102400.0000 - val_false_positives: 4233134.0000 - val_true_negatives: 56678508.0000 - val_false_negatives: 3957685.0000 - val_precision: 0.9066 - val_recall: 0.9122\n",
      "Epoch 370/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0571 - accuracy: 0.9539 - binary_iou: 0.9092 - true_positives: 123805608.0000 - false_positives: 7335254.0000 - true_negatives: 180991456.0000 - false_negatives: 7388420.0000 - precision: 0.9441 - recall: 0.9437 - val_loss: 0.0958 - val_accuracy: 0.9191 - val_binary_iou: 0.8475 - val_true_positives: 40964624.0000 - val_false_positives: 4441435.0000 - val_true_negatives: 56433904.0000 - val_false_negatives: 4131752.0000 - val_precision: 0.9022 - val_recall: 0.9084\n",
      "Epoch 371/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0561 - accuracy: 0.9546 - binary_iou: 0.9105 - true_positives: 123835232.0000 - false_positives: 7211173.0000 - true_negatives: 181179936.0000 - false_negatives: 7294423.0000 - precision: 0.9450 - recall: 0.9444 - val_loss: 0.0959 - val_accuracy: 0.9201 - val_binary_iou: 0.8488 - val_true_positives: 40445976.0000 - val_false_positives: 3794738.0000 - val_true_negatives: 57054724.0000 - val_false_negatives: 4676258.0000 - val_precision: 0.9142 - val_recall: 0.8964\n",
      "Epoch 372/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0559 - accuracy: 0.9547 - binary_iou: 0.9108 - true_positives: 123958616.0000 - false_positives: 7281386.0000 - true_negatives: 181101056.0000 - false_negatives: 7179659.0000 - precision: 0.9445 - recall: 0.9453 - val_loss: 0.0926 - val_accuracy: 0.9225 - val_binary_iou: 0.8534 - val_true_positives: 40953640.0000 - val_false_positives: 4119556.0000 - val_true_negatives: 56807356.0000 - val_false_negatives: 4091146.0000 - val_precision: 0.9086 - val_recall: 0.9092\n",
      "Epoch 373/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0558 - accuracy: 0.9548 - binary_iou: 0.9110 - true_positives: 123967520.0000 - false_positives: 7191908.0000 - true_negatives: 181121680.0000 - false_negatives: 7239697.0000 - precision: 0.9452 - recall: 0.9448 - val_loss: 0.0938 - val_accuracy: 0.9216 - val_binary_iou: 0.8517 - val_true_positives: 40794812.0000 - val_false_positives: 3944282.0000 - val_true_negatives: 56870100.0000 - val_false_negatives: 4362513.0000 - val_precision: 0.9118 - val_recall: 0.9034\n",
      "Epoch 374/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0543 - accuracy: 0.9561 - binary_iou: 0.9133 - true_positives: 124124944.0000 - false_positives: 7004296.0000 - true_negatives: 181355520.0000 - false_negatives: 7036005.0000 - precision: 0.9466 - recall: 0.9464 - val_loss: 0.0939 - val_accuracy: 0.9206 - val_binary_iou: 0.8502 - val_true_positives: 41214088.0000 - val_false_positives: 4477104.0000 - val_true_negatives: 56342504.0000 - val_false_negatives: 3938020.0000 - val_precision: 0.9020 - val_recall: 0.9128\n",
      "Epoch 375/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0556 - accuracy: 0.9550 - binary_iou: 0.9112 - true_positives: 123990008.0000 - false_positives: 7212635.0000 - true_negatives: 181142384.0000 - false_negatives: 7175765.0000 - precision: 0.9450 - recall: 0.9453 - val_loss: 0.0956 - val_accuracy: 0.9191 - val_binary_iou: 0.8478 - val_true_positives: 41233060.0000 - val_false_positives: 4729738.0000 - val_true_negatives: 56169548.0000 - val_false_negatives: 3839375.0000 - val_precision: 0.8971 - val_recall: 0.9148\n",
      "Epoch 376/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0596 - accuracy: 0.9520 - binary_iou: 0.9057 - true_positives: 123401344.0000 - false_positives: 7607916.0000 - true_negatives: 180787376.0000 - false_negatives: 7724177.0000 - precision: 0.9419 - recall: 0.9411 - val_loss: 0.0954 - val_accuracy: 0.9194 - val_binary_iou: 0.8482 - val_true_positives: 41315356.0000 - val_false_positives: 4829101.0000 - val_true_negatives: 56112324.0000 - val_false_negatives: 3714943.0000 - val_precision: 0.8953 - val_recall: 0.9175\n",
      "Epoch 377/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0555 - accuracy: 0.9551 - binary_iou: 0.9115 - true_positives: 123980264.0000 - false_positives: 7099333.0000 - true_negatives: 181208736.0000 - false_negatives: 7232419.0000 - precision: 0.9458 - recall: 0.9449 - val_loss: 0.0936 - val_accuracy: 0.9220 - val_binary_iou: 0.8521 - val_true_positives: 40489756.0000 - val_false_positives: 3795497.0000 - val_true_negatives: 57215620.0000 - val_false_negatives: 4470819.0000 - val_precision: 0.9143 - val_recall: 0.9006\n",
      "Epoch 378/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0559 - accuracy: 0.9550 - binary_iou: 0.9112 - true_positives: 123942104.0000 - false_positives: 7201411.0000 - true_negatives: 181185456.0000 - false_negatives: 7191784.0000 - precision: 0.9451 - recall: 0.9452 - val_loss: 0.0920 - val_accuracy: 0.9220 - val_binary_iou: 0.8528 - val_true_positives: 41249540.0000 - val_false_positives: 4367496.0000 - val_true_negatives: 56461384.0000 - val_false_negatives: 3893301.0000 - val_precision: 0.9043 - val_recall: 0.9138\n",
      "Epoch 379/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9549 - binary_iou: 0.9110 - true_positives: 123850200.0000 - false_positives: 7159296.0000 - true_negatives: 181256752.0000 - false_negatives: 7254544.0000 - precision: 0.9454 - recall: 0.9447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 106s 530ms/step - loss: 0.0560 - accuracy: 0.9549 - binary_iou: 0.9110 - true_positives: 123850200.0000 - false_positives: 7159296.0000 - true_negatives: 181256752.0000 - false_negatives: 7254544.0000 - precision: 0.9454 - recall: 0.9447 - val_loss: 0.0916 - val_accuracy: 0.9227 - val_binary_iou: 0.8541 - val_true_positives: 41470364.0000 - val_false_positives: 4523639.0000 - val_true_negatives: 56313800.0000 - val_false_negatives: 3663911.0000 - val_precision: 0.9016 - val_recall: 0.9188\n",
      "Epoch 380/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0554 - accuracy: 0.9553 - binary_iou: 0.9118 - true_positives: 123846584.0000 - false_positives: 7029280.0000 - true_negatives: 181385200.0000 - false_negatives: 7259723.0000 - precision: 0.9463 - recall: 0.9446 - val_loss: 0.0936 - val_accuracy: 0.9221 - val_binary_iou: 0.8524 - val_true_positives: 40527300.0000 - val_false_positives: 3674282.0000 - val_true_negatives: 57191888.0000 - val_false_negatives: 4578257.0000 - val_precision: 0.9169 - val_recall: 0.8985\n",
      "Epoch 381/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0555 - accuracy: 0.9553 - binary_iou: 0.9119 - true_positives: 124041104.0000 - false_positives: 7157115.0000 - true_negatives: 181199232.0000 - false_negatives: 7123285.0000 - precision: 0.9454 - recall: 0.9457 - val_loss: 0.0932 - val_accuracy: 0.9212 - val_binary_iou: 0.8512 - val_true_positives: 41118188.0000 - val_false_positives: 4324489.0000 - val_true_negatives: 56504240.0000 - val_false_negatives: 4024791.0000 - val_precision: 0.9048 - val_recall: 0.9108\n",
      "Epoch 382/500\n",
      "199/199 [==============================] - 90s 454ms/step - loss: 0.0555 - accuracy: 0.9550 - binary_iou: 0.9113 - true_positives: 123942464.0000 - false_positives: 7188704.0000 - true_negatives: 181213680.0000 - false_negatives: 7175955.0000 - precision: 0.9452 - recall: 0.9453 - val_loss: 0.0941 - val_accuracy: 0.9201 - val_binary_iou: 0.8494 - val_true_positives: 41299240.0000 - val_false_positives: 4568791.0000 - val_true_negatives: 56201228.0000 - val_false_negatives: 3902439.0000 - val_precision: 0.9004 - val_recall: 0.9137\n",
      "Epoch 383/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0538 - accuracy: 0.9565 - binary_iou: 0.9141 - true_positives: 124181992.0000 - false_positives: 6955521.0000 - true_negatives: 181441088.0000 - false_negatives: 6942219.0000 - precision: 0.9470 - recall: 0.9471 - val_loss: 0.0967 - val_accuracy: 0.9190 - val_binary_iou: 0.8470 - val_true_positives: 40573128.0000 - val_false_positives: 4044793.0000 - val_true_negatives: 56813764.0000 - val_false_negatives: 4540032.0000 - val_precision: 0.9093 - val_recall: 0.8994\n",
      "Epoch 384/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0554 - accuracy: 0.9551 - binary_iou: 0.9115 - true_positives: 123981936.0000 - false_positives: 7176396.0000 - true_negatives: 181200736.0000 - false_negatives: 7161717.0000 - precision: 0.9453 - recall: 0.9454 - val_loss: 0.0966 - val_accuracy: 0.9180 - val_binary_iou: 0.8459 - val_true_positives: 41216728.0000 - val_false_positives: 4778605.0000 - val_true_negatives: 56066804.0000 - val_false_negatives: 3909586.0000 - val_precision: 0.8961 - val_recall: 0.9134\n",
      "Epoch 385/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0536 - accuracy: 0.9565 - binary_iou: 0.9140 - true_positives: 124214744.0000 - false_positives: 6944311.0000 - true_negatives: 181393632.0000 - false_negatives: 6968135.0000 - precision: 0.9471 - recall: 0.9469 - val_loss: 0.0921 - val_accuracy: 0.9222 - val_binary_iou: 0.8531 - val_true_positives: 41375144.0000 - val_false_positives: 4581838.0000 - val_true_negatives: 56353040.0000 - val_false_negatives: 3661691.0000 - val_precision: 0.9003 - val_recall: 0.9187\n",
      "Epoch 386/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0547 - accuracy: 0.9560 - binary_iou: 0.9131 - true_positives: 124006792.0000 - false_positives: 6995740.0000 - true_negatives: 181444016.0000 - false_negatives: 7074150.0000 - precision: 0.9466 - recall: 0.9460 - val_loss: 0.0973 - val_accuracy: 0.9206 - val_binary_iou: 0.8492 - val_true_positives: 39829468.0000 - val_false_positives: 3257736.0000 - val_true_negatives: 57727256.0000 - val_false_negatives: 5157254.0000 - val_precision: 0.9244 - val_recall: 0.8854\n",
      "Epoch 387/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0553 - accuracy: 0.9553 - binary_iou: 0.9118 - true_positives: 123863128.0000 - false_positives: 7042776.0000 - true_negatives: 181377776.0000 - false_negatives: 7237039.0000 - precision: 0.9462 - recall: 0.9448 - val_loss: 0.0923 - val_accuracy: 0.9226 - val_binary_iou: 0.8536 - val_true_positives: 41068736.0000 - val_false_positives: 4217738.0000 - val_true_negatives: 56702400.0000 - val_false_negatives: 3982833.0000 - val_precision: 0.9069 - val_recall: 0.9116\n",
      "Epoch 388/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9557 - binary_iou: 0.9126 - true_positives: 124129896.0000 - false_positives: 7116042.0000 - true_negatives: 181235792.0000 - false_negatives: 7038957.0000 - precision: 0.9458 - recall: 0.9463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 105s 526ms/step - loss: 0.0551 - accuracy: 0.9557 - binary_iou: 0.9126 - true_positives: 124129896.0000 - false_positives: 7116042.0000 - true_negatives: 181235792.0000 - false_negatives: 7038957.0000 - precision: 0.9458 - recall: 0.9463 - val_loss: 0.0918 - val_accuracy: 0.9231 - val_binary_iou: 0.8545 - val_true_positives: 41229008.0000 - val_false_positives: 4236268.0000 - val_true_negatives: 56593624.0000 - val_false_negatives: 3912809.0000 - val_precision: 0.9068 - val_recall: 0.9133\n",
      "Epoch 389/500\n",
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0543 - accuracy: 0.9560 - binary_iou: 0.9132 - true_positives: 124022400.0000 - false_positives: 6966910.0000 - true_negatives: 181442368.0000 - false_negatives: 7089058.0000 - precision: 0.9468 - recall: 0.9459 - val_loss: 0.0951 - val_accuracy: 0.9199 - val_binary_iou: 0.8491 - val_true_positives: 41247056.0000 - val_false_positives: 4679360.0000 - val_true_negatives: 56237256.0000 - val_false_negatives: 3808055.0000 - val_precision: 0.8981 - val_recall: 0.9155\n",
      "Epoch 390/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0551 - accuracy: 0.9553 - binary_iou: 0.9119 - true_positives: 124009360.0000 - false_positives: 7161906.0000 - true_negatives: 181237376.0000 - false_negatives: 7112116.0000 - precision: 0.9454 - recall: 0.9458 - val_loss: 0.0956 - val_accuracy: 0.9185 - val_binary_iou: 0.8468 - val_true_positives: 41232492.0000 - val_false_positives: 4788157.0000 - val_true_negatives: 56105816.0000 - val_false_negatives: 3845240.0000 - val_precision: 0.8960 - val_recall: 0.9147\n",
      "Epoch 391/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0558 - accuracy: 0.9550 - binary_iou: 0.9113 - true_positives: 123856896.0000 - false_positives: 7111902.0000 - true_negatives: 181289040.0000 - false_negatives: 7262922.0000 - precision: 0.9457 - recall: 0.9446 - val_loss: 0.0961 - val_accuracy: 0.9191 - val_binary_iou: 0.8475 - val_true_positives: 40797016.0000 - val_false_positives: 4212082.0000 - val_true_negatives: 56606076.0000 - val_false_negatives: 4356531.0000 - val_precision: 0.9064 - val_recall: 0.9035\n",
      "Epoch 392/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0540 - accuracy: 0.9563 - binary_iou: 0.9136 - true_positives: 124127952.0000 - false_positives: 6994419.0000 - true_negatives: 181418688.0000 - false_negatives: 6979703.0000 - precision: 0.9467 - recall: 0.9468 - val_loss: 0.0930 - val_accuracy: 0.9222 - val_binary_iou: 0.8527 - val_true_positives: 40896232.0000 - val_false_positives: 3952532.0000 - val_true_negatives: 56826308.0000 - val_false_negatives: 4296644.0000 - val_precision: 0.9119 - val_recall: 0.9049\n",
      "Epoch 393/500\n",
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0529 - accuracy: 0.9571 - binary_iou: 0.9153 - true_positives: 124366520.0000 - false_positives: 6909129.0000 - true_negatives: 181457648.0000 - false_negatives: 6787427.0000 - precision: 0.9474 - recall: 0.9482 - val_loss: 0.0932 - val_accuracy: 0.9205 - val_binary_iou: 0.8502 - val_true_positives: 41409456.0000 - val_false_positives: 4736284.0000 - val_true_negatives: 56136168.0000 - val_false_negatives: 3689812.0000 - val_precision: 0.8974 - val_recall: 0.9182\n",
      "Epoch 394/500\n",
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0529 - accuracy: 0.9573 - binary_iou: 0.9155 - true_positives: 124279768.0000 - false_positives: 6786705.0000 - true_negatives: 181585344.0000 - false_negatives: 6868977.0000 - precision: 0.9482 - recall: 0.9476 - val_loss: 0.0939 - val_accuracy: 0.9224 - val_binary_iou: 0.8528 - val_true_positives: 40528952.0000 - val_false_positives: 3611580.0000 - val_true_negatives: 57218896.0000 - val_false_negatives: 4612296.0000 - val_precision: 0.9182 - val_recall: 0.8978\n",
      "Epoch 395/500\n",
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0524 - accuracy: 0.9576 - binary_iou: 0.9161 - true_positives: 124289120.0000 - false_positives: 6721946.0000 - true_negatives: 181669536.0000 - false_negatives: 6840109.0000 - precision: 0.9487 - recall: 0.9478 - val_loss: 0.0972 - val_accuracy: 0.9186 - val_binary_iou: 0.8465 - val_true_positives: 40703988.0000 - val_false_positives: 4300568.0000 - val_true_negatives: 56643456.0000 - val_false_negatives: 4323700.0000 - val_precision: 0.9044 - val_recall: 0.9040\n",
      "Epoch 396/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0536 - accuracy: 0.9567 - binary_iou: 0.9146 - true_positives: 124253712.0000 - false_positives: 6896811.0000 - true_negatives: 181446016.0000 - false_negatives: 6924292.0000 - precision: 0.9474 - recall: 0.9472 - val_loss: 0.0922 - val_accuracy: 0.9225 - val_binary_iou: 0.8533 - val_true_positives: 40923396.0000 - val_false_positives: 4077760.0000 - val_true_negatives: 56838004.0000 - val_false_negatives: 4132553.0000 - val_precision: 0.9094 - val_recall: 0.9083\n",
      "Epoch 397/500\n",
      "199/199 [==============================] - 90s 454ms/step - loss: 0.0529 - accuracy: 0.9575 - binary_iou: 0.9159 - true_positives: 124315912.0000 - false_positives: 6822511.0000 - true_negatives: 181613136.0000 - false_negatives: 6769308.0000 - precision: 0.9480 - recall: 0.9484 - val_loss: 0.0951 - val_accuracy: 0.9211 - val_binary_iou: 0.8505 - val_true_positives: 40468236.0000 - val_false_positives: 3697451.0000 - val_true_negatives: 57139380.0000 - val_false_negatives: 4666638.0000 - val_precision: 0.9163 - val_recall: 0.8966\n",
      "Epoch 398/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0531 - accuracy: 0.9570 - binary_iou: 0.9151 - true_positives: 124347376.0000 - false_positives: 6898690.0000 - true_negatives: 181447024.0000 - false_negatives: 6827664.0000 - precision: 0.9474 - recall: 0.9480 - val_loss: 0.0944 - val_accuracy: 0.9209 - val_binary_iou: 0.8505 - val_true_positives: 40946184.0000 - val_false_positives: 4169263.0000 - val_true_negatives: 56638552.0000 - val_false_negatives: 4217703.0000 - val_precision: 0.9076 - val_recall: 0.9066\n",
      "Epoch 399/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0525 - accuracy: 0.9575 - binary_iou: 0.9161 - true_positives: 124311112.0000 - false_positives: 6779881.0000 - true_negatives: 181642896.0000 - false_negatives: 6786899.0000 - precision: 0.9483 - recall: 0.9482 - val_loss: 0.0931 - val_accuracy: 0.9217 - val_binary_iou: 0.8520 - val_true_positives: 40975316.0000 - val_false_positives: 4184615.0000 - val_true_negatives: 56699712.0000 - val_false_negatives: 4112067.0000 - val_precision: 0.9073 - val_recall: 0.9088\n",
      "Epoch 400/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0530 - accuracy: 0.9573 - binary_iou: 0.9156 - true_positives: 124355080.0000 - false_positives: 6770570.0000 - true_negatives: 181523920.0000 - false_negatives: 6871200.0000 - precision: 0.9484 - recall: 0.9476 - val_loss: 0.0929 - val_accuracy: 0.9222 - val_binary_iou: 0.8527 - val_true_positives: 40897884.0000 - val_false_positives: 4069871.0000 - val_true_negatives: 56824872.0000 - val_false_negatives: 4179075.0000 - val_precision: 0.9095 - val_recall: 0.9073\n",
      "Epoch 401/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0531 - accuracy: 0.9569 - binary_iou: 0.9148 - true_positives: 124134144.0000 - false_positives: 6826288.0000 - true_negatives: 181608832.0000 - false_negatives: 6951454.0000 - precision: 0.9479 - recall: 0.9470 - val_loss: 0.0933 - val_accuracy: 0.9212 - val_binary_iou: 0.8511 - val_true_positives: 40902968.0000 - val_false_positives: 4207415.0000 - val_true_negatives: 56722384.0000 - val_false_negatives: 4138936.0000 - val_precision: 0.9067 - val_recall: 0.9081\n",
      "Epoch 402/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0525 - accuracy: 0.9576 - binary_iou: 0.9161 - true_positives: 124282104.0000 - false_positives: 6664449.0000 - true_negatives: 181686800.0000 - false_negatives: 6887462.0000 - precision: 0.9491 - recall: 0.9475 - val_loss: 0.0944 - val_accuracy: 0.9214 - val_binary_iou: 0.8513 - val_true_positives: 40833968.0000 - val_false_positives: 4073275.0000 - val_true_negatives: 56804860.0000 - val_false_negatives: 4259611.0000 - val_precision: 0.9093 - val_recall: 0.9055\n",
      "Epoch 403/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0521 - accuracy: 0.9579 - binary_iou: 0.9168 - true_positives: 124439808.0000 - false_positives: 6733831.0000 - true_negatives: 181633136.0000 - false_negatives: 6714072.0000 - precision: 0.9487 - recall: 0.9488 - val_loss: 0.1153 - val_accuracy: 0.9042 - val_binary_iou: 0.8216 - val_true_positives: 39698344.0000 - val_false_positives: 4695279.0000 - val_true_negatives: 56122280.0000 - val_false_negatives: 5455822.0000 - val_precision: 0.8942 - val_recall: 0.8792\n",
      "Epoch 404/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0534 - accuracy: 0.9566 - binary_iou: 0.9143 - true_positives: 124215200.0000 - false_positives: 6903006.0000 - true_negatives: 181446848.0000 - false_negatives: 6955681.0000 - precision: 0.9474 - recall: 0.9470 - val_loss: 0.0944 - val_accuracy: 0.9210 - val_binary_iou: 0.8507 - val_true_positives: 40807664.0000 - val_false_positives: 4023888.0000 - val_true_negatives: 56792704.0000 - val_false_negatives: 4347441.0000 - val_precision: 0.9102 - val_recall: 0.9037\n",
      "Epoch 405/500\n",
      "199/199 [==============================] - 91s 455ms/step - loss: 0.0518 - accuracy: 0.9580 - binary_iou: 0.9170 - true_positives: 124347104.0000 - false_positives: 6647183.0000 - true_negatives: 181767440.0000 - false_negatives: 6759063.0000 - precision: 0.9493 - recall: 0.9484 - val_loss: 0.0936 - val_accuracy: 0.9213 - val_binary_iou: 0.8514 - val_true_positives: 41078664.0000 - val_false_positives: 4391452.0000 - val_true_negatives: 56555332.0000 - val_false_negatives: 3946266.0000 - val_precision: 0.9034 - val_recall: 0.9124\n",
      "Epoch 406/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0520 - accuracy: 0.9579 - binary_iou: 0.9167 - true_positives: 124336704.0000 - false_positives: 6670031.0000 - true_negatives: 181731984.0000 - false_negatives: 6782009.0000 - precision: 0.9491 - recall: 0.9483 - val_loss: 0.0946 - val_accuracy: 0.9201 - val_binary_iou: 0.8493 - val_true_positives: 41023392.0000 - val_false_positives: 4317248.0000 - val_true_negatives: 56485736.0000 - val_false_negatives: 4145318.0000 - val_precision: 0.9048 - val_recall: 0.9082\n",
      "Epoch 407/500\n",
      "199/199 [==============================] - 90s 454ms/step - loss: 0.0524 - accuracy: 0.9577 - binary_iou: 0.9164 - true_positives: 124261112.0000 - false_positives: 6657059.0000 - true_negatives: 181753568.0000 - false_negatives: 6849082.0000 - precision: 0.9492 - recall: 0.9478 - val_loss: 0.0931 - val_accuracy: 0.9222 - val_binary_iou: 0.8527 - val_true_positives: 40875316.0000 - val_false_positives: 3915595.0000 - val_true_negatives: 56847504.0000 - val_false_negatives: 4333301.0000 - val_precision: 0.9126 - val_recall: 0.9041\n",
      "Epoch 408/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0514 - accuracy: 0.9584 - binary_iou: 0.9177 - true_positives: 124366720.0000 - false_positives: 6558092.0000 - true_negatives: 181860864.0000 - false_negatives: 6735140.0000 - precision: 0.9499 - recall: 0.9486 - val_loss: 0.0933 - val_accuracy: 0.9219 - val_binary_iou: 0.8523 - val_true_positives: 40968296.0000 - val_false_positives: 4208294.0000 - val_true_negatives: 56724568.0000 - val_false_negatives: 4070572.0000 - val_precision: 0.9068 - val_recall: 0.9096\n",
      "Epoch 409/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0510 - accuracy: 0.9589 - binary_iou: 0.9186 - true_positives: 124525968.0000 - false_positives: 6492105.0000 - true_negatives: 181864832.0000 - false_negatives: 6637769.0000 - precision: 0.9504 - recall: 0.9494 - val_loss: 0.0960 - val_accuracy: 0.9213 - val_binary_iou: 0.8505 - val_true_positives: 40096864.0000 - val_false_positives: 3368452.0000 - val_true_negatives: 57529752.0000 - val_false_negatives: 4976645.0000 - val_precision: 0.9225 - val_recall: 0.8896\n",
      "Epoch 410/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0528 - accuracy: 0.9572 - binary_iou: 0.9155 - true_positives: 124315456.0000 - false_positives: 6814936.0000 - true_negatives: 181542832.0000 - false_negatives: 6847509.0000 - precision: 0.9480 - recall: 0.9478 - val_loss: 0.0937 - val_accuracy: 0.9219 - val_binary_iou: 0.8524 - val_true_positives: 41002376.0000 - val_false_positives: 4133850.0000 - val_true_negatives: 56695516.0000 - val_false_negatives: 4139976.0000 - val_precision: 0.9084 - val_recall: 0.9083\n",
      "Epoch 411/500\n",
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0510 - accuracy: 0.9587 - binary_iou: 0.9182 - true_positives: 124429096.0000 - false_positives: 6512460.0000 - true_negatives: 181880992.0000 - false_negatives: 6698194.0000 - precision: 0.9503 - recall: 0.9489 - val_loss: 0.0917 - val_accuracy: 0.9224 - val_binary_iou: 0.8536 - val_true_positives: 41528680.0000 - val_false_positives: 4652289.0000 - val_true_negatives: 56224188.0000 - val_false_negatives: 3566538.0000 - val_precision: 0.8993 - val_recall: 0.9209\n",
      "Epoch 412/500\n",
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0503 - accuracy: 0.9593 - binary_iou: 0.9194 - true_positives: 124583232.0000 - false_positives: 6478918.0000 - true_negatives: 181933488.0000 - false_negatives: 6525216.0000 - precision: 0.9506 - recall: 0.9502 - val_loss: 0.0939 - val_accuracy: 0.9217 - val_binary_iou: 0.8518 - val_true_positives: 40745324.0000 - val_false_positives: 3936372.0000 - val_true_negatives: 56926464.0000 - val_false_negatives: 4363544.0000 - val_precision: 0.9119 - val_recall: 0.9033\n",
      "Epoch 413/500\n",
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0504 - accuracy: 0.9591 - binary_iou: 0.9191 - true_positives: 124601320.0000 - false_positives: 6460394.0000 - true_negatives: 181860128.0000 - false_negatives: 6598842.0000 - precision: 0.9507 - recall: 0.9497 - val_loss: 0.0929 - val_accuracy: 0.9219 - val_binary_iou: 0.8524 - val_true_positives: 41093804.0000 - val_false_positives: 4200714.0000 - val_true_negatives: 56601612.0000 - val_false_negatives: 4075589.0000 - val_precision: 0.9073 - val_recall: 0.9098\n",
      "Epoch 414/500\n",
      "199/199 [==============================] - 95s 480ms/step - loss: 0.0509 - accuracy: 0.9589 - binary_iou: 0.9186 - true_positives: 124551136.0000 - false_positives: 6541151.0000 - true_negatives: 181826656.0000 - false_negatives: 6601838.0000 - precision: 0.9501 - recall: 0.9497 - val_loss: 0.0947 - val_accuracy: 0.9205 - val_binary_iou: 0.8497 - val_true_positives: 40692576.0000 - val_false_positives: 3984069.0000 - val_true_negatives: 56853944.0000 - val_false_negatives: 4441120.0000 - val_precision: 0.9108 - val_recall: 0.9016\n",
      "Epoch 415/500\n",
      "199/199 [==============================] - 92s 462ms/step - loss: 0.0516 - accuracy: 0.9584 - binary_iou: 0.9176 - true_positives: 124435480.0000 - false_positives: 6642698.0000 - true_negatives: 181782288.0000 - false_negatives: 6660343.0000 - precision: 0.9493 - recall: 0.9492 - val_loss: 0.0949 - val_accuracy: 0.9208 - val_binary_iou: 0.8503 - val_true_positives: 40730056.0000 - val_false_positives: 3951604.0000 - val_true_negatives: 56851748.0000 - val_false_negatives: 4438301.0000 - val_precision: 0.9116 - val_recall: 0.9017\n",
      "Epoch 416/500\n",
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0512 - accuracy: 0.9586 - binary_iou: 0.9181 - true_positives: 124494912.0000 - false_positives: 6523631.0000 - true_negatives: 181807552.0000 - false_negatives: 6694642.0000 - precision: 0.9502 - recall: 0.9490 - val_loss: 0.0978 - val_accuracy: 0.9181 - val_binary_iou: 0.8458 - val_true_positives: 40880052.0000 - val_false_positives: 4490230.0000 - val_true_negatives: 56412044.0000 - val_false_negatives: 4189371.0000 - val_precision: 0.9010 - val_recall: 0.9070\n",
      "Epoch 417/500\n",
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0509 - accuracy: 0.9589 - binary_iou: 0.9186 - true_positives: 124507400.0000 - false_positives: 6517523.0000 - true_negatives: 181868432.0000 - false_negatives: 6627392.0000 - precision: 0.9503 - recall: 0.9495 - val_loss: 0.0940 - val_accuracy: 0.9203 - val_binary_iou: 0.8499 - val_true_positives: 41536600.0000 - val_false_positives: 4867346.0000 - val_true_negatives: 55986696.0000 - val_false_negatives: 3581076.0000 - val_precision: 0.8951 - val_recall: 0.9206\n",
      "Epoch 418/500\n",
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0496 - accuracy: 0.9600 - binary_iou: 0.9207 - true_positives: 124672656.0000 - false_positives: 6312900.0000 - true_negatives: 182064560.0000 - false_negatives: 6470699.0000 - precision: 0.9518 - recall: 0.9507 - val_loss: 0.0920 - val_accuracy: 0.9226 - val_binary_iou: 0.8536 - val_true_positives: 41031352.0000 - val_false_positives: 4141857.0000 - val_true_negatives: 56742576.0000 - val_false_negatives: 4055934.0000 - val_precision: 0.9083 - val_recall: 0.9100\n",
      "Epoch 419/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0497 - accuracy: 0.9599 - binary_iou: 0.9205 - true_positives: 124700224.0000 - false_positives: 6350251.0000 - true_negatives: 182008256.0000 - false_negatives: 6462049.0000 - precision: 0.9515 - recall: 0.9507 - val_loss: 0.0951 - val_accuracy: 0.9216 - val_binary_iou: 0.8509 - val_true_positives: 39888380.0000 - val_false_positives: 3200307.0000 - val_true_negatives: 57774968.0000 - val_false_negatives: 5108064.0000 - val_precision: 0.9257 - val_recall: 0.8865\n",
      "Epoch 420/500\n",
      "199/199 [==============================] - 88s 442ms/step - loss: 0.0503 - accuracy: 0.9594 - binary_iou: 0.9197 - true_positives: 124653544.0000 - false_positives: 6450177.0000 - true_negatives: 181907744.0000 - false_negatives: 6509379.0000 - precision: 0.9508 - recall: 0.9504 - val_loss: 0.0953 - val_accuracy: 0.9200 - val_binary_iou: 0.8490 - val_true_positives: 40899024.0000 - val_false_positives: 4213555.0000 - val_true_negatives: 56593396.0000 - val_false_negatives: 4265734.0000 - val_precision: 0.9066 - val_recall: 0.9056\n",
      "Epoch 421/500\n",
      "199/199 [==============================] - 88s 442ms/step - loss: 0.0503 - accuracy: 0.9594 - binary_iou: 0.9196 - true_positives: 124569960.0000 - false_positives: 6464284.0000 - true_negatives: 181980144.0000 - false_negatives: 6506346.0000 - precision: 0.9507 - recall: 0.9504 - val_loss: 0.0986 - val_accuracy: 0.9161 - val_binary_iou: 0.8427 - val_true_positives: 41435208.0000 - val_false_positives: 5200894.0000 - val_true_negatives: 55642428.0000 - val_false_negatives: 3693192.0000 - val_precision: 0.8885 - val_recall: 0.9182\n",
      "Epoch 422/500\n",
      "199/199 [==============================] - 88s 444ms/step - loss: 0.0507 - accuracy: 0.9590 - binary_iou: 0.9188 - true_positives: 124547504.0000 - false_positives: 6540003.0000 - true_negatives: 181872480.0000 - false_negatives: 6560775.0000 - precision: 0.9501 - recall: 0.9500 - val_loss: 0.0965 - val_accuracy: 0.9186 - val_binary_iou: 0.8467 - val_true_positives: 41044200.0000 - val_false_positives: 4621838.0000 - val_true_negatives: 56299976.0000 - val_false_negatives: 4005696.0000 - val_precision: 0.8988 - val_recall: 0.9111\n",
      "Epoch 423/500\n",
      "199/199 [==============================] - 88s 443ms/step - loss: 0.0500 - accuracy: 0.9596 - binary_iou: 0.9199 - true_positives: 124630288.0000 - false_positives: 6393065.0000 - true_negatives: 181974640.0000 - false_negatives: 6522828.0000 - precision: 0.9512 - recall: 0.9503 - val_loss: 0.1109 - val_accuracy: 0.9089 - val_binary_iou: 0.8292 - val_true_positives: 39561680.0000 - val_false_positives: 4088024.0000 - val_true_negatives: 56756400.0000 - val_false_negatives: 5565589.0000 - val_precision: 0.9063 - val_recall: 0.8767\n",
      "Epoch 424/500\n",
      "199/199 [==============================] - 88s 441ms/step - loss: 0.0504 - accuracy: 0.9593 - binary_iou: 0.9193 - true_positives: 124497104.0000 - false_positives: 6421780.0000 - true_negatives: 182011072.0000 - false_negatives: 6590742.0000 - precision: 0.9509 - recall: 0.9497 - val_loss: 0.0941 - val_accuracy: 0.9200 - val_binary_iou: 0.8495 - val_true_positives: 41536976.0000 - val_false_positives: 4832156.0000 - val_true_negatives: 55961700.0000 - val_false_negatives: 3640888.0000 - val_precision: 0.8958 - val_recall: 0.9194\n",
      "Epoch 425/500\n",
      "199/199 [==============================] - 88s 443ms/step - loss: 0.0498 - accuracy: 0.9596 - binary_iou: 0.9200 - true_positives: 124551864.0000 - false_positives: 6382364.0000 - true_negatives: 182074656.0000 - false_negatives: 6511833.0000 - precision: 0.9513 - recall: 0.9503 - val_loss: 0.0940 - val_accuracy: 0.9196 - val_binary_iou: 0.8488 - val_true_positives: 41577056.0000 - val_false_positives: 4980649.0000 - val_true_negatives: 55873072.0000 - val_false_negatives: 3540919.0000 - val_precision: 0.8930 - val_recall: 0.9215\n",
      "Epoch 426/500\n",
      "199/199 [==============================] - 88s 444ms/step - loss: 0.0489 - accuracy: 0.9605 - binary_iou: 0.9216 - true_positives: 124754424.0000 - false_positives: 6220859.0000 - true_negatives: 182132064.0000 - false_negatives: 6413414.0000 - precision: 0.9525 - recall: 0.9511 - val_loss: 0.0961 - val_accuracy: 0.9185 - val_binary_iou: 0.8466 - val_true_positives: 41104844.0000 - val_false_positives: 4727882.0000 - val_true_negatives: 56227008.0000 - val_false_negatives: 3911989.0000 - val_precision: 0.8968 - val_recall: 0.9131\n",
      "Epoch 427/500\n",
      "199/199 [==============================] - 88s 443ms/step - loss: 0.0490 - accuracy: 0.9603 - binary_iou: 0.9214 - true_positives: 124755024.0000 - false_positives: 6270996.0000 - true_negatives: 182095792.0000 - false_negatives: 6398901.0000 - precision: 0.9521 - recall: 0.9512 - val_loss: 0.0916 - val_accuracy: 0.9231 - val_binary_iou: 0.8544 - val_true_positives: 40937368.0000 - val_false_positives: 3948493.0000 - val_true_negatives: 56889232.0000 - val_false_negatives: 4196619.0000 - val_precision: 0.9120 - val_recall: 0.9070\n",
      "Epoch 428/500\n",
      "199/199 [==============================] - 88s 440ms/step - loss: 0.0500 - accuracy: 0.9596 - binary_iou: 0.9200 - true_positives: 124583336.0000 - false_positives: 6379575.0000 - true_negatives: 182030544.0000 - false_negatives: 6527364.0000 - precision: 0.9513 - recall: 0.9502 - val_loss: 0.0992 - val_accuracy: 0.9148 - val_binary_iou: 0.8407 - val_true_positives: 41675512.0000 - val_false_positives: 5580215.0000 - val_true_negatives: 55266432.0000 - val_false_negatives: 3449561.0000 - val_precision: 0.8819 - val_recall: 0.9236\n",
      "Epoch 429/500\n",
      "199/199 [==============================] - 88s 440ms/step - loss: 0.0506 - accuracy: 0.9591 - binary_iou: 0.9190 - true_positives: 124635184.0000 - false_positives: 6536305.0000 - true_negatives: 181816192.0000 - false_negatives: 6533070.0000 - precision: 0.9502 - recall: 0.9502 - val_loss: 0.0978 - val_accuracy: 0.9181 - val_binary_iou: 0.8458 - val_true_positives: 41037292.0000 - val_false_positives: 4668867.0000 - val_true_negatives: 56252856.0000 - val_false_negatives: 4012697.0000 - val_precision: 0.8979 - val_recall: 0.9109\n",
      "Epoch 430/500\n",
      "199/199 [==============================] - 88s 443ms/step - loss: 0.0501 - accuracy: 0.9595 - binary_iou: 0.9197 - true_positives: 124636664.0000 - false_positives: 6457731.0000 - true_negatives: 181932944.0000 - false_negatives: 6493393.0000 - precision: 0.9507 - recall: 0.9505 - val_loss: 0.1054 - val_accuracy: 0.9121 - val_binary_iou: 0.8349 - val_true_positives: 39993152.0000 - val_false_positives: 4244760.0000 - val_true_negatives: 56660528.0000 - val_false_negatives: 5073268.0000 - val_precision: 0.9040 - val_recall: 0.8874\n",
      "Epoch 431/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0501 - accuracy: 0.9594 - binary_iou: 0.9197 - true_positives: 124697512.0000 - false_positives: 6451416.0000 - true_negatives: 181865584.0000 - false_negatives: 6506157.0000 - precision: 0.9508 - recall: 0.9504 - val_loss: 0.0961 - val_accuracy: 0.9203 - val_binary_iou: 0.8492 - val_true_positives: 40389572.0000 - val_false_positives: 3804620.0000 - val_true_negatives: 57137272.0000 - val_false_negatives: 4640255.0000 - val_precision: 0.9139 - val_recall: 0.8970\n",
      "Epoch 432/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0480 - accuracy: 0.9612 - binary_iou: 0.9229 - true_positives: 124825144.0000 - false_positives: 6132136.0000 - true_negatives: 182283536.0000 - false_negatives: 6279968.0000 - precision: 0.9532 - recall: 0.9521 - val_loss: 0.0942 - val_accuracy: 0.9214 - val_binary_iou: 0.8511 - val_true_positives: 40497992.0000 - val_false_positives: 3615495.0000 - val_true_negatives: 57142104.0000 - val_false_negatives: 4716114.0000 - val_precision: 0.9180 - val_recall: 0.8957\n",
      "Epoch 433/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0491 - accuracy: 0.9603 - binary_iou: 0.9213 - true_positives: 124772456.0000 - false_positives: 6332571.0000 - true_negatives: 182066288.0000 - false_negatives: 6349474.0000 - precision: 0.9517 - recall: 0.9516 - val_loss: 0.0953 - val_accuracy: 0.9202 - val_binary_iou: 0.8493 - val_true_positives: 40889700.0000 - val_false_positives: 4260224.0000 - val_true_negatives: 56623188.0000 - val_false_negatives: 4198599.0000 - val_precision: 0.9056 - val_recall: 0.9069\n",
      "Epoch 434/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0491 - accuracy: 0.9605 - binary_iou: 0.9217 - true_positives: 124707968.0000 - false_positives: 6238895.0000 - true_negatives: 182192736.0000 - false_negatives: 6381095.0000 - precision: 0.9524 - recall: 0.9513 - val_loss: 0.0938 - val_accuracy: 0.9217 - val_binary_iou: 0.8518 - val_true_positives: 40836176.0000 - val_false_positives: 4071977.0000 - val_true_negatives: 56836444.0000 - val_false_negatives: 4227125.0000 - val_precision: 0.9093 - val_recall: 0.9062\n",
      "Epoch 435/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0486 - accuracy: 0.9607 - binary_iou: 0.9220 - true_positives: 124843040.0000 - false_positives: 6258126.0000 - true_negatives: 182110832.0000 - false_negatives: 6308738.0000 - precision: 0.9523 - recall: 0.9519 - val_loss: 0.0944 - val_accuracy: 0.9215 - val_binary_iou: 0.8515 - val_true_positives: 40819772.0000 - val_false_positives: 4087711.0000 - val_true_negatives: 56834144.0000 - val_false_negatives: 4230067.0000 - val_precision: 0.9090 - val_recall: 0.9061\n",
      "Epoch 436/500\n",
      "199/199 [==============================] - 87s 437ms/step - loss: 0.0482 - accuracy: 0.9609 - binary_iou: 0.9224 - true_positives: 124735880.0000 - false_positives: 6141078.0000 - true_negatives: 182297088.0000 - false_negatives: 6346758.0000 - precision: 0.9531 - recall: 0.9516 - val_loss: 0.0948 - val_accuracy: 0.9212 - val_binary_iou: 0.8509 - val_true_positives: 40561828.0000 - val_false_positives: 3812838.0000 - val_true_negatives: 57064612.0000 - val_false_negatives: 4532435.0000 - val_precision: 0.9141 - val_recall: 0.8995\n",
      "Epoch 437/500\n",
      "199/199 [==============================] - 88s 442ms/step - loss: 0.0489 - accuracy: 0.9605 - binary_iou: 0.9217 - true_positives: 124827344.0000 - false_positives: 6298016.0000 - true_negatives: 182078848.0000 - false_negatives: 6316543.0000 - precision: 0.9520 - recall: 0.9518 - val_loss: 0.0940 - val_accuracy: 0.9227 - val_binary_iou: 0.8535 - val_true_positives: 40679432.0000 - val_false_positives: 3762014.0000 - val_true_negatives: 57100344.0000 - val_false_negatives: 4429909.0000 - val_precision: 0.9153 - val_recall: 0.9018\n",
      "Epoch 438/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0483 - accuracy: 0.9610 - binary_iou: 0.9227 - true_positives: 124812768.0000 - false_positives: 6130597.0000 - true_negatives: 182254144.0000 - false_negatives: 6323229.0000 - precision: 0.9532 - recall: 0.9518 - val_loss: 0.0950 - val_accuracy: 0.9216 - val_binary_iou: 0.8513 - val_true_positives: 40271648.0000 - val_false_positives: 3513636.0000 - val_true_negatives: 57396516.0000 - val_false_negatives: 4789900.0000 - val_precision: 0.9198 - val_recall: 0.8937\n",
      "Epoch 439/500\n",
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0477 - accuracy: 0.9615 - binary_iou: 0.9235 - true_positives: 124859680.0000 - false_positives: 6058543.0000 - true_negatives: 182352768.0000 - false_negatives: 6249767.0000 - precision: 0.9537 - recall: 0.9523 - val_loss: 0.0913 - val_accuracy: 0.9224 - val_binary_iou: 0.8534 - val_true_positives: 41344208.0000 - val_false_positives: 4447719.0000 - val_true_negatives: 56402388.0000 - val_false_negatives: 3777400.0000 - val_precision: 0.9029 - val_recall: 0.9163\n",
      "Epoch 440/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0476 - accuracy: 0.9615 - binary_iou: 0.9235 - true_positives: 124967088.0000 - false_positives: 6140172.0000 - true_negatives: 182239232.0000 - false_negatives: 6174306.0000 - precision: 0.9532 - recall: 0.9529 - val_loss: 0.0923 - val_accuracy: 0.9219 - val_binary_iou: 0.8524 - val_true_positives: 41174832.0000 - val_false_positives: 4319120.0000 - val_true_negatives: 56519416.0000 - val_false_negatives: 3958347.0000 - val_precision: 0.9051 - val_recall: 0.9123\n",
      "Epoch 441/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0482 - accuracy: 0.9611 - binary_iou: 0.9228 - true_positives: 124744560.0000 - false_positives: 6160548.0000 - true_negatives: 182340880.0000 - false_negatives: 6274775.0000 - precision: 0.9529 - recall: 0.9521 - val_loss: 0.0919 - val_accuracy: 0.9223 - val_binary_iou: 0.8532 - val_true_positives: 41314936.0000 - val_false_positives: 4341346.0000 - val_true_negatives: 56421532.0000 - val_false_negatives: 3893893.0000 - val_precision: 0.9049 - val_recall: 0.9139\n",
      "Epoch 442/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0478 - accuracy: 0.9613 - binary_iou: 0.9232 - true_positives: 124780520.0000 - false_positives: 6104541.0000 - true_negatives: 182375808.0000 - false_negatives: 6259885.0000 - precision: 0.9534 - recall: 0.9522 - val_loss: 0.0931 - val_accuracy: 0.9217 - val_binary_iou: 0.8518 - val_true_positives: 40834984.0000 - val_false_positives: 4014486.0000 - val_true_negatives: 56834776.0000 - val_false_negatives: 4287473.0000 - val_precision: 0.9105 - val_recall: 0.9050\n",
      "Epoch 443/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0483 - accuracy: 0.9609 - binary_iou: 0.9225 - true_positives: 124825744.0000 - false_positives: 6212165.0000 - true_negatives: 182207632.0000 - false_negatives: 6275327.0000 - precision: 0.9526 - recall: 0.9521 - val_loss: 0.0939 - val_accuracy: 0.9220 - val_binary_iou: 0.8523 - val_true_positives: 40801216.0000 - val_false_positives: 3935072.0000 - val_true_negatives: 56903780.0000 - val_false_negatives: 4331637.0000 - val_precision: 0.9120 - val_recall: 0.9040\n",
      "Epoch 444/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0477 - accuracy: 0.9616 - binary_iou: 0.9238 - true_positives: 124892920.0000 - false_positives: 6076041.0000 - true_negatives: 182362576.0000 - false_negatives: 6189214.0000 - precision: 0.9536 - recall: 0.9528 - val_loss: 0.0991 - val_accuracy: 0.9175 - val_binary_iou: 0.8444 - val_true_positives: 40294560.0000 - val_false_positives: 3860016.0000 - val_true_negatives: 56938996.0000 - val_false_negatives: 4878144.0000 - val_precision: 0.9126 - val_recall: 0.8920\n",
      "Epoch 445/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0479 - accuracy: 0.9611 - binary_iou: 0.9229 - true_positives: 124936640.0000 - false_positives: 6211699.0000 - true_negatives: 182166560.0000 - false_negatives: 6205862.0000 - precision: 0.9526 - recall: 0.9527 - val_loss: 0.0935 - val_accuracy: 0.9218 - val_binary_iou: 0.8519 - val_true_positives: 40637108.0000 - val_false_positives: 3844190.0000 - val_true_negatives: 57050056.0000 - val_false_negatives: 4440355.0000 - val_precision: 0.9136 - val_recall: 0.9015\n",
      "Epoch 446/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0475 - accuracy: 0.9616 - binary_iou: 0.9238 - true_positives: 124905616.0000 - false_positives: 6062113.0000 - true_negatives: 182357568.0000 - false_negatives: 6195441.0000 - precision: 0.9537 - recall: 0.9527 - val_loss: 0.0936 - val_accuracy: 0.9216 - val_binary_iou: 0.8517 - val_true_positives: 40973708.0000 - val_false_positives: 4189998.0000 - val_true_negatives: 56686760.0000 - val_false_negatives: 4121243.0000 - val_precision: 0.9072 - val_recall: 0.9086\n",
      "Epoch 447/500\n",
      "199/199 [==============================] - 88s 444ms/step - loss: 0.0473 - accuracy: 0.9619 - binary_iou: 0.9243 - true_positives: 125004248.0000 - false_positives: 6063810.0000 - true_negatives: 182341808.0000 - false_negatives: 6110928.0000 - precision: 0.9537 - recall: 0.9534 - val_loss: 0.0925 - val_accuracy: 0.9220 - val_binary_iou: 0.8526 - val_true_positives: 41161076.0000 - val_false_positives: 4319780.0000 - val_true_negatives: 56543736.0000 - val_false_negatives: 3947130.0000 - val_precision: 0.9050 - val_recall: 0.9125\n",
      "Epoch 448/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0479 - accuracy: 0.9613 - binary_iou: 0.9231 - true_positives: 124942016.0000 - false_positives: 6177060.0000 - true_negatives: 182200160.0000 - false_negatives: 6201609.0000 - precision: 0.9529 - recall: 0.9527 - val_loss: 0.0971 - val_accuracy: 0.9164 - val_binary_iou: 0.8436 - val_true_positives: 41851856.0000 - val_false_positives: 5566667.0000 - val_true_negatives: 55263404.0000 - val_false_negatives: 3289777.0000 - val_precision: 0.8826 - val_recall: 0.9271\n",
      "Epoch 449/500\n",
      "199/199 [==============================] - 89s 447ms/step - loss: 0.0465 - accuracy: 0.9624 - binary_iou: 0.9253 - true_positives: 125068304.0000 - false_positives: 5896822.0000 - true_negatives: 182434560.0000 - false_negatives: 6121019.0000 - precision: 0.9550 - recall: 0.9533 - val_loss: 0.0941 - val_accuracy: 0.9211 - val_binary_iou: 0.8509 - val_true_positives: 40882076.0000 - val_false_positives: 4099626.0000 - val_true_negatives: 56731476.0000 - val_false_negatives: 4258531.0000 - val_precision: 0.9089 - val_recall: 0.9057\n",
      "Epoch 450/500\n",
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0467 - accuracy: 0.9622 - binary_iou: 0.9250 - true_positives: 124980112.0000 - false_positives: 5975379.0000 - true_negatives: 182472736.0000 - false_negatives: 6092596.0000 - precision: 0.9544 - recall: 0.9535 - val_loss: 0.0921 - val_accuracy: 0.9224 - val_binary_iou: 0.8533 - val_true_positives: 41208992.0000 - val_false_positives: 4366910.0000 - val_true_negatives: 56534352.0000 - val_false_negatives: 3861467.0000 - val_precision: 0.9042 - val_recall: 0.9143\n",
      "Epoch 451/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0461 - accuracy: 0.9627 - binary_iou: 0.9259 - true_positives: 125143224.0000 - false_positives: 5924500.0000 - true_negatives: 182472416.0000 - false_negatives: 5980658.0000 - precision: 0.9548 - recall: 0.9544 - val_loss: 0.0941 - val_accuracy: 0.9216 - val_binary_iou: 0.8515 - val_true_positives: 40545368.0000 - val_false_positives: 3673602.0000 - val_true_negatives: 57120376.0000 - val_false_negatives: 4632361.0000 - val_precision: 0.9169 - val_recall: 0.8975\n",
      "Epoch 452/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0460 - accuracy: 0.9629 - binary_iou: 0.9262 - true_positives: 125043632.0000 - false_positives: 5856416.0000 - true_negatives: 182618560.0000 - false_negatives: 6002277.0000 - precision: 0.9553 - recall: 0.9542 - val_loss: 0.0955 - val_accuracy: 0.9205 - val_binary_iou: 0.8495 - val_true_positives: 40508484.0000 - val_false_positives: 3793990.0000 - val_true_negatives: 57034064.0000 - val_false_negatives: 4635161.0000 - val_precision: 0.9144 - val_recall: 0.8973\n",
      "Epoch 453/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0463 - accuracy: 0.9625 - binary_iou: 0.9254 - true_positives: 125056312.0000 - false_positives: 5888395.0000 - true_negatives: 182474176.0000 - false_negatives: 6101830.0000 - precision: 0.9550 - recall: 0.9535 - val_loss: 0.0920 - val_accuracy: 0.9223 - val_binary_iou: 0.8531 - val_true_positives: 41069992.0000 - val_false_positives: 4167169.0000 - val_true_negatives: 56670016.0000 - val_false_negatives: 4064546.0000 - val_precision: 0.9079 - val_recall: 0.9099\n",
      "Epoch 454/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0471 - accuracy: 0.9620 - binary_iou: 0.9245 - true_positives: 124988480.0000 - false_positives: 6016529.0000 - true_negatives: 182389440.0000 - false_negatives: 6126312.0000 - precision: 0.9541 - recall: 0.9533 - val_loss: 0.0924 - val_accuracy: 0.9224 - val_binary_iou: 0.8534 - val_true_positives: 41289908.0000 - val_false_positives: 4311137.0000 - val_true_negatives: 56457836.0000 - val_false_negatives: 3912820.0000 - val_precision: 0.9055 - val_recall: 0.9134\n",
      "Epoch 455/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0459 - accuracy: 0.9629 - binary_iou: 0.9263 - true_positives: 125188688.0000 - false_positives: 5873586.0000 - true_negatives: 182478848.0000 - false_negatives: 5979737.0000 - precision: 0.9552 - recall: 0.9544 - val_loss: 0.0956 - val_accuracy: 0.9211 - val_binary_iou: 0.8503 - val_true_positives: 40132468.0000 - val_false_positives: 3269894.0000 - val_true_negatives: 57476612.0000 - val_false_negatives: 5092743.0000 - val_precision: 0.9247 - val_recall: 0.8874\n",
      "Epoch 456/500\n",
      "199/199 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9628 - binary_iou: 0.9260 - true_positives: 125027160.0000 - false_positives: 5864801.0000 - true_negatives: 182606640.0000 - false_negatives: 6022169.0000 - precision: 0.9552 - recall: 0.9540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/final_runs_checkpoints\\Final_NO_TL_rgbDrop_0_earlyStop_False_e500\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 107s 536ms/step - loss: 0.0459 - accuracy: 0.9628 - binary_iou: 0.9260 - true_positives: 125027160.0000 - false_positives: 5864801.0000 - true_negatives: 182606640.0000 - false_negatives: 6022169.0000 - precision: 0.9552 - recall: 0.9540 - val_loss: 0.0910 - val_accuracy: 0.9234 - val_binary_iou: 0.8550 - val_true_positives: 41134408.0000 - val_false_positives: 4181101.0000 - val_true_negatives: 56723196.0000 - val_false_negatives: 3933017.0000 - val_precision: 0.9077 - val_recall: 0.9127\n",
      "Epoch 457/500\n",
      "199/199 [==============================] - 91s 454ms/step - loss: 0.0459 - accuracy: 0.9629 - binary_iou: 0.9262 - true_positives: 125130440.0000 - false_positives: 5854961.0000 - true_negatives: 182528512.0000 - false_negatives: 6006818.0000 - precision: 0.9553 - recall: 0.9542 - val_loss: 0.0924 - val_accuracy: 0.9225 - val_binary_iou: 0.8533 - val_true_positives: 40846864.0000 - val_false_positives: 3963102.0000 - val_true_negatives: 56913104.0000 - val_false_negatives: 4248646.0000 - val_precision: 0.9116 - val_recall: 0.9058\n",
      "Epoch 458/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0457 - accuracy: 0.9630 - binary_iou: 0.9264 - true_positives: 125201424.0000 - false_positives: 5891243.0000 - true_negatives: 182485136.0000 - false_negatives: 5942967.0000 - precision: 0.9551 - recall: 0.9547 - val_loss: 0.0921 - val_accuracy: 0.9224 - val_binary_iou: 0.8534 - val_true_positives: 41219904.0000 - val_false_positives: 4345443.0000 - val_true_negatives: 56529960.0000 - val_false_negatives: 3876404.0000 - val_precision: 0.9046 - val_recall: 0.9140\n",
      "Epoch 459/500\n",
      "199/199 [==============================] - 90s 452ms/step - loss: 0.0455 - accuracy: 0.9632 - binary_iou: 0.9268 - true_positives: 125206672.0000 - false_positives: 5812317.0000 - true_negatives: 182545760.0000 - false_negatives: 5955986.0000 - precision: 0.9556 - recall: 0.9546 - val_loss: 0.0965 - val_accuracy: 0.9185 - val_binary_iou: 0.8465 - val_true_positives: 40884444.0000 - val_false_positives: 4363282.0000 - val_true_negatives: 56454468.0000 - val_false_negatives: 4269513.0000 - val_precision: 0.9036 - val_recall: 0.9054\n",
      "Epoch 460/500\n",
      "199/199 [==============================] - 90s 453ms/step - loss: 0.0470 - accuracy: 0.9621 - binary_iou: 0.9247 - true_positives: 124988496.0000 - false_positives: 5941938.0000 - true_negatives: 182414480.0000 - false_negatives: 6175919.0000 - precision: 0.9546 - recall: 0.9529 - val_loss: 0.0966 - val_accuracy: 0.9181 - val_binary_iou: 0.8462 - val_true_positives: 41415772.0000 - val_false_positives: 4995370.0000 - val_true_negatives: 55877848.0000 - val_false_negatives: 3682716.0000 - val_precision: 0.8924 - val_recall: 0.9183\n",
      "Epoch 461/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0461 - accuracy: 0.9628 - binary_iou: 0.9261 - true_positives: 125181680.0000 - false_positives: 5943224.0000 - true_negatives: 182456912.0000 - false_negatives: 5938935.0000 - precision: 0.9547 - recall: 0.9547 - val_loss: 0.0945 - val_accuracy: 0.9218 - val_binary_iou: 0.8518 - val_true_positives: 40470016.0000 - val_false_positives: 3728073.0000 - val_true_negatives: 57216632.0000 - val_false_negatives: 4557015.0000 - val_precision: 0.9157 - val_recall: 0.8988\n",
      "Epoch 462/500\n",
      "199/199 [==============================] - 89s 446ms/step - loss: 0.0452 - accuracy: 0.9635 - binary_iou: 0.9273 - true_positives: 125209664.0000 - false_positives: 5767946.0000 - true_negatives: 182633664.0000 - false_negatives: 5909526.0000 - precision: 0.9560 - recall: 0.9549 - val_loss: 0.0913 - val_accuracy: 0.9229 - val_binary_iou: 0.8542 - val_true_positives: 41214224.0000 - val_false_positives: 4198297.0000 - val_true_negatives: 56584424.0000 - val_false_negatives: 3974778.0000 - val_precision: 0.9076 - val_recall: 0.9120\n",
      "Epoch 463/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0459 - accuracy: 0.9629 - binary_iou: 0.9262 - true_positives: 125151976.0000 - false_positives: 5918097.0000 - true_negatives: 182499792.0000 - false_negatives: 5950824.0000 - precision: 0.9548 - recall: 0.9546 - val_loss: 0.0907 - val_accuracy: 0.9233 - val_binary_iou: 0.8550 - val_true_positives: 41313564.0000 - val_false_positives: 4293921.0000 - val_true_negatives: 56531016.0000 - val_false_negatives: 3833212.0000 - val_precision: 0.9059 - val_recall: 0.9151\n",
      "Epoch 464/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0463 - accuracy: 0.9625 - binary_iou: 0.9256 - true_positives: 125081496.0000 - false_positives: 5913259.0000 - true_negatives: 182470768.0000 - false_negatives: 6055216.0000 - precision: 0.9549 - recall: 0.9538 - val_loss: 0.0962 - val_accuracy: 0.9186 - val_binary_iou: 0.8468 - val_true_positives: 41203008.0000 - val_false_positives: 4786589.0000 - val_true_negatives: 56138672.0000 - val_false_negatives: 3843447.0000 - val_precision: 0.8959 - val_recall: 0.9147\n",
      "Epoch 465/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0453 - accuracy: 0.9635 - binary_iou: 0.9275 - true_positives: 125172096.0000 - false_positives: 5737543.0000 - true_negatives: 182701328.0000 - false_negatives: 5909791.0000 - precision: 0.9562 - recall: 0.9549 - val_loss: 0.0914 - val_accuracy: 0.9229 - val_binary_iou: 0.8542 - val_true_positives: 41324564.0000 - val_false_positives: 4396504.0000 - val_true_negatives: 56472688.0000 - val_false_negatives: 3777952.0000 - val_precision: 0.9038 - val_recall: 0.9162\n",
      "Epoch 466/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0446 - accuracy: 0.9639 - binary_iou: 0.9282 - true_positives: 125299872.0000 - false_positives: 5717668.0000 - true_negatives: 182700912.0000 - false_negatives: 5802306.0000 - precision: 0.9564 - recall: 0.9557 - val_loss: 0.0945 - val_accuracy: 0.9206 - val_binary_iou: 0.8500 - val_true_positives: 40939860.0000 - val_false_positives: 4444410.0000 - val_true_negatives: 56613472.0000 - val_false_negatives: 3973975.0000 - val_precision: 0.9021 - val_recall: 0.9115\n",
      "Epoch 467/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0458 - accuracy: 0.9629 - binary_iou: 0.9263 - true_positives: 125067968.0000 - false_positives: 5796283.0000 - true_negatives: 182613888.0000 - false_negatives: 6042596.0000 - precision: 0.9557 - recall: 0.9539 - val_loss: 0.0925 - val_accuracy: 0.9228 - val_binary_iou: 0.8537 - val_true_positives: 40883904.0000 - val_false_positives: 3983488.0000 - val_true_negatives: 56902172.0000 - val_false_negatives: 4202139.0000 - val_precision: 0.9112 - val_recall: 0.9068\n",
      "Epoch 468/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0449 - accuracy: 0.9639 - binary_iou: 0.9281 - true_positives: 125306640.0000 - false_positives: 5724231.0000 - true_negatives: 182667904.0000 - false_negatives: 5822005.0000 - precision: 0.9563 - recall: 0.9556 - val_loss: 0.0952 - val_accuracy: 0.9197 - val_binary_iou: 0.8486 - val_true_positives: 41092560.0000 - val_false_positives: 4479211.0000 - val_true_negatives: 56369544.0000 - val_false_negatives: 4030396.0000 - val_precision: 0.9017 - val_recall: 0.9107\n",
      "Epoch 469/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0454 - accuracy: 0.9634 - binary_iou: 0.9272 - true_positives: 125271736.0000 - false_positives: 5785094.0000 - true_negatives: 182559664.0000 - false_negatives: 5904280.0000 - precision: 0.9559 - recall: 0.9550 - val_loss: 0.0963 - val_accuracy: 0.9202 - val_binary_iou: 0.8490 - val_true_positives: 40320976.0000 - val_false_positives: 3634209.0000 - val_true_negatives: 57197316.0000 - val_false_negatives: 4819203.0000 - val_precision: 0.9173 - val_recall: 0.8932\n",
      "Epoch 470/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0456 - accuracy: 0.9632 - binary_iou: 0.9267 - true_positives: 125162240.0000 - false_positives: 5819406.0000 - true_negatives: 182588576.0000 - false_negatives: 5950589.0000 - precision: 0.9556 - recall: 0.9546 - val_loss: 0.0928 - val_accuracy: 0.9217 - val_binary_iou: 0.8521 - val_true_positives: 41184536.0000 - val_false_positives: 4411620.0000 - val_true_negatives: 56491208.0000 - val_false_negatives: 3884357.0000 - val_precision: 0.9032 - val_recall: 0.9138\n",
      "Epoch 471/500\n",
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0444 - accuracy: 0.9641 - binary_iou: 0.9285 - true_positives: 125302560.0000 - false_positives: 5658295.0000 - true_negatives: 182744064.0000 - false_negatives: 5815860.0000 - precision: 0.9568 - recall: 0.9556 - val_loss: 0.0920 - val_accuracy: 0.9221 - val_binary_iou: 0.8529 - val_true_positives: 41147584.0000 - val_false_positives: 4286312.0000 - val_true_negatives: 56573828.0000 - val_false_negatives: 3963981.0000 - val_precision: 0.9057 - val_recall: 0.9121\n",
      "Epoch 472/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0441 - accuracy: 0.9643 - binary_iou: 0.9290 - true_positives: 125333024.0000 - false_positives: 5614145.0000 - true_negatives: 182792016.0000 - false_negatives: 5781538.0000 - precision: 0.9571 - recall: 0.9559 - val_loss: 0.0940 - val_accuracy: 0.9215 - val_binary_iou: 0.8517 - val_true_positives: 41042512.0000 - val_false_positives: 4246712.0000 - val_true_negatives: 56609940.0000 - val_false_negatives: 4072563.0000 - val_precision: 0.9062 - val_recall: 0.9097\n",
      "Epoch 473/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0444 - accuracy: 0.9640 - binary_iou: 0.9284 - true_positives: 125391984.0000 - false_positives: 5715765.0000 - true_negatives: 182638704.0000 - false_negatives: 5774471.0000 - precision: 0.9564 - recall: 0.9560 - val_loss: 0.0986 - val_accuracy: 0.9166 - val_binary_iou: 0.8431 - val_true_positives: 40803296.0000 - val_false_positives: 4517257.0000 - val_true_negatives: 56325148.0000 - val_false_negatives: 4326005.0000 - val_precision: 0.9003 - val_recall: 0.9041\n",
      "Epoch 474/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0445 - accuracy: 0.9641 - binary_iou: 0.9285 - true_positives: 125293072.0000 - false_positives: 5674714.0000 - true_negatives: 182751776.0000 - false_negatives: 5801309.0000 - precision: 0.9567 - recall: 0.9557 - val_loss: 0.0937 - val_accuracy: 0.9214 - val_binary_iou: 0.8515 - val_true_positives: 41005508.0000 - val_false_positives: 4173223.0000 - val_true_negatives: 56637452.0000 - val_false_negatives: 4155511.0000 - val_precision: 0.9076 - val_recall: 0.9080\n",
      "Epoch 475/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0442 - accuracy: 0.9643 - binary_iou: 0.9289 - true_positives: 125387304.0000 - false_positives: 5640180.0000 - true_negatives: 182725040.0000 - false_negatives: 5768333.0000 - precision: 0.9570 - recall: 0.9560 - val_loss: 0.0926 - val_accuracy: 0.9225 - val_binary_iou: 0.8533 - val_true_positives: 40987296.0000 - val_false_positives: 4151222.0000 - val_true_negatives: 56770984.0000 - val_false_negatives: 4062196.0000 - val_precision: 0.9080 - val_recall: 0.9098\n",
      "Epoch 476/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0446 - accuracy: 0.9640 - binary_iou: 0.9283 - true_positives: 125326744.0000 - false_positives: 5670913.0000 - true_negatives: 182676144.0000 - false_negatives: 5846965.0000 - precision: 0.9567 - recall: 0.9554 - val_loss: 0.0991 - val_accuracy: 0.9177 - val_binary_iou: 0.8445 - val_true_positives: 40034472.0000 - val_false_positives: 3713382.0000 - val_true_negatives: 57217496.0000 - val_false_negatives: 5006383.0000 - val_precision: 0.9151 - val_recall: 0.8888\n",
      "Epoch 477/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0476 - accuracy: 0.9616 - binary_iou: 0.9237 - true_positives: 125030056.0000 - false_positives: 6176614.0000 - true_negatives: 182210176.0000 - false_negatives: 6103860.0000 - precision: 0.9529 - recall: 0.9535 - val_loss: 0.1028 - val_accuracy: 0.9135 - val_binary_iou: 0.8379 - val_true_positives: 40742296.0000 - val_false_positives: 4812386.0000 - val_true_negatives: 56064556.0000 - val_false_negatives: 4352476.0000 - val_precision: 0.8944 - val_recall: 0.9035\n",
      "Epoch 478/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0451 - accuracy: 0.9636 - binary_iou: 0.9275 - true_positives: 125297648.0000 - false_positives: 5789405.0000 - true_negatives: 182584032.0000 - false_negatives: 5849693.0000 - precision: 0.9558 - recall: 0.9554 - val_loss: 0.0947 - val_accuracy: 0.9220 - val_binary_iou: 0.8522 - val_true_positives: 40552300.0000 - val_false_positives: 3803720.0000 - val_true_negatives: 57158744.0000 - val_false_negatives: 4456958.0000 - val_precision: 0.9142 - val_recall: 0.9010\n",
      "Epoch 479/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0449 - accuracy: 0.9637 - binary_iou: 0.9278 - true_positives: 125258984.0000 - false_positives: 5702158.0000 - true_negatives: 182664080.0000 - false_negatives: 5895572.0000 - precision: 0.9565 - recall: 0.9550 - val_loss: 0.0921 - val_accuracy: 0.9216 - val_binary_iou: 0.8521 - val_true_positives: 41488084.0000 - val_false_positives: 4736748.0000 - val_true_negatives: 56174912.0000 - val_false_negatives: 3571961.0000 - val_precision: 0.8975 - val_recall: 0.9207\n",
      "Epoch 480/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0439 - accuracy: 0.9644 - binary_iou: 0.9291 - true_positives: 125376528.0000 - false_positives: 5624431.0000 - true_negatives: 182769392.0000 - false_negatives: 5750342.0000 - precision: 0.9571 - recall: 0.9561 - val_loss: 0.0939 - val_accuracy: 0.9225 - val_binary_iou: 0.8528 - val_true_positives: 40341404.0000 - val_false_positives: 3493397.0000 - val_true_negatives: 57414712.0000 - val_false_negatives: 4722202.0000 - val_precision: 0.9203 - val_recall: 0.8952\n",
      "Epoch 481/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0435 - accuracy: 0.9651 - binary_iou: 0.9305 - true_positives: 125448936.0000 - false_positives: 5514700.0000 - true_negatives: 182927376.0000 - false_negatives: 5629764.0000 - precision: 0.9579 - recall: 0.9571 - val_loss: 0.0928 - val_accuracy: 0.9223 - val_binary_iou: 0.8527 - val_true_positives: 40668516.0000 - val_false_positives: 3831390.0000 - val_true_negatives: 57064804.0000 - val_false_negatives: 4406990.0000 - val_precision: 0.9139 - val_recall: 0.9022\n",
      "Epoch 482/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0425 - accuracy: 0.9657 - binary_iou: 0.9315 - true_positives: 125552384.0000 - false_positives: 5438537.0000 - true_negatives: 182993856.0000 - false_negatives: 5535947.0000 - precision: 0.9585 - recall: 0.9578 - val_loss: 0.0951 - val_accuracy: 0.9215 - val_binary_iou: 0.8511 - val_true_positives: 40234336.0000 - val_false_positives: 3493945.0000 - val_true_negatives: 57418844.0000 - val_false_negatives: 4824591.0000 - val_precision: 0.9201 - val_recall: 0.8929\n",
      "Epoch 483/500\n",
      "199/199 [==============================] - 90s 449ms/step - loss: 0.0427 - accuracy: 0.9655 - binary_iou: 0.9313 - true_positives: 125478736.0000 - false_positives: 5439641.0000 - true_negatives: 183025808.0000 - false_negatives: 5576598.0000 - precision: 0.9585 - recall: 0.9574 - val_loss: 0.0936 - val_accuracy: 0.9233 - val_binary_iou: 0.8543 - val_true_positives: 40508476.0000 - val_false_positives: 3486062.0000 - val_true_negatives: 57333456.0000 - val_false_negatives: 4643726.0000 - val_precision: 0.9208 - val_recall: 0.8972\n",
      "Epoch 484/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0434 - accuracy: 0.9649 - binary_iou: 0.9302 - true_positives: 125488272.0000 - false_positives: 5538416.0000 - true_negatives: 182830096.0000 - false_negatives: 5663976.0000 - precision: 0.9577 - recall: 0.9568 - val_loss: 0.0939 - val_accuracy: 0.9219 - val_binary_iou: 0.8520 - val_true_positives: 40664088.0000 - val_false_positives: 3918204.0000 - val_true_negatives: 57028652.0000 - val_false_negatives: 4360769.0000 - val_precision: 0.9121 - val_recall: 0.9031\n",
      "Epoch 485/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0429 - accuracy: 0.9652 - binary_iou: 0.9306 - true_positives: 125550528.0000 - false_positives: 5482648.0000 - true_negatives: 182847728.0000 - false_negatives: 5639852.0000 - precision: 0.9582 - recall: 0.9570 - val_loss: 0.0916 - val_accuracy: 0.9217 - val_binary_iou: 0.8524 - val_true_positives: 41540152.0000 - val_false_positives: 4701400.0000 - val_true_negatives: 56133764.0000 - val_false_negatives: 3596403.0000 - val_precision: 0.8983 - val_recall: 0.9203\n",
      "Epoch 486/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0430 - accuracy: 0.9653 - binary_iou: 0.9308 - true_positives: 125450632.0000 - false_positives: 5451078.0000 - true_negatives: 182969568.0000 - false_negatives: 5649486.0000 - precision: 0.9584 - recall: 0.9569 - val_loss: 0.0911 - val_accuracy: 0.9235 - val_binary_iou: 0.8550 - val_true_positives: 40952440.0000 - val_false_positives: 3949485.0000 - val_true_negatives: 56909672.0000 - val_false_negatives: 4160114.0000 - val_precision: 0.9120 - val_recall: 0.9078\n",
      "Epoch 487/500\n",
      "199/199 [==============================] - 91s 456ms/step - loss: 0.0437 - accuracy: 0.9647 - binary_iou: 0.9297 - true_positives: 125392736.0000 - false_positives: 5551366.0000 - true_negatives: 182844832.0000 - false_negatives: 5731777.0000 - precision: 0.9576 - recall: 0.9563 - val_loss: 0.0950 - val_accuracy: 0.9210 - val_binary_iou: 0.8507 - val_true_positives: 40894704.0000 - val_false_positives: 4117771.0000 - val_true_negatives: 56706328.0000 - val_false_negatives: 4252913.0000 - val_precision: 0.9085 - val_recall: 0.9058\n",
      "Epoch 488/500\n",
      "199/199 [==============================] - 89s 448ms/step - loss: 0.0443 - accuracy: 0.9642 - binary_iou: 0.9288 - true_positives: 125340864.0000 - false_positives: 5660075.0000 - true_negatives: 182744640.0000 - false_negatives: 5775095.0000 - precision: 0.9568 - recall: 0.9560 - val_loss: 0.0930 - val_accuracy: 0.9219 - val_binary_iou: 0.8522 - val_true_positives: 40970160.0000 - val_false_positives: 4156918.0000 - val_true_negatives: 56721488.0000 - val_false_negatives: 4123152.0000 - val_precision: 0.9079 - val_recall: 0.9086\n",
      "Epoch 489/500\n",
      "199/199 [==============================] - 90s 451ms/step - loss: 0.0435 - accuracy: 0.9649 - binary_iou: 0.9301 - true_positives: 125485520.0000 - false_positives: 5541205.0000 - true_negatives: 182828992.0000 - false_negatives: 5665006.0000 - precision: 0.9577 - recall: 0.9568 - val_loss: 0.0920 - val_accuracy: 0.9229 - val_binary_iou: 0.8540 - val_true_positives: 40842472.0000 - val_false_positives: 3911081.0000 - val_true_negatives: 56962212.0000 - val_false_negatives: 4255950.0000 - val_precision: 0.9126 - val_recall: 0.9056\n",
      "Epoch 490/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0424 - accuracy: 0.9657 - binary_iou: 0.9316 - true_positives: 125517888.0000 - false_positives: 5378848.0000 - true_negatives: 183048352.0000 - false_negatives: 5575578.0000 - precision: 0.9589 - recall: 0.9575 - val_loss: 0.0925 - val_accuracy: 0.9221 - val_binary_iou: 0.8529 - val_true_positives: 41177100.0000 - val_false_positives: 4403061.0000 - val_true_negatives: 56544196.0000 - val_false_negatives: 3847348.0000 - val_precision: 0.9034 - val_recall: 0.9145\n",
      "Epoch 491/500\n",
      "199/199 [==============================] - 89s 449ms/step - loss: 0.0426 - accuracy: 0.9655 - binary_iou: 0.9312 - true_positives: 125523840.0000 - false_positives: 5431796.0000 - true_negatives: 182970320.0000 - false_negatives: 5594759.0000 - precision: 0.9585 - recall: 0.9573 - val_loss: 0.0934 - val_accuracy: 0.9216 - val_binary_iou: 0.8519 - val_true_positives: 41040080.0000 - val_false_positives: 4239574.0000 - val_true_negatives: 56626360.0000 - val_false_negatives: 4065713.0000 - val_precision: 0.9064 - val_recall: 0.9099\n",
      "Epoch 492/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0422 - accuracy: 0.9659 - binary_iou: 0.9320 - true_positives: 125605152.0000 - false_positives: 5409941.0000 - true_negatives: 183022960.0000 - false_negatives: 5482672.0000 - precision: 0.9587 - recall: 0.9582 - val_loss: 0.0966 - val_accuracy: 0.9203 - val_binary_iou: 0.8490 - val_true_positives: 40202424.0000 - val_false_positives: 3479556.0000 - val_true_negatives: 57323384.0000 - val_false_negatives: 4966353.0000 - val_precision: 0.9203 - val_recall: 0.8900\n",
      "Epoch 493/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0421 - accuracy: 0.9660 - binary_iou: 0.9322 - true_positives: 125599632.0000 - false_positives: 5390800.0000 - true_negatives: 183051984.0000 - false_negatives: 5478317.0000 - precision: 0.9588 - recall: 0.9582 - val_loss: 0.0941 - val_accuracy: 0.9216 - val_binary_iou: 0.8518 - val_true_positives: 41094876.0000 - val_false_positives: 4340845.0000 - val_true_negatives: 56564248.0000 - val_false_negatives: 3971739.0000 - val_precision: 0.9045 - val_recall: 0.9119\n",
      "Epoch 494/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0428 - accuracy: 0.9655 - binary_iou: 0.9312 - true_positives: 125612752.0000 - false_positives: 5445524.0000 - true_negatives: 182870544.0000 - false_negatives: 5591964.0000 - precision: 0.9584 - recall: 0.9574 - val_loss: 0.0957 - val_accuracy: 0.9215 - val_binary_iou: 0.8508 - val_true_positives: 39987292.0000 - val_false_positives: 3204436.0000 - val_true_negatives: 57663080.0000 - val_false_negatives: 5116913.0000 - val_precision: 0.9258 - val_recall: 0.8866\n",
      "Epoch 495/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0427 - accuracy: 0.9656 - binary_iou: 0.9315 - true_positives: 125601736.0000 - false_positives: 5469329.0000 - true_negatives: 182934224.0000 - false_negatives: 5515352.0000 - precision: 0.9583 - recall: 0.9579 - val_loss: 0.0908 - val_accuracy: 0.9226 - val_binary_iou: 0.8538 - val_true_positives: 41548184.0000 - val_false_positives: 4636988.0000 - val_true_negatives: 56217336.0000 - val_false_negatives: 3569199.0000 - val_precision: 0.8996 - val_recall: 0.9209\n",
      "Epoch 496/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0428 - accuracy: 0.9656 - binary_iou: 0.9314 - true_positives: 125534936.0000 - false_positives: 5440138.0000 - true_negatives: 182986736.0000 - false_negatives: 5558977.0000 - precision: 0.9585 - recall: 0.9576 - val_loss: 0.0936 - val_accuracy: 0.9220 - val_binary_iou: 0.8523 - val_true_positives: 40774288.0000 - val_false_positives: 3957043.0000 - val_true_negatives: 56932244.0000 - val_false_negatives: 4308143.0000 - val_precision: 0.9115 - val_recall: 0.9044\n",
      "Epoch 497/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0418 - accuracy: 0.9662 - binary_iou: 0.9326 - true_positives: 125678976.0000 - false_positives: 5351874.0000 - true_negatives: 183042800.0000 - false_negatives: 5447158.0000 - precision: 0.9592 - recall: 0.9585 - val_loss: 0.0926 - val_accuracy: 0.9223 - val_binary_iou: 0.8530 - val_true_positives: 40878104.0000 - val_false_positives: 4076212.0000 - val_true_negatives: 56862528.0000 - val_false_negatives: 4154859.0000 - val_precision: 0.9093 - val_recall: 0.9077\n",
      "Epoch 498/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0428 - accuracy: 0.9655 - binary_iou: 0.9313 - true_positives: 125502312.0000 - false_positives: 5453302.0000 - true_negatives: 183008304.0000 - false_negatives: 5556917.0000 - precision: 0.9584 - recall: 0.9576 - val_loss: 0.0930 - val_accuracy: 0.9220 - val_binary_iou: 0.8526 - val_true_positives: 41098708.0000 - val_false_positives: 4319418.0000 - val_true_negatives: 56606408.0000 - val_false_negatives: 3947185.0000 - val_precision: 0.9049 - val_recall: 0.9124\n",
      "Epoch 499/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0420 - accuracy: 0.9661 - binary_iou: 0.9323 - true_positives: 125672560.0000 - false_positives: 5364440.0000 - true_negatives: 183005472.0000 - false_negatives: 5478350.0000 - precision: 0.9591 - recall: 0.9582 - val_loss: 0.0940 - val_accuracy: 0.9224 - val_binary_iou: 0.8530 - val_true_positives: 40709324.0000 - val_false_positives: 3899442.0000 - val_true_negatives: 57038384.0000 - val_false_negatives: 4324557.0000 - val_precision: 0.9126 - val_recall: 0.9040\n",
      "Epoch 500/500\n",
      "199/199 [==============================] - 90s 450ms/step - loss: 0.0413 - accuracy: 0.9666 - binary_iou: 0.9333 - true_positives: 125707936.0000 - false_positives: 5283518.0000 - true_negatives: 183132320.0000 - false_negatives: 5396856.0000 - precision: 0.9597 - recall: 0.9588 - val_loss: 0.0931 - val_accuracy: 0.9216 - val_binary_iou: 0.8518 - val_true_positives: 41017876.0000 - val_false_positives: 4229544.0000 - val_true_negatives: 56646232.0000 - val_false_negatives: 4078053.0000 - val_precision: 0.9065 - val_recall: 0.9096\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix, early_stop)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "# Kopie der ursprünglichen Log, da Fine-tuning-Log sie überschreibt\n",
    "shutil.copy(f'../output/{output_folder_prefix}_logger/{model_name}.log', f'../output/{output_folder_prefix}_logger/{model_name}_I.log', follow_symlinks=True)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "# \n",
    "if pretrained_weights != 'NO_TL':\n",
    "    set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= initial_epochs)\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 12s 133ms/step - loss: 574.0284 - accuracy: 0.9211 - binary_iou: 0.8503 - true_positives: 40104336.0000 - false_positives: 4276853.0000 - true_negatives: 57507880.0000 - false_negatives: 4082633.0000 - precision: 0.9036 - recall: 0.9076\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zusammenführen von Training- und Fine-Tuning-History\n",
    "iou = model_history.history['binary_iou']\n",
    "iou += history_fine.history['binary_iou']\n",
    "\n",
    "val_iou = model_history.history['val_binary_iou']\n",
    "val_iou += history_fine.history['val_binary_iou']\n",
    "\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "eval_out_path = '../output/final_runs.csv'\n",
    "# Anlegen der Datei für ersten Durchlauf\n",
    "if not os.path.isfile(FT_output_path):\n",
    "    with open(eval_out_path, 'w', newline='') as f_object:\n",
    "        writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "        header = ['model_name', 'loss', 'accuracy', 'binary_iou', 'true_pos', 'false_pos', 'true_neg', 'false_neg', 'precision', 'recall', 'training_time [min]', 'max_val_iou', 'idx_max_val_iou' ]\n",
    "        writer_object.writerow(header)\n",
    "\n",
    "        row = []\n",
    "    \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)            \n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "# Anhängen an Datei für weitere Durchläufe\n",
    "else:\n",
    "    with open(FT_output_path, 'a', newline='') as f_object:\n",
    "        row = []\n",
    "        \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)\n",
    "\n",
    "        # Einfügen der Trainingszeit in Minuten\n",
    "        row.append(training_time/60)\n",
    "\n",
    "        # Einfügen der maximalen Val-IoU\n",
    "        row.append(max(val_iou))\n",
    "\n",
    "        # Einfügen des Index der maximalen Val-IoU\n",
    "        row.append(np.argmax(val_iou))\n",
    "\n",
    "        writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Schreiben der Eval-Ergebnisse in csv\n",
    "with open('../output/final_runs.csv', 'a') as f_object:\n",
    "    row = []\n",
    "    \n",
    "    row.append(model_name)\n",
    "\n",
    "    for x in eval_out:\n",
    "        row.append(x)\n",
    "\n",
    "    # Einfügen der Trainingszeit in Minuten\n",
    "    row.append(training_time/60)\n",
    "\n",
    "    # Einfügen der maximalen Val-IoU\n",
    "    row.append(max(val_iou))\n",
    "\n",
    "    # Einfügen des Index der maximalen Val-IoU\n",
    "    row.append(np.argmax(val_iou))\n",
    "\n",
    "    writer_object = csv.writer(f_object, delimiter= ';')\n",
    "\n",
    "    writer_object.writerow(row)\n",
    "\"\"\"\n",
    "\n",
    "# Plotten\n",
    "epochs = range(1, len(val_iou)+1)\n",
    "\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], iou[0:(len(val_iou) - 1)], 'g', label= 'Training IoU')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_iou[0:(len(val_iou) - 1)], 'b', label= 'Validation IoU')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'../output/plots/IoU/iou_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACKG0lEQVR4nO3dd1QU198G8GcXpFcBKYqiiCIqNpTYjRJBjbEllpioJLFrNGoSjbFrsMUYNbHGGmP92WLsxN4bVlQkKBZAUelS975/zMsuS6+7IM/nnDns3Llz586wOl9umZEJIQSIiIiIyhG5titAREREpGkMgIiIiKjcYQBERERE5Q4DICIiIip3GAARERFRucMAiIiIiModBkBERERU7jAAIiIionKHARARERGVOwyAiMqgQYMGwcnJqVD7Tp8+HTKZrHgrVMadOHECMpkMJ06cUKbl9xo/evQIMpkM69evL9Y6OTk5YdCgQcVaJhGpMAAiKkYymSxfS8YbbXmjUCiwcOFCuLi4wNDQEM7Ozhg+fDji4uLytb+7uzuqVq2K3N7i07JlS9ja2iI1NbW4ql0izp07h+nTpyMqKkrbVVFav349ZDIZrly5ou2qEJUoXW1XgOhdsmnTJrX1jRs34ujRo1nS69SpU6TjrF69GgqFolD7/vjjj5g4cWKRjl8Uv/76K7799lt0794d3377LR4/fowtW7bg+++/h4mJSZ779+/fHxMnTsTp06fRpk2bLNsfPXqE8+fPY9SoUdDVLfx/cUW5xvl17tw5zJgxA4MGDYKFhYXatvv370Mu59+oRCWFARBRMfrss8/U1i9cuICjR49mSc8sISEBRkZG+T5OhQoVClU/ANDV1S1SYFBUW7duRd26dbFr1y5lV9ysWbPyHWx8+umnmDRpEv76669sA6AtW7ZACIH+/fsXqZ5FucbFQV9fX6vHJ3rX8c8LIg1r164d6tWrh6tXr6JNmzYwMjLCDz/8AADYu3cvunTpAgcHB+jr68PZ2RmzZs1CWlqaWhmZx6ekj0NZuHAhVq1aBWdnZ+jr66Np06a4fPmy2r7ZjQGSyWQYNWoU9uzZg3r16kFfXx9169bFoUOHstT/xIkT8PDwgIGBAZydnbFy5coCjSuSy+VQKBRq+eVyeb6DMkdHR7Rp0wY7d+5ESkpKlu1//fUXnJ2d4enpicePH2PEiBGoXbs2DA0NYWVlhU8++QSPHj3K8zjZjQGKiorCoEGDYG5uDgsLCwwcODDb7qubN29i0KBBqFGjBgwMDGBnZ4cvvvgCr169UuaZPn06vv32WwBA9erVld2j6XXLbgzQf//9h08++QQVK1aEkZER3nvvPfzzzz9qedLHM23fvh1z5sxBlSpVYGBggA4dOuDhw4d5nnd+Xb9+HZ06dYKZmRlMTEzQoUMHXLhwQS1PSkoKZsyYARcXFxgYGMDKygqtWrXC0aNHlXnCw8Ph6+uLKlWqQF9fH/b29ujWrVu+fkdERcEWICItePXqFTp16oS+ffvis88+g62tLQBp/IWJiQnGjRsHExMT/Pvvv5g6dSpiYmKwYMGCPMv966+/EBsbi6FDh0Imk2H+/Pno2bMn/vvvvzxbNM6cOYNdu3ZhxIgRMDU1xZIlS9CrVy+EhobCysoKgHTT8/Hxgb29PWbMmIG0tDTMnDkTNjY2+T53X19fDB06FCtXrsTQoUPzvV9G/fv3x5AhQ3D48GF8+OGHyvRbt27h9u3bmDp1KgDg8uXLOHfuHPr27YsqVarg0aNHWL58Odq1a4e7d+8WqNVNCIFu3brhzJkzGDZsGOrUqYPdu3dj4MCBWfIePXoU//33H3x9fWFnZ4c7d+5g1apVuHPnDi5cuACZTIaePXviwYMH2LJlC3755RdYW1sDQI7XMiIiAi1atEBCQgK+/vprWFlZYcOGDfjoo4+wc+dO9OjRQy3/3LlzIZfLMWHCBERHR2P+/Pno378/Ll68mO9zzsmdO3fQunVrmJmZ4bvvvkOFChWwcuVKtGvXDidPnoSnpycAKcjz8/PDV199hWbNmiEmJgZXrlzBtWvX8MEHHwAAevXqhTt37mD06NFwcnLCixcvcPToUYSGhhZ6oD9RvggiKjEjR44Umf+ZtW3bVgAQK1asyJI/ISEhS9rQoUOFkZGRSExMVKYNHDhQVKtWTbkeEhIiAAgrKyvx+vVrZfrevXsFAPH3338r06ZNm5alTgCEnp6eePjwoTLtxo0bAoBYunSpMq1r167CyMhIPHv2TJkWFBQkdHV1s5SZk4kTJwo9PT2ho6Mjdu3ala99Mnv9+rXQ19cX/fr1y1I2AHH//n0hRPbX8/z58wKA2LhxozLt+PHjAoA4fvy4Mi3zNd6zZ48AIObPn69MS01NFa1btxYAxLp165Tp2R13y5YtAoA4deqUMm3BggUCgAgJCcmSv1q1amLgwIHK9bFjxwoA4vTp08q02NhYUb16deHk5CTS0tLUzqVOnToiKSlJmffXX38VAMStW7eyHCujdevWCQDi8uXLOebp3r270NPTE8HBwcq058+fC1NTU9GmTRtlWoMGDUSXLl1yLOfNmzcCgFiwYEGudSIqCewCI9ICfX19+Pr6Zkk3NDRUfo6NjUVkZCRat26NhIQE3Lt3L89y+/TpA0tLS+V669atAUhdJ3nx8vKCs7Ozct3d3R1mZmbKfdPS0nDs2DF0794dDg4Oynw1a9ZEp06d8iwfAJYsWYJFixbh7Nmz6NevH/r27YsjR46o5dHX18eUKVNyLcfS0hKdO3fGvn37EB8fD0Bqodm6dSs8PDxQq1YtAOrXMyUlBa9evULNmjVhYWGBa9eu5avO6Q4cOABdXV0MHz5cmaajo4PRo0dnyZvxuImJiYiMjMR7770HAAU+bsbjN2vWDK1atVKmmZiYYMiQIXj06BHu3r2rlt/X1xd6enrK9YJ8F3KTlpaGI0eOoHv37qhRo4Yy3d7eHp9++inOnDmDmJgYAICFhQXu3LmDoKCgbMsyNDSEnp4eTpw4gTdv3hSpXkQFxQCISAsqV66sdnNKd+fOHfTo0QPm5uYwMzODjY2NcgB1dHR0nuVWrVpVbT09GMrPzSXzvun7p+/74sULvH37FjVr1sySL7u0zN6+fYtp06bhq6++goeHB9atW4f27dujR48eOHPmDAAgKCgIycnJyi6U3PTv3x/x8fHYu3cvAGlG1aNHj9QGP799+xZTp06Fo6Mj9PX1YW1tDRsbG0RFReXremb0+PFj2NvbZ5mpVrt27Sx5X79+jTFjxsDW1haGhoawsbFB9erVAeTv95jT8bM7VvqMwsePH6ulF+W7kJuXL18iISEhx7ooFAo8efIEADBz5kxERUWhVq1aqF+/Pr799lvcvHlTmV9fXx/z5s3DwYMHYWtrizZt2mD+/PkIDw8vUh2J8oMBEJEWZGwhSBcVFYW2bdvixo0bmDlzJv7++28cPXoU8+bNA4B8zZLS0dHJNl3k8syc4tg3PwIDAxEVFaVsCdHV1cXOnTtRr149dOnSBdeuXcOqVatQqVIl5fiQ3Hz44YcwNzfHX3/9BUAa/6Sjo4O+ffsq84wePRpz5sxB7969sX37dhw5cgRHjx6FlZVViU5x7927N1avXo1hw4Zh165dOHLkiHJAeUlPrU9X0r/P/GjTpg2Cg4Oxdu1a1KtXD2vWrEHjxo2xZs0aZZ6xY8fiwYMH8PPzg4GBAaZMmYI6derg+vXrGqsnlU8cBE1USpw4cQKvXr3Crl271KZ3h4SEaLFWKpUqVYKBgUG2M4nyM7sofdZXeusAABgbG+PAgQNo1aoVvL29kZiYiNmzZ+drCri+vj4+/vhjbNy4EREREdixYwfat28POzs7ZZ6dO3di4MCB+Pnnn5VpiYmJhXrwYLVq1eDv74+4uDi1VqD79++r5Xvz5g38/f0xY8YM5WBsANl2AxXkidzVqlXLciwAyq7RatWq5busorCxsYGRkVGOdZHL5XB0dFSmVaxYEb6+vvD19UVcXBzatGmD6dOn46uvvlLmcXZ2xvjx4zF+/HgEBQWhYcOG+Pnnn/Hnn39q5JyofGILEFEpkf4Xe8a/0JOTk/H7779rq0pqdHR04OXlhT179uD58+fK9IcPH+LgwYN57l+/fn3Y2tpi2bJlePHihTLdysoK69atQ2RkJN6+fYuuXbvmu079+/dHSkoKhg4dipcvX2Z59o+Ojk6WFo+lS5dmeaxAfnTu3BmpqalYvny5Mi0tLQ1Lly7Nckwga0vL4sWLs5RpbGwMAPkKyDp37oxLly7h/PnzyrT4+HisWrUKTk5OcHNzy++pFImOjg46duyIvXv3qk1Vj4iIwF9//YVWrVrBzMwMANSm/QPSmKWaNWsiKSkJgPT8q8TERLU8zs7OMDU1VeYhKilsASIqJVq0aAFLS0sMHDgQX3/9NWQyGTZt2qTRLou8TJ8+HUeOHEHLli0xfPhwpKWlYdmyZahXrx4CAgJy3VdXVxfLli1Dnz59UL9+fQwdOhTVqlVDYGAg1q5di/r16+Pp06fo1q0bzp49q7yJ5qZt27aoUqUK9u7dC0NDQ/Ts2VNt+4cffohNmzbB3Nwcbm5uOH/+PI4dO6ac1l8QXbt2RcuWLTFx4kQ8evQIbm5u2LVrV5YxPWZmZsqxLCkpKahcuTKOHDmSbUtekyZNAACTJ09G3759UaFCBXTt2lUZGGU0ceJEbNmyBZ06dcLXX3+NihUrYsOGDQgJCcH//ve/Yn9q9Nq1a7N9DtSYMWMwe/ZsHD16FK1atcKIESOgq6uLlStXIikpCfPnz1fmdXNzQ7t27dCkSRNUrFgRV65cwc6dOzFq1CgAwIMHD9ChQwf07t0bbm5u0NXVxe7duxEREaHWlUlUIrQ3AY3o3ZfTNPi6detmm//s2bPivffeE4aGhsLBwUF899134vDhw3lO0U6fBp/ddGIAYtq0acr1nKbBjxw5Msu+madiCyGEv7+/aNSokdDT0xPOzs5izZo1Yvz48cLAwCCHq6Du1KlTwtvbW5iZmQl9fX1Rr1494efnJxISEsTBgweFXC4XHTt2FCkpKfkq79tvvxUARO/evbNse/PmjfD19RXW1tbCxMREeHt7i3v37mU5r/xMgxdCiFevXonPP/9cmJmZCXNzc/H555+L69evZ5kG//TpU9GjRw9hYWEhzM3NxSeffCKeP3+e5XchhBCzZs0SlStXFnK5XG1KfHbXPjg4WHz88cfCwsJCGBgYiGbNmon9+/er5Uk/lx07dqilp39HMtYzO+nT4HNanjx5IoQQ4tq1a8Lb21uYmJgIIyMj8f7774tz586plTV79mzRrFkzYWFhIQwNDYWrq6uYM2eOSE5OFkIIERkZKUaOHClcXV2FsbGxMDc3F56enmL79u251pGoOMiEKEV/XhJRmdS9e/dcpzsTEZU2HANERAXy9u1btfWgoCAcOHAA7dq1006FiIgKgS1ARFQg9vb2yvdcPX78GMuXL0dSUhKuX78OFxcXbVePiChfOAiaiArEx8cHW7ZsQXh4OPT19dG8eXP89NNPDH6IqExhCxARERGVOxwDREREROUOAyAiIiIqdzgGKBsKhQLPnz+HqalpgR5VT0RERNojhEBsbCwcHBzyfDgoA6BsPH/+XO1dNkRERFR2PHnyBFWqVMk1DwOgbJiamgKQLmB+HsdPRERE2hcTEwNHR0flfTw3DICykd7tZWZmxgCIiIiojMnP8BUOgiYiIqJyhwEQERERlTsMgIiIiKjc4RggIiLKlUKhQHJysrarQYQKFSpAR0enWMpiAERERDlKTk5GSEgIFAqFtqtCBACwsLCAnZ1dkZ/TxwCIiIiyJYRAWFgYdHR04OjomOeD5YhKkhACCQkJePHiBQDA3t6+SOUxACIiomylpqYiISEBDg4OMDIy0nZ1iGBoaAgAePHiBSpVqlSk7jCG80RElK20tDQAgJ6enpZrQqSSHoynpKQUqRwGQERElCu+E5FKk+L6PjIAIiIionKHARAREVEenJycsHjx4nznP3HiBGQyGaKiokqsTlQ0DICIiOidIZPJcl2mT59eqHIvX76MIUOG5Dt/ixYtEBYWBnNz80IdL78YaBUeZ4GVJUIACQnSZyMjgP3yRERqwsLClJ+3bduGqVOn4v79+8o0ExMT5WchBNLS0qCrm/et0MbGpkD10NPTg52dXYH2Ic1iC1BZkpAAmJhIS3ogRERESnZ2dsrF3NwcMplMuX7v3j2Ympri4MGDaNKkCfT19XHmzBkEBwejW7dusLW1hYmJCZo2bYpjx46plZu5C0wmk2HNmjXo0aMHjIyM4OLign379im3Z26ZWb9+PSwsLHD48GHUqVMHJiYm8PHxUQvYUlNT8fXXX8PCwgJWVlb4/vvvMXDgQHTv3r3Q1+PNmzcYMGAALC0tYWRkhE6dOiEoKEi5/fHjx+jatSssLS1hbGyMunXr4sCBA8p9+/fvDxsbGxgaGsLFxQXr1q0rdF1KGwZARESUL0IIxCfHa2URQhTbeUycOBFz585FYGAg3N3dERcXh86dO8Pf3x/Xr1+Hj48PunbtitDQ0FzLmTFjBnr37o2bN2+ic+fO6N+/P16/fp1j/oSEBCxcuBCbNm3CqVOnEBoaigkTJii3z5s3D5s3b8a6detw9uxZxMTEYM+ePUU610GDBuHKlSvYt28fzp8/DyEEOnfurJxCPnLkSCQlJeHUqVO4desW5s2bp2wlmzJlCu7evYuDBw8iMDAQy5cvh7W1dZHqU5qwC4yIiPIlISUBJn4meWcsAXGT4mCsZ1wsZc2cORMffPCBcr1ixYpo0KCBcn3WrFnYvXs39u3bh1GjRuVYzqBBg9CvXz8AwE8//YQlS5bg0qVL8PHxyTZ/SkoKVqxYAWdnZwDAqFGjMHPmTOX2pUuXYtKkSejRowcAYNmyZcrWmMIICgrCvn37cPbsWbRo0QIAsHnzZjg6OmLPnj345JNPEBoail69eqF+/foAgBo1aij3Dw0NRaNGjeDh4QFAagV7l7AFiIiIypX0G3q6uLg4TJgwAXXq1IGFhQVMTEwQGBiYZwuQu7u78rOxsTHMzMyUr2nIjpGRkTL4AaRXOaTnj46ORkREBJo1a6bcrqOjgyZNmhTo3DIKDAyErq4uPD09lWlWVlaoXbs2AgMDAQBff/01Zs+ejZYtW2LatGm4efOmMu/w4cOxdetWNGzYEN999x3OnTtX6LqURmwBIiKifDGqYIS4SXFaO3ZxMTZWb0maMGECjh49ioULF6JmzZowNDTExx9/jOTk5FzLqVChgtq6TCbL9aWx2eUvzq69wvjqq6/g7e2Nf/75B0eOHIGfnx9+/vlnjB49Gp06dcLjx49x4MABHD16FB06dMDIkSOxcOFCrda5uLAFiIiI8kUmk8FYz1grS0k+jfrs2bMYNGgQevTogfr168POzg6PHj0qseNlx9zcHLa2trh8+bIyLS0tDdeuXSt0mXXq1EFqaiouXryoTHv16hXu378PNzc3ZZqjoyOGDRuGXbt2Yfz48Vi9erVym42NDQYOHIg///wTixcvxqpVqwpdn9KGLUBERFSuubi4YNeuXejatStkMhmmTJmSa0tOSRk9ejT8/PxQs2ZNuLq6YunSpXjz5k2+gr9bt27B1NRUuS6TydCgQQN069YNgwcPxsqVK2FqaoqJEyeicuXK6NatGwBg7Nix6NSpE2rVqoU3b97g+PHjqFOnDgBg6tSpaNKkCerWrYukpCTs379fue1dwACIiIjKtUWLFuGLL75AixYtYG1tje+//x4xMTEar8f333+P8PBwDBgwADo6OhgyZAi8vb3z9cbzNm3aqK3r6OggNTUV69atw5gxY/Dhhx8iOTkZbdq0wYEDB5TdcWlpaRg5ciSePn0KMzMz+Pj44JdffgEgPcto0qRJePToEQwNDdG6dWts3bq1+E9cS2RC2x2QpVBMTAzMzc0RHR0NMzMzbVdHJT5eegYQAMTFAcbFMyOCiCg7iYmJCAkJQfXq1WFgYKDt6pQ7CoUCderUQe/evTFr1ixtV6fUyO17WZD7N1uAiIiISoHHjx/jyJEjaNu2LZKSkrBs2TKEhITg008/1XbV3kkcBE1ERFQKyOVyrF+/Hk2bNkXLli1x69YtHDt27J0ad1OasAWIiIioFHB0dMTZs2e1XY1yo1S0AP32229wcnKCgYEBPD09cenSpXztt3XrVshksizvSRFCYOrUqbC3t4ehoSG8vLzU3n1CRERE5ZvWA6Bt27Zh3LhxmDZtGq5du4YGDRrA29s716dpAsCjR48wYcIEtG7dOsu2+fPnY8mSJVixYgUuXrwIY2NjeHt7IzExsaROg4iIiMoQrQdAixYtwuDBg+Hr6ws3NzesWLECRkZGWLt2bY77pKWloX///pgxY4bae0sAqfVn8eLF+PHHH9GtWze4u7tj48aNeP78eZFfKkdERETvBq0GQMnJybh69Sq8vLyUaXK5HF5eXjh//nyO+82cOROVKlXCl19+mWVbSEgIwsPD1co0NzeHp6dnjmUmJSUhJiZGbSlJhw4B7dsDISElehgiIiLKgVYDoMjISKSlpcHW1lYt3dbWFuHh4dnuc+bMGfzxxx9qj+rOKH2/gpTp5+cHc3Nz5eLo6FjQUymQTp2A48eBgQNL9DBERESUA613gRVEbGwsPv/8c6xevRrW1tbFVu6kSZMQHR2tXJ48eVJsZecmIkIjhyEiIqJMtBoAWVtbQ0dHBxGZIoGIiAjY2dllyR8cHIxHjx6ha9eu0NXVha6uLjZu3Ih9+/ZBV1cXwcHByv3yWyYA6Ovrw8zMTG0hIqLyq127dhg7dqxy3cnJCYsXL851H5lMVixjTYurHMqdVgMgPT09NGnSBP7+/so0hUIBf39/NG/ePEt+V1dX3Lp1CwEBAcrlo48+wvvvv4+AgAA4OjqievXqsLOzUyszJiYGFy9ezLZMIiJ6d3Tt2hU+Pj7Zbjt9+jRkMhlu3rxZ4HIvX76MIUOGFLV6aqZPn46GDRtmSQ8LC0OnTp2K9ViZrV+/HhYWFiV6jNJO6w9CHDduHAYOHAgPDw80a9YMixcvRnx8PHx9fQEAAwYMQOXKleHn5wcDAwPUq1dPbf/0X2DG9LFjx2L27NlwcXFB9erVMWXKFDg4OGR5XhAREb1bvvzyS/Tq1QtPnz5FlSpV1LatW7cOHh4ecHd3L3C5NjY2xVXFPOXUW0HFS+tjgPr06YOFCxdi6tSpaNiwIQICAnDo0CHlIObQ0FCEhYUVqMzvvvsOo0ePxpAhQ9C0aVPExcXh0KFDfJkfEdE77sMPP4SNjQ3Wr1+vlh4XF4cdO3bgyy+/xKtXr9CvXz9UrlwZRkZGqF+/PrZs2ZJruZm7wIKCgtCmTRsYGBjAzc0NR48ezbLP999/j1q1asHIyAg1atTAlClTkJKSAkBqgZkxYwZu3LgBmUwGmUymrHPmLrBbt26hffv2MDQ0hJWVFYYMGYK4uDjl9kGDBqF79+5YuHAh7O3tYWVlhZEjRyqPVRihoaHo1q0bTExMYGZmht69e6sNLblx4wbef/99mJqawszMDE2aNMGVK1cASO8069q1KywtLWFsbIy6deviwIEDha5LSdF6CxAAjBo1CqNGjcp224kTJ3LdN/OXHJC+PDNnzsTMmTOLoXZERAQAQgAJCdo5tpERIJPlnU9XVxcDBgzA+vXrMXnyZMj+f6cdO3YgLS0N/fr1Q1xcHJo0aYLvv/8eZmZm+Oeff/D555/D2dkZzZo1y/MYCoUCPXv2hK2tLS5evIjo6Gi18ULpTE1NsX79ejg4OODWrVsYPHgwTE1N8d1336FPnz64ffs2Dh06hGPHjgGQHtmSWXx8PLy9vdG8eXNcvnwZL168wFdffYVRo0ap3f+OHz8Oe3t7HD9+HA8fPkSfPn3QsGFDDB48OO+Lls35pQc/J0+eRGpqKkaOHIk+ffoo78n9+/dHo0aNsHz5cujo6CAgIAAVKlQAAIwcORLJyck4deoUjI2NcffuXZiYmBS4HiVOUBbR0dECgIiOji6R8qX/RoSoVUtav3dPiMDAfOwYF6faOS6uROpGRJTu7du34u7du+Lt27dCCPX/gjS9FOS/vMDAQAFAHD9+XJnWunVr8dlnn+W4T5cuXcT48eOV623bthVjxoxRrlerVk388ssvQgghDh8+LHR1dcWzZ8+U2w8ePCgAiN27d+d4jAULFogmTZoo16dNmyYaNGiQJV/GclatWiUsLS1FXIYL8M8//wi5XC7Cw8OFEEIMHDhQVKtWTaSmpirzfPLJJ6JPnz451mXdunXC3Nw8221HjhwROjo6IjQ0VJl2584dAUBcunRJCCGEqampWL9+fbb7169fX0yfPj3HYxdV5u9lRgW5f2u9C6y8S0oCXF2BOnWAt2+1XRsiorLP1dUVLVq0UL5R4OHDhzh9+rTy4blpaWmYNWsW6tevj4oVK8LExASHDx9GaGhovsoPDAyEo6MjHBwclGnZTbLZtm0bWrZsCTs7O5iYmODHH3/M9zEyHqtBgwYwNjZWprVs2RIKhQL3799XptWtWxc6OjrKdXt7+zxfKZXbMR0dHdWeiefm5gYLCwsEBgYCkMbvfvXVV/Dy8sLcuXMRHByszPv1119j9uzZaNmyJaZNm1aoQeeawABIi4QAYmNV6yX8AGoioiIxMgLi4rSzGBkVrK5ffvkl/ve//yE2Nhbr1q2Ds7Mz2rZtCwBYsGABfv31V3z//fc4fvw4AgIC4O3tjeTk5GK7VufPn0f//v3RuXNn7N+/H9evX8fkyZOL9RgZpXc/pZPJZFAoFCVyLECawXbnzh106dIF//77L9zc3LB7924AwFdffYX//vsPn3/+OW7dugUPDw8sXbq0xOpSWAyAiIgoX2QywNhYO0t+xv9k1Lt3b8jlcvz111/YuHEjvvjiC+V4oLNnz6Jbt2747LPP0KBBA9SoUQMPHjzId9l16tTBkydP1CboXLhwQS3PuXPnUK1aNUyePBkeHh5wcXHB48eP1fLo6ekhLS0tz2PduHED8fHxyrSzZ89CLpejdu3a+a5zQaSfX8aHAt+9exdRUVFwc3NTptWqVQvffPMNjhw5gp49e2LdunXKbY6Ojhg2bBh27dqF8ePH5/j2Bm1iAKRlQqg+F/QfOBERZc/ExAR9+vTBpEmTEBYWhkGDBim3ubi44OjRozh37hwCAwMxdOjQLA/PzY2Xlxdq1aqFgQMH4saNGzh9+jQmT56slsfFxQWhoaHYunUrgoODsWTJEmULSTonJyeEhIQgICAAkZGRSEpKynKs/v37w8DAAAMHDsTt27dx/PhxjB49Gp9//nmWVz4VVFpamtpz9QICAhAYGAgvLy/Ur18f/fv3x7Vr13Dp0iUMGDAAbdu2hYeHB96+fYtRo0bhxIkTePz4Mc6ePYvLly+jTp06AKRH0Rw+fBghISG4du0ajh8/rtxWmjAA0jIGQEREJePLL7/Emzdv4O3trTZe58cff0Tjxo3h7e2Ndu3awc7OrkDPiZPL5di9ezfevn2LZs2a4auvvsKcOXPU8nz00Uf45ptvMGrUKDRs2BDnzp3DlClT1PL06tULPj4+eP/992FjY5PtVHwjIyMcPnwYr1+/RtOmTfHxxx+jQ4cOWLZsWcEuRjbi4uLQqFEjtaVr166QyWTYu3cvLC0t0aZNG3h5eaFGjRrYtm0bAEBHRwevXr3CgAEDUKtWLfTu3RudOnXCjBkzAEiB1ciRI1GnTh34+PigVq1a+P3334tc3+ImEyLjLZgA6cnR5ubmiI6OLpHXYqQHOi4uwKlTgL29tB4eDuQa0MfHA+lTCePipHZhIqISkpiYiJCQEFSvXp3PUaNSI7fvZUHu32wB0rKMY9RKcLwaERERZcAASMsyjn9jAERERKQZDIC0LGMAlMdkACIiIiomDIC0jC1AREREmscASMsYABEREWkeAyAtYxcYERGR5jEA0jLOAiMiItI8BkBaxi4wIiIizWMApEVCMAAiIiLSBgZAWsYxQEREdOLECchkMkRFRWm7KkXi5OSExYsXa7sa+cIASMvYAkREVLxevnyJ4cOHo2rVqtDX14ednR28vb1x9uxZZR6ZTIY9e/YUy/EePXoEmUyGgICAfOXLvHz22Wdo0aIFwsLCYG5uXix1yk52x864TJ8+vcjHuHz5MoYMGVL0ymqArrYrUN4xACIiKl69evVCcnIyNmzYgBo1aiAiIgL+/v549epVsR8rOTm5wPscO3YMdevWVa4bGhpCT08PdnZ2xVm1LMLCwpSft23bhqlTp+L+/fvKNJP0d00WgY2NTZHL0BS2AGnQ9evAypXqaRmDHnaBEREVTVRUFE6fPo158+bh/fffR7Vq1dCsWTNMmjQJH330EQCpmwYAevToAZlMplwPDg5Gt27dYGtrCxMTEzRt2hTHjh1TK9/JyQmzZs3CgAEDYGZmhiFDhqB69eoAgEaNGkEmk6Fdu3a51tHKygp2dnbKxdzcPEsX2Pr162FhYYHDhw+jTp06MDExgY+Pj1oQAwBr1qxBnTp1YGBgAFdX11zfup75mDKZTLm+YsUKtGrVSi3/4sWLldcGAAYNGoTu3btj4cKFsLe3h5WVFUaOHImUlBS165OxC0wmk2HNmjXo0aMHjIyM4OLign379qkdZ9++fXBxcYGBgQHef/99bNiwQSPdgQyANOjQIWDYMPU0tgARUZkhBBAfr51FiHxV0cTEBCYmJtizZw+SkpKyzXP58mUAwLp16xAWFqZcj4uLQ+fOneHv74/r16/Dx8cHXbt2RWhoqNr+CxcuRIMGDXD9+nVMmTIFly5dAiC17ISFhWHXrl2FvcJqEhISsHDhQmzatAmnTp1CaGgoJkyYoNy+efNmTJ06FXPmzEFgYCB++uknTJkyBRs2bCiW42fn+PHjCA4OxvHjx7FhwwasX78e69evz3WfGTNmoHfv3rh58yY6d+6M/v374/Xr1wCAkJAQfPzxx+jevTtu3LiBoUOHYvLkySVW/4zYBaZB8mzCTQZARFRmJCQAxdBNUihxcYCxcZ7ZdHV1sX79egwePBgrVqxA48aN0bZtW/Tt2xfu7u4AVN00FhYWat1ODRo0QIMGDZTrs2bNwu7du7Fv3z6MGjVKmd6+fXuMHz9eua6jowNA1bKTlxYtWkCe4YZw+vTpbPOlpKRgxYoVcHZ2BgCMGjUKM2fOVG6fNm0afv75Z/Ts2RMAUL16ddy9excrV67EwIED86xHYVhaWmLZsmXQ0dGBq6srunTpAn9/fwwePDjHfQYNGoR+/foBAH766ScsWbIEly5dgo+PD1auXInatWtjwYIFAIDatWvj9u3bmDNnTonUPyO2AGnQ//8bUcMAiIioePXq1QvPnz/Hvn374OPjgxMnTqBx48Z5tlTExcVhwoQJqFOnDiwsLGBiYoLAwMAsLUAeHh5Fqt+2bdsQEBCgXNzc3LLNZ2RkpAx+AMDe3h4vXrwAAMTHxyM4OBhffvmlstXLxMQEs2fPRnBwcJHql5u6desqA77MdcpJeuAJAMbGxjAzM1Puc//+fTRt2lQtf7NmzYqxxjljC5AG5dUCxDFARFSqGRlJLTHaOnYBGBgY4IMPPsAHH3yAKVOm4KuvvsK0adMwaNCgHPeZMGECjh49ioULF6JmzZowNDTExx9/nGWgs3E+WqJy4+joiJo1a+aZr0KFCmrrMpkM4v+7AuP+//ewevVqeHp6quXTye6v7TzI5XJl2ekyju3JrU6KPP56L8w+msAASIPYAkREZZpMlq9uqNLIzc1Nbdp7hQoVkJbpr86zZ89i0KBB6NGjBwApyHj06FGeZevp6QFAlvJKkq2tLRwcHPDff/+hf//+RS7PxsYG4eHhEEJAJpMBQJ7T+otD7dq1ceDAAbW09DFZJY1dYBqUXQsQ3wVGRFR8Xr16hfbt2+PPP//EzZs3ERISgh07dmD+/Pno1q2bMp+TkxP8/f0RHh6ON2/eAABcXFywa9cuBAQE4MaNG/j000/z1VJRqVIlGBoa4tChQ4iIiEB0dHSJnV9GM2bMgJ+fH5YsWYIHDx7g1q1bWLduHRYtWlTgstq1a4eXL19i/vz5CA4Oxm+//YaDBw+WQK3VDR06FPfu3cP333+PBw8eYPv27cquyvRArKQwANKgvFqA2AVGRFQ0JiYm8PT0xC+//II2bdqgXr16mDJlCgYPHoxly5Yp8/388884evQoHB0d0ahRIwDAokWLYGlpiRYtWqBr167w9vZG48aN8zymrq4ulixZgpUrV8LBwUEt0CpJX331FdasWYN169ahfv36aNu2LdavX6+cll8QderUwe+//47ffvsNDRo0wKVLl9RmnJWU6tWrY+fOndi1axfc3d2xfPly5SwwfX39Ej22TGTu9CPExMTA3Nwc0dHRMDMzK7ZyV65Unwbv7AzMmwd8/LG0fugQ4O2dSwHx8aoZGPmcEUFEVFiJiYkICQlB9erVYWBgoO3qUDkxZ84crFixAk+ePMl2e27fy4LcvzkGSIM4DZ6IiEjd77//jqZNm8LKygpnz57FggUL1B47UFIYAGkQu8CIiIjUBQUFYfbs2Xj9+jWqVq2K8ePHY9KkSSV+XAZAGsQWICIiInW//PILfvnlF40ft1QMgv7tt9/g5OQEAwMDeHp6Kh8rnp1du3bBw8MDFhYWMDY2RsOGDbFp0ya1PIMGDcryllsfH5+SPo08ZdcCxFlgREREmqf1FqBt27Zh3LhxWLFiBTw9PbF48WJ4e3vj/v37qFSpUpb8FStWxOTJk+Hq6go9PT3s378fvr6+qFSpErwzjCD28fHBunXrlOslPZo8P9gCRERlEefKUGlSXN9HrbcALVq0CIMHD4avry/c3NywYsUKGBkZYe3atdnmb9euHXr06IE6derA2dkZY8aMgbu7O86cOaOWT19fX+3Nt5aWlpo4nVxxDBARlSXpTxTO/CRkIm1KSEgAkPUJ0wWl1Rag5ORkXL16VW2wk1wuh5eXF86fP5/n/kII/Pvvv7h//z7mzZuntu3EiROoVKkSLC0t0b59e8yePRtWVlbFfg4FwSdBE1FZoqurCyMjI7x8+RIVKlRQe4EnkaYJIZCQkIAXL17AwsKiUK/8yEirAVBkZCTS0tJga2urlm5ra4t79+7luF90dDQqV66MpKQk6Ojo4Pfff8cHH3yg3O7j44OePXuievXqCA4Oxg8//IBOnTrh/Pnz2V6wpKQkJCUlKddjYmKK4eyyYhcYEZUlMpkM9vb2CAkJwePHj7VdHSIAgIWFBezs7IpcjtbHABWGqakpAgICEBcXB39/f4wbNw41atRAu3btAAB9+/ZV5q1fvz7c3d3h7OyMEydOoEOHDlnK8/Pzw4wZM0q83uwCI6KyRk9PDy4uLuwGo1KhQoUKRW75SafVAMja2ho6OjqIiIhQS4+IiMg1upPL5co36TZs2BCBgYHw8/NTBkCZ1ahRA9bW1nj48GG2AdCkSZMwbtw45XpMTAwcHR0LcUa547vAiKgsksvlfBI0vXO02qGrp6eHJk2awN/fX5mmUCjg7++P5s2b57schUKh1oWV2dOnT/Hq1SvY29tnu11fXx9mZmZqS0ngGCAiIqLSQetdYOPGjcPAgQPh4eGBZs2aYfHixYiPj4evry8AYMCAAahcuTL8/PwASN1VHh4ecHZ2RlJSEg4cOIBNmzZh+fLlAIC4uDjMmDEDvXr1gp2dHYKDg/Hdd9+hZs2aatPktSGvMUDsAiMiItIMrQdAffr0wcuXLzF16lSEh4ejYcOGOHTokHJgdGhoqNrMg/j4eIwYMQJPnz6FoaEhXF1d8eeff6JPnz4ApGmbN2/exIYNGxAVFQUHBwd07NgRs2bN0vqzgNgCREREVDrwbfDZKKm3wfv7A15eqnVnZ8DXF/jxR2l9xQpg6NBcCuDb4ImIiHJUkPs3H+qgQRwETUREVDowANIgToMnIiIqHRgAaRAfhEhERFQ6MADSIA6CJiIiKh0YAGkQu8CIiIhKBwZAGsQuMCIiotKBAZAGZW4BEoKzwIiIiLSBAZAGZW4BUijYBUZERKQNDIA0KHMLUOYAiC1AREREmsEASIPyagFiAERERKQZDIA0KHMLUFoaAyAiIiJtYACkQXl1gXEMEBERkWYwANKg7LrAOAuMiIhI8xgAaRAHQRMREZUODIA0iNPgiYiISgcGQBrEFiAiIqLSgQGQBnEaPBERUenAAEiDOAuMiIiodGAApEHZBUCcBUZERKR5DIA0iF1gREREpQMDIA3iIGgiIqLSgQGQBnEaPBERUenAAEiD2AJERERUOjAA0qDMLUBCMAAiIiLSBgZAGpS5BQgAUlNVn9kFRkREpBkMgDQocwsQAKSkqD6zBYiIiEgzGABpkEyWNY0BEBERkeYxANIyBkBERESaxwBIyzIGQBwDREREpBkMgLSMLUBERESaxwBIyzLOAmMAREREpBkMgLSMXWBERESaVyoCoN9++w1OTk4wMDCAp6cnLl26lGPeXbt2wcPDAxYWFjA2NkbDhg2xadMmtTxCCEydOhX29vYwNDSEl5cXgoKCSvo0CoVdYERERJqn9QBo27ZtGDduHKZNm4Zr166hQYMG8Pb2xosXL7LNX7FiRUyePBnnz5/HzZs34evrC19fXxw+fFiZZ/78+ViyZAlWrFiBixcvwtjYGN7e3khMTNTUaeUbAyAiIiLNkwkhhDYr4OnpiaZNm2LZsmUAAIVCAUdHR4wePRoTJ07MVxmNGzdGly5dMGvWLAgh4ODggPHjx2PChAkAgOjoaNja2mL9+vXo27dvnuXFxMTA3Nwc0dHRMDMzK/zJZSPzs4CMjYH4eOmztzdw6FAuO8fHAyYm0ue4OGlnIiIiAlCw+7dWW4CSk5Nx9epVeHl5KdPkcjm8vLxw/vz5PPcXQsDf3x/3799HmzZtAAAhISEIDw9XK9Pc3Byenp45lpmUlISYmBi1RVPYAkRERKR5Wg2AIiMjkZaWBltbW7V0W1tbhIeH57hfdHQ0TExMoKenhy5dumDp0qX44IMPAEC5X0HK9PPzg7m5uXJxdHQsymkVCAMgIiIizdP6GKDCMDU1RUBAAC5fvow5c+Zg3LhxOHHiRKHLmzRpEqKjo5XLkydPiq+yecjYAckAiIiISDN0tXlwa2tr6OjoICIiQi09IiICdnZ2Oe4nl8tRs2ZNAEDDhg0RGBgIPz8/tGvXTrlfREQE7O3t1cps2LBhtuXp6+tDX1+/iGdTdJwGT0REpBlabQHS09NDkyZN4O/vr0xTKBTw9/dH8+bN812OQqFAUlISAKB69eqws7NTKzMmJgYXL14sUJnawBYgIiIizdBqCxAAjBs3DgMHDoSHhweaNWuGxYsXIz4+Hr6+vgCAAQMGoHLlyvDz8wMgjdfx8PCAs7MzkpKScODAAWzatAnLly8HAMhkMowdOxazZ8+Gi4sLqlevjilTpsDBwQHdu3fX1mnmCwMgIiIizdB6ANSnTx+8fPkSU6dORXh4OBo2bIhDhw4pBzGHhoZCLlc1VMXHx2PEiBF4+vQpDA0N4erqij///BN9+vRR5vnuu+8QHx+PIUOGICoqCq1atcKhQ4dgYGCg8fMrCHaBERERaYbWnwNUGmnyOUAZNW0K5PIQbD4HiIiIKBdl5jlApI5dYERERJrBAKgUSO/hYxcYERGRZjAAKgXq1pV+sgWIiIhIMxgAlQIMgIiIiDSLAVApULu29JMBEBERkWYwACoFrK2lnxwDREREpBkMgEoBc3PpJ1uAiIiINIMBUClgYSH9ZABERESkGQyASoH0AIhdYERERJrBAKgUMDSUfrIFiIiISDMYAJUC6Q9CZABERESkGQyASgE+CZqIiEizGACVAmwBIiIi0iwGQKWAjo70kwEQERGRZjAA0jIdHbYAERERaRoDIC0zNuYYICIiIk1jAKRlxsbsAiMiItI0BkBaZmLCFiAiIiJNYwCkZcbGQIUK0ueUFO3WhYiIqLxgAKRlRkaAnp70OSUFEEK79SEiIioPGABpmbGxKgASgt1gREREmsAASMsqVlR1gQFAcrL26kJERFReMADSopo1gQULVC1AAAMgIiIiTWAApEF77u1RWw8KAhwd1VuAOBCaiIio5DEA0qB7kfeyTZfJVEEQW4CIiIhKHgMgDaogrwBAetphpUqZtjEAIiIi0hgGQBqkK9cFBjeDXcMbOHZMfVv6OCAGQERERCWPAZAG6cp1gcpX0eqH2ahfX31bxmcBERERUcliAKRBFXSkfq5URWqWbWwBIiIi0hwGQBqkK9cFkH0AxDFAREREmsMASIPSA6CUtKz9XGwBIiIi0hwGQBokzQLLvQuMY4CIiIhKXqkIgH777Tc4OTnBwMAAnp6euHTpUo55V69ejdatW8PS0hKWlpbw8vLKkn/QoEGQyWRqi4+PT0mfRp5y6wJjCxAREZHmaD0A2rZtG8aNG4dp06bh2rVraNCgAby9vfHixYts8584cQL9+vXD8ePHcf78eTg6OqJjx4549uyZWj4fHx+EhYUply1btmjidHKl7AJTZG3m4RggIiIizdF6ALRo0SIMHjwYvr6+cHNzw4oVK2BkZIS1a9dmm3/z5s0YMWIEGjZsCFdXV6xZswYKhQL+/v5q+fT19WFnZ6dcLC0tNXE6uWILEBERUemg1QAoOTkZV69ehZeXlzJNLpfDy8sL58+fz1cZCQkJSElJQcWKFdXST5w4gUqVKqF27doYPnw4Xr16lWMZSUlJiImJUVtKQn6mwXMMEBERUcnTagAUGRmJtLQ02NraqqXb2toiPDw8X2V8//33cHBwUAuifHx8sHHjRvj7+2PevHk4efIkOnXqhLS0tGzL8PPzg7m5uXJxdHQs/EnlgrPAiIiISgddbVegKObOnYutW7fixIkTMDAwUKb37dtX+bl+/fpwd3eHs7MzTpw4gQ4dOmQpZ9KkSRg3bpxyPSYmpkSCID4HiIiIqHTQaguQtbU1dHR0EBERoZYeEREBOzu7XPdduHAh5s6diyNHjsDd3T3XvDVq1IC1tTUePnyY7XZ9fX2YmZmpLSUhP9PgGQARERGVPK0GQHp6emjSpInaAOb0Ac3NmzfPcb/58+dj1qxZOHToEDw8PPI8ztOnT/Hq1SvY29sXS70LK7dZYBwDREREpDlanwU2btw4rF69Ghs2bEBgYCCGDx+O+Ph4+Pr6AgAGDBiASZMmKfPPmzcPU6ZMwdq1a+Hk5ITw8HCEh4cjLi4OABAXF4dvv/0WFy5cwKNHj+Dv749u3bqhZs2a8Pb21so5puMsMCIiotJB62OA+vTpg5cvX2Lq1KkIDw9Hw4YNcejQIeXA6NDQUMjlqjht+fLlSE5Oxscff6xWzrRp0zB9+nTo6Ojg5s2b2LBhA6KiouDg4ICOHTti1qxZ0NfX1+i5ZZbbLLDMY4CEAGQyTdWMiIiofNF6AAQAo0aNwqhRo7LdduLECbX1R48e5VqWoaEhDh8+XEw1K175nQV2+DDQpw+wZg2QKc4jIiKiYlAqAqDyIj9dYCkpQPpbOz75RGoJIiIiouKl9TFA5QlngREREZUODIA0iO8CIyIiKh0YAGlQQWeBZXi2IxERERUjBkAalD4LTCEUUAiF2rbsngNkaqqpmhEREZUvDIA0KL0FCMjaCpRdC1AJPZCaiIio3CtUAPTkyRM8ffpUuX7p0iWMHTsWq1atKraKvYtyC4CyGwPEFiAiIqKSUagA6NNPP8Xx48cBAOHh4fjggw9w6dIlTJ48GTNnzizWCr5L0meBATm3ACUkqNLYAkRERFQyChUA3b59G82aNQMAbN++HfXq1cO5c+ewefNmrF+/vjjr907J2AKU+WGI6QHQy5eqNBMTTdSKiIio/ClUAJSSkqJ8rcSxY8fw0UcfAQBcXV0RFhZWfLV7x8hlqsudUwtQRIQqja/CICIiKhmFCoDq1q2LFStW4PTp0zh69Ch8/v/Rxc+fP4eVlVWxVvBdIpPJcnwYYvoYoIwBUFqapmpGRERUvhQqAJo3bx5WrlyJdu3aoV+/fmjQoAEAYN++fcquMcpeTg9DTG8BSkpSpTEAIiIiKhmFehdYu3btEBkZiZiYGFhaWirThwwZAiMjo2Kr3Lsop4chpgdAGaVmfV4iERERFYNCtQC9ffsWSUlJyuDn8ePHWLx4Me7fv49KlSoVawXfNekPQ8xPAMQWICIiopJRqACoW7du2LhxIwAgKioKnp6e+Pnnn9G9e3csX768WCv4rlF2gWWaBVahQta8bAEiIiIqGYUKgK5du4bWrVsDAHbu3AlbW1s8fvwYGzduxJIlS4q1gu+anLrAsus5ZAsQERFRyShUAJSQkADT/39M8ZEjR9CzZ0/I5XK89957ePz4cbFW8F2T0yyw7J76zBYgIiKiklGoAKhmzZrYs2cPnjx5gsOHD6Njx44AgBcvXsCMjy/OVU6zwLK7bGwBIiIiKhmFCoCmTp2KCRMmwMnJCc2aNUPz5s0BSK1BjRo1KtYKvmty6gLLLgBiCxAREVHJKNQ0+I8//hitWrVCWFiY8hlAANChQwf06NGj2Cr3LsppFpihISCXAwqFKo0tQERERCWjUAEQANjZ2cHOzk75VvgqVarwIYj5kNMsMJlMagWKilKlsQWIiIioZBSqC0yhUGDmzJkwNzdHtWrVUK1aNVhYWGDWrFlQZGzCoCxy6gIDsg6EZgsQERFRyShUC9DkyZPxxx9/YO7cuWjZsiUA4MyZM5g+fToSExMxZ86cYq3kuyS3ACjzOCAGQERERCWjUAHQhg0bsGbNGuVb4AHA3d0dlStXxogRIxgA5SJ9GnzmWWBA1gCIXWBEREQlo1BdYK9fv4arq2uWdFdXV7x+/brIlXqXsQuMiIhI+woVADVo0ADLli3Lkr5s2TK4u7sXuVLvstwCIBMT9XW2ABEREZWMQnWBzZ8/H126dMGxY8eUzwA6f/48njx5ggMHDhRrBd816dPgM88CAwAdHfV1tgARERGVjEK1ALVt2xYPHjxAjx49EBUVhaioKPTs2RN37tzBpk2biruO75TcWoBkMvX1jC1Ad+8CV66UZM2IiIjKj0I/B8jBwSHLYOcbN27gjz/+wKpVq4pcsXdVQQKgjC1AdesCRgDiS7BuRERE5UWhWoCo8HKbBZZTC5AQJV0rIiKi8oUBkIYVpgUoJWusREREREVQKgKg3377DU5OTjAwMICnpycuXbqUY97Vq1ejdevWsLS0hKWlJby8vLLkF0Jg6tSpsLe3h6GhIby8vBAUFFTSp5EvuQVAupk6JNPSpNaf5GRN1IyIiKj8KNAYoJ49e+a6PSrji6zyadu2bRg3bhxWrFgBT09PLF68GN7e3rh//z4qVaqUJf+JEyfQr18/tGjRAgYGBpg3bx46duyIO3fuoHLlygCkWWpLlizBhg0bUL16dUyZMgXe3t64e/cuDAwMClzH4qTsAstmFtj06cDffwN9+wIrVkhpCgUDICIiouJWoBYgc3PzXJdq1aphwIABBarAokWLMHjwYPj6+sLNzQ0rVqyAkZER1q5dm23+zZs3Y8SIEWjYsCFcXV2xZs0aKBQK+Pv7A5BafxYvXowff/wR3bp1g7u7OzZu3Ijnz59jz549BapbScitBahGDSAyEpg7V5WWlsYAiIiIqLgVqAVo3bp1xXrw5ORkXL16FZMmTVKmyeVyeHl54fz58/kqIyEhASkpKahYsSIAICQkBOHh4fDy8lLmMTc3h6enJ86fP4++ffsW6zkUlPJt8NkMggakZwFlfB5QaioDICIiouJW6GnwxSEyMhJpaWmwtbVVS7e1tcW9e/fyVcb3338PBwcHZcATHh6uLCNzmenbMktKSkJSUpJyPSYmJt/nUFAWBhYAgNdvc35lSMaxQGlpHARNRERU3ErFIOjCmjt3LrZu3Yrdu3cXaWyPn5+fWleeo6NjMdZSXWUzaZzSs9hnOeZhCxAREVHJ0moAZG1tDR0dHURERKilR0REwM7OLtd9Fy5ciLlz5+LIkSNq7x9L368gZU6aNAnR0dHK5cmTJ4U5nXxxMHUAADyPfQ4AiEmKQVhsmFqejAEQxwAREREVP60GQHp6emjSpIlyADMA5YDm9HeMZWf+/PmYNWsWDh06BA8PD7Vt1atXh52dnVqZMTExuHjxYo5l6uvrw8zMTG0pKZVN/78FKOYZroVdQ41fa8BlqYtal5hcrnomEFuAiIiIip/Wu8DGjRuH1atXY8OGDQgMDMTw4cMRHx8PX19fAMCAAQPUBknPmzcPU6ZMwdq1a+Hk5ITw8HCEh4cjLi4OACCTyTB27FjMnj0b+/btw61btzBgwAA4ODige/fu2jhFNektQBHxEfhs12d49fYV4lPiEfgyUC1feisQxwAREREVP60OggaAPn364OXLl5g6dSrCw8PRsGFDHDp0SDmIOTQ0FHK5Kk5bvnw5kpOT8fHHH6uVM23aNEyfPh0A8N133yE+Ph5DhgxBVFQUWrVqhUOHDmn9GUAAUMm4EnRkOkgTaQiMVAU9odGhaImWynVdXan1hy1ARERExU8mBN80lVlMTAzMzc0RHR1dIt1hVRZVyTII2q+DHya2mqhcNzEB4uOB4GDg4UPA2xswQjziYSJliIsDjI2LvW5ERERlVUHu31rvAiuP7EyyDsYOjQ5VW0+fCs9B0ERERMWPAZAWOFk4KT8PbTIUQNYAKH0MUGoqxwAREREVN62PASqPvmv5HUz1TTG48WDEJsVi5dWVbAEiIiLSIAZAWtCscjM0q9wMAJSzv3JrAWIAREREVLzYBaZlVc2rQgYZopOi8SxGNTA6vQUoNRUowTdzEBERlUsMgLTMWM8YHg7SwxwPBx9Wpqe3AA0dCowapY2aERERvbsYAJUCnV06AwAOBB1QpqW3AF27po0aERERvdsYAJUCnWp2AgD4h/gj/bFMGd8HRkRERMWLAVApUN+2PgAgKjEKUYlRABgAERERlSQGQKWAUQUj2BjZAAAeRz8GoOoCIyIiouLHAKiUqGpeFQDwOEoKgPJqAUpLK+kaERERvbsYAJUS1SyqAQCmnZiGoFdBebYAhYbmvp2IiIhyxgColKhmLgVANyJuoNmaZpDJc2/iefhQE7UiIiJ6NzEAKiXSAyBAGgwdnvAsl9xAUFBJ14iIiOjdxQColLA2slZbj0l+nWt+BkBERESFxwColGhfvT1M9ExgZWgFAHiriMs1P7vAiIiICo8BUClhb2qPFxNeIGBYAAAgSRGfa/7wcA1UioiI6B3FAKgUMaxgiMqmlWGiZwLIch8E/fathipFRET0DmIAVMrIZDI4WzoDecwCYwBERERUeAyASqHKZpWBJLNc8yQlaagyRERE7yAGQKVQQ9uGQIJ1rnnYAkRERFR4DIBKoVHNRsEopVqueRKTgP9/cTwREREVEAOgUsje1B5vo03yzJeYqIHKEBERvYMYAJVS2bXuyKCeyG4wIiKiwmEAVIZM/ln98c9sASIiIiocBkCl1KhR0k8/P1Xa7BPz1PKwBYiIiKhwGACVUosXAzduAN99lyFRplDLwwCIiIiocBgAlVI6OoC7OyCXA5MnA++1SEG/jw3V8sTGp2qpdkRERGUbA6AyYPZs4PzZCljT83e19KevIrVUIyIiorKNAVAZFvrqpbarQEREVCYxACrDnr5+pe0qEBERlUkMgMqw56/faLsKREREZZLWA6DffvsNTk5OMDAwgKenJy5dupRj3jt37qBXr15wcnKCTCbD4sWLs+SZPn06ZDKZ2uLq6lqCZ6A9EdHR2q4CERFRmaTVAGjbtm0YN24cpk2bhmvXrqFBgwbw9vbGixcvss2fkJCAGjVqYO7cubCzs8ux3Lp16yIsLEy5nDlzpqROQavC3zAAIiIiKgytBkCLFi3C4MGD4evrCzc3N6xYsQJGRkZYu3ZttvmbNm2KBQsWoG/fvtDX18+xXF1dXdjZ2SkXa+vc36xeVoW+egnBN6ISEREVmNYCoOTkZFy9ehVeXl6qysjl8PLywvnz54tUdlBQEBwcHFCjRg30798foaGhueZPSkpCTEyM2lIWvH0rEBIVou1qEBERlTlaC4AiIyORlpYGW1tbtXRbW1uEh4cXulxPT0+sX78ehw4dwvLlyxESEoLWrVsjNjY2x338/Pxgbm6uXBwdHQt9fI1KMcSV51e0XQsiIqIyR+uDoItbp06d8Mknn8Dd3R3e3t44cOAAoqKisH379hz3mTRpEqKjo5XLkydPNFjjIkg1wL77+9gNRkREVEBaC4Csra2ho6ODiIgItfSIiIhcBzgXlIWFBWrVqoWHDx/mmEdfXx9mZmZqS5mQaojNtzZjzbU12q4JERFRmaK1AEhPTw9NmjSBv7+/Mk2hUMDf3x/NmzcvtuPExcUhODgY9vb2xVZmadHIugUAYM11BkBEREQFodUusHHjxmH16tXYsGEDAgMDMXz4cMTHx8PX1xcAMGDAAEyaNEmZPzk5GQEBAQgICEBycjKePXuGgIAAtdadCRMm4OTJk3j06BHOnTuHHj16QEdHB/369dP4+ZW0asZ1IJfJcenZJTyKeoSUtBTEJccpt79+DYwcCVy+rMVKEhERlUK62jx4nz598PLlS0ydOhXh4eFo2LAhDh06pBwYHRoaCrlcFaM9f/4cjRo1Uq4vXLgQCxcuRNu2bXHixAkAwNOnT9GvXz+8evUKNjY2aNWqFS5cuAAbGxuNnpsmiBQDNDP8FBfi/sL7G95HSloKElISEDQ6CFZGVvj2W2DtWuD33wEOEyIiIlKRCY6gzSImJgbm5uaIjo4uXeOB4uMBExMAgDHikABjAICs0l2IAe8DJtIDJP/s8Sf6u/dH3brA3bvSrvwtExHRu64g9+93bhZYeSReuKHZ8w2oIK8AANh0cxM2b09QBj9ERESkjgFQGVUpU4+ebawPDn92GABw+OQbfNbHSAu1IiIiKhsYAJVRK1cCMhnQrZu0fv060MKxBaqaVwXCG2bJHx+v2foRERGVZgyAyqiOHYG3b4FNm6T1p0+BmDf6uD70OppWapsl//5rV7BxIzBjBpCaCjx/DmR6BBMiI4G//gISEzVwAkRERFqk1VlgVDT6+tLi4gIEBQHTpwOtWlVEA8MPkXnm+8DBsUi6L32uWlWaHp+SAiQkABWkoUPo0QM4cwaYOBHw89PkmRAREWkWW4DeAR9+KP38/Xfg00+Bo/uzjnxPuv++8vOGTal4+1ZqCbp9W5XnzBnp57p1JVlbIiIi7WMA9A6YOROoVUu1/vhx7vlPnlR99j8Tk2W7LtsFiYjoHccA6B1gYiI97Xnp0tzzyWT//zAghSrC+XbddlT1nYylBw8o03R0pC61s2dLorZERETaxwchZqMsPAgRcXGAsbHaZiEANzfg3j1pfd8+4O+/gdWrpfVPPgHOnBEIC5PlehgbG0AulwZF37sH1KxZ3CdCRERU/PggxHJKJgN+/FG13rmzFPTo60vrXbsC772Xe/ADAC9fSjPE0tKA4ydTS6i2RERE2sMA6B3z6afAL78A27ZJXVkffCAFNEFBwGefAe+9V7DydhzJfkDR+fNSsJWUVAyVJiIi0jAOd33HyGTA2LHqaaam0gIAzZur0p2cgEePci/v6OkofLbrM4yu8Tvq1DBDeotiixbSTxsbYMyYYqg4ERGRBrEFqJxp0kT13J8JE9S3pXeVAQCqH5N+hjXB5sFT8V4jMzhWS8XmPS+gUKiGjd25Azx4ILUwERERlRVsASpnjIyAtWuBsDDpYYiVKwN16khBka2t1HX2228CG/5shU59gvH0ljPwWppjHxOli8+GP8WpuFUApMFGKSmAhwcQGwu8eQNYWGjv3IiIiPKLs8CyUVZngRW316+Bzz8HhDwJ4XUn4/q8hdKGbr7AXulpiba2qldq/PEH8MUX0ufwcGmbLO8x10RERMWCs8CoWFSsCPzzD3Dgb31c+mkuarlHSRv2qh4VnfF9Yn/9Jf386SfA3h6YN0+9PCEAhQK4cUMKrrRFoQCePdPe8YmISPsYAFG+6Mp18cWnFrnm+fe4AvrtFmHyZGl90iTppauA9OLWunWlmWkNGwJ9+uR+vNBQIDq6yNXO1ogRQJUqwMGDJVM+ERGVfgyAKN+++QbYvBlwafAy2+1CIUfyyXFqaX/8If08eRIIDFSlHzsmPWjx5EnpeUMZPXwIVKsGeHsXZ+1VVq6Ufk6dWjLlExFR6ccAiPJNT096ztCDABskJGTaWOOo6nOjNfjyhwAAUpDh/uFpDJh5KEt51asD7doB338vtcpUrw68eAHs2CFtv3gRSEwsXF2FAAYPlp59pFBkn0dt1lsZcfo04OUF3L2r7ZqUb2/eANeva7sWRFQUDICoUAwNgaZNpc8zZwrMH9VatfH9afjj1SDl6q1/WuPleR8AgKz2PzB0vA9AGscNAD//DCxfLj2T6M8/gVevVEUNHAgcPy59vnYN+PVX9YAmPh4YPVr1Jvt04eHAmjVSi1XGYCHjkH89vUKcuJa1aQP4++fdhUglq359oHHjrN87Iio7OA2eCu1//5OCltatZYiMNMC61UAtjyfYbx6BNOOIrDvoR0N0/wxvX7oB605DLpNBoVCfJjZ+vPou27dLy08/SYHSq1fS7LLwcGmGWXQ0sGyZtCgUqllnGbvbrl4F6tWTPsfEqNLLYgCULq8HWFLJSh9Ev2cP0KqVVqtCRIXEAIgKzdFRWgDA2jq9pcURYbFPEPQ6CJOOp+LcGV3gvUVA7b8By2DAMAqoeg741gYKmQKtLfvh9MTf8zzWDz+oPv/8M3DlStY8584BLVtKn9NfCAsAly9LLUmA9PyjdG/fFuRsS5f0h1k+fSq1gtWurd36lFd8zMO77dUrwMpK27WgksIuMCp29qb2aFOtDf76Uxc///4aBzbUQ9OW8ahWTQ6fmlJXGIxeA4ZROJ24HGiyMtfyMrfUZBf8ANJf4r6+wOHD6i1AGfOnz0oDgFOngEGDpHel9ewJTJyY/3PUNl1dqTvP0RFwdVXvNiSiotu8WfrDbs4cbdeESgofhJgNPgix+AkhkCbSsP/BfvTY1gMAUEFeASmKFEAhA9L0gG27gaeegH4M9KvdxIDWHfDRhzL8siYC//6vOoYMAfbuVX/2UDqZTH18T0YVKkjT6u3spDFGn3+uvj3jO9EePZIGuLq6AgYG2Z0HsHq19C609G61woqNBXr1Arp2lcYx5Ud6i4ODA3DzpvQfNCANjmZXjGakpUkBKCC9TmbBAu3Wh0qGvj6QnCx95l2y7CjI/ZtdYKQRMpkMujJddKvdDSs/XAnPyp5ISEnAlONT0LVWV1wJuwKLFgfQqaYMow+NxH9v/sN2fXP876YOXrukwGnwUMyYPxH16lnh66+lMqdOFZg9W4YOHaTWm1mzpIHSGcf5yOXS6zp8fICFC6U32GeWcTyNk5P08+OPpYBi8GDp9SG//y6V6+ICDB0q5ck45ggoeHfUX38BR49Ky5dfSsfJTfp/xoAU1D15olp/8SJ/x9QUIaRrCAA7d75bXUXpg/eJqGxjAEQaJZPJMKTJEOX6sQHHsuRxsvwbbde3RWRCpJRgADyqvBA+W45ievvZQC0BJJqj3We66Nu3BezsAEtLoH174MIF1RvvraykwdH9+klPn/7gg/zXc+dOaTl5Utp/5EgpvVEjVZ4rV1Qz4YQAqlaVfqa/BiQvb96oPv/zD/DJJ7nnz9zNFRqa/efSIDwc2LVL+vzqlaqlqjAiI6WgIz041bbYWNXnlBTt1YNKVnEF7WlpwN9/S63GlSoVT5lUPBgAUanjZuOGkDEhOPfkHIQQsDayRpe/uuBGxA302NkV+FTK99XBGtjcczOWnduEuJQ4TGg+AZ6e9VGlitQaM2uWNF08PBw4dEgaG2RhAdSqBVy6JJXh6gp06ya1qAQFSS+DzWj3bmlJl/HZL2vWAE2aSK1MDx+qmskvXACioqRgyd095/P87z/V5+3b8w6AIiNVn2Nj1VuAHj/Ofd9r16Sbtadn7vmKy8sMz8qMiip8ABQfD9SoId1EQkNLx4DUjAFQxs9E2Vm+XOridnEBHjzQdm0oIwZAVCqZ6Jmgo3NH5fqZL87g64Nf4+BD1fsr/nvzH5r/0Vy5fvjhYSzptATfLbOH8euW8B0kh0wGjB0rLZGR0g1UJlP9dWdnB8ydqzru2rVSa8/69XnXcdUqadm8WX2MQPfuqs/vvy+9EsTNDahcWX3/jAHQsWNAaqpqbEl2MgZA0dHqQU9uLUBPn0qBWvpjA0xNcz2tYhEervr8+jWQkCBd248+klrK8mvJElWQERxc+gIgdodRXrZulX4GBWm3HpQVZ4FRmVCzYk0c6H8A90bew/Wh1zHGcwzq2tQFANga28Jc3xwR8RHos7MPvg5ogwUJdTFs/1AcCT6iLMPaOmuzdp066utGRsCiRcD8+cCdO9LndBlvvhkHUvfvLz1xOjvHjwMdO0rvHqtWDXB2VgU+GQOgqKicZ7elyxgApaWpT/XPLQBKH6QrhPoxS1LGgeqvXwNTpkh/Bbdvn/M+oaFSl+LGjaq0dar37paamW5sAaKCyPyqHyo9GABRmVLbujYa2jXEYp/FuD3iNu6NvIfgr4Nxe8Rt9KrTC8YVpJlx9yLvYdW1VfD+0xs/nf4J8cnx2HJrCxqvbIy/bv2F5cul7qAZM7Iew9IS+PZbqdXmm2+k6fKbNgFLl6rybNggPV+oWrXs6+nqmrXbJzRUCkCcnaXnGoWESOktWkg/V6+WAq9ly6QWKCGkQMLRUZrenzEAAoBbt1SfHz+WWlnGjJGehwRIAdWkSVK56dKPeeMGMHy4+uMCilPGFqBXr1Rdi8HBOe8zYYJU5/RnNiUnqwdsDIDKhoAA9edtlXcMgEovdoFRmVbbWppyZaxnjJ29dwIALj+7jCPBR3Du6TkcCDqAyf9OxuR/Jyv36b+rP3b1NsSFYT3ydYzWraVFCKk1o04dqSXJw0MaJL1hgzSIOX1cESAFToMHSwOdJ08GVqxQL9PPT/qprw989ZUUtKxdq57H2FgaW/T0qRQQmZurb884e+3lS8DeXpqptmSJ1J2WPkA78z5Xr0p1B4CkpKzHzY+UFGnsU1QUMGqUdK7t20sBzMGD6i1Sr19Lx8lLenCWcT3jzSNzAKgtDIBydu+eNPbN0BBZ3xdYhglR+EHRuQVAP/0kbZ8ypXBlU9EwAKJ3TtPKTdG0clOkKlIx7fg0zD83H6mKVLU8Pbf3hJ2JHXTlupjaZioGNxmcZ7kymWo2WLpq1aQXvk6dKrXCpM9Uat1ayl+xojSFPmMA5OICNGsmDUzu3FkaqP3FF1mP17u3+vqvv2bNo6cnHfvHH9Wn/2cch5TRo0fqXW23b+dwsrlITJRax2xspONs3SoFae3bA+PGSc8kyii/AVDGF98qFFnHTBS1BSg2ViqjqLPJCjIGSKGQziuvRxy8K479/6TOt2+LFjSUNgkJhX/sWsYAKCVF9RT3V6+kP44AYNgw6d8TaZbWu8B+++03ODk5wcDAAJ6enriU8c/oTO7cuYNevXrByckJMpkMixcvLnKZ9O7SletiToc5OO17GvYm9vii4RdI/jEZfepKbxINjwvH05inGLJ/CHz3+mLsobHYe28v4pPjcejhIUQmROLC0wvI77NCq1aVniw9aJDUBZZOJgO2bJGCosePpZkgf/4pvTpk4ULp5jh1qpR3+nSp+yCn95SZmamX7ekpdadlnna/f3/2+9+4Ib3DLd2jR9J/7rl1TQFSS9Qff0iBzNWrUuvMpUvSu7AA6aWgBgZZgx9ACoAyBjcZn2eUUcYWg8jIrDNmihoA9e4tzQC8eTPrtmvXpIdS5meWTkFagPr2lX43GZ9AntGGDUCDBnlf/3TbtwPz5pXeB/NlfL1MTIx0PTO+vLgsyRi4FKWlLzXD317R0arPGX/nT58WvnxNSE6WxuOVlm7oYiO0aOvWrUJPT0+sXbtW3LlzRwwePFhYWFiIiIiIbPNfunRJTJgwQWzZskXY2dmJX375pchlZic6OloAENHR0YU9tZIRFyeE9H+f9JnyLU2RpvysUChEQFiAOBh0UIw7NE5gOtQWvVl6autW86xE582dRXxyvAiNChWxSbHFX780Ia5dE0KhkNb/+UcIV1fVrzt9+eYbId5/X7U+daqUv0cP9XwuLkJ88YVqvVEj9e1Vq6o+t2un+ty0qRDPnwvx4YdCjBwp1aNuXdX24cOF2LQpa71yWz75RH394EEhpk8XIj5edf4HD6rnWbtW9dnUVFVOWJgQDRsK8euvBbu+r16pyhs8WIj//hPi2TPVdnNzaZuHR/b7P3smRGKi9HnyZFVZhobqx+jVS4jDh1Vp6flmz1alKRRCnDghRHS0anuvXnmfQ1qaKv+xY/k+dY369ltVHb/7Tvr5/ffqee7eFeLOHe3UL78SE9W/jw8eFL6sKlVU5QQFqdI3b1al791b9DqXpIEDpXr27q3tmuStIPdvrQZAzZo1EyNHjlSup6WlCQcHB+Hn55fnvtWqVcs2ACpKmekYAJUfCoVCrLm6Rnyy/RNRcV7FLMFQdou5n7mYfXK2iE+Oz/sARZCWJt04Z84UonJlIb78UojkZCkwSf8aXLki5Z06VZWWHkQJIUSXLkLo6QmxZ49qu0wm3UBtbbMPWNzccg9oMgZERVlGjhTi4UMhNm7MPZ+Pj/SzfXshJkxQpefl1CkhLCyEmD9fiG7dVPtVr64KrPbvF+LJE/XjCSEFWN9/L13L8+eFkMulwEkIIb7+Wj1/SoqUPmSIehlv36rWp02TbqLPngkxb56UNmyYanuzZtL2mzdzPp+M9Zw3ryDfpOIREyNEhw65H7t37+x/h+kSElRp8SX7z6dIXr5Ur//Vq4Uvy9BQVc6lS6r0GTNU6UuXFr3OJSm732VpVSYCoKSkJKGjoyN2796tlj5gwADx0Ucf5bl/dgFQYctMTEwU0dHRyuXJkycMgMqhNEWaOBZ8TOy9t1ecf3Je/HDsB3E29Kxov6F9toFQl81dxLbb28Qn2z8RJx+dFCdCTqi1NJWUxETp5p7xr8moKCG8vIRYvFg9b1ycdNNNSxPi00+FeO896S9PIYRo1Sr/wcr06VIAkJ+87u5SS5Wubt5501t3clratFEFbw0aCPHVV6ptef3zrFgxf/WtWVN9/e5d9Rtfixaq9e3bhahfXz1/VJR0vPRADZAC1YcPVevpgYGZWfZ1cHWVtunpSS1wz55lDRCOH1fl79lTfVtMjBC+vkI4Owtx40b+v0sJCVKglh8LFqiOnzHIzqhZs9wDoFu3VGknT0pB7fr1+a+vpvz3n3r9T5woXDkZAz5AiCNHpPT799W/n999l/8yz54V4s2bwtWnMCIiVPU0MNDccQurTARAz549EwDEuXPn1NK//fZb0axZszz3zy4AKmyZ06ZNEwCyLAyASAghYhJjhM18G2Ew20CcCz0n/rzxp9CfpZ9tUGQ8x1h02dxFnAs9J17GvxSPox6L1LRUbZ9CtjIGE0uWSDfO9PU6daQA65tvVDfUpCQpCMl8c7OwUF9v2lTKf+pU/gMsQAgHByHs7VXrZmZCpKZKrVyA1AqWsatv716pTkIIsWaNFGRs2ybEsmVSq09Bjp3TkrGVJqflyROpDt7eqrSAAOkGX5hjjhghBULdu6t+V1euCOHoqMpjaysFLj/8IMTp06ruJkCIfv1U+71+LQVww4YJce+e1PLXoYMUnEVGClGjhtQdmh5s3boltX5kZ9Qo1TGePpXSwsKE2LVLCrCFyLlVMd2uXerfsczbS4uM/xYAIf7+O+99kpNV10UIKfhp2lS9nO3bpW2NG6unZ/yd5WbHDil/x44FP6eCSEkR4qOPpFbnLVtU9dTRUbV4llYMgApYJluAKC9Pop+IkDchyvUFZxfkq7sM0yE8V3uK5zHPxdnQs2LemXni1wu/itVXVwtFTn9Ga0hQkDSmZ8kSKZBQKIT45Rchfvwx55vgv/9mvbmdPSvEn3+q1uvXl/JmvIn8+68QnTqp1jO3DtWqJd1AfvlFldapk1ROSEjOwYKxsdTqpaeXd2Dx9Kn6Tby4lhs3hPj9d/W0lSvVx3gUdomPl4LAChWybuvcWfopl6vfaPX0pOBGCCFWr86+XB8fIfr2Va3v2SPd5NPLc3eXWggfPlT97jOOFTtwQErr2VNanzlTqmtO55GcLOVP7/7LvCQkSGOoikNiohTo/fef9DsYO1a6htm5cEHqVk1IUE8/c0a9fn/9lfdxhwyRupePH5fWs/v9r1ol1SVzeqtW+Tu35s3Vg8ZLl6QxaXm14ikUQjx+LAWs+XH6tOo4gwap1/W///JXhhDS/yuavo2WiQCoNHWBZcYxQJQXhUIhbkfcFmGxYeLui7ti2cVl4mX8SzHt+LRsgyDdmbpZ0s4/OS9S0lLExoCNYt6ZeeJJ9BNtn1a+LFqkaokxNVX9RWhlJaWNHy+tp6RIN9qhQ6X1jIOy0/+SBYQYM0Z1A4qNFeKDD6T01atVaYUJHurUUY2zSO9m2bat6EHJqVNC/Pyz1J0ISMFCUcvMbRk9Ov9507vY/PzUb5Z5LV98oRromnH57DPpuqWlqXdXpo8DsrOT1vX11cdnZV5u35byZ2x1zLiYmEg/N26UAhYbG2ngfkyMdBP9+WchJk2SgmEhhAgPlwbOv3iR9fv5zTdZy9+yRQo8tmwRomtXIdJvEenbZ85ULyPzoPyVK1Xb/PyyjoN680aVt0MHKe2jj7LWo2dPIVq3Vq2nT0aoWjV/LStNmqj2jYiQuqQy/pv77z9VkHPxovRvRwjVd8jAQPpdxMVJ1yF97JFCIZ1Xo0bSNV64MOffpb9/3vVM17at1EK8caNqvGJJKxMBkBDSgOVRo0Yp19PS0kTlypWLPAi6sGWmYwBEhaVQKMT66+vF6AOjhc4MHdFhQwfhusw1Xy1F9gvtxb2X98TFpxfFH9f+0HoLUW4UCmlc0M6dqrT796VB2zEx2e9z/750A7hyRX0GVOa/rhWKrH+pZhwwCkjdQbNmSV0H6WmrVkkDlCdOlG6M6TeUjP9Unj9X5bewkGa7OTmply2Xq//V6+sr3ZQBKehJt3Jl9jeIzOXltaxcKbXE/fNP9jfNzEvHjtmnV6wodf9lt+30aSGqVcuaLpNJPy0tpSAGkILFSZPUb9oZZ74BQvTpI/2OsjtW+iDzzEvv3nkPsM+8WFioD6zu3l0Kll1cVPXOOEMrLi77cVbjx0sz/DIGHoGB6nm8vaWWHyGkrqqM24YOlVo5L15UpV24IOUNCxOiXj1VepUq0qy+9PXsWu8AadzXy5dSt1J62uefS9/jAQOk72C3bqoxZpmD0N27VZ+trYW4fFlq/ataVYh166T0wYOl/TJ2U/fsKbWapq/v3KneMvfDD6qWvYxL+nmsWSP9G/X1lVoF0+sXEiIFf//8I63fvq2+v5mZaialENL1LwllJgDaunWr0NfXF+vXrxd3794VQ4YMERYWFiI8PFwIIcTnn38uJk6cqMyflJQkrl+/Lq5fvy7s7e3FhAkTxPXr10VQhtGgeZWZHwyAqDiExYaJ5NRkEZsUK7bd3ib23tsr4pLixD8P/slXQLTjzg5tn0KJ+u47aRBsfr/Kly9L/wm//74qTaGQumNWrVKNQ8nLokVCzJmjWk9JUY2P6d1bal14+1Yac1SlitS1k5IiBWqvX6v2i4xUBQ0ZA4rY2KwBW+YlffvAgep1e/NGmrmX8TEF6cuiRVJr2ePH0nENDNTHTHXsKO2fcdYRIOVLTpa6PH191cdxbdqkPhbHwEDVneLllbUO6QO9dXSEmDJF+mxrq2qJqFs35263giyffpr/vN26Sb+jiRPznqFoZqa6PpUrZ90uk0m/5/798z5u8+bS9ze3PB07St/RjLM005cuXaTrnHH2YHbL8uVSPn//wl3LgICsad2755zfzS37sVy5BXUjR0rfrfT12Fhp5mPmMry8pADp11+lPzRKYgB8mQmAhBBi6dKlomrVqkJPT080a9ZMXEgPq4UQbdu2FQMz/A8REhIishus3LZt23yXmR8MgKgkKRQK8ful38Wwv4eJblu6iT+u/SEi4iKE02IntQCo+Zrmyn2SUpPE8svLxYDdA8S3R74V3x35TsQkxoiQNyHi7ou7WjwbzXr0SHNjCiIjVWNpcnLypPQX8fPn0k0u42yh9BvsunXSf/RLlqj++SYnS11pOXV7pKRI+dPLyDxG5NYt6S/ukydVLQjpN8o//5SCgunTpecppY9JSRcdLbU6LV2qev6UpaVURsbnvMTESAFS5cpSy8KMGdLNPPNU9z59pPP+/XcpEEkf++XgoJ7vq6+kYCtja0n6MmyYtMhkQvzxh3ScpUtzv7H/9JPq3NNbhNKXmTOz32fixPwFN+nB0OzZWQf557SsXKn+uAUfH9W19PfPGiwPHy5tCwtTD0orVcp67TI/56swi7d39kFtfpeMsxDzWoyMVEFxbsuECbn/+yqMMhUAlUYMgEgbnkY/FT+d+knMPjlbGQTJZ8iF229u2Y4hGrF/hLCaZyV0Z+qKM4/PaLv6lMmrV1mDj//9Twpe8is0VBrTknF2UWZv3kjjQYoiJkaa/p9dQBYfr97yFRWl3kWSzUgEERAglZnedZh52v6IEVJ61arSLLq0NOnYz5+r58v4YMU5c6SfH34odacKkbVrDpACTiGyv+FeuiR1wVarJnWJbd2q2jZ1qlRPPT3pcQLpM7ZCQqQgd+JEITw9pe7BjIEOoHow5/XrqrStW7Nex8hI1fYhQ7Jetxs3VP+1X7iQtf6dO0vfhZkzVd1h6dcYyLl7FJACxpy6bQHpvDK2DM2fr+oa69pVCkptbFTbjY2loDu3QMfHRxrDlblFVEdHCi5LopefAVARMQAibfM77Zcl4DH9yVQM+3uY0Jmhk2VbpQWVxLdHvhXbb28XKWnqdzGFQiEOPDggdt7ZKZJTk7V0RvSuuXJFamFKfxRBdqKjpdlQGcd+CCEFO4sWSS1YuYmKkrpe1qyRBjHfvKl+00xOllp0ZDIhWrZU7wY9fFia9bdhg/T08F69sr/hHjkiBVLpM9Xy05UaHCy1jA0YkLVMPz9p8Hjmc073zTdSkHU3j4ZbhUJ9PFnv3uqzvaKjhdi3T7qWf/whnUN8vDR1fdAg1WSC9H1fv5bGxmUOUj76SGqhSk6WbivjxknnlT4x4c4d1bi+M2ekbtvHj1Vjf+7dk7qzAClA/N//pLFBS5eqAur0GYaAFFjmdzZaYRTk/i0TQogSfttGmRMTEwNzc3NER0fDzMxM29VRiY8HTEykz3FxhX87H5V6QgjMPTMXr96+QofqHfA05inaOrVFLataSElLQfVfq+NZ7LMc95/vNR9danXBhCMTcOjhIQhI/8xbVW2Fk4NO4t+QfzH64GjM95qPrrW7auq0iErE69fSO/UMDLRdk7wpFNKim49Xkd+/L72vr2PHgr9YNiwMmDtXetFqnTqq9FOngPHjgaZNgREjgOrVi34refwY2LUL6NRJ/V2F6ZKSgH79AHd36X2HJakg928GQNlgAESl3dnQs9gVuAsdanRA8OtgfH3o63zvu6zTMkw/OR2RCZF4r8p7OP/leeW2+5H3oSvXhXNF55KoNhFRiWIAVEQMgKgseZvyFoP2DoJLRRd82+JbvL/hfVwPvw4A6OHaA+Obj0fdSnXx87mfMfv07Cz7b+qxCfcj78NEzwST/52MCjoVcHnwZdSrVE/Tp0JEVCQMgIqIARCVZaHRoVhycQl61+2NZpWbKdMjEyLReGVjPIl5AkNdQzhZOCEwMjDbMtxt3XF1yFUEvgzE6muroRAKNK/SHH3q9YGOTAfrA9bDwsACPer00NRpERHliQFQETEAondVRFwEFpxbgE41O0FA4KMtH+Ft6lsAgIGuAQY3How/b/6JN4lvAAA6Mh2kiTTl/j41feBq5YrFFxdDBhkufnURTSs3LdE6K4QCMsggK+ggCCIqdxgAFREDICovnkQ/waVnl/BhrQ+RJtJgVMEIyy8vx4gDI5R5vJ294WrtipVXVyIxNVFtf2sja3xY60O8SngFz8qeGPveWMhkMuy9txfJack49+QcKhpWhFcNLzhZOBV4bJEQAh3/7IgHrx7g1vBbMNMvRf8eiajUYQBURAyAqDxTCAVWXlmJVEUqOtToADcbNwDAjfAbmHZiGgIjA9HYvjEuPr2IkKiQLPvrynWRqkjNtuwxnmOwsONCxCbF4lHUIzSyb4T7kfdRQacCaljWyJL/eth1NF7VGABwqP8heNf0LsYzJaJ3TUHu3/mYiEdE5YlcJsfwpsOzpDewa4A9ffco1xNTE7Ht9jY8iXkChVBgzuk5SE5LzjH4AYBfL/6KoNdBCIsNw/Xw69jUYxOG7h8KfR19PPz6ISoaVlTL/9etv5Sfr4ZdZQBERMWGARARFYqBrgEGNhyoXK9fqT6WX1mO8c3H4wPnDzDjxAzoyHUwoukImOiZ4EDQAXy26zMcCDqg3Ofz3Z8DABJSEmA13wq2xrb4sNaHmOc1D5aGlthye4sy79WwqwCAB68ewMHUASZ6Jho6UyJ6F7ELLBvsAiMqGZefXUbXLV0RER+Raz65TA5LA0u8evtKmWZhYIF13dah57ae6OzSGfs/3V/S1SWiMoZjgIqIARBRyXkR/wLXw65jbcBabL+zHR4OHujh2gOmeqaoal4Vw/8ZjrC4MGX+XnV6Yd/9fUhRpKiVc3/Ufey4swM/n/8ZXzT6AvHJ8bgbeReOZo6oY10Hw5sOR0XDilAIBeQyuaZPk4i0gAFQETEAItKMNEUadOQ6amnBr4Px68Vfsf/BfjyOfoxzX5xD8JtgjPhnBKKTovNdtoeDB7rV7oa5Z+aiS60u+KDGB3C2dEZIVAiMKxjD3dYddWykdwQIIfAy4SUqGVcq1vMjIs1iAFREDICItE8IgajEKFgaWgIAYpNicfzRcbx++xpD/h6ibBHK+KwiNxs39K3bFzNOzlB7flF2KhpWxINRDxCZEIlNNzdhzuk5WNN1Db5s/GW+6vfHtT9w5+UdzP9gPnTlHE5JVBowACoiBkBEpVt8cjzuv7qP2y9uo3fd3th2extuvbiFOe3nQF9XH1OPT8WsU7MAAB2dO8JUzxSnQ0/jZfxLNLBrgIDwgBzLPv/leUQlRsHb2RsymQzRidEw0TNRa6l68/YNKs6XZqzt6bMH3Vy7lej5ElH+cBo8Eb3TjPWM0di+MRrbS88IyjgbDQB+aP0DjCsYo2XVlmhVtRUAICk1Ca/fvoa9qT2mHZ+GmadmZlt28z+aA5BeGlvDsgZ6be8FKyMrdKrZCU4WThjceDD23d+nzH/w4cEcA6Ck1CTEJcfBysiqyOdMRMWLLUDZYAsQ0bvtUdQj1F9eHzUr1sSBTw/g0rNLUAgFhuwfgsiEyFz3lcvkUAiFct3exB6h34Tizos7qGFZA6b6pkhTpCFVkYo269vgVsQtBAwLQC2rWlnKuvvyLrbf2Y4+dfsoxyMRUeGxC6yIGAARvfuiEqNgqGsIfV19ZVpCSgIi4iIw89RMrA9YDwBo6tAUbaq1gUIo8Netv5RT+CubVsaz2GcApGciJaYmwlzfHK2qtsK/If9CT0dPOWh7QvMJmP/BfAgItRlp7615DxefXQQAXB58GR4OHpo4daJ3FgOgImIARFS+pSnSMP/sfMhlcoxvMV45yPlZzDPsuLsDLhVd8IHzB9hxZwc+2/1ZvsqsaFgRiamJ8G3oi8TURLxNfav2pGsA6F+/P9Z1W4cKOhWK/ZyIygMGQEXEAIiI8mvjjY04+PAgbI1tcT38Osz1zfH3g78BAKObjcbue7vxNOZpjvs7mjnieexz5ay1ZZ2WwdXaFW42brA3tUfw62BsvrUZXzb6EpXNKudYTlJqEh5HP862q42ovGAAVEQMgIioKKITo3Em9Ax8avogLC4MR4OPoqJhRay+thr/BP0DAKhkXAkv4l9gxyc78PrtawzdPzRLOS4VXRD0OkiZf4znGLyMfwkDXQNMbDUR+rr60NPRg1wmx+B9g7Hm+hps7bUVfer10ej5EpUWDICKiAEQEZWEl/EvMeLACPRw7YF+9frhTeIb5QtgU9JS4P2nN44/Ol6gMj+t/ymWdloKq/nSTLMK8gpI/DExy9OvhRCQyWRFqv/z2Ocw0zfje9io1GIAVEQMgIhIG9IUadh2Zxv0dPSw594ePIp6hJikGPzU4SeEx4Xjlwu/IOhVUJbXgmQ2pc0UxCXHYfe93bA2skZKWgruvLyDttXaYn339ahiViXb/eKT43Hh6QW8V+U9GOup//8S+DIQjVY2Qluntjj82eFiO2ei4sQAqIgYABFRaSWEwIGgA/hwy4dZtjWv0hznn57Pdf9edXrhz55/4lrYNWy8sRE6Mh387P0zbkbcRKfNnfD67WtUNa+K3X12K5+zBABjDo7BkktLAAAvv30JayPr4j0xomLAAKiIGAARUWl35fkV2Brb4mrYVVQxqwJrI2tUM6+GWadmYdqJaQCkZxSFxYWhsmllTGkzBcP+GQYdmQ7M9M3wJvGNsqxaVrUQFhuG2ORYZZqtsS1+bPMjutXuBkdzR3iu8cSlZ5cAoMjjjFLSUiCXybO8B46oqBgAFREDICIqq4QQWHV1FV6/fY3vW32Pa2HXUMOyBioaVkTb9W1x6vEpAICNkQ0q6FTA89jnyn2rmFXB2S/OouuWrrgZcROANKboc/fPsTZgrdpxtn28De627hhzaAwevn6I3X12o65NXfx8/mfIIMOBhwfQvXZ3jHlvjNp+M07MwNyzc+Hh4IFTg04VeVwSUUYMgIqIARARvYuCXgVh9bXV8KrhhQ7VO0BHroNbEbcw4sAIVDKuhJ/a/4Ta1rXx5u0brLm2BjsDdypbfQDAzsQOEXEREMh626hmXg1fNvoSU09MVUtf1HERvmn+DQDgeth1NF6l6lYLHBkIV2vXQp3LwaCDCI0OxVCPrLPnqPxiAFREDICIiKRB2VOOT8H/Av8Hl4ou2PrxVkQlRuHHf3/EhhsbAABVzaviWcwz5XOMsjO0yVCMaz4O44+Mx/4H+5Xpi70XK1uIFEIBuUyOoFdBeBb7DPsf7IelgSUmt5mcpbzE1EQYzjEEAJz94ixaOLYoztOmMowBUBExACIiypkQAscfHcfZ0LMY5jEMj6IeocXaFkhVpMKzsiecKzqjU81O+DfkX6wLWJdlf5+aPjj08BCcLZ3xZaMvcen5Jfx9/2/Ym9pneWjkGd8zeB77HJ5VPFHVvCoA4N+Qf9FhYwcAwE/tf8Kk1pNK/qSpTGAAVEQMgIiICuZs6Fm8evsKH9b6UPkMIoVQ4EDQAcw9Mxdnn5yFnYkdRjUdhT71+sDtN7c8p/NnZGVoheEew9HQriEuP7+MeWfnKbdNaTMFHg4eaOrQFDKZDHYmdtk+9yglLQWHgw+jeZXmsDKyKp4Tp1KFAVARMQAiIipeCSkJMKpgpFwPeROCXYG7cPLxSVQ1r4o+dftALpPDVN8UiamJuBF+A6MPjkZSWlKBjyWXyaGno4c57efgQNAB/PfmP9SyqoXQ6FAERgaikV0jXB58mbPQ3kFlLgD67bffsGDBAoSHh6NBgwZYunQpmjVrlmP+HTt2YMqUKXj06BFcXFwwb948dO7cWbl90KBB2LBhg9o+3t7eOHToUL7qwwCIiEj7Lj+7jFmnZqFV1VYw1DXEtfBrWB+wHgBgbWSNJvZNEBYXhuoW1XE4+DASUxPzXfayTsswstlI3Iu8h2th19CzTk/o6+gDAFIUKdDT0UOaIg3Xw6+jiX0TzlYrI8pUALRt2zYMGDAAK1asgKenJxYvXowdO3bg/v37qFSpUpb8586dQ5s2beDn54cPP/wQf/31F+bNm4dr166hXr16AKQAKCIiAuvWqfqe9fX1YWlpma86MQAiIiqdxh8ej/U31mNv371oVbWVMj05LRlymRxdt3TFoYeqP3a9anjh03qfYtGFRahsWhkN7Roqu88sDSzVnodkXMEYMpkMcclxaOrQFHde3kFCSgK+avQVetbpiZikGHxU+yMM3DMQThZOmP/BfM2dOOVLmQqAPD090bRpUyxbtgwAoFAo4OjoiNGjR2PixIlZ8vfp0wfx8fHYv181k+C9995Dw4YNsWLFCgBSABQVFYU9e/YUqk4MgIiIyqboxGjsubcHDewa4MLTCxjUcBAMdA2U2xVCgeH7h2PVtVVFPtbB/gfxQY0PsPLqSuy7vw8eDh74tP6ncLNxU+ZJVaRCR6bDFiQNKTMBUHJyMoyMjLBz5050795dmT5w4EBERUVh7969WfapWrUqxo0bh7FjxyrTpk2bhj179uDGjRsApABoz5490NPTg6WlJdq3b4/Zs2fDyip/g94YABERvdsevHqAK8+v4OHrhxjaZCiik6Jx9flV6Ovqw93WHeuur8OJxyfwMv4lgl4HZVuGvo4+rI2s8Sz2mTJNLpNjwQcL8Prta1wNu4rjIcdRxawKGtk3QtdaXfG5++e4/eI2JhydgBfxL/C+0/vo6NwRPjV9NHXq77SC3L91NVSnbEVGRiItLQ22trZq6ba2trh37162+4SHh2ebPzw8XLnu4+ODnj17onr16ggODsYPP/yATp064fz589DRyTroLSkpCUlJqoF2MTExRTktIiIq5WpZ1UItq1rKdVsTW7X1OR3mAJCm/MenxMNEzwRHgo9gycUlMNU3xcPXD3Hl+RU8i32GioYV0atOL/z35j/4h/hj/JHxascKfhOM4DfB2Hl3J+aemYvH0Y+RkJIAAAgID8AvF35Bn7p9oCvXRfvq7dHAtgGuhl1Fn7p9YG5groGrUT5pNQAqKX379lV+rl+/Ptzd3eHs7IwTJ06gQ4cOWfL7+flhxowZmqwiERGVATKZDCZ6Ust7R+eO6OjcEYA0pf5A0AHIZDK0r94eJnomSElLQc/tPXE0+Cga2zfGp/U/RRWzKrj6/CoeRT/C9jvbERgZCABo4dgCrau2Vo5H2nZnGwBg863NymP/+O+PGNx4MK6GXcWL+BeISYpBVfOqqGNdB80dmyMxNRH/vfkP37f8vkQDpTRFGvxD/NGmWhu17sSyTqsBkLW1NXR0dBAREaGWHhERATs7u2z3sbOzK1B+AKhRowasra3x8OHDbAOgSZMmYdy4ccr1mJgYODo6FuRUiIioHKmgUwHdXLtlSfu7399ZnkHU3bU7AGCs51hsub0F1S2q46vGX0FfVx8dnTuiw8YOMNUzxYAGA3Do4SEEvwkGALxMeImfzvykdozgN8E4/ug4fr/yuzJt0flFmNx6MoY3HY4zoWcw5fgUfFTrI8xuP1tZjyn/TsGFZxfwW+ff4FLRBYGRgXA0c4Spvmme5/rLhV/w7dFvMaTxEKzsurJQ16s0KhWDoJs1a4alS5cCkAZBV61aFaNGjcpxEHRCQgL+/vtvZVqLFi3g7u6uHASd2dOnT1G1alXs2bMHH330UZ514hggIiLSlNOPT6OaRTVUNa8KhVAgISUB+jr6WHV1FU48PgE7YzvUsKwBAAiLC0N8cjzOPjmLGxE3ci3X0sASCqFAdcvqCAgPUKbLZXIohALVzKthYquJ+PvB32hg2wAKoYAMMkxpO0X5zCYhBOQz5cp9i/L+Nk0oM4OgAWka/MCBA7Fy5Uo0a9YMixcvxvbt23Hv3j3Y2tpiwIABqFy5Mvz8/ABI0+Dbtm2LuXPnokuXLti6dSt++ukn5TT4uLg4zJgxA7169YKdnR2Cg4Px3XffITY2Frdu3YK+vn6edWIAREREZcGBoAPKB0o+fP0QpnrSgySze8q2jZENXia8zLNMz8qeaFOtDQIjAxGdGI3ToafVtv/i/QvGeI7JMrPt7su72HJrCz5z/wy1rWsX7cQKqUwFQACwbNky5YMQGzZsiCVLlsDT0xMA0K5dOzg5OWH9+vXK/Dt27MCPP/6ofBDi/PnzlQ9CfPv2Lbp3747r168jKioKDg4O6NixI2bNmpVl8HROGAAREVFZIoRAVGIUjPWMoaejh6cxTxGTFAOFUOBWxC0kpSXhY7ePMeXfKZDJZBjuMRyjDo7CkeAjAABDXUM0d2yO4yHHIZA1LKhiVgVymRyh0aEAgCb2TfBD6x+w5fYWGFcwhqmeKVZcXYFURSqMKxhjY4+NaFutLayMrPDfm/8QFhsGXbkuGtg1wH9v/oNLRRdU0KlQ7NehzAVApQ0DICIietcJIRAYGYjaVrWVrwW5/eI21gesR1xyHFytXRERFwFHc0d80egL6OvoY97ZeZh5cibepr7N1zFcrV1xLzLrrO4m9k2w7eNtcK7oXKznxACoiBgAERERZe9ZzDP039Ufl59fhpuNG2yNbWGqb4p+9frBp6YP+v2vH3YF7lLbx0zfDDFJ6o+Y+aj2R9jbN+vz/oqCAVARMQAiIiLKXebZbhnToxKjEJ0UjQtPL6CqeVW0cGyBZzHP4HfGD43tG2P/g/34rfNvsDe1L9Y6MQAqIgZAREREZU9B7t/yXLcSERERvYMYABEREVG5wwCIiIiIyh0GQERERFTuMAAiIiKicocBEBEREZU7DICIiIio3GEAREREROUOAyAiIiIqdxgAERERUbnDAIiIiIjKHQZAREREVO4wACIiIqJyhwEQERERlTu62q4AFYCRERAXp/pMREREhcIAqCyRyQBjY23XgoiIqMxjFxgRERGVOwyAiIiIqNxhAERERETlDgMgIiIiKncYABEREVG5wwCIiIiIyh0GQERERFTuMAAiIiKicocBEBEREZU7DICIiIio3GEAREREROUOAyAiIiIqdxgAERERUbnDt8FnQwgBAIiJidFyTYiIiCi/0u/b6ffx3DAAykZsbCwAwNHRUcs1ISIiooKKjY2Fubl5rnlkIj9hUjmjUCjw/PlzmJqaQiaTFVu5MTExcHR0xJMnT2BmZlZs5ZI6XmfN4bXWDF5nzeG11oySus5CCMTGxsLBwQFyee6jfNgClA25XI4qVaqUWPlmZmb8h6UBvM6aw2utGbzOmsNrrRklcZ3zavlJx0HQREREVO4wACIiIqJyhwGQBunr62PatGnQ19fXdlXeabzOmsNrrRm8zprDa60ZpeE6cxA0ERERlTtsASIiIqJyhwEQERERlTsMgIiIiKjcYQBERERE5Q4DIA357bff4OTkBAMDA3h6euLSpUvarlKZc+rUKXTt2hUODg6QyWTYs2eP2nYhBKZOnQp7e3sYGhrCy8sLQUFBanlev36N/v37w8zMDBYWFvjyyy8RFxenwbMo/fz8/NC0aVOYmpqiUqVK6N69O+7fv6+WJzExESNHjoSVlRVMTEzQq1cvREREqOUJDQ1Fly5dYGRkhEqVKuHbb79FamqqJk+lVFu+fDnc3d2VD4Jr3rw5Dh48qNzOa1wy5s6dC5lMhrFjxyrTeK2Lx/Tp0yGTydQWV1dX5fZSd50FlbitW7cKPT09sXbtWnHnzh0xePBgYWFhISIiIrRdtTLlwIEDYvLkyWLXrl0CgNi9e7fa9rlz5wpzc3OxZ88ecePGDfHRRx+J6tWri7dv3yrz+Pj4iAYNGogLFy6I06dPi5o1a4p+/fpp+ExKN29vb7Fu3Tpx+/ZtERAQIDp37iyqVq0q4uLilHmGDRsmHB0dhb+/v7hy5Yp47733RIsWLZTbU1NTRb169YSXl5e4fv26OHDggLC2thaTJk3SximVSvv27RP//POPePDggbh//7744YcfRIUKFcTt27eFELzGJeHSpUvCyclJuLu7izFjxijTea2Lx7Rp00TdunVFWFiYcnn58qVye2m7zgyANKBZs2Zi5MiRyvW0tDTh4OAg/Pz8tFirsi1zAKRQKISdnZ1YsGCBMi0qKkro6+uLLVu2CCGEuHv3rgAgLl++rMxz8OBBIZPJxLNnzzRW97LmxYsXAoA4efKkEEK6rhUqVBA7duxQ5gkMDBQAxPnz54UQUrAql8tFeHi4Ms/y5cuFmZmZSEpK0uwJlCGWlpZizZo1vMYlIDY2Vri4uIijR4+Ktm3bKgMgXuviM23aNNGgQYNst5XG68wusBKWnJyMq1evwsvLS5kml8vh5eWF8+fPa7Fm75aQkBCEh4erXWdzc3N4enoqr/P58+dhYWEBDw8PZR4vLy/I5XJcvHhR43UuK6KjowEAFStWBABcvXoVKSkpatfa1dUVVatWVbvW9evXh62trTKPt7c3YmJicOfOHQ3WvmxIS0vD1q1bER8fj+bNm/Mal4CRI0eiS5cuatcU4Pe5uAUFBcHBwQE1atRA//79ERoaCqB0Xme+DLWERUZGIi0tTe0XCgC2tra4d++elmr17gkPDweAbK9z+rbw8HBUqlRJbbuuri4qVqyozEPqFAoFxo4di5YtW6JevXoApOuop6cHCwsLtbyZr3V2v4v0bSS5desWmjdvjsTERJiYmGD37t1wc3NDQEAAr3Ex2rp1K65du4bLly9n2cbvc/Hx9PTE+vXrUbt2bYSFhWHGjBlo3bo1bt++XSqvMwMgIsrRyJEjcfv2bZw5c0bbVXkn1a5dGwEBAYiOjsbOnTsxcOBAnDx5UtvVeqc8efIEY8aMwdGjR2FgYKDt6rzTOnXqpPzs7u4OT09PVKtWDdu3b4ehoaEWa5Y9doGVMGtra+jo6GQZ6R4REQE7Ozst1erdk34tc7vOdnZ2ePHihdr21NRUvH79mr+LbIwaNQr79+/H8ePHUaVKFWW6nZ0dkpOTERUVpZY/87XO7neRvo0kenp6qFmzJpo0aQI/Pz80aNAAv/76K69xMbp69SpevHiBxo0bQ1dXF7q6ujh58iSWLFkCXV1d2Nra8lqXEAsLC9SqVQsPHz4sld9pBkAlTE9PD02aNIG/v78yTaFQwN/fH82bN9dizd4t1atXh52dndp1jomJwcWLF5XXuXnz5oiKisLVq1eVef79918oFAp4enpqvM6llRACo0aNwu7du/Hvv/+ievXqatubNGmCChUqqF3r+/fvIzQ0VO1a37p1Sy3gPHr0KMzMzODm5qaZEymDFAoFkpKSeI2LUYcOHXDr1i0EBAQoFw8PD/Tv31/5mde6ZMTFxSE4OBj29val8ztd7MOqKYutW7cKfX19sX79enH37l0xZMgQYWFhoTbSnfIWGxsrrl+/Lq5fvy4AiEWLFonr16+Lx48fCyGkafAWFhZi79694ubNm6Jbt27ZToNv1KiRuHjxojhz5oxwcXHhNPhMhg8fLszNzcWJEyfUprMmJCQo8wwbNkxUrVpV/Pvvv+LKlSuiefPmonnz5srt6dNZO3bsKAICAsShQ4eEjY0Npw1nMHHiRHHy5EkREhIibt68KSZOnChkMpk4cuSIEILXuCRlnAUmBK91cRk/frw4ceKECAkJEWfPnhVeXl7C2tpavHjxQghR+q4zAyANWbp0qahatarQ09MTzZo1ExcuXNB2lcqc48ePCwBZloEDBwohpKnwU6ZMEba2tkJfX1906NBB3L9/X62MV69eiX79+gkTExNhZmYmfH19RWxsrBbOpvTK7hoDEOvWrVPmefv2rRgxYoSwtLQURkZGokePHiIsLEytnEePHolOnToJQ0NDYW1tLcaPHy9SUlI0fDal1xdffCGqVasm9PT0hI2NjejQoYMy+BGC17gkZQ6AeK2LR58+fYS9vb3Q09MTlStXFn369BEPHz5Ubi9t11kmhBDF365EREREVHpxDBARERGVOwyAiIiIqNxhAERERETlDgMgIiIiKncYABEREVG5wwCIiIiIyh0GQERERFTuMAAiIsqBTCbDnj17tF0NIioBDICIqFQaNGgQZDJZlsXHx0fbVSOid4CutitARJQTHx8frFu3Ti1NX19fS7UhoncJW4CIqNTS19eHnZ2d2mJpaQlA6p5avnw5OnXqBENDQ9SoUQM7d+5U2//WrVto3749DA0NYWVlhSFDhiAuLk4tz9q1a1G3bl3o6+vD3t4eo0aNUtseGRmJHj16wMjICC4uLti3b59y25s3b9C/f3/Y2NjA0NAQLi4uWQI2IiqdGAARUZk1ZcoU9OrVCzdu3ED//v3Rt29fBAYGAgDi4+Ph7e0NS0tLXL58GTt27MCxY8fUApzly5dj5MiRGDJkCG7duoV9+/ahZs2aaseYMWMGevfujZs3b6Jz587o378/Xr9+rTz+3bt3cfDgQQQGBmL58uWwtrbW3AUgosIrkVesEhEV0cCBA4WOjo4wNjZWW+bMmSOEkN5aP2zYMLV9PD09xfDhw4UQQqxatUpYWlqKuLg45fZ//vlHyOVyER4eLoQQwsHBQUyePDnHOgAQP/74o3I9Li5OABAHDx4UQgjRtWtX4evrWzwnTEQaxTFARFRqvf/++1i+fLlaWsWKFZWfmzdvrratefPmCAgIAAAEBgaiQYMGMDY2Vm5v2bIlFAoF7t+/D5lMhufPn6NDhw651sHd3V352djYGGZmZnjx4gUAYPjw4ejVqxeuXbuGjh07onv37mjRokWhzpWINIsBEBGVWsbGxlm6pIqLoaFhvvJVqFBBbV0mk0GhUAAAOnXqhMePH+PAgQM4evQoOnTogJEjR2LhwoXFXl8iKl4cA0REZdaFCxeyrNepUwcAUKdOHdy4cQPx8fHK7WfPnoVcLkft2rVhamoKJycn+Pv7F6kONjY2GDhwIP78808sXrwYq1atKlJ5RKQZbAEiolIrKSkJ4eHhamm6urrKgcY7duyAh4cHWrVqhc2bN+PSpUv4448/AAD9+/fHtGnTMHDgQEyfPh0vX77E6NGj8fnnn8PW1hYAMH36dAwbNgyVKlVCp06dEBsbi7Nnz2L06NH5qt/UqVPRpEkT1K1bF0lJSdi/f78yACOi0o0BEBGVWocOHYK9vb1aWu3atXHv3j0A0gytrVu3YsSIEbC3t8eWLVvg5uYGADAyMsLhw4cxZswYNG3aFEZGRujVqxcWLVqkLGvgwIFITEzEL7/8ggkTJsDa2hoff/xxvuunp6eHSZMm4dGjRzA0NETr1q2xdevWYjhzIippMiGE0HYliIgKSiaTYffu3ejevbu2q0JEZRDHABEREVG5wwCIiIiIyh2OASKiMom990RUFGwBIiIionKHARARERGVOwyAiIiIqNxhAERERETlDgMgIiIiKncYABEREVG5wwCIiIiIyh0GQERERFTuMAAiIiKicuf/APjUwvbOuppNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model_history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = model_history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], loss[0:(len(val_iou) - 1)], 'g', label= 'Training Loss')\n",
    "plt.plot(epochs[0:(len(val_iou) - 1)], val_loss[0:(len(val_iou) - 1)], 'b', label= 'Validation Loss')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'../output/plots/Loss/loss_{model_name}.png', bbox_inches='tight', dpi= 500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 120ms/step\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "#unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "#compile_model(unet, learning_rate)\n",
    "\n",
    "# Prognose mit Hilfe des geladenen besten Modells\n",
    "prediction = unet.predict(test_data_generator)\n",
    "\n",
    "# Erstellung einer binären Maske aus den wahrscheinlichkeiten, Schwellwert 0.5\n",
    "out = (prediction > 0.5).astype(np.uint8)\n",
    "\n",
    "# lediglich halbe Batch Size in eine Abbildung wegen Übersichtlichkeit\n",
    "rows = int(batch_size / 2)\n",
    "columns = 3\n",
    "\n",
    "# Anzahl verfügbarer Batches des Data-Generators\n",
    "no_of_batches = test_data_generator.__len__()\n",
    "\n",
    "# Prognose kommt als Tensor mit der Länge der Anzahl der Beispiele\n",
    "out_idx = 0\n",
    "\n",
    "# Erstellen des Prognosen-Ordners\n",
    "if not os.path.isdir(f'../output/predictions/{model_name}'):\n",
    "    os.makedirs(f'../output/predictions/{model_name}')\n",
    "\n",
    "# Input und Masken kommen als Batches, über die iteriert wird\n",
    "for batch_no in range(0, no_of_batches):\n",
    "\n",
    "    # iterieren über erste Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_I.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # iterieren über zweite Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][rows + i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][rows + i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    print(batch_no)\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_II.png', bbox_inches='tight', dpi= 400)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Zusammenführen der .log-Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "combine_log_files(output_folder_prefix, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 7,\n",
       " 11,\n",
       " 15,\n",
       " 18,\n",
       " 22,\n",
       " 26,\n",
       " 27,\n",
       " 30,\n",
       " 34,\n",
       " 38,\n",
       " 42,\n",
       " 46,\n",
       " 50,\n",
       " 53,\n",
       " 57,\n",
       " 61,\n",
       " 64,\n",
       " 68,\n",
       " 72,\n",
       " 75,\n",
       " 79,\n",
       " 83,\n",
       " 86,\n",
       " 90,\n",
       " 94,\n",
       " 95,\n",
       " 98,\n",
       " 102,\n",
       " 106,\n",
       " 110,\n",
       " 114,\n",
       " 118,\n",
       " 121,\n",
       " 125,\n",
       " 129,\n",
       " 132,\n",
       " 136,\n",
       " 140,\n",
       " 141,\n",
       " 144,\n",
       " 148,\n",
       " 152,\n",
       " 156,\n",
       " 160,\n",
       " 164,\n",
       " 167,\n",
       " 171,\n",
       " 175,\n",
       " 176,\n",
       " 179,\n",
       " 183,\n",
       " 188]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "idx = 0\n",
    "\n",
    "conv_idx_list = []\n",
    "\n",
    "for i, layer in enumerate(reversed(unet.layers)):\n",
    "    if layer.name == 'up_sampling2d':\n",
    "        idx = 0\n",
    "    #print(layer.name)\n",
    "    if re.search(r\"conv$\", layer.name):\n",
    "        conv_idx_list.append(idx)\n",
    "        #print(idx, layer.name)\n",
    "\n",
    "    idx +=1\n",
    "\n",
    "conv_idx_list   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " split_input (Lambda)           [(None, 224, 224, 1  0           ['input[0][0]']                  \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dropout_r (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_g (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][1]']            \n",
      "                                                                                                  \n",
      " dropout_b (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][2]']            \n",
      "                                                                                                  \n",
      " dropout_ir (Dropout)           (None, 224, 224, 1)  0           ['split_input[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_dropout (Concatena  (None, 224, 224, 4)  0          ['dropout_r[0][0]',              \n",
      " te)                                                              'dropout_g[0][0]',              \n",
      "                                                                  'dropout_b[0][0]',              \n",
      "                                                                  'dropout_ir[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 2048  0           ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 2304  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 256)  5308416     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 14, 256)  1024       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 14, 256)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 256)  589824      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  442368      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  147456      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   110592      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36864       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_3[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 32  36864       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 112, 112, 32  9216        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 36  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 16  5184        ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 224, 224, 16  2304        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 16  64         ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 1)  145         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 18,787,025\n",
      "Non-trainable params: 11,474,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"Final_AVG_rgbDrop_0_earlyStop_True_e500\"\n",
    "\n",
    "def combine_log_files():\n",
    "    # Zusammenführen der .log Dateien von Initial- und Fine-Tuning Training und Schreiben in neue CSV-Datei\n",
    "    filenames = [f'../output/{output_folder_prefix}_logger/{model_name}_I.log', f'../output/{output_folder_prefix}_logger/{model_name}.log']\n",
    "    with open(f'../output/{output_folder_prefix}_logger/{model_name}.csv', 'w') as outfile:\n",
    "        # spezifizieren des Delimiters für Excel in erster Zeile\n",
    "        outfile.write('sep=,\\n')\n",
    "\n",
    "        for i, fname in enumerate(filenames):\n",
    "            with open(fname) as infile:\n",
    "                reader = csv.reader(infile)\n",
    "\n",
    "                for j, row in enumerate(reader):\n",
    "                    # überspringen des 2. Headers\n",
    "                    if i == 1 and j == 0:\n",
    "                        continue\n",
    "\n",
    "                    delimiter = ','\n",
    "                    list_to_string = delimiter.join(row)\n",
    "                    list_to_string += '\\n'\n",
    "\n",
    "                    outfile.write(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.7961242198944092', '0.6587730646133423', '20309084.0', '44833484.0', '0.24731293320655823', '0.7116237282752991', '0.8449028730392456', '143743008.0', '110635216.0', '0.8323593139648438', '0.7104504108428955', '6571040.0', '11194135.0', '0.19853559136390686', '0.7745783925056458', '0.8540922403335571', '49742008.0', '38464532.0']\n",
      "['1', '0.8555810451507568', '0.7428621053695679', '19262012.0', '26882816.0', '0.17415392398834229', '0.8062108755111694', '0.8530752658843994', '161536704.0', '111839176.0', '0.8509215116500854', '0.7363330125808716', '7721061.0', '8077029.0', '0.17862582206726074', '0.8224303126335144', '0.8289172649383545', '52764112.0', '37409496.0']\n",
      "['2', '0.868036687374115', '0.7619959115982056', '18203548.0', '23961460.0', '0.15954600274562836', '0.8248876929283142', '0.8611232042312622', '164482416.0', '112873368.0', '0.855846107006073', '0.7469853162765503', '3632307.0', '11643931.0', '0.15823477506637573', '0.7808046936988831', '0.9194782376289368', '49218136.0', '41477340.0']\n",
      "['3', '0.8770635724067688', '0.7761090993881226', '17652532.0', '21628236.0', '0.14948749542236328', '0.8399236798286438', '0.8653879761695862', '166756288.0', '113483792.0', '0.8836488127708435', '0.7868425846099854', '7168806.0', '5161118.0', '0.1418834626674652', '0.8805040121078491', '0.8413925170898438', '55612164.0', '38029616.0']\n",
      "['4', '0.883385956287384', '0.7862225770950317', '16949292.0', '20311302.0', '0.14213760197162628', '0.8488912582397461', '0.8706685900688171', '168156272.0', '114103848.0', '0.8866237998008728', '0.7932666540145874', '5359944.0', '6654737.0', '0.13384389877319336', '0.8567112684249878', '0.8812807202339172', '54168920.0', '39788112.0']\n",
      "['5', '0.8867051005363464', '0.7916681170463562', '16491997.0', '19708040.0', '0.13844023644924164', '0.8533272743225098', '0.8742521405220032', '168661360.0', '114659360.0', '0.8920537829399109', '0.8013637065887451', '5901398.0', '5537848.0', '0.12899699807167053', '0.8761326670646667', '0.8690656423568726', '55362416.0', '39170048.0']\n",
      "['6', '0.8899984359741211', '0.797005295753479', '16219609.0', '18928164.0', '0.13410015404224396', '0.8585999608039856', '0.8763315081596375', '169438704.0', '114934304.0', '0.8933471441268921', '0.8045114278793335', '4735190.0', '6566981.0', '0.12450148910284042', '0.8601561188697815', '0.8950710296630859', '54277184.0', '40392380.0']\n",
      "['7', '0.8955606818199158', '0.8061417937278748', '15626842.0', '17743680.0', '0.1278112232685089', '0.866841197013855', '0.8808341026306152', '170641936.0', '115508360.0', '0.8974204063415527', '0.8101271390914917', '5816458.0', '5054095.0', '0.12367336452007294', '0.8860129714012146', '0.8710364103317261', '55816044.0', '39285116.0']\n",
      "['8', '0.8968602418899536', '0.8083475828170776', '15260560.0', '17694812.0', '0.12622345983982086', '0.8674541115760803', '0.8835651874542236', '170760672.0', '115804736.0', '0.898605465888977', '0.8104246854782104', '7315006.0', '3429948.0', '0.12633559107780457', '0.916635274887085', '0.8375488519668579', '57512820.0', '37713940.0']\n",
      "['9', '0.900827169418335', '0.814872145652771', '15107959.0', '16579737.0', '0.1218128651380539', '0.8749462366104126', '0.8847680687904358', '171831952.0', '116001152.0', '0.8998227715492249', '0.8146814703941345', '5080673.0', '5535273.0', '0.11853206157684326', '0.8784630298614502', '0.8873198628425598', '55347104.0', '40008656.0']\n",
      "['10', '0.9033365249633789', '0.8191630840301514', '14566899.0', '16319088.0', '0.1187213733792305', '0.8771561980247498', '0.8888803720474243', '172109632.0', '116525144.0', '0.9009268283843994', '0.8165515661239624', '5037168.0', '5461766.0', '0.11778794229030609', '0.8800939917564392', '0.8883749842643738', '55384136.0', '40088640.0']\n",
      "['11', '0.9063057899475098', '0.8241333961486816', '14384998.0', '15552271.0', '0.11546950787305832', '0.8824447989463806', '0.8902999758720398', '172838176.0', '116745344.0', '0.8959559202194214', '0.8076335787773132', '5974802.0', '5050926.0', '0.12591783702373505', '0.8857436776161194', '0.8676116466522217', '55789924.0', '39156056.0']\n",
      "['12', '0.9102160334587097', '0.8309040665626526', '13612249.0', '15075643.0', '0.10997866094112396', '0.8863572478294373', '0.8962439894676208', '173250304.0', '117582520.0', '0.9019008874893188', '0.8180277347564697', '5200968.0', '5194741.0', '0.11701411753892899', '0.8849327564239502', '0.8848106861114502', '55625476.0', '39950520.0']\n",
      "['13', '0.9113559722900391', '0.8327949643135071', '13592185.0', '14731369.0', '0.10891933739185333', '0.8886242508888245', '0.8963442444801331', '173661312.0', '117535936.0', '0.9012283086776733', '0.8175053596496582', '4434233.0', '6032764.0', '0.11556345224380493', '0.8707954287528992', '0.9016647934913635', '54845904.0', '40658800.0']\n",
      "['14', '0.9112589955329895', '0.8326512575149536', '13557967.0', '14796571.0', '0.10920999199151993', '0.8882356882095337', '0.8966241478919983', '173571968.0', '117594240.0', '0.9038447737693787', '0.8203587532043457', '6198846.0', '3990891.0', '0.11703916639089584', '0.9071902632713318', '0.862883985042572', '56772072.0', '39009900.0']\n",
      "['15', '0.9150487780570984', '0.8391707539558411', '13070933.0', '14072871.0', '0.10437954217195511', '0.893510639667511', '0.9003366827964783', '174296912.0', '118079960.0', '0.9026321172714233', '0.81894850730896', '5502799.0', '4815433.0', '0.11641963571310043', '0.8916648030281067', '0.8780860304832458', '56019548.0', '39633948.0']\n",
      "['16', '0.9170372486114502', '0.8425793647766113', '12875547.0', '13632801.0', '0.10238707065582275', '0.8966102004051208', '0.901789128780365', '174786896.0', '118225480.0', '0.9023330807685852', '0.8191585540771484', '4628317.0', '5721616.0', '0.11487342417240143', '0.8761098980903625', '0.8973531723022461', '55160384.0', '40461384.0']\n",
      "['17', '0.9163618683815002', '0.8415076732635498', '12748003.0', '13976263.0', '0.10324450582265854', '0.8944720029830933', '0.902845025062561', '174331424.0', '118465040.0', '0.9080192446708679', '0.82755446434021', '5744502.0', '4002860.0', '0.11195121705532074', '0.9076095223426819', '0.8725345134735107', '56901776.0', '39322596.0']\n",
      "['18', '0.9190995693206787', '0.8461706042289734', '12620972.0', '13228408.0', '0.0997830331325531', '0.8995869159698486', '0.9037539958953857', '175159920.0', '118511456.0', '0.9019047021865845', '0.8167356252670288', '6489242.0', '3906086.0', '0.12046819925308228', '0.9080408215522766', '0.8559849858283997', '57006160.0', '38570224.0']\n",
      "['19', '0.9203644394874573', '0.8483947515487671', '12331894.0', '13113312.0', '0.09815822541713715', '0.9005417823791504', '0.905910849571228', '175341472.0', '118734152.0', '0.9094333648681641', '0.830341100692749', '5351531.0', '4245958.0', '0.10895109176635742', '0.9036170840263367', '0.8814947605133057', '56567128.0', '39807088.0']\n"
     ]
    }
   ],
   "source": [
    "with open(f'../output/{output_folder_prefix}_logger/{model_name}_I.log') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " split_input (Lambda)           [(None, 224, 224, 1  0           ['input[0][0]']                  \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 224, 224, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dropout_r (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_g (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][1]']            \n",
      "                                                                                                  \n",
      " dropout_b (Dropout)            (None, 224, 224, 1)  0           ['split_input[0][2]']            \n",
      "                                                                                                  \n",
      " dropout_ir (Dropout)           (None, 224, 224, 1)  0           ['split_input[0][3]']            \n",
      "                                                                                                  \n",
      " concatenate_dropout (Concatena  (None, 224, 224, 4)  0          ['dropout_r[0][0]',              \n",
      " te)                                                              'dropout_g[0][0]',              \n",
      "                                                                  'dropout_b[0][0]',              \n",
      "                                                                  'dropout_ir[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 4)  0           ['concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  12608       ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 2048  0           ['post_relu[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 2304  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 256)  5308416     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14, 14, 256)  1024       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 14, 14, 256)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 256)  589824      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  442368      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 128)  147456      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 192)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   110592      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36864       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64  0          ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 12  0           ['up_sampling2d_3[0][0]',        \n",
      "                                8)                                'conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 112, 112, 32  36864       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 112, 112, 32  9216        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 36  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'concatenate_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 16  5184        ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 224, 224, 16  2304        ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 16  64         ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 1)  145         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " masks (Activation)             (None, 224, 224, 1)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,261,137\n",
      "Trainable params: 18,787,025\n",
      "Non-trainable params: 11,474,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "unet.save(f'{model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
