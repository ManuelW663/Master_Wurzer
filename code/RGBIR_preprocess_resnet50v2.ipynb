{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auszuführen mit Environment \"tf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importe & Definitionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# Definition des Data-Generators\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, batch_size, img_directory, msk_directory, shuffle= False, augment= False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_directory = img_directory\n",
    "        self.msk_directory = msk_directory\n",
    "        self.list_img_IDs = os.listdir(self.img_directory)\n",
    "        self.list_msk_IDs = os.listdir(self.msk_directory)\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "\n",
    "    def augment_data(self, x, y):     \n",
    "        x_flip = x\n",
    "        y_flip = y\n",
    "\n",
    "        # zufällige horizontale & vertikale Flips\n",
    "        horiz = random.randint(0, 9)\n",
    "        if horiz <= 4:\n",
    "            x_flip = np.fliplr(x)\n",
    "            y_flip = np.fliplr(y)\n",
    "\n",
    "        vert = random.randint(0, 9)\n",
    "        if vert <= 4:\n",
    "            x_flip = np.flipud(x_flip)\n",
    "            y_flip = np.flipud(y_flip)\n",
    "        \n",
    "        return x_flip, y_flip\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.img_directory)) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_img_IDs = self.list_img_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_msk_IDs = self.list_msk_IDs[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_id, msk_id in zip(batch_img_IDs, batch_msk_IDs):\n",
    "            # einlesen Bild\n",
    "            img_path = os.path.join(self.img_directory, img_id)\n",
    "            with open(img_path, 'rb') as f:\n",
    "                image = tifffile.imread(f)\n",
    "\n",
    "            image = np.moveaxis(image, 0, -1)\n",
    "            \n",
    "            # einlesen Maske\n",
    "            msk_path = os.path.join(self.msk_directory, msk_id)\n",
    "            with open(msk_path, 'rb') as f:\n",
    "                mask = tifffile.imread(f)\n",
    "\n",
    "            mask = mask[:, :, np.newaxis]\n",
    "\n",
    "            # Data Augmentation\n",
    "            if self.augment:\n",
    "                image, mask = self.augment_data(image, mask)\n",
    "\n",
    "            images.append((image / 127.5) - 1)\n",
    "            masks.append(mask/255)\n",
    "        \n",
    "        return (np.array(images), np.array(masks))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            a = self.list_img_IDs\n",
    "            b = self.list_msk_IDs\n",
    "\n",
    "            c = list(zip(a, b))\n",
    "\n",
    "            random.shuffle(c)\n",
    "\n",
    "            self.list_img_IDs, self.list_msk_IDs = zip(*c)\n",
    "\n",
    "\n",
    "def Dice_coefficient(y_true, y_pred, smooth=10e-6):        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def Dice_loss(y_true, y_pred):\n",
    "    return 1 - Dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def reverse_scaling(image):\n",
    "    return (((image + 1) / 2 )* 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def load_model(model_type):\n",
    "    model_dict = {\n",
    "        'BN': './model_config_files/conf.json',\n",
    "        'CONV': './model_config_files/conf_RGB_addConv3.json',\n",
    "        'SPLIT': './model_config_files/conf_splitRGB.json'\n",
    "        }\n",
    "\n",
    "    path = model_dict[model_type]\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        new_conf = json.load(f)\n",
    "\n",
    "    unet = tf.keras.Model().from_config(new_conf)\n",
    "\n",
    "    # Wo die shape der Gewichte des Layers es zulässt, werden immer die selben zufällig initialisierten Gewichte verwendet\n",
    "    random_path = './saved_weights/unet_resnet50v2_random.npy'\n",
    "\n",
    "    if model_type == 'BN':\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "        unet.set_weights(loaded_weights)\n",
    "\n",
    "\n",
    "    elif model_type == 'CONV':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(2):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[2:], loaded_weights):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    elif model_type == 'SPLIT':\n",
    "        # zufällige Gewichte des neu erstellten U-Nets\n",
    "        unet_weights = unet.get_weights()\n",
    "\n",
    "        # gespeicherte zufällige Gewichte für den einheitlichen Decoder-Teil des U-Nets\n",
    "        loaded_weights = np.load(random_path, allow_pickle= True)\n",
    "\n",
    "        # Leere Liste für neue Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # kernel und bias Gewichte des zusätzlichen Convolution-layer\n",
    "        for i in range(4):\n",
    "            updated_weights.append(unet_weights[i])\n",
    "\n",
    "        # einfügen aller weiteren Gewichte\n",
    "        for unet_w, loaded_w in zip(unet_weights[4:], loaded_weights[2:]):\n",
    "            # für den 2. Convolution-layer passt die shape nicht, bleibt daher unberührt\n",
    "            if unet_w.shape != loaded_w.shape:\n",
    "                updated_weights.append(unet_w)\n",
    "\n",
    "            # alle anderen werden durch die geladenen ersetzt\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "    return unet\n",
    "\n",
    "def set_dropout(unet, rgb_drop, ir_drop):\n",
    "    rgb_names = ['dropout_r', 'dropout_g', 'dropout_b']\n",
    "    ir_name = 'dropout_ir'\n",
    "\n",
    "    for layer in unet.layers:\n",
    "        if layer.name in rgb_names:\n",
    "            layer.rate = rgb_drop\n",
    "\n",
    "        if layer.name in ir_name:\n",
    "            layer.rate = ir_drop\n",
    "\n",
    "\n",
    "def set_weight_decay(unet, l1, l2):\n",
    "    regularizer = tf.keras.regularizers.L1L2(l1= l1, l2= l2)\n",
    "\n",
    "    for layer in unet.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                layer.kernel_regularizer = regularizer\n",
    "\n",
    "\n",
    "def mean_of_RGB_weights(weights):\n",
    "  # Mittelwert entlang der Kanal-Achse (=-2)\n",
    "  mean_weights = np.mean(weights, axis=-2).reshape(weights[:,:,-1:,:].shape)\n",
    "  # Squeeze um Kanalachse = 1 zu kollabieren\n",
    "  mean_weights = np.squeeze(mean_weights, axis= -2)\n",
    "  return(mean_weights)\n",
    "  \n",
    "def set_pretrained_weights(unet, option):\n",
    "    unet = unet\n",
    "    unet_weights = unet.get_weights()\n",
    "\n",
    "    # Laden der Gewichte des vortrainierten ResNet aus Keras\n",
    "    RGB_weights_path = './saved_weights/orig_resnet50v2_imagenet_weights.npy'\n",
    "    saved_weights = np.load(RGB_weights_path, allow_pickle= True)\n",
    "\n",
    "    # Abschneiden der Classifier-Gewichte\n",
    "    saved_weights = saved_weights[:-2]\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte Mittelwert aus RGB\n",
    "    if option == 'AVG':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            # Ende des Encoder-Teils\n",
    "            if i == len(saved_weights):\n",
    "                break\n",
    "            \n",
    "            # 1. Conv-layer ist i=0\n",
    "            if i == 0:\n",
    "                layer[:,:, 3, :] = mean_of_RGB_weights(saved_weights[i])\n",
    "                layer[:,:, 0:3, :] = saved_weights[i][...]\n",
    "\n",
    "            # alle anderen Gewichte können übernommen werden\n",
    "            else:\n",
    "                layer[...] = saved_weights[i][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # Übernehmen der RGB Gewichte für 1. Convolution-layer, IR Gewichte zufällig\n",
    "    if option == 'RNDM':\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Iterieren über geladene Gewichte und zufällige\n",
    "        for unet_w, loaded_w in zip(unet_weights, saved_weights):\n",
    "            # Für 1. Conv-Layer stimmt shape nicht überein\n",
    "            if (unet_w.shape != loaded_w.shape):\n",
    "                new_weights = unet_w\n",
    "                # Gewichte für RGB-Channel werden übernommen, IR bleibt wie er ist\n",
    "                new_weights[:,:, 0:3, :] = loaded_w\n",
    "                updated_weights.append(new_weights)\n",
    "\n",
    "            # alle anderen shapes stimmen überein und können übernommen werden\n",
    "            else:\n",
    "                updated_weights.append(loaded_w)\n",
    "\n",
    "        # hinzufügen der zufälligen Gewichte des Decoder-parts\n",
    "        for unet_w in unet_weights[len(saved_weights):]:\n",
    "            updated_weights.append(unet_w)\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "    # Zusätzlicher Convolution-Layer vor Encoder\n",
    "    if option == 'RGB':\n",
    "        # Gewichte setzen für den Encoder-Teil:\n",
    "        # Beginn ab i=2 durch eingeschobenen Conv-Layer, bis Bottleneck i=269+2\n",
    "        for i, layer in enumerate(unet_weights):\n",
    "            if 2 <= i <= 269+2:\n",
    "                layer[...] = saved_weights[i-2][...]\n",
    "                \n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(unet_weights)\n",
    "\n",
    "\n",
    "    # seperate Convolution Layer für RGB und IR\n",
    "    if option == 'RGB_SPLIT':\n",
    "        loaded = np.load('./saved_weights/orig_resnet50v2_imagenet_weight_paths.npy', allow_pickle= True)\n",
    "        loaded = loaded[()]\n",
    "\n",
    "        # Leere Liste für aktualisierte Gewichte\n",
    "        updated_weights = []\n",
    "\n",
    "        # Liste mit Layernamen die später übersprungen werden\n",
    "        skip_BN = ['conv2_block1_preact_bn.gamma', 'conv2_block1_preact_bn.beta', 'conv2_block1_preact_bn.moving_mean', 'conv2_block1_preact_bn.moving_variance']\n",
    "\n",
    "        # Iteriere über Layer des Modells\n",
    "        for l in unet.layers:\n",
    "            # Falls Gewichte vorhanden für diesen Layer, iteriere über diese   \n",
    "            if (len(l.weights) > 0):\n",
    "                for w in l.weights:\n",
    "                    try:\n",
    "                        # standardisieren der Layernamen aus layer.weigths und model.get_weigths\n",
    "                        w_name = w.name.replace('/', '.')[:-2]\n",
    "                        # durch die beiden Convolutional-Layer verdoppelt sich auch die Anzahl der BN-Gewichte, diese können daher nicht übernommen werden\n",
    "                        if w_name in skip_BN:\n",
    "                            updated_weights.append(w)\n",
    "                            #print(w.name, \"not replaced\")\n",
    "\n",
    "                        # für die übrigen Layer werden die Gewichte übernommen, sofern der Layername im Dict vorhanden ist                                    \n",
    "                        else:\n",
    "                            updated_weights.append(loaded[w_name])\n",
    "                            #print(w.name, 'replaced')\n",
    "\n",
    "                    # ansonsten kommt es zu einer Fehlermeldung und es bleibt es bei den zufälligen Gewichten\n",
    "                    except KeyError as e:\n",
    "                        updated_weights.append(w)\n",
    "                        #print(w.name, \"not replaced\")\n",
    "\n",
    "        # Einsetzen der aktualisierten Gewichte\n",
    "        unet.set_weights(updated_weights)\n",
    "\n",
    "\n",
    "def set_encoder_frozen(unet, pretrained_weights, train_first_layer= False):\n",
    "    unet.trainable = True\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    if pretrained_weights == 'AVG' or pretrained_weights == 'RNDM':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if train_first_layer and layer.name == 'conv1_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'EXTRA_CONV':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv0_conv':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "\n",
    "    if pretrained_weights == 'RGB_SPLIT':\n",
    "\n",
    "        for layer in unet.layers:\n",
    "            # erster Layer des Decoder-parts, ab hier trainierbar\n",
    "            if layer.name == 'up_sampling2d':\n",
    "                break\n",
    "            \n",
    "            # erster Convolution-Layer trainierbar?\n",
    "            if layer.name == 'conv1_conv_ir':\n",
    "                # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "                layer.trainable = True\n",
    "                continue\n",
    "\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = False        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            # beim Split sind für erstes BN keine Gewichte vorhanden, daher trainierbar und Einfrieren danach\n",
    "            if layer.name == 'conv2_block1_preact_bn':\n",
    "                layer.training = True\n",
    "                #freeze_start = True\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def set_trainable_fine_tuning(unet, pretrained_weights, train_first_layer= False):\n",
    "    # Anzahl der trainierbaren Encoder Layer, durch Versuchsreihe bestimmt\n",
    "    train_encoder_layers= 27\n",
    "\n",
    "    # Encoder bleibt größtenteils eingefroren\n",
    "    set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "\n",
    "    # Falls RGB und IR in seperaten Conv-Layern wird RGB immer eingefroren, IR nicht\n",
    "    #if pretrained_weights in ['AVG', 'RNDM']:\n",
    "\n",
    "    # Für das Fine-Tuning werden Top_layer des Encoder-Parts wieder trainable geschaltet\n",
    "    freeze_encoder = False\n",
    "    countdown = int(train_encoder_layers)\n",
    "    \n",
    "    # dafür werden die Layer jetzt rückwärts durchlaufen\n",
    "    for layer in reversed(unet.layers):\n",
    "        # ab dem Bottleneck beginnt der Encoder-part\n",
    "        if layer.name == 'up_sampling2d':\n",
    "            freeze_encoder = True\n",
    "\n",
    "        # für train_encoder_layers (int) werden Layer trainierbar\n",
    "        if freeze_encoder and countdown >= 0:\n",
    "            # \"trainable\" reguliert ob Gewichte bei back prop angepasst werden\n",
    "            layer.trainable = True        \n",
    "\n",
    "            # \"training\" reguliert ob BN Gewichte beim forward pass geändert werden\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.training = False\n",
    "\n",
    "            countdown -= 1\n",
    "\n",
    "\n",
    "def compile_model(unet, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "    loss = Dice_loss\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, saving_location):\n",
    "    checkpoint_path = f'../output/{saving_location}_checkpoints/{model_name}'\n",
    "    logger_path = f'../output/{saving_location}_logger/{model_name}'\n",
    "\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path + '.log')\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuchsreihe Freeze-From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 233s 546ms/step - loss: 0.1210 - accuracy: 0.7791 - binary_iou: 0.6300 - true_positives: 95432864.0000 - false_positives: 35058872.0000 - true_negatives: 153517664.0000 - false_negatives: 35511420.0000 - precision: 0.7313 - recall: 0.7288 - val_loss: 0.1324 - val_accuracy: 0.7237 - val_binary_iou: 0.5219 - val_true_positives: 17575076.0000 - val_false_positives: 1821869.0000 - val_true_negatives: 59114264.0000 - val_false_negatives: 27460492.0000 - val_precision: 0.9061 - val_recall: 0.3902\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.1008 - accuracy: 0.8260 - binary_iou: 0.6955 - true_positives: 101502720.0000 - false_positives: 25956264.0000 - true_negatives: 162417888.0000 - false_negatives: 29643882.0000 - precision: 0.7964 - recall: 0.7740 - val_loss: 0.3162 - val_accuracy: 0.5801 - val_binary_iou: 0.2986 - val_true_positives: 944899.0000 - val_false_positives: 370912.0000 - val_true_negatives: 60533532.0000 - val_false_negatives: 44122376.0000 - val_precision: 0.7181 - val_recall: 0.0210\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0977 - accuracy: 0.8331 - binary_iou: 0.7060 - true_positives: 102678080.0000 - false_positives: 24950844.0000 - true_negatives: 163498944.0000 - false_negatives: 28392818.0000 - precision: 0.8045 - recall: 0.7834 - val_loss: 0.1000 - val_accuracy: 0.8302 - val_binary_iou: 0.6984 - val_true_positives: 31970022.0000 - val_false_positives: 4808101.0000 - val_true_negatives: 56008240.0000 - val_false_negatives: 13185362.0000 - val_precision: 0.8693 - val_recall: 0.7080\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 137s 343ms/step - loss: 0.0970 - accuracy: 0.8354 - binary_iou: 0.7095 - true_positives: 102972568.0000 - false_positives: 24451394.0000 - true_negatives: 163957824.0000 - false_negatives: 28139152.0000 - precision: 0.8081 - recall: 0.7854 - val_loss: 0.1056 - val_accuracy: 0.8190 - val_binary_iou: 0.6918 - val_true_positives: 38703920.0000 - val_false_positives: 12815742.0000 - val_true_negatives: 48088272.0000 - val_false_negatives: 6363783.0000 - val_precision: 0.7512 - val_recall: 0.8588\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0961 - accuracy: 0.8378 - binary_iou: 0.7132 - true_positives: 103382480.0000 - false_positives: 24086258.0000 - true_negatives: 164319424.0000 - false_negatives: 27732654.0000 - precision: 0.8110 - recall: 0.7885 - val_loss: 0.1097 - val_accuracy: 0.8059 - val_binary_iou: 0.6742 - val_true_positives: 39755736.0000 - val_false_positives: 15181283.0000 - val_true_negatives: 45644488.0000 - val_false_negatives: 5390192.0000 - val_precision: 0.7237 - val_recall: 0.8806\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0937 - accuracy: 0.8421 - binary_iou: 0.7197 - true_positives: 104078240.0000 - false_positives: 23499364.0000 - true_negatives: 164992912.0000 - false_negatives: 26950208.0000 - precision: 0.8158 - recall: 0.7943 - val_loss: 0.1153 - val_accuracy: 0.7939 - val_binary_iou: 0.6582 - val_true_positives: 41479488.0000 - val_false_positives: 18216578.0000 - val_true_negatives: 42647984.0000 - val_false_negatives: 3627668.0000 - val_precision: 0.6948 - val_recall: 0.9196\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0933 - accuracy: 0.8443 - binary_iou: 0.7231 - true_positives: 104509376.0000 - false_positives: 23135430.0000 - true_negatives: 165270080.0000 - false_negatives: 26605972.0000 - precision: 0.8188 - recall: 0.7971 - val_loss: 0.1052 - val_accuracy: 0.8228 - val_binary_iou: 0.6981 - val_true_positives: 40455752.0000 - val_false_positives: 14088869.0000 - val_true_negatives: 46733252.0000 - val_false_negatives: 4693854.0000 - val_precision: 0.7417 - val_recall: 0.8960\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0915 - accuracy: 0.8489 - binary_iou: 0.7301 - true_positives: 105247752.0000 - false_positives: 22374920.0000 - true_negatives: 165985184.0000 - false_negatives: 25912952.0000 - precision: 0.8247 - recall: 0.8024 - val_loss: 0.0954 - val_accuracy: 0.8371 - val_binary_iou: 0.7186 - val_true_positives: 40248520.0000 - val_false_positives: 12413144.0000 - val_true_negatives: 48463540.0000 - val_false_negatives: 4846510.0000 - val_precision: 0.7643 - val_recall: 0.8925\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0901 - accuracy: 0.8508 - binary_iou: 0.7330 - true_positives: 105533640.0000 - false_positives: 22092700.0000 - true_negatives: 166309040.0000 - false_negatives: 25585432.0000 - precision: 0.8269 - recall: 0.8049 - val_loss: 0.1245 - val_accuracy: 0.7245 - val_binary_iou: 0.5193 - val_true_positives: 16856334.0000 - val_false_positives: 888026.0000 - val_true_negatives: 59925316.0000 - val_false_negatives: 28302036.0000 - val_precision: 0.9500 - val_recall: 0.3733\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0893 - accuracy: 0.8526 - binary_iou: 0.7359 - true_positives: 105886944.0000 - false_positives: 21818420.0000 - true_negatives: 166548864.0000 - false_negatives: 25266544.0000 - precision: 0.8292 - recall: 0.8074 - val_loss: 0.1029 - val_accuracy: 0.8326 - val_binary_iou: 0.7124 - val_true_positives: 40830816.0000 - val_false_positives: 13431411.0000 - val_true_negatives: 47404960.0000 - val_false_negatives: 4304522.0000 - val_precision: 0.7525 - val_recall: 0.9046\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0876 - accuracy: 0.8564 - binary_iou: 0.7417 - true_positives: 106360520.0000 - false_positives: 21117784.0000 - true_negatives: 167273232.0000 - false_negatives: 24769200.0000 - precision: 0.8343 - recall: 0.8111 - val_loss: 0.1123 - val_accuracy: 0.8113 - val_binary_iou: 0.6824 - val_true_positives: 41546704.0000 - val_false_positives: 16377837.0000 - val_true_negatives: 44430472.0000 - val_false_negatives: 3616706.0000 - val_precision: 0.7173 - val_recall: 0.9199\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0871 - accuracy: 0.8573 - binary_iou: 0.7432 - true_positives: 106628432.0000 - false_positives: 21060946.0000 - true_negatives: 167308336.0000 - false_negatives: 24523056.0000 - precision: 0.8351 - recall: 0.8130 - val_loss: 0.1330 - val_accuracy: 0.7197 - val_binary_iou: 0.5101 - val_true_positives: 16018910.0000 - val_false_positives: 714509.0000 - val_true_negatives: 60247680.0000 - val_false_negatives: 28990608.0000 - val_precision: 0.9573 - val_recall: 0.3559\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0856 - accuracy: 0.8597 - binary_iou: 0.7470 - true_positives: 107072760.0000 - false_positives: 20767824.0000 - true_negatives: 167630992.0000 - false_negatives: 24049344.0000 - precision: 0.8375 - recall: 0.8166 - val_loss: 0.0904 - val_accuracy: 0.8501 - val_binary_iou: 0.7374 - val_true_positives: 39858736.0000 - val_false_positives: 10601939.0000 - val_true_negatives: 50232448.0000 - val_false_negatives: 5278578.0000 - val_precision: 0.7899 - val_recall: 0.8831\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0849 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107398296.0000 - false_positives: 20543202.0000 - true_negatives: 167856336.0000 - false_negatives: 23722896.0000 - precision: 0.8394 - recall: 0.8191 - val_loss: 0.1110 - val_accuracy: 0.8005 - val_binary_iou: 0.6440 - val_true_positives: 26109266.0000 - val_false_positives: 2097758.0000 - val_true_negatives: 58726144.0000 - val_false_negatives: 19038536.0000 - val_precision: 0.9256 - val_recall: 0.5783\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0847 - accuracy: 0.8615 - binary_iou: 0.7497 - true_positives: 107239304.0000 - false_positives: 20393872.0000 - true_negatives: 168027744.0000 - false_negatives: 23859782.0000 - precision: 0.8402 - recall: 0.8180 - val_loss: 0.0989 - val_accuracy: 0.8373 - val_binary_iou: 0.7068 - val_true_positives: 31232048.0000 - val_false_positives: 3293441.0000 - val_true_negatives: 57497820.0000 - val_false_negatives: 13948394.0000 - val_precision: 0.9046 - val_recall: 0.6913\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0836 - accuracy: 0.8641 - binary_iou: 0.7538 - true_positives: 107708280.0000 - false_positives: 20027540.0000 - true_negatives: 168384784.0000 - false_negatives: 23400352.0000 - precision: 0.8432 - recall: 0.8215 - val_loss: 0.0895 - val_accuracy: 0.8523 - val_binary_iou: 0.7406 - val_true_positives: 39827064.0000 - val_false_positives: 10344540.0000 - val_true_negatives: 50490480.0000 - val_false_negatives: 5309619.0000 - val_precision: 0.7938 - val_recall: 0.8824\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 166s 418ms/step - loss: 0.0833 - accuracy: 0.8637 - binary_iou: 0.7532 - true_positives: 107732096.0000 - false_positives: 20081816.0000 - true_negatives: 168233280.0000 - false_negatives: 23473564.0000 - precision: 0.8429 - recall: 0.8211 - val_loss: 0.0852 - val_accuracy: 0.8639 - val_binary_iou: 0.7554 - val_true_positives: 37170488.0000 - val_false_positives: 6445220.0000 - val_true_negatives: 54378644.0000 - val_false_negatives: 7977376.0000 - val_precision: 0.8522 - val_recall: 0.8233\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 131s 327ms/step - loss: 0.0821 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108301392.0000 - false_positives: 19837088.0000 - true_negatives: 168606352.0000 - false_negatives: 22776036.0000 - precision: 0.8452 - recall: 0.8262 - val_loss: 0.1531 - val_accuracy: 0.7313 - val_binary_iou: 0.5348 - val_true_positives: 18643914.0000 - val_false_positives: 1994139.0000 - val_true_negatives: 58851064.0000 - val_false_negatives: 26482600.0000 - val_precision: 0.9034 - val_recall: 0.4131\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 131s 329ms/step - loss: 0.0818 - accuracy: 0.8666 - binary_iou: 0.7579 - true_positives: 108285344.0000 - false_positives: 19770572.0000 - true_negatives: 168614816.0000 - false_negatives: 22850008.0000 - precision: 0.8456 - recall: 0.8258 - val_loss: 0.1024 - val_accuracy: 0.8322 - val_binary_iou: 0.7115 - val_true_positives: 40046760.0000 - val_false_positives: 12674211.0000 - val_true_negatives: 48147576.0000 - val_false_negatives: 5103174.0000 - val_precision: 0.7596 - val_recall: 0.8870\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 131s 330ms/step - loss: 0.0813 - accuracy: 0.8676 - binary_iou: 0.7596 - true_positives: 108523808.0000 - false_positives: 19610268.0000 - true_negatives: 168706416.0000 - false_negatives: 22680374.0000 - precision: 0.8470 - recall: 0.8271 - val_loss: 0.0870 - val_accuracy: 0.8546 - val_binary_iou: 0.7357 - val_true_positives: 33240562.0000 - val_false_positives: 3608494.0000 - val_true_negatives: 57325588.0000 - val_false_negatives: 11797062.0000 - val_precision: 0.9021 - val_recall: 0.7381\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 132s 330ms/step - loss: 0.0808 - accuracy: 0.8688 - binary_iou: 0.7614 - true_positives: 108646064.0000 - false_positives: 19449168.0000 - true_negatives: 168965888.0000 - false_negatives: 22459632.0000 - precision: 0.8482 - recall: 0.8287 - val_loss: 0.0867 - val_accuracy: 0.8618 - val_binary_iou: 0.7540 - val_true_positives: 38839240.0000 - val_false_positives: 8306769.0000 - val_true_negatives: 52484908.0000 - val_false_negatives: 6340797.0000 - val_precision: 0.8238 - val_recall: 0.8597\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0805 - accuracy: 0.8692 - binary_iou: 0.7619 - true_positives: 108503840.0000 - false_positives: 19143860.0000 - true_negatives: 169210224.0000 - false_negatives: 22662762.0000 - precision: 0.8500 - recall: 0.8272 - val_loss: 0.0967 - val_accuracy: 0.8472 - val_binary_iou: 0.7338 - val_true_positives: 40768900.0000 - val_false_positives: 11939663.0000 - val_true_negatives: 49015408.0000 - val_false_negatives: 4247704.0000 - val_precision: 0.7735 - val_recall: 0.9056\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 132s 333ms/step - loss: 0.0795 - accuracy: 0.8707 - binary_iou: 0.7643 - true_positives: 108716080.0000 - false_positives: 18938558.0000 - true_negatives: 169478768.0000 - false_negatives: 22387304.0000 - precision: 0.8516 - recall: 0.8292 - val_loss: 0.1078 - val_accuracy: 0.8230 - val_binary_iou: 0.6988 - val_true_positives: 41153548.0000 - val_false_positives: 14788690.0000 - val_true_negatives: 46060360.0000 - val_false_negatives: 3969113.0000 - val_precision: 0.7356 - val_recall: 0.9120\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0801 - accuracy: 0.8702 - binary_iou: 0.7636 - true_positives: 108823816.0000 - false_positives: 19210666.0000 - true_negatives: 169220608.0000 - false_negatives: 22265680.0000 - precision: 0.8500 - recall: 0.8301 - val_loss: 0.0927 - val_accuracy: 0.8444 - val_binary_iou: 0.7203 - val_true_positives: 32952966.0000 - val_false_positives: 4359997.0000 - val_true_negatives: 56526712.0000 - val_false_negatives: 12132058.0000 - val_precision: 0.8832 - val_recall: 0.7309\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 132s 331ms/step - loss: 0.0790 - accuracy: 0.8721 - binary_iou: 0.7667 - true_positives: 109167728.0000 - false_positives: 18871536.0000 - true_negatives: 169501680.0000 - false_negatives: 21979664.0000 - precision: 0.8526 - recall: 0.8324 - val_loss: 0.0850 - val_accuracy: 0.8600 - val_binary_iou: 0.7507 - val_true_positives: 38290392.0000 - val_false_positives: 8004973.0000 - val_true_negatives: 52842848.0000 - val_false_negatives: 6833502.0000 - val_precision: 0.8271 - val_recall: 0.8486\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 132s 332ms/step - loss: 0.0791 - accuracy: 0.8710 - binary_iou: 0.7649 - true_positives: 108841576.0000 - false_positives: 18948360.0000 - true_negatives: 169474752.0000 - false_negatives: 22256104.0000 - precision: 0.8517 - recall: 0.8302 - val_loss: 0.0908 - val_accuracy: 0.8506 - val_binary_iou: 0.7392 - val_true_positives: 41490552.0000 - val_false_positives: 12217507.0000 - val_true_negatives: 48650728.0000 - val_false_negatives: 3612923.0000 - val_precision: 0.7725 - val_recall: 0.9199\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 167s 420ms/step - loss: 0.0783 - accuracy: 0.8728 - binary_iou: 0.7677 - true_positives: 109027872.0000 - false_positives: 18534094.0000 - true_negatives: 169850336.0000 - false_negatives: 22108422.0000 - precision: 0.8547 - recall: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.8688 - val_binary_iou: 0.7620 - val_true_positives: 36486688.0000 - val_false_positives: 5333113.0000 - val_true_negatives: 55582152.0000 - val_false_negatives: 8569759.0000 - val_precision: 0.8725 - val_recall: 0.8098\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0786 - accuracy: 0.8725 - binary_iou: 0.7673 - true_positives: 109270320.0000 - false_positives: 18891796.0000 - true_negatives: 169503328.0000 - false_negatives: 21855380.0000 - precision: 0.8526 - recall: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.8727 - val_binary_iou: 0.7702 - val_true_positives: 38349988.0000 - val_false_positives: 6743923.0000 - val_true_negatives: 54133528.0000 - val_false_negatives: 6744254.0000 - val_precision: 0.8504 - val_recall: 0.8504\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0780 - accuracy: 0.8735 - binary_iou: 0.7690 - true_positives: 109509312.0000 - false_positives: 18740822.0000 - true_negatives: 169604432.0000 - false_negatives: 21666136.0000 - precision: 0.8539 - recall: 0.8348 - val_loss: 0.0788 - val_accuracy: 0.8748 - val_binary_iou: 0.7732 - val_true_positives: 38262152.0000 - val_false_positives: 6452901.0000 - val_true_negatives: 54439296.0000 - val_false_negatives: 6817371.0000 - val_precision: 0.8557 - val_recall: 0.8488\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0770 - accuracy: 0.8750 - binary_iou: 0.7714 - true_positives: 109860424.0000 - false_positives: 18651358.0000 - true_negatives: 169709808.0000 - false_negatives: 21299248.0000 - precision: 0.8549 - recall: 0.8376 - val_loss: 0.1144 - val_accuracy: 0.8331 - val_binary_iou: 0.7128 - val_true_positives: 40152272.0000 - val_false_positives: 12796243.0000 - val_true_negatives: 48135368.0000 - val_false_negatives: 4887845.0000 - val_precision: 0.7583 - val_recall: 0.8915\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 178s 447ms/step - loss: 0.0771 - accuracy: 0.8750 - binary_iou: 0.7713 - true_positives: 109402512.0000 - false_positives: 18328428.0000 - true_negatives: 170191040.0000 - false_negatives: 21598874.0000 - precision: 0.8565 - recall: 0.8351 - val_loss: 0.0760 - val_accuracy: 0.8774 - val_binary_iou: 0.7753 - val_true_positives: 36616788.0000 - val_false_positives: 4558136.0000 - val_true_negatives: 56358976.0000 - val_false_negatives: 8437822.0000 - val_precision: 0.8893 - val_recall: 0.8127\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0768 - accuracy: 0.8754 - binary_iou: 0.7720 - true_positives: 109704112.0000 - false_positives: 18303342.0000 - true_negatives: 170015376.0000 - false_negatives: 21497948.0000 - precision: 0.8570 - recall: 0.8361 - val_loss: 0.0893 - val_accuracy: 0.8511 - val_binary_iou: 0.7392 - val_true_positives: 40275688.0000 - val_false_positives: 11033940.0000 - val_true_negatives: 49917440.0000 - val_false_negatives: 4744650.0000 - val_precision: 0.7850 - val_recall: 0.8946\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0759 - accuracy: 0.8769 - binary_iou: 0.7744 - true_positives: 109680688.0000 - false_positives: 17862716.0000 - true_negatives: 170521232.0000 - false_negatives: 21456152.0000 - precision: 0.8599 - recall: 0.8364 - val_loss: 0.1278 - val_accuracy: 0.7639 - val_binary_iou: 0.5848 - val_true_positives: 21954286.0000 - val_false_positives: 1845093.0000 - val_true_negatives: 58996816.0000 - val_false_negatives: 23175526.0000 - val_precision: 0.9225 - val_recall: 0.4865\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0763 - accuracy: 0.8771 - binary_iou: 0.7746 - true_positives: 109722248.0000 - false_positives: 17865852.0000 - true_negatives: 170533120.0000 - false_negatives: 21399564.0000 - precision: 0.8600 - recall: 0.8368 - val_loss: 0.0804 - val_accuracy: 0.8689 - val_binary_iou: 0.7605 - val_true_positives: 35240620.0000 - val_false_positives: 4020838.0000 - val_true_negatives: 56843064.0000 - val_false_negatives: 9867173.0000 - val_precision: 0.8976 - val_recall: 0.7813\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0752 - accuracy: 0.8781 - binary_iou: 0.7763 - true_positives: 109918400.0000 - false_positives: 17765496.0000 - true_negatives: 170650224.0000 - false_negatives: 21186664.0000 - precision: 0.8609 - recall: 0.8384 - val_loss: 0.0844 - val_accuracy: 0.8658 - val_binary_iou: 0.7554 - val_true_positives: 35053628.0000 - val_false_positives: 4161809.0000 - val_true_negatives: 56692608.0000 - val_false_negatives: 10063672.0000 - val_precision: 0.8939 - val_recall: 0.7769\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0756 - accuracy: 0.8780 - binary_iou: 0.7762 - true_positives: 109991488.0000 - false_positives: 17822768.0000 - true_negatives: 170557728.0000 - false_negatives: 21148782.0000 - precision: 0.8606 - recall: 0.8387 - val_loss: 0.0847 - val_accuracy: 0.8642 - val_binary_iou: 0.7593 - val_true_positives: 40863752.0000 - val_false_positives: 10137314.0000 - val_true_negatives: 50722208.0000 - val_false_negatives: 4248468.0000 - val_precision: 0.8012 - val_recall: 0.9058\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0755 - accuracy: 0.8783 - binary_iou: 0.7766 - true_positives: 110056080.0000 - false_positives: 17851890.0000 - true_negatives: 170569152.0000 - false_negatives: 21043648.0000 - precision: 0.8604 - recall: 0.8395 - val_loss: 0.0940 - val_accuracy: 0.8438 - val_binary_iou: 0.7149 - val_true_positives: 30703540.0000 - val_false_positives: 2279773.0000 - val_true_negatives: 58713400.0000 - val_false_negatives: 14274987.0000 - val_precision: 0.9309 - val_recall: 0.6826\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0748 - accuracy: 0.8801 - binary_iou: 0.7794 - true_positives: 110202584.0000 - false_positives: 17466404.0000 - true_negatives: 170994736.0000 - false_negatives: 20856996.0000 - precision: 0.8632 - recall: 0.8409 - val_loss: 0.0782 - val_accuracy: 0.8715 - val_binary_iou: 0.7644 - val_true_positives: 35198112.0000 - val_false_positives: 3698824.0000 - val_true_negatives: 57161548.0000 - val_false_negatives: 9913227.0000 - val_precision: 0.9049 - val_recall: 0.7802\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0746 - accuracy: 0.8794 - binary_iou: 0.7784 - true_positives: 110242680.0000 - false_positives: 17726232.0000 - true_negatives: 170747120.0000 - false_negatives: 20804768.0000 - precision: 0.8615 - recall: 0.8412 - val_loss: 0.0825 - val_accuracy: 0.8634 - val_binary_iou: 0.7571 - val_true_positives: 39490388.0000 - val_false_positives: 8987308.0000 - val_true_negatives: 52010136.0000 - val_false_negatives: 5483891.0000 - val_precision: 0.8146 - val_recall: 0.8781\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0738 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110744256.0000 - false_positives: 17311324.0000 - true_negatives: 171002512.0000 - false_negatives: 20462732.0000 - precision: 0.8648 - recall: 0.8440 - val_loss: 0.0911 - val_accuracy: 0.8514 - val_binary_iou: 0.7390 - val_true_positives: 39461084.0000 - val_false_positives: 10119243.0000 - val_true_negatives: 50764184.0000 - val_false_negatives: 5627177.0000 - val_precision: 0.7959 - val_recall: 0.8752\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0740 - accuracy: 0.8811 - binary_iou: 0.7813 - true_positives: 110620672.0000 - false_positives: 17410712.0000 - true_negatives: 170911776.0000 - false_negatives: 20577528.0000 - precision: 0.8640 - recall: 0.8432 - val_loss: 0.0893 - val_accuracy: 0.8568 - val_binary_iou: 0.7480 - val_true_positives: 40675372.0000 - val_false_positives: 10765509.0000 - val_true_negatives: 50123008.0000 - val_false_negatives: 4407833.0000 - val_precision: 0.7907 - val_recall: 0.9022\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0741 - accuracy: 0.8810 - binary_iou: 0.7810 - true_positives: 110477176.0000 - false_positives: 17368754.0000 - true_negatives: 171013616.0000 - false_negatives: 20661116.0000 - precision: 0.8641 - recall: 0.8424 - val_loss: 0.0915 - val_accuracy: 0.8609 - val_binary_iou: 0.7545 - val_true_positives: 41110948.0000 - val_false_positives: 10759448.0000 - val_true_negatives: 50124624.0000 - val_false_negatives: 3976692.0000 - val_precision: 0.7926 - val_recall: 0.9118\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8818 - binary_iou: 0.7824 - true_positives: 110759184.0000 - false_positives: 17434206.0000 - true_negatives: 170991264.0000 - false_negatives: 20336120.0000 - precision: 0.8640 - recall: 0.8449 - val_loss: 0.0767 - val_accuracy: 0.8763 - val_binary_iou: 0.7738 - val_true_positives: 36665456.0000 - val_false_positives: 4793163.0000 - val_true_negatives: 56202104.0000 - val_false_negatives: 8311005.0000 - val_precision: 0.8844 - val_recall: 0.8152\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0732 - accuracy: 0.8824 - binary_iou: 0.7833 - true_positives: 110589928.0000 - false_positives: 17049368.0000 - true_negatives: 171352096.0000 - false_negatives: 20529470.0000 - precision: 0.8664 - recall: 0.8434 - val_loss: 0.3467 - val_accuracy: 0.6217 - val_binary_iou: 0.3609 - val_true_positives: 5513703.0000 - val_false_positives: 492476.0000 - val_true_negatives: 60369508.0000 - val_false_negatives: 39596012.0000 - val_precision: 0.9180 - val_recall: 0.1222\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0728 - accuracy: 0.8823 - binary_iou: 0.7831 - true_positives: 110610448.0000 - false_positives: 17153838.0000 - true_negatives: 171295808.0000 - false_negatives: 20460704.0000 - precision: 0.8657 - recall: 0.8439 - val_loss: 0.1083 - val_accuracy: 0.8334 - val_binary_iou: 0.7133 - val_true_positives: 40344744.0000 - val_false_positives: 12932603.0000 - val_true_negatives: 47975588.0000 - val_false_negatives: 4718782.0000 - val_precision: 0.7573 - val_recall: 0.8953\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0727 - accuracy: 0.8833 - binary_iou: 0.7848 - true_positives: 110786432.0000 - false_positives: 16934720.0000 - true_negatives: 171444560.0000 - false_negatives: 20355044.0000 - precision: 0.8674 - recall: 0.8448 - val_loss: 0.0720 - val_accuracy: 0.8834 - val_binary_iou: 0.7860 - val_true_positives: 37677948.0000 - val_false_positives: 4890033.0000 - val_true_negatives: 55932928.0000 - val_false_negatives: 7470800.0000 - val_precision: 0.8851 - val_recall: 0.8345\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 138s 345ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7851 - true_positives: 110872664.0000 - false_positives: 16952142.0000 - true_negatives: 171421840.0000 - false_negatives: 20274174.0000 - precision: 0.8674 - recall: 0.8454 - val_loss: 0.0791 - val_accuracy: 0.8718 - val_binary_iou: 0.7701 - val_true_positives: 39755304.0000 - val_false_positives: 8201396.0000 - val_true_negatives: 52630668.0000 - val_false_negatives: 5384339.0000 - val_precision: 0.8290 - val_recall: 0.8807\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0720 - accuracy: 0.8844 - binary_iou: 0.7866 - true_positives: 111036360.0000 - false_positives: 16833284.0000 - true_negatives: 171542160.0000 - false_negatives: 20108824.0000 - precision: 0.8684 - recall: 0.8467 - val_loss: 0.0752 - val_accuracy: 0.8761 - val_binary_iou: 0.7749 - val_true_positives: 37911000.0000 - val_false_positives: 6057223.0000 - val_true_negatives: 54926472.0000 - val_false_negatives: 7077021.0000 - val_precision: 0.8622 - val_recall: 0.8427\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0724 - accuracy: 0.8837 - binary_iou: 0.7855 - true_positives: 111067640.0000 - false_positives: 17154754.0000 - true_negatives: 171286816.0000 - false_negatives: 20011544.0000 - precision: 0.8662 - recall: 0.8473 - val_loss: 0.0718 - val_accuracy: 0.8838 - val_binary_iou: 0.7886 - val_true_positives: 39486004.0000 - val_false_positives: 6718828.0000 - val_true_negatives: 54175552.0000 - val_false_negatives: 5591349.0000 - val_precision: 0.8546 - val_recall: 0.8760\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0711 - accuracy: 0.8859 - binary_iou: 0.7891 - true_positives: 111437792.0000 - false_positives: 16779652.0000 - true_negatives: 171621232.0000 - false_negatives: 19682034.0000 - precision: 0.8691 - recall: 0.8499 - val_loss: 0.0789 - val_accuracy: 0.8750 - val_binary_iou: 0.7750 - val_true_positives: 39677440.0000 - val_false_positives: 7832372.0000 - val_true_negatives: 53050432.0000 - val_false_negatives: 5411455.0000 - val_precision: 0.8351 - val_recall: 0.8800\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0723 - accuracy: 0.8840 - binary_iou: 0.7860 - true_positives: 110917688.0000 - false_positives: 16858026.0000 - true_negatives: 171550656.0000 - false_negatives: 20194422.0000 - precision: 0.8681 - recall: 0.8460 - val_loss: 0.0761 - val_accuracy: 0.8785 - val_binary_iou: 0.7793 - val_true_positives: 38523632.0000 - val_false_positives: 6267567.0000 - val_true_negatives: 54571044.0000 - val_false_negatives: 6609449.0000 - val_precision: 0.8601 - val_recall: 0.8536\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 136s 341ms/step - loss: 0.0713 - accuracy: 0.8857 - binary_iou: 0.7888 - true_positives: 111161040.0000 - false_positives: 16627165.0000 - true_negatives: 171846624.0000 - false_negatives: 19886010.0000 - precision: 0.8699 - recall: 0.8483 - val_loss: 0.0784 - val_accuracy: 0.8712 - val_binary_iou: 0.7654 - val_true_positives: 36260056.0000 - val_false_positives: 4831201.0000 - val_true_negatives: 56061988.0000 - val_false_negatives: 8818443.0000 - val_precision: 0.8824 - val_recall: 0.8044\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0713 - accuracy: 0.8850 - binary_iou: 0.7875 - true_positives: 110992376.0000 - false_positives: 16666216.0000 - true_negatives: 171785184.0000 - false_negatives: 20076980.0000 - precision: 0.8694 - recall: 0.8468 - val_loss: 0.0749 - val_accuracy: 0.8792 - val_binary_iou: 0.7783 - val_true_positives: 36636472.0000 - val_false_positives: 4348723.0000 - val_true_negatives: 56539000.0000 - val_false_negatives: 8447519.0000 - val_precision: 0.8939 - val_recall: 0.8126\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0712 - accuracy: 0.8865 - binary_iou: 0.7901 - true_positives: 111404088.0000 - false_positives: 16538362.0000 - true_negatives: 171853856.0000 - false_negatives: 19724452.0000 - precision: 0.8707 - recall: 0.8496 - val_loss: 0.0919 - val_accuracy: 0.8460 - val_binary_iou: 0.7183 - val_true_positives: 30782204.0000 - val_false_positives: 1975765.0000 - val_true_negatives: 58874352.0000 - val_false_negatives: 14339410.0000 - val_precision: 0.9397 - val_recall: 0.6822\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0705 - accuracy: 0.8877 - binary_iou: 0.7921 - true_positives: 111597744.0000 - false_positives: 16313104.0000 - true_negatives: 172038480.0000 - false_negatives: 19571406.0000 - precision: 0.8725 - recall: 0.8508 - val_loss: 0.0778 - val_accuracy: 0.8731 - val_binary_iou: 0.7718 - val_true_positives: 39438596.0000 - val_false_positives: 7786716.0000 - val_true_negatives: 53084064.0000 - val_false_negatives: 5662343.0000 - val_precision: 0.8351 - val_recall: 0.8745\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0707 - accuracy: 0.8871 - binary_iou: 0.7910 - true_positives: 111379944.0000 - false_positives: 16308250.0000 - true_negatives: 172061968.0000 - false_negatives: 19770506.0000 - precision: 0.8723 - recall: 0.8493 - val_loss: 0.0848 - val_accuracy: 0.8574 - val_binary_iou: 0.7399 - val_true_positives: 33218982.0000 - val_false_positives: 3312352.0000 - val_true_negatives: 57644400.0000 - val_false_negatives: 11795967.0000 - val_precision: 0.9093 - val_recall: 0.7380\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0705 - accuracy: 0.8872 - binary_iou: 0.7912 - true_positives: 111304640.0000 - false_positives: 16271008.0000 - true_negatives: 172181952.0000 - false_negatives: 19763074.0000 - precision: 0.8725 - recall: 0.8492 - val_loss: 0.0780 - val_accuracy: 0.8788 - val_binary_iou: 0.7815 - val_true_positives: 40363296.0000 - val_false_positives: 8102494.0000 - val_true_negatives: 52768896.0000 - val_false_negatives: 4737019.0000 - val_precision: 0.8328 - val_recall: 0.8950\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0703 - accuracy: 0.8879 - binary_iou: 0.7923 - true_positives: 111497272.0000 - false_positives: 16185796.0000 - true_negatives: 172192080.0000 - false_negatives: 19645634.0000 - precision: 0.8732 - recall: 0.8502 - val_loss: 0.0729 - val_accuracy: 0.8834 - val_binary_iou: 0.7850 - val_true_positives: 36861128.0000 - val_false_positives: 4175830.0000 - val_true_negatives: 56752168.0000 - val_false_negatives: 8182607.0000 - val_precision: 0.8982 - val_recall: 0.8183\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0702 - accuracy: 0.8878 - binary_iou: 0.7922 - true_positives: 111428296.0000 - false_positives: 16189002.0000 - true_negatives: 172243248.0000 - false_negatives: 19660228.0000 - precision: 0.8731 - recall: 0.8500 - val_loss: 0.0748 - val_accuracy: 0.8787 - val_binary_iou: 0.7808 - val_true_positives: 39858764.0000 - val_false_positives: 7576542.0000 - val_true_negatives: 53255492.0000 - val_false_negatives: 5280936.0000 - val_precision: 0.8403 - val_recall: 0.8830\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0699 - accuracy: 0.8884 - binary_iou: 0.7932 - true_positives: 111605032.0000 - false_positives: 16211818.0000 - true_negatives: 172253808.0000 - false_negatives: 19450116.0000 - precision: 0.8732 - recall: 0.8516 - val_loss: 0.0724 - val_accuracy: 0.8823 - val_binary_iou: 0.7848 - val_true_positives: 38025824.0000 - val_false_positives: 5357245.0000 - val_true_negatives: 55475288.0000 - val_false_negatives: 7113354.0000 - val_precision: 0.8765 - val_recall: 0.8424\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0698 - accuracy: 0.8882 - binary_iou: 0.7928 - true_positives: 111625056.0000 - false_positives: 16248429.0000 - true_negatives: 172164304.0000 - false_negatives: 19482984.0000 - precision: 0.8729 - recall: 0.8514 - val_loss: 0.0719 - val_accuracy: 0.8857 - val_binary_iou: 0.7920 - val_true_positives: 40008660.0000 - val_false_positives: 6950614.0000 - val_true_negatives: 53851884.0000 - val_false_negatives: 5160537.0000 - val_precision: 0.8520 - val_recall: 0.8858\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111832104.0000 - false_positives: 16087610.0000 - true_negatives: 172342992.0000 - false_negatives: 19257988.0000 - precision: 0.8742 - recall: 0.8531 - val_loss: 0.0860 - val_accuracy: 0.8592 - val_binary_iou: 0.7425 - val_true_positives: 33238404.0000 - val_false_positives: 3034032.0000 - val_true_negatives: 57809696.0000 - val_false_negatives: 11889571.0000 - val_precision: 0.9164 - val_recall: 0.7365\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0693 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111810888.0000 - false_positives: 16032721.0000 - true_negatives: 172367728.0000 - false_negatives: 19309438.0000 - precision: 0.8746 - recall: 0.8527 - val_loss: 0.0795 - val_accuracy: 0.8735 - val_binary_iou: 0.7676 - val_true_positives: 35400352.0000 - val_false_positives: 3689432.0000 - val_true_negatives: 57161040.0000 - val_false_negatives: 9720906.0000 - val_precision: 0.9056 - val_recall: 0.7846\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0695 - accuracy: 0.8884 - binary_iou: 0.7933 - true_positives: 111689736.0000 - false_positives: 16202075.0000 - true_negatives: 172186048.0000 - false_negatives: 19442862.0000 - precision: 0.8733 - recall: 0.8517 - val_loss: 0.0758 - val_accuracy: 0.8776 - val_binary_iou: 0.7791 - val_true_positives: 39693812.0000 - val_false_positives: 7559088.0000 - val_true_negatives: 53310804.0000 - val_false_negatives: 5407998.0000 - val_precision: 0.8400 - val_recall: 0.8801\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0689 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 111939024.0000 - false_positives: 15899358.0000 - true_negatives: 172475312.0000 - false_negatives: 19207072.0000 - precision: 0.8756 - recall: 0.8535 - val_loss: 0.1359 - val_accuracy: 0.7880 - val_binary_iou: 0.6222 - val_true_positives: 24266056.0000 - val_false_positives: 1582781.0000 - val_true_negatives: 59243448.0000 - val_false_negatives: 20879408.0000 - val_precision: 0.9388 - val_recall: 0.5375\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 428ms/step - loss: 0.0689 - accuracy: 0.8894 - binary_iou: 0.7949 - true_positives: 111899968.0000 - false_positives: 16145603.0000 - true_negatives: 172293216.0000 - false_negatives: 19182052.0000 - precision: 0.8739 - recall: 0.8537 - val_loss: 0.0701 - val_accuracy: 0.8880 - val_binary_iou: 0.7950 - val_true_positives: 39279140.0000 - val_false_positives: 6042733.0000 - val_true_negatives: 54825964.0000 - val_false_negatives: 5823879.0000 - val_precision: 0.8667 - val_recall: 0.8709\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0688 - accuracy: 0.8901 - binary_iou: 0.7960 - true_positives: 111865480.0000 - false_positives: 15830442.0000 - true_negatives: 172532208.0000 - false_negatives: 19292612.0000 - precision: 0.8760 - recall: 0.8529 - val_loss: 0.0774 - val_accuracy: 0.8784 - val_binary_iou: 0.7808 - val_true_positives: 40402348.0000 - val_false_positives: 8221260.0000 - val_true_negatives: 52680000.0000 - val_false_negatives: 4668108.0000 - val_precision: 0.8309 - val_recall: 0.8964\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0690 - accuracy: 0.8891 - binary_iou: 0.7944 - true_positives: 111709696.0000 - false_positives: 15976760.0000 - true_negatives: 172388368.0000 - false_negatives: 19445922.0000 - precision: 0.8749 - recall: 0.8517 - val_loss: 0.0803 - val_accuracy: 0.8730 - val_binary_iou: 0.7725 - val_true_positives: 40478668.0000 - val_false_positives: 8900463.0000 - val_true_negatives: 52034368.0000 - val_false_negatives: 4558195.0000 - val_precision: 0.8198 - val_recall: 0.8988\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0688 - accuracy: 0.8902 - binary_iou: 0.7962 - true_positives: 111886672.0000 - false_positives: 15776121.0000 - true_negatives: 172563696.0000 - false_negatives: 19294172.0000 - precision: 0.8764 - recall: 0.8529 - val_loss: 0.0752 - val_accuracy: 0.8810 - val_binary_iou: 0.7845 - val_true_positives: 39947648.0000 - val_false_positives: 7431002.0000 - val_true_negatives: 53413960.0000 - val_false_negatives: 5179119.0000 - val_precision: 0.8432 - val_recall: 0.8852\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0691 - accuracy: 0.8894 - binary_iou: 0.7948 - true_positives: 111791048.0000 - false_positives: 16044969.0000 - true_negatives: 172387392.0000 - false_negatives: 19297388.0000 - precision: 0.8745 - recall: 0.8528 - val_loss: 0.0951 - val_accuracy: 0.8679 - val_binary_iou: 0.7649 - val_true_positives: 40768648.0000 - val_false_positives: 9800652.0000 - val_true_negatives: 51205848.0000 - val_false_negatives: 4196562.0000 - val_precision: 0.8062 - val_recall: 0.9067\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0686 - accuracy: 0.8903 - binary_iou: 0.7963 - true_positives: 112000912.0000 - false_positives: 15904758.0000 - true_negatives: 172459744.0000 - false_negatives: 19155282.0000 - precision: 0.8757 - recall: 0.8540 - val_loss: 0.0771 - val_accuracy: 0.8741 - val_binary_iou: 0.7688 - val_true_positives: 35527912.0000 - val_false_positives: 3736203.0000 - val_true_negatives: 57103272.0000 - val_false_negatives: 9604338.0000 - val_precision: 0.9048 - val_recall: 0.7872\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 135s 339ms/step - loss: 0.0678 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112179992.0000 - false_positives: 15409854.0000 - true_negatives: 173029520.0000 - false_negatives: 18901586.0000 - precision: 0.8792 - recall: 0.8558 - val_loss: 0.0724 - val_accuracy: 0.8848 - val_binary_iou: 0.7907 - val_true_positives: 40174352.0000 - val_false_positives: 7346762.0000 - val_true_negatives: 53591184.0000 - val_false_negatives: 4859408.0000 - val_precision: 0.8454 - val_recall: 0.8921\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 171s 429ms/step - loss: 0.0682 - accuracy: 0.8912 - binary_iou: 0.7977 - true_positives: 111957296.0000 - false_positives: 15631962.0000 - true_negatives: 172790976.0000 - false_negatives: 19140550.0000 - precision: 0.8775 - recall: 0.8540 - val_loss: 0.0689 - val_accuracy: 0.8901 - val_binary_iou: 0.7975 - val_true_positives: 38453356.0000 - val_false_positives: 4979271.0000 - val_true_negatives: 55869972.0000 - val_false_negatives: 6669114.0000 - val_precision: 0.8854 - val_recall: 0.8522\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 160s 402ms/step - loss: 0.0682 - accuracy: 0.8911 - binary_iou: 0.7976 - true_positives: 112027632.0000 - false_positives: 15746636.0000 - true_negatives: 172694192.0000 - false_negatives: 19052250.0000 - precision: 0.8768 - recall: 0.8547 - val_loss: 0.0703 - val_accuracy: 0.8876 - val_binary_iou: 0.7944 - val_true_positives: 39253120.0000 - val_false_positives: 6203339.0000 - val_true_negatives: 54812624.0000 - val_false_negatives: 5702634.0000 - val_precision: 0.8635 - val_recall: 0.8732\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0678 - accuracy: 0.8924 - binary_iou: 0.7998 - true_positives: 112174480.0000 - false_positives: 15427345.0000 - true_negatives: 172958144.0000 - false_negatives: 18960760.0000 - precision: 0.8791 - recall: 0.8554 - val_loss: 0.0714 - val_accuracy: 0.8860 - val_binary_iou: 0.7922 - val_true_positives: 39661624.0000 - val_false_positives: 6618287.0000 - val_true_negatives: 54230892.0000 - val_false_negatives: 5460903.0000 - val_precision: 0.8570 - val_recall: 0.8790\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0676 - accuracy: 0.8918 - binary_iou: 0.7988 - true_positives: 112268576.0000 - false_positives: 15669733.0000 - true_negatives: 172670096.0000 - false_negatives: 18912436.0000 - precision: 0.8775 - recall: 0.8558 - val_loss: 0.0768 - val_accuracy: 0.8799 - val_binary_iou: 0.7831 - val_true_positives: 40321992.0000 - val_false_positives: 7994599.0000 - val_true_negatives: 52923220.0000 - val_false_negatives: 4731924.0000 - val_precision: 0.8345 - val_recall: 0.8950\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 135s 338ms/step - loss: 0.0672 - accuracy: 0.8930 - binary_iou: 0.8009 - true_positives: 112414688.0000 - false_positives: 15411543.0000 - true_negatives: 172917456.0000 - false_negatives: 18777054.0000 - precision: 0.8794 - recall: 0.8569 - val_loss: 0.1484 - val_accuracy: 0.7818 - val_binary_iou: 0.6113 - val_true_positives: 23371532.0000 - val_false_positives: 1365110.0000 - val_true_negatives: 59475000.0000 - val_false_negatives: 21760066.0000 - val_precision: 0.9448 - val_recall: 0.5179\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0670 - accuracy: 0.8930 - binary_iou: 0.8007 - true_positives: 112071688.0000 - false_positives: 15228398.0000 - true_negatives: 173257568.0000 - false_negatives: 18963102.0000 - precision: 0.8804 - recall: 0.8553 - val_loss: 0.0730 - val_accuracy: 0.8837 - val_binary_iou: 0.7859 - val_true_positives: 37128412.0000 - val_false_positives: 4391111.0000 - val_true_negatives: 56520536.0000 - val_false_negatives: 7931644.0000 - val_precision: 0.8942 - val_recall: 0.8240\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 170s 427ms/step - loss: 0.0676 - accuracy: 0.8922 - binary_iou: 0.7995 - true_positives: 112183280.0000 - false_positives: 15484272.0000 - true_negatives: 172888128.0000 - false_negatives: 18965140.0000 - precision: 0.8787 - recall: 0.8554 - val_loss: 0.0678 - val_accuracy: 0.8915 - val_binary_iou: 0.7994 - val_true_positives: 38122228.0000 - val_false_positives: 4515762.0000 - val_true_negatives: 56352220.0000 - val_false_negatives: 6981488.0000 - val_precision: 0.8941 - val_recall: 0.8452\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 133s 333ms/step - loss: 0.0669 - accuracy: 0.8936 - binary_iou: 0.8018 - true_positives: 112442640.0000 - false_positives: 15260840.0000 - true_negatives: 173075456.0000 - false_negatives: 18741888.0000 - precision: 0.8805 - recall: 0.8571 - val_loss: 0.0707 - val_accuracy: 0.8882 - val_binary_iou: 0.7955 - val_true_positives: 39381688.0000 - val_false_positives: 6069700.0000 - val_true_negatives: 54746240.0000 - val_false_negatives: 5774078.0000 - val_precision: 0.8665 - val_recall: 0.8721\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0668 - accuracy: 0.8932 - binary_iou: 0.8013 - true_positives: 112449040.0000 - false_positives: 15470578.0000 - true_negatives: 172959840.0000 - false_negatives: 18641352.0000 - precision: 0.8791 - recall: 0.8578 - val_loss: 0.0734 - val_accuracy: 0.8809 - val_binary_iou: 0.7799 - val_true_positives: 35980932.0000 - val_false_positives: 3395829.0000 - val_true_negatives: 57365376.0000 - val_false_negatives: 9229588.0000 - val_precision: 0.9138 - val_recall: 0.7959\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8015 - true_positives: 112170456.0000 - false_positives: 15109560.0000 - true_negatives: 173310432.0000 - false_negatives: 18930238.0000 - precision: 0.8813 - recall: 0.8556 - val_loss: 0.0687 - val_accuracy: 0.8896 - val_binary_iou: 0.7965 - val_true_positives: 38277924.0000 - val_false_positives: 4777362.0000 - val_true_negatives: 55992768.0000 - val_false_negatives: 6923645.0000 - val_precision: 0.8890 - val_recall: 0.8468\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0665 - accuracy: 0.8945 - binary_iou: 0.8033 - true_positives: 112567264.0000 - false_positives: 15171494.0000 - true_negatives: 173237200.0000 - false_negatives: 18544780.0000 - precision: 0.8812 - recall: 0.8586 - val_loss: 0.1019 - val_accuracy: 0.8186 - val_binary_iou: 0.6723 - val_true_positives: 27651104.0000 - val_false_positives: 1777387.0000 - val_true_negatives: 59099132.0000 - val_false_negatives: 17444088.0000 - val_precision: 0.9396 - val_recall: 0.6132\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0674 - accuracy: 0.8926 - binary_iou: 0.8001 - true_positives: 112299664.0000 - false_positives: 15546087.0000 - true_negatives: 172895488.0000 - false_negatives: 18779640.0000 - precision: 0.8784 - recall: 0.8567 - val_loss: 0.0816 - val_accuracy: 0.8774 - val_binary_iou: 0.7792 - val_true_positives: 40354892.0000 - val_false_positives: 8312571.0000 - val_true_negatives: 52624612.0000 - val_false_negatives: 4679636.0000 - val_precision: 0.8292 - val_recall: 0.8961\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0667 - accuracy: 0.8937 - binary_iou: 0.8020 - true_positives: 112282648.0000 - false_positives: 15109516.0000 - true_negatives: 173280112.0000 - false_negatives: 18848368.0000 - precision: 0.8814 - recall: 0.8563 - val_loss: 0.0783 - val_accuracy: 0.8691 - val_binary_iou: 0.7659 - val_true_positives: 39678192.0000 - val_false_positives: 8383734.0000 - val_true_negatives: 52426100.0000 - val_false_negatives: 5483700.0000 - val_precision: 0.8256 - val_recall: 0.8786\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0666 - accuracy: 0.8935 - binary_iou: 0.8018 - true_positives: 112706776.0000 - false_positives: 15555337.0000 - true_negatives: 172791440.0000 - false_negatives: 18467180.0000 - precision: 0.8787 - recall: 0.8592 - val_loss: 0.0741 - val_accuracy: 0.8826 - val_binary_iou: 0.7877 - val_true_positives: 40878036.0000 - val_false_positives: 8097197.0000 - val_true_negatives: 52650636.0000 - val_false_negatives: 4345838.0000 - val_precision: 0.8347 - val_recall: 0.9039\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8952 - binary_iou: 0.8046 - true_positives: 112822448.0000 - false_positives: 15160487.0000 - true_negatives: 173219936.0000 - false_negatives: 18317834.0000 - precision: 0.8815 - recall: 0.8603 - val_loss: 0.0712 - val_accuracy: 0.8861 - val_binary_iou: 0.7889 - val_true_positives: 36594128.0000 - val_false_positives: 3547294.0000 - val_true_negatives: 57302372.0000 - val_false_negatives: 8527889.0000 - val_precision: 0.9116 - val_recall: 0.8110\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0661 - accuracy: 0.8949 - binary_iou: 0.8041 - true_positives: 112634032.0000 - false_positives: 15075881.0000 - true_negatives: 173317312.0000 - false_negatives: 18493656.0000 - precision: 0.8820 - recall: 0.8590 - val_loss: 0.1567 - val_accuracy: 0.7551 - val_binary_iou: 0.5705 - val_true_positives: 20908572.0000 - val_false_positives: 1721498.0000 - val_true_negatives: 59106516.0000 - val_false_negatives: 24235132.0000 - val_precision: 0.9239 - val_recall: 0.4632\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0659 - accuracy: 0.8953 - binary_iou: 0.8046 - true_positives: 112573032.0000 - false_positives: 14919423.0000 - true_negatives: 173497088.0000 - false_negatives: 18531148.0000 - precision: 0.8830 - recall: 0.8587 - val_loss: 0.0721 - val_accuracy: 0.8864 - val_binary_iou: 0.7910 - val_true_positives: 37871184.0000 - val_false_positives: 4839935.0000 - val_true_negatives: 56064496.0000 - val_false_negatives: 7196119.0000 - val_precision: 0.8867 - val_recall: 0.8403\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0654 - accuracy: 0.8963 - binary_iou: 0.8064 - true_positives: 112841192.0000 - false_positives: 14810634.0000 - true_negatives: 173555312.0000 - false_negatives: 18313536.0000 - precision: 0.8840 - recall: 0.8604 - val_loss: 0.0810 - val_accuracy: 0.8655 - val_binary_iou: 0.7549 - val_true_positives: 35077924.0000 - val_false_positives: 4263421.0000 - val_true_negatives: 56635472.0000 - val_false_negatives: 9994884.0000 - val_precision: 0.8916 - val_recall: 0.7783\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0652 - accuracy: 0.8962 - binary_iou: 0.8062 - true_positives: 112972344.0000 - false_positives: 15045884.0000 - true_negatives: 173367568.0000 - false_negatives: 18134990.0000 - precision: 0.8825 - recall: 0.8617 - val_loss: 0.0913 - val_accuracy: 0.8630 - val_binary_iou: 0.7575 - val_true_positives: 40925680.0000 - val_false_positives: 10408766.0000 - val_true_negatives: 50531900.0000 - val_false_negatives: 4105355.0000 - val_precision: 0.7972 - val_recall: 0.9088\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 134s 335ms/step - loss: 0.0655 - accuracy: 0.8956 - binary_iou: 0.8053 - true_positives: 112770296.0000 - false_positives: 14935553.0000 - true_negatives: 173408240.0000 - false_negatives: 18406754.0000 - precision: 0.8830 - recall: 0.8597 - val_loss: 0.0681 - val_accuracy: 0.8916 - val_binary_iou: 0.7991 - val_true_positives: 37650052.0000 - val_false_positives: 4016793.0000 - val_true_negatives: 56835504.0000 - val_false_negatives: 7469375.0000 - val_precision: 0.9036 - val_recall: 0.8345\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8965 - binary_iou: 0.8066 - true_positives: 112672744.0000 - false_positives: 14632333.0000 - true_negatives: 173781648.0000 - false_negatives: 18434098.0000 - precision: 0.8851 - recall: 0.8594 - val_loss: 0.0741 - val_accuracy: 0.8843 - val_binary_iou: 0.7891 - val_true_positives: 39229924.0000 - val_false_positives: 6452676.0000 - val_true_negatives: 54484932.0000 - val_false_negatives: 5804178.0000 - val_precision: 0.8587 - val_recall: 0.8711\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0654 - accuracy: 0.8961 - binary_iou: 0.8061 - true_positives: 112790800.0000 - false_positives: 14832199.0000 - true_negatives: 173542400.0000 - false_negatives: 18355386.0000 - precision: 0.8838 - recall: 0.8600 - val_loss: 0.0749 - val_accuracy: 0.8854 - val_binary_iou: 0.7920 - val_true_positives: 40681160.0000 - val_false_positives: 7715254.0000 - val_true_negatives: 53141616.0000 - val_false_negatives: 4433672.0000 - val_precision: 0.8406 - val_recall: 0.9017\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 133s 335ms/step - loss: 0.0653 - accuracy: 0.8962 - binary_iou: 0.8061 - true_positives: 112847560.0000 - false_positives: 14876293.0000 - true_negatives: 173496784.0000 - false_negatives: 18300084.0000 - precision: 0.8835 - recall: 0.8605 - val_loss: 0.0764 - val_accuracy: 0.8787 - val_binary_iou: 0.7810 - val_true_positives: 40074776.0000 - val_false_positives: 7857041.0000 - val_true_negatives: 53039168.0000 - val_false_negatives: 5000726.0000 - val_precision: 0.8361 - val_recall: 0.8891\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_183_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 169s 425ms/step - loss: 0.0654 - accuracy: 0.8957 - binary_iou: 0.8054 - true_positives: 112712896.0000 - false_positives: 14928653.0000 - true_negatives: 173495776.0000 - false_negatives: 18383450.0000 - precision: 0.8830 - recall: 0.8598 - val_loss: 0.0676 - val_accuracy: 0.8920 - val_binary_iou: 0.8012 - val_true_positives: 39038164.0000 - val_false_positives: 5411304.0000 - val_true_negatives: 55491768.0000 - val_false_negatives: 6030472.0000 - val_precision: 0.8783 - val_recall: 0.8662\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 133s 334ms/step - loss: 0.0649 - accuracy: 0.8968 - binary_iou: 0.8072 - true_positives: 112836920.0000 - false_positives: 14683751.0000 - true_negatives: 173715984.0000 - false_negatives: 18284156.0000 - precision: 0.8849 - recall: 0.8606 - val_loss: 0.0736 - val_accuracy: 0.8828 - val_binary_iou: 0.7850 - val_true_positives: 37599728.0000 - val_false_positives: 4910598.0000 - val_true_negatives: 55953576.0000 - val_false_negatives: 7507811.0000 - val_precision: 0.8845 - val_recall: 0.8336\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 134s 337ms/step - loss: 0.0644 - accuracy: 0.8975 - binary_iou: 0.8083 - true_positives: 113073528.0000 - false_positives: 14661790.0000 - true_negatives: 173689344.0000 - false_negatives: 18096160.0000 - precision: 0.8852 - recall: 0.8620 - val_loss: 0.0808 - val_accuracy: 0.8723 - val_binary_iou: 0.7642 - val_true_positives: 34353932.0000 - val_false_positives: 2753126.0000 - val_true_negatives: 58084044.0000 - val_false_negatives: 10780616.0000 - val_precision: 0.9258 - val_recall: 0.7611\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0650 - accuracy: 0.8971 - binary_iou: 0.8076 - true_positives: 112894736.0000 - false_positives: 14678940.0000 - true_negatives: 173739488.0000 - false_negatives: 18207648.0000 - precision: 0.8849 - recall: 0.8611 - val_loss: 0.0691 - val_accuracy: 0.8917 - val_binary_iou: 0.8007 - val_true_positives: 39146796.0000 - val_false_positives: 5586695.0000 - val_true_negatives: 55345212.0000 - val_false_negatives: 5892998.0000 - val_precision: 0.8751 - val_recall: 0.8692\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 134s 336ms/step - loss: 0.0648 - accuracy: 0.8970 - binary_iou: 0.8074 - true_positives: 112868432.0000 - false_positives: 14630436.0000 - true_negatives: 173732256.0000 - false_negatives: 18289650.0000 - precision: 0.8853 - recall: 0.8606 - val_loss: 0.0872 - val_accuracy: 0.8663 - val_binary_iou: 0.7620 - val_true_positives: 40245384.0000 - val_false_positives: 9343865.0000 - val_true_negatives: 51557684.0000 - val_false_negatives: 4824793.0000 - val_precision: 0.8116 - val_recall: 0.8929\n",
      "132/132 [==============================] - 45s 317ms/step - loss: 212.9752 - accuracy: 0.8897 - binary_iou: 0.7965 - true_positives: 38099952.0000 - false_positives: 5604668.0000 - true_negatives: 56180072.0000 - false_negatives: 6087014.0000 - precision: 0.8718 - recall: 0.8622\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "-1\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 185s 442ms/step - loss: 0.1136 - accuracy: 0.7974 - binary_iou: 0.6551 - true_positives: 98326080.0000 - false_positives: 32122076.0000 - true_negatives: 156454464.0000 - false_negatives: 32618228.0000 - precision: 0.7538 - recall: 0.7509 - val_loss: 0.1105 - val_accuracy: 0.8061 - val_binary_iou: 0.6605 - val_true_positives: 29558962.0000 - val_false_positives: 5074877.0000 - val_true_negatives: 55861256.0000 - val_false_negatives: 15476612.0000 - val_precision: 0.8535 - val_recall: 0.6563\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0969 - accuracy: 0.8330 - binary_iou: 0.7067 - true_positives: 103866728.0000 - false_positives: 26122214.0000 - true_negatives: 162309504.0000 - false_negatives: 27222196.0000 - precision: 0.7990 - recall: 0.7923 - val_loss: 0.1090 - val_accuracy: 0.7971 - val_binary_iou: 0.6466 - val_true_positives: 28650442.0000 - val_false_positives: 5022378.0000 - val_true_negatives: 55819924.0000 - val_false_negatives: 16478962.0000 - val_precision: 0.8508 - val_recall: 0.6349\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 441ms/step - loss: 0.0945 - accuracy: 0.8377 - binary_iou: 0.7135 - true_positives: 104209056.0000 - false_positives: 24911088.0000 - true_negatives: 163465440.0000 - false_negatives: 26935170.0000 - precision: 0.8071 - recall: 0.7946 - val_loss: 0.1040 - val_accuracy: 0.8304 - val_binary_iou: 0.7052 - val_true_positives: 36088200.0000 - val_false_positives: 8909478.0000 - val_true_negatives: 51910856.0000 - val_false_negatives: 9063180.0000 - val_precision: 0.8020 - val_recall: 0.7993\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0933 - accuracy: 0.8420 - binary_iou: 0.7202 - true_positives: 105374728.0000 - false_positives: 24733490.0000 - true_negatives: 163660432.0000 - false_negatives: 25752116.0000 - precision: 0.8099 - recall: 0.8036 - val_loss: 0.0947 - val_accuracy: 0.8398 - val_binary_iou: 0.7195 - val_true_positives: 36842232.0000 - val_false_positives: 8677888.0000 - val_true_negatives: 52152584.0000 - val_false_negatives: 8299018.0000 - val_precision: 0.8094 - val_recall: 0.8162\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 137s 344ms/step - loss: 0.0914 - accuracy: 0.8468 - binary_iou: 0.7275 - true_positives: 106150000.0000 - false_positives: 23878964.0000 - true_negatives: 164412704.0000 - false_negatives: 25079016.0000 - precision: 0.8164 - recall: 0.8089 - val_loss: 0.1028 - val_accuracy: 0.8082 - val_binary_iou: 0.6639 - val_true_positives: 29808732.0000 - val_false_positives: 5023932.0000 - val_true_negatives: 55838920.0000 - val_false_negatives: 15300131.0000 - val_precision: 0.8558 - val_recall: 0.6608\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0905 - accuracy: 0.8479 - binary_iou: 0.7292 - true_positives: 106345344.0000 - false_positives: 23792932.0000 - true_negatives: 164588064.0000 - false_negatives: 24794420.0000 - precision: 0.8172 - recall: 0.8109 - val_loss: 0.0844 - val_accuracy: 0.8593 - val_binary_iou: 0.7474 - val_true_positives: 36334244.0000 - val_false_positives: 6082476.0000 - val_true_negatives: 54722900.0000 - val_false_negatives: 8832084.0000 - val_precision: 0.8566 - val_recall: 0.8045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0889 - accuracy: 0.8510 - binary_iou: 0.7339 - true_positives: 106864624.0000 - false_positives: 23327616.0000 - true_negatives: 165044144.0000 - false_negatives: 24284384.0000 - precision: 0.8208 - recall: 0.8148 - val_loss: 0.1001 - val_accuracy: 0.8204 - val_binary_iou: 0.6782 - val_true_positives: 29000756.0000 - val_false_positives: 3039177.0000 - val_true_negatives: 57938184.0000 - val_false_negatives: 15993596.0000 - val_precision: 0.9051 - val_recall: 0.6445\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0877 - accuracy: 0.8533 - binary_iou: 0.7374 - true_positives: 107015776.0000 - false_positives: 22760176.0000 - true_negatives: 165621696.0000 - false_negatives: 24123068.0000 - precision: 0.8246 - recall: 0.8160 - val_loss: 0.0992 - val_accuracy: 0.8232 - val_binary_iou: 0.6827 - val_true_positives: 29234104.0000 - val_false_positives: 2876097.0000 - val_true_negatives: 58006276.0000 - val_false_negatives: 15855237.0000 - val_precision: 0.9104 - val_recall: 0.6484\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0868 - accuracy: 0.8551 - binary_iou: 0.7402 - true_positives: 107298048.0000 - false_positives: 22419816.0000 - true_negatives: 165917520.0000 - false_negatives: 23885356.0000 - precision: 0.8272 - recall: 0.8179 - val_loss: 0.0907 - val_accuracy: 0.8447 - val_binary_iou: 0.7263 - val_true_positives: 36638376.0000 - val_false_positives: 7956607.0000 - val_true_negatives: 52870960.0000 - val_false_negatives: 8505777.0000 - val_precision: 0.8216 - val_recall: 0.8116\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0860 - accuracy: 0.8567 - binary_iou: 0.7427 - true_positives: 107560656.0000 - false_positives: 22263318.0000 - true_negatives: 166169616.0000 - false_negatives: 23527152.0000 - precision: 0.8285 - recall: 0.8205 - val_loss: 0.0871 - val_accuracy: 0.8539 - val_binary_iou: 0.7427 - val_true_positives: 39383768.0000 - val_false_positives: 9782407.0000 - val_true_negatives: 51109704.0000 - val_false_negatives: 5695821.0000 - val_precision: 0.8010 - val_recall: 0.8736\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0840 - accuracy: 0.8601 - binary_iou: 0.7481 - true_positives: 108232024.0000 - false_positives: 21758164.0000 - true_negatives: 166597248.0000 - false_negatives: 22933332.0000 - precision: 0.8326 - recall: 0.8252 - val_loss: 0.0899 - val_accuracy: 0.8479 - val_binary_iou: 0.7261 - val_true_positives: 33317968.0000 - val_false_positives: 4355052.0000 - val_true_negatives: 56538512.0000 - val_false_negatives: 11760183.0000 - val_precision: 0.8844 - val_recall: 0.7391\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0836 - accuracy: 0.8615 - binary_iou: 0.7502 - true_positives: 108323264.0000 - false_positives: 21464682.0000 - true_negatives: 166940784.0000 - false_negatives: 22792124.0000 - precision: 0.8346 - recall: 0.8262 - val_loss: 0.0843 - val_accuracy: 0.8626 - val_binary_iou: 0.7532 - val_true_positives: 36904740.0000 - val_false_positives: 6333535.0000 - val_true_negatives: 54509848.0000 - val_false_negatives: 8223592.0000 - val_precision: 0.8535 - val_recall: 0.8178\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0827 - accuracy: 0.8639 - binary_iou: 0.7537 - true_positives: 108190992.0000 - false_positives: 20585124.0000 - true_negatives: 167837744.0000 - false_negatives: 22906836.0000 - precision: 0.8401 - recall: 0.8253 - val_loss: 0.0861 - val_accuracy: 0.8567 - val_binary_iou: 0.7439 - val_true_positives: 36617192.0000 - val_false_positives: 6830996.0000 - val_true_negatives: 54164012.0000 - val_false_negatives: 8359509.0000 - val_precision: 0.8428 - val_recall: 0.8141\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0819 - accuracy: 0.8642 - binary_iou: 0.7545 - true_positives: 108930208.0000 - false_positives: 21142038.0000 - true_negatives: 167195552.0000 - false_negatives: 22252968.0000 - precision: 0.8375 - recall: 0.8304 - val_loss: 0.0832 - val_accuracy: 0.8657 - val_binary_iou: 0.7568 - val_true_positives: 36133160.0000 - val_false_positives: 5289682.0000 - val_true_negatives: 55606572.0000 - val_false_negatives: 8942304.0000 - val_precision: 0.8723 - val_recall: 0.8016\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0805 - accuracy: 0.8679 - binary_iou: 0.7603 - true_positives: 109205312.0000 - false_positives: 20384652.0000 - true_negatives: 168115712.0000 - false_negatives: 21815188.0000 - precision: 0.8427 - recall: 0.8335 - val_loss: 0.0826 - val_accuracy: 0.8640 - val_binary_iou: 0.7537 - val_true_positives: 35741368.0000 - val_false_positives: 5012108.0000 - val_true_negatives: 55818184.0000 - val_false_negatives: 9400030.0000 - val_precision: 0.8770 - val_recall: 0.7918\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0796 - accuracy: 0.8695 - binary_iou: 0.7628 - true_positives: 109519336.0000 - false_positives: 20095204.0000 - true_negatives: 168288400.0000 - false_negatives: 21617852.0000 - precision: 0.8450 - recall: 0.8352 - val_loss: 0.0904 - val_accuracy: 0.8553 - val_binary_iou: 0.7370 - val_true_positives: 33358712.0000 - val_false_positives: 3548969.0000 - val_true_negatives: 57280136.0000 - val_false_negatives: 11783893.0000 - val_precision: 0.9038 - val_recall: 0.7390\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0802 - accuracy: 0.8684 - binary_iou: 0.7611 - true_positives: 109389072.0000 - false_positives: 20335696.0000 - true_negatives: 168089696.0000 - false_negatives: 21706340.0000 - precision: 0.8432 - recall: 0.8344 - val_loss: 0.0819 - val_accuracy: 0.8643 - val_binary_iou: 0.7543 - val_true_positives: 35849168.0000 - val_false_positives: 5100314.0000 - val_true_negatives: 55738372.0000 - val_false_negatives: 9283861.0000 - val_precision: 0.8754 - val_recall: 0.7943\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0787 - accuracy: 0.8711 - binary_iou: 0.7654 - true_positives: 109737320.0000 - false_positives: 19834218.0000 - true_negatives: 168589664.0000 - false_negatives: 21359514.0000 - precision: 0.8469 - recall: 0.8371 - val_loss: 0.0840 - val_accuracy: 0.8606 - val_binary_iou: 0.7474 - val_true_positives: 34968736.0000 - val_false_positives: 4551350.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 10224023.0000 - val_precision: 0.8848 - val_recall: 0.7738\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0781 - accuracy: 0.8722 - binary_iou: 0.7672 - true_positives: 110207600.0000 - false_positives: 19916546.0000 - true_negatives: 168471104.0000 - false_negatives: 20925544.0000 - precision: 0.8469 - recall: 0.8404 - val_loss: 0.0795 - val_accuracy: 0.8686 - val_binary_iou: 0.7619 - val_true_positives: 36683320.0000 - val_false_positives: 5540348.0000 - val_true_negatives: 55363864.0000 - val_false_negatives: 8384161.0000 - val_precision: 0.8688 - val_recall: 0.8140\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0776 - accuracy: 0.8728 - binary_iou: 0.7680 - true_positives: 109780352.0000 - false_positives: 19325732.0000 - true_negatives: 169090848.0000 - false_negatives: 21323936.0000 - precision: 0.8503 - recall: 0.8374 - val_loss: 0.0809 - val_accuracy: 0.8656 - val_binary_iou: 0.7602 - val_true_positives: 39312376.0000 - val_false_positives: 8557187.0000 - val_true_negatives: 52416080.0000 - val_false_negatives: 5686077.0000 - val_precision: 0.8212 - val_recall: 0.8736\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 444ms/step - loss: 0.0763 - accuracy: 0.8761 - binary_iou: 0.7733 - true_positives: 110311784.0000 - false_positives: 18727964.0000 - true_negatives: 169617920.0000 - false_negatives: 20863094.0000 - precision: 0.8549 - recall: 0.8410 - val_loss: 0.0794 - val_accuracy: 0.8732 - val_binary_iou: 0.7725 - val_true_positives: 40125432.0000 - val_false_positives: 8428567.0000 - val_true_negatives: 52404920.0000 - val_false_negatives: 5012805.0000 - val_precision: 0.8264 - val_recall: 0.8889\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0762 - accuracy: 0.8764 - binary_iou: 0.7739 - true_positives: 110538152.0000 - false_positives: 18913164.0000 - true_negatives: 169494592.0000 - false_negatives: 20574936.0000 - precision: 0.8539 - recall: 0.8431 - val_loss: 0.0951 - val_accuracy: 0.8363 - val_binary_iou: 0.7062 - val_true_positives: 31574824.0000 - val_false_positives: 3741021.0000 - val_true_negatives: 57054612.0000 - val_false_negatives: 13601249.0000 - val_precision: 0.8941 - val_recall: 0.6989\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0753 - accuracy: 0.8777 - binary_iou: 0.7759 - true_positives: 110752488.0000 - false_positives: 18647580.0000 - true_negatives: 169676000.0000 - false_negatives: 20444714.0000 - precision: 0.8559 - recall: 0.8442 - val_loss: 0.0744 - val_accuracy: 0.8783 - val_binary_iou: 0.7776 - val_true_positives: 37268520.0000 - val_false_positives: 5039199.0000 - val_true_negatives: 55808504.0000 - val_false_negatives: 7855478.0000 - val_precision: 0.8809 - val_recall: 0.8259\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0753 - accuracy: 0.8775 - binary_iou: 0.7757 - true_positives: 110844512.0000 - false_positives: 18808940.0000 - true_negatives: 169537376.0000 - false_negatives: 20330032.0000 - precision: 0.8549 - recall: 0.8450 - val_loss: 0.0757 - val_accuracy: 0.8756 - val_binary_iou: 0.7748 - val_true_positives: 38605216.0000 - val_false_positives: 6663971.0000 - val_true_negatives: 54178532.0000 - val_false_negatives: 6523988.0000 - val_precision: 0.8528 - val_recall: 0.8554\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0744 - accuracy: 0.8792 - binary_iou: 0.7784 - true_positives: 110836560.0000 - false_positives: 18290544.0000 - true_negatives: 170090624.0000 - false_negatives: 20303034.0000 - precision: 0.8584 - recall: 0.8452 - val_loss: 0.0838 - val_accuracy: 0.8686 - val_binary_iou: 0.7643 - val_true_positives: 38808680.0000 - val_false_positives: 7733552.0000 - val_true_negatives: 53238424.0000 - val_false_negatives: 6191043.0000 - val_precision: 0.8338 - val_recall: 0.8624\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0742 - accuracy: 0.8794 - binary_iou: 0.7788 - true_positives: 110882384.0000 - false_positives: 18254576.0000 - true_negatives: 170115376.0000 - false_negatives: 20268464.0000 - precision: 0.8586 - recall: 0.8455 - val_loss: 0.0743 - val_accuracy: 0.8803 - val_binary_iou: 0.7815 - val_true_positives: 37964788.0000 - val_false_positives: 5535672.0000 - val_true_negatives: 55320728.0000 - val_false_negatives: 7150529.0000 - val_precision: 0.8727 - val_recall: 0.8415\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0736 - accuracy: 0.8807 - binary_iou: 0.7808 - true_positives: 110972968.0000 - false_positives: 17974036.0000 - true_negatives: 170442016.0000 - false_negatives: 20131872.0000 - precision: 0.8606 - recall: 0.8464 - val_loss: 0.0780 - val_accuracy: 0.8706 - val_binary_iou: 0.7684 - val_true_positives: 39906784.0000 - val_false_positives: 8499998.0000 - val_true_negatives: 52356132.0000 - val_false_negatives: 5208790.0000 - val_precision: 0.8244 - val_recall: 0.8845\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0728 - accuracy: 0.8829 - binary_iou: 0.7843 - true_positives: 111373168.0000 - false_positives: 17715180.0000 - true_negatives: 170722176.0000 - false_negatives: 19710296.0000 - precision: 0.8628 - recall: 0.8496 - val_loss: 0.0770 - val_accuracy: 0.8757 - val_binary_iou: 0.7717 - val_true_positives: 35798568.0000 - val_false_positives: 3818787.0000 - val_true_negatives: 57002196.0000 - val_false_negatives: 9352164.0000 - val_precision: 0.9036 - val_recall: 0.7929\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0726 - accuracy: 0.8827 - binary_iou: 0.7841 - true_positives: 111452024.0000 - false_positives: 17798892.0000 - true_negatives: 170586352.0000 - false_negatives: 19683584.0000 - precision: 0.8623 - recall: 0.8499 - val_loss: 0.0810 - val_accuracy: 0.8639 - val_binary_iou: 0.7540 - val_true_positives: 36116544.0000 - val_false_positives: 5372076.0000 - val_true_negatives: 55429736.0000 - val_false_negatives: 9053340.0000 - val_precision: 0.8705 - val_recall: 0.7996\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0726 - accuracy: 0.8835 - binary_iou: 0.7854 - true_positives: 111503784.0000 - false_positives: 17627908.0000 - true_negatives: 170794800.0000 - false_negatives: 19594356.0000 - precision: 0.8635 - recall: 0.8505 - val_loss: 0.0704 - val_accuracy: 0.8863 - val_binary_iou: 0.7915 - val_true_positives: 38513900.0000 - val_false_positives: 5352287.0000 - val_true_negatives: 55406376.0000 - val_false_negatives: 6699139.0000 - val_precision: 0.8780 - val_recall: 0.8518\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 139s 350ms/step - loss: 0.0720 - accuracy: 0.8833 - binary_iou: 0.7852 - true_positives: 111675440.0000 - false_positives: 17808288.0000 - true_negatives: 170566208.0000 - false_negatives: 19470846.0000 - precision: 0.8625 - recall: 0.8515 - val_loss: 0.0821 - val_accuracy: 0.8666 - val_binary_iou: 0.7624 - val_true_positives: 40110328.0000 - val_false_positives: 9223599.0000 - val_true_negatives: 51725288.0000 - val_false_negatives: 4912495.0000 - val_precision: 0.8130 - val_recall: 0.8909\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0706 - accuracy: 0.8862 - binary_iou: 0.7899 - true_positives: 111930336.0000 - false_positives: 17126412.0000 - true_negatives: 171239056.0000 - false_negatives: 19225072.0000 - precision: 0.8673 - recall: 0.8534 - val_loss: 0.0739 - val_accuracy: 0.8792 - val_binary_iou: 0.7784 - val_true_positives: 36755232.0000 - val_false_positives: 4481793.0000 - val_true_negatives: 56420288.0000 - val_false_negatives: 8314384.0000 - val_precision: 0.8913 - val_recall: 0.8155\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 137s 345ms/step - loss: 0.0708 - accuracy: 0.8861 - binary_iou: 0.7896 - true_positives: 111675448.0000 - false_positives: 17012134.0000 - true_negatives: 171463120.0000 - false_negatives: 19370032.0000 - precision: 0.8678 - recall: 0.8522 - val_loss: 0.0725 - val_accuracy: 0.8842 - val_binary_iou: 0.7874 - val_true_positives: 37718920.0000 - val_false_positives: 4882348.0000 - val_true_negatives: 55984972.0000 - val_false_negatives: 7385472.0000 - val_precision: 0.8854 - val_recall: 0.8363\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0706 - accuracy: 0.8864 - binary_iou: 0.7901 - true_positives: 112083648.0000 - false_positives: 17320000.0000 - true_negatives: 171126784.0000 - false_negatives: 18990262.0000 - precision: 0.8662 - recall: 0.8551 - val_loss: 0.0778 - val_accuracy: 0.8782 - val_binary_iou: 0.7759 - val_true_positives: 36081004.0000 - val_false_positives: 3847325.0000 - val_true_negatives: 56984628.0000 - val_false_negatives: 9058767.0000 - val_precision: 0.9036 - val_recall: 0.7993\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0708 - accuracy: 0.8855 - binary_iou: 0.7886 - true_positives: 111719080.0000 - false_positives: 17155256.0000 - true_negatives: 171213584.0000 - false_negatives: 19432856.0000 - precision: 0.8669 - recall: 0.8518 - val_loss: 0.0713 - val_accuracy: 0.8854 - val_binary_iou: 0.7898 - val_true_positives: 38198888.0000 - val_false_positives: 5231896.0000 - val_true_negatives: 55629572.0000 - val_false_negatives: 6911343.0000 - val_precision: 0.8795 - val_recall: 0.8468\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 437ms/step - loss: 0.0698 - accuracy: 0.8885 - binary_iou: 0.7936 - true_positives: 112434120.0000 - false_positives: 16930284.0000 - true_negatives: 171448272.0000 - false_negatives: 18708080.0000 - precision: 0.8691 - recall: 0.8573 - val_loss: 0.0690 - val_accuracy: 0.8875 - val_binary_iou: 0.7944 - val_true_positives: 39463176.0000 - val_false_positives: 6336379.0000 - val_true_negatives: 54590884.0000 - val_false_negatives: 5581280.0000 - val_precision: 0.8616 - val_recall: 0.8761\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0696 - accuracy: 0.8883 - binary_iou: 0.7932 - true_positives: 112009744.0000 - false_positives: 16654082.0000 - true_negatives: 171826960.0000 - false_negatives: 19029884.0000 - precision: 0.8706 - recall: 0.8548 - val_loss: 0.0782 - val_accuracy: 0.8673 - val_binary_iou: 0.7644 - val_true_positives: 41361104.0000 - val_false_positives: 10324735.0000 - val_true_negatives: 50551800.0000 - val_false_negatives: 3734080.0000 - val_precision: 0.8002 - val_recall: 0.9172\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 443ms/step - loss: 0.0688 - accuracy: 0.8894 - binary_iou: 0.7951 - true_positives: 112377720.0000 - false_positives: 16558084.0000 - true_negatives: 171814512.0000 - false_negatives: 18770476.0000 - precision: 0.8716 - recall: 0.8569 - val_loss: 0.0699 - val_accuracy: 0.8879 - val_binary_iou: 0.7946 - val_true_positives: 38986240.0000 - val_false_positives: 5839663.0000 - val_true_negatives: 55106392.0000 - val_false_negatives: 6039420.0000 - val_precision: 0.8697 - val_recall: 0.8659\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0682 - accuracy: 0.8907 - binary_iou: 0.7971 - true_positives: 112353240.0000 - false_positives: 16102053.0000 - true_negatives: 172235680.0000 - false_negatives: 18829746.0000 - precision: 0.8746 - recall: 0.8565 - val_loss: 0.0704 - val_accuracy: 0.8881 - val_binary_iou: 0.7939 - val_true_positives: 38109872.0000 - val_false_positives: 4901732.0000 - val_true_negatives: 55998932.0000 - val_false_negatives: 6961182.0000 - val_precision: 0.8860 - val_recall: 0.8456\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 177s 445ms/step - loss: 0.0679 - accuracy: 0.8914 - binary_iou: 0.7983 - true_positives: 112329176.0000 - false_positives: 15916602.0000 - true_negatives: 172495872.0000 - false_negatives: 18779148.0000 - precision: 0.8759 - recall: 0.8568 - val_loss: 0.0682 - val_accuracy: 0.8908 - val_binary_iou: 0.7980 - val_true_positives: 37943940.0000 - val_false_positives: 4332921.0000 - val_true_negatives: 56451604.0000 - val_false_negatives: 7243249.0000 - val_precision: 0.8975 - val_recall: 0.8397\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0678 - accuracy: 0.8911 - binary_iou: 0.7979 - true_positives: 112549024.0000 - false_positives: 16229167.0000 - true_negatives: 172190704.0000 - false_negatives: 18551880.0000 - precision: 0.8740 - recall: 0.8585 - val_loss: 0.0777 - val_accuracy: 0.8769 - val_binary_iou: 0.7724 - val_true_positives: 34971264.0000 - val_false_positives: 2822913.0000 - val_true_negatives: 57959224.0000 - val_false_negatives: 10218323.0000 - val_precision: 0.9253 - val_recall: 0.7739\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0684 - accuracy: 0.8901 - binary_iou: 0.7961 - true_positives: 112222048.0000 - false_positives: 16198421.0000 - true_negatives: 172183216.0000 - false_negatives: 18917136.0000 - precision: 0.8739 - recall: 0.8557 - val_loss: 0.0680 - val_accuracy: 0.8908 - val_binary_iou: 0.7986 - val_true_positives: 38459688.0000 - val_false_positives: 4965429.0000 - val_true_negatives: 55937692.0000 - val_false_negatives: 6608893.0000 - val_precision: 0.8857 - val_recall: 0.8534\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0672 - accuracy: 0.8924 - binary_iou: 0.8000 - true_positives: 112625344.0000 - false_positives: 15909708.0000 - true_negatives: 172527040.0000 - false_negatives: 18458692.0000 - precision: 0.8762 - recall: 0.8592 - val_loss: 0.0681 - val_accuracy: 0.8911 - val_binary_iou: 0.7985 - val_true_positives: 37945288.0000 - val_false_positives: 4341430.0000 - val_true_negatives: 56481624.0000 - val_false_negatives: 7203356.0000 - val_precision: 0.8973 - val_recall: 0.8405\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0670 - accuracy: 0.8926 - binary_iou: 0.8004 - true_positives: 112697608.0000 - false_positives: 15912619.0000 - true_negatives: 172519168.0000 - false_negatives: 18391396.0000 - precision: 0.8763 - recall: 0.8597 - val_loss: 0.0695 - val_accuracy: 0.8885 - val_binary_iou: 0.7942 - val_true_positives: 37790920.0000 - val_false_positives: 4531809.0000 - val_true_negatives: 56360128.0000 - val_false_negatives: 7288845.0000 - val_precision: 0.8929 - val_recall: 0.8383\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0677 - accuracy: 0.8915 - binary_iou: 0.7986 - true_positives: 112710072.0000 - false_positives: 16261744.0000 - true_negatives: 172151872.0000 - false_negatives: 18397136.0000 - precision: 0.8739 - recall: 0.8597 - val_loss: 0.0678 - val_accuracy: 0.8902 - val_binary_iou: 0.7985 - val_true_positives: 39367096.0000 - val_false_positives: 5935776.0000 - val_true_negatives: 54966212.0000 - val_false_negatives: 5702605.0000 - val_precision: 0.8690 - val_recall: 0.8735\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 438ms/step - loss: 0.0659 - accuracy: 0.8949 - binary_iou: 0.8042 - true_positives: 113095896.0000 - false_positives: 15677050.0000 - true_negatives: 172837472.0000 - false_negatives: 17910376.0000 - precision: 0.8783 - recall: 0.8633 - val_loss: 0.0660 - val_accuracy: 0.8946 - val_binary_iou: 0.8052 - val_true_positives: 39001808.0000 - val_false_positives: 4980377.0000 - val_true_negatives: 55796588.0000 - val_false_negatives: 6192927.0000 - val_precision: 0.8868 - val_recall: 0.8630\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 139s 347ms/step - loss: 0.0664 - accuracy: 0.8936 - binary_iou: 0.8020 - true_positives: 112788272.0000 - false_positives: 15639641.0000 - true_negatives: 172750048.0000 - false_negatives: 18342840.0000 - precision: 0.8782 - recall: 0.8601 - val_loss: 0.0699 - val_accuracy: 0.8875 - val_binary_iou: 0.7919 - val_true_positives: 37142420.0000 - val_false_positives: 4069980.0000 - val_true_negatives: 56904784.0000 - val_false_negatives: 7854534.0000 - val_precision: 0.9012 - val_recall: 0.8254\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0655 - accuracy: 0.8950 - binary_iou: 0.8044 - true_positives: 113115328.0000 - false_positives: 15486498.0000 - true_negatives: 172855152.0000 - false_negatives: 18063804.0000 - precision: 0.8796 - recall: 0.8623 - val_loss: 0.0692 - val_accuracy: 0.8888 - val_binary_iou: 0.7959 - val_true_positives: 38962320.0000 - val_false_positives: 5677038.0000 - val_true_negatives: 55221624.0000 - val_false_negatives: 6110758.0000 - val_precision: 0.8728 - val_recall: 0.8644\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0651 - accuracy: 0.8960 - binary_iou: 0.8059 - true_positives: 113075528.0000 - false_positives: 15203770.0000 - true_negatives: 173212272.0000 - false_negatives: 18029176.0000 - precision: 0.8815 - recall: 0.8625 - val_loss: 0.0729 - val_accuracy: 0.8840 - val_binary_iou: 0.7863 - val_true_positives: 37080092.0000 - val_false_positives: 4269862.0000 - val_true_negatives: 56597916.0000 - val_false_negatives: 8023830.0000 - val_precision: 0.8967 - val_recall: 0.8221\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0648 - accuracy: 0.8961 - binary_iou: 0.8062 - true_positives: 113327736.0000 - false_positives: 15474886.0000 - true_negatives: 172995104.0000 - false_negatives: 17722972.0000 - precision: 0.8799 - recall: 0.8648 - val_loss: 0.0675 - val_accuracy: 0.8916 - val_binary_iou: 0.7997 - val_true_positives: 38295708.0000 - val_false_positives: 4763659.0000 - val_true_negatives: 56185512.0000 - val_false_negatives: 6726823.0000 - val_precision: 0.8894 - val_recall: 0.8506\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0644 - accuracy: 0.8971 - binary_iou: 0.8078 - true_positives: 113363456.0000 - false_positives: 15155710.0000 - true_negatives: 173270416.0000 - false_negatives: 17731144.0000 - precision: 0.8821 - recall: 0.8647 - val_loss: 0.0699 - val_accuracy: 0.8883 - val_binary_iou: 0.7926 - val_true_positives: 36737004.0000 - val_false_positives: 3459131.0000 - val_true_negatives: 57393536.0000 - val_false_negatives: 8382044.0000 - val_precision: 0.9139 - val_recall: 0.8142\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0649 - accuracy: 0.8960 - binary_iou: 0.8061 - true_positives: 113351536.0000 - false_positives: 15406054.0000 - true_negatives: 172946240.0000 - false_negatives: 17816920.0000 - precision: 0.8803 - recall: 0.8642 - val_loss: 0.0693 - val_accuracy: 0.8881 - val_binary_iou: 0.7931 - val_true_positives: 37406232.0000 - val_false_positives: 4189810.0000 - val_true_negatives: 56703164.0000 - val_false_negatives: 7672504.0000 - val_precision: 0.8993 - val_recall: 0.8298\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 439ms/step - loss: 0.0646 - accuracy: 0.8966 - binary_iou: 0.8069 - true_positives: 113306208.0000 - false_positives: 15135919.0000 - true_negatives: 173161216.0000 - false_negatives: 17917392.0000 - precision: 0.8822 - recall: 0.8635 - val_loss: 0.0644 - val_accuracy: 0.8982 - val_binary_iou: 0.8115 - val_true_positives: 39367752.0000 - val_false_positives: 4995223.0000 - val_true_negatives: 55818860.0000 - val_false_negatives: 5789865.0000 - val_precision: 0.8874 - val_recall: 0.8718\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0637 - accuracy: 0.8982 - binary_iou: 0.8098 - true_positives: 113737680.0000 - false_positives: 15229448.0000 - true_negatives: 173259152.0000 - false_negatives: 17294578.0000 - precision: 0.8819 - recall: 0.8680 - val_loss: 0.0701 - val_accuracy: 0.8890 - val_binary_iou: 0.7959 - val_true_positives: 38609764.0000 - val_false_positives: 5199589.0000 - val_true_negatives: 55594380.0000 - val_false_negatives: 6567994.0000 - val_precision: 0.8813 - val_recall: 0.8546\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0643 - accuracy: 0.8975 - binary_iou: 0.8085 - true_positives: 113463744.0000 - false_positives: 15104503.0000 - true_negatives: 173302384.0000 - false_negatives: 17650162.0000 - precision: 0.8825 - recall: 0.8654 - val_loss: 0.0674 - val_accuracy: 0.8904 - val_binary_iou: 0.7991 - val_true_positives: 39483080.0000 - val_false_positives: 5960064.0000 - val_true_negatives: 54877108.0000 - val_false_negatives: 5651467.0000 - val_precision: 0.8688 - val_recall: 0.8748\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0637 - accuracy: 0.8983 - binary_iou: 0.8098 - true_positives: 113509408.0000 - false_positives: 14836776.0000 - true_negatives: 173506304.0000 - false_negatives: 17668256.0000 - precision: 0.8844 - recall: 0.8653 - val_loss: 0.0679 - val_accuracy: 0.8912 - val_binary_iou: 0.7994 - val_true_positives: 38486376.0000 - val_false_positives: 4910151.0000 - val_true_negatives: 55960840.0000 - val_false_negatives: 6614339.0000 - val_precision: 0.8869 - val_recall: 0.8533\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0631 - accuracy: 0.8992 - binary_iou: 0.8113 - true_positives: 113698048.0000 - false_positives: 14690406.0000 - true_negatives: 173600240.0000 - false_negatives: 17532068.0000 - precision: 0.8856 - recall: 0.8664 - val_loss: 0.0652 - val_accuracy: 0.8966 - val_binary_iou: 0.8095 - val_true_positives: 40043744.0000 - val_false_positives: 5826681.0000 - val_true_negatives: 54969080.0000 - val_false_negatives: 5132186.0000 - val_precision: 0.8730 - val_recall: 0.8864\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0637 - accuracy: 0.8980 - binary_iou: 0.8094 - true_positives: 113588616.0000 - false_positives: 14980239.0000 - true_negatives: 173351664.0000 - false_negatives: 17600292.0000 - precision: 0.8835 - recall: 0.8658 - val_loss: 0.0656 - val_accuracy: 0.8946 - val_binary_iou: 0.8057 - val_true_positives: 39386224.0000 - val_false_positives: 5345324.0000 - val_true_negatives: 55416720.0000 - val_false_negatives: 5823438.0000 - val_precision: 0.8805 - val_recall: 0.8712\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0632 - accuracy: 0.8994 - binary_iou: 0.8117 - true_positives: 113913360.0000 - false_positives: 14901580.0000 - true_negatives: 173453984.0000 - false_negatives: 17251912.0000 - precision: 0.8843 - recall: 0.8685 - val_loss: 0.0677 - val_accuracy: 0.8909 - val_binary_iou: 0.7967 - val_true_positives: 36674312.0000 - val_false_positives: 3143865.0000 - val_true_negatives: 57733296.0000 - val_false_negatives: 8420255.0000 - val_precision: 0.9210 - val_recall: 0.8133\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0628 - accuracy: 0.8998 - binary_iou: 0.8124 - true_positives: 113707192.0000 - false_positives: 14696928.0000 - true_negatives: 173804480.0000 - false_negatives: 17312232.0000 - precision: 0.8855 - recall: 0.8679 - val_loss: 0.0644 - val_accuracy: 0.8966 - val_binary_iou: 0.8081 - val_true_positives: 38568048.0000 - val_false_positives: 4499647.0000 - val_true_negatives: 56449208.0000 - val_false_negatives: 6454799.0000 - val_precision: 0.8955 - val_recall: 0.8566\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0629 - accuracy: 0.8991 - binary_iou: 0.8111 - true_positives: 113587144.0000 - false_positives: 14703208.0000 - true_negatives: 173683136.0000 - false_negatives: 17547360.0000 - precision: 0.8854 - recall: 0.8662 - val_loss: 0.0652 - val_accuracy: 0.8961 - val_binary_iou: 0.8068 - val_true_positives: 38103600.0000 - val_false_positives: 3996850.0000 - val_true_negatives: 56860540.0000 - val_false_negatives: 7010724.0000 - val_precision: 0.9051 - val_recall: 0.8446\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9011 - binary_iou: 0.8147 - true_positives: 114228344.0000 - false_positives: 14679725.0000 - true_negatives: 173688992.0000 - false_negatives: 16923826.0000 - precision: 0.8861 - recall: 0.8710 - val_loss: 0.0670 - val_accuracy: 0.8930 - val_binary_iou: 0.8033 - val_true_positives: 39714736.0000 - val_false_positives: 5934338.0000 - val_true_negatives: 54915616.0000 - val_false_negatives: 5407036.0000 - val_precision: 0.8700 - val_recall: 0.8802\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0620 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114160192.0000 - false_positives: 14541802.0000 - true_negatives: 173797200.0000 - false_negatives: 17021584.0000 - precision: 0.8870 - recall: 0.8702 - val_loss: 0.0660 - val_accuracy: 0.8971 - val_binary_iou: 0.8080 - val_true_positives: 37770996.0000 - val_false_positives: 3567448.0000 - val_true_negatives: 57291268.0000 - val_false_negatives: 7341999.0000 - val_precision: 0.9137 - val_recall: 0.8373\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0617 - accuracy: 0.9012 - binary_iou: 0.8149 - true_positives: 114073448.0000 - false_positives: 14479113.0000 - true_negatives: 173890848.0000 - false_negatives: 17077416.0000 - precision: 0.8874 - recall: 0.8698 - val_loss: 0.0689 - val_accuracy: 0.8869 - val_binary_iou: 0.7917 - val_true_positives: 37728168.0000 - val_false_positives: 4620711.0000 - val_true_negatives: 56262276.0000 - val_false_negatives: 7360528.0000 - val_precision: 0.8909 - val_recall: 0.8368\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0619 - accuracy: 0.9012 - binary_iou: 0.8148 - true_positives: 114021800.0000 - false_positives: 14454801.0000 - true_negatives: 173942048.0000 - false_negatives: 17102218.0000 - precision: 0.8875 - recall: 0.8696 - val_loss: 0.0649 - val_accuracy: 0.8959 - val_binary_iou: 0.8076 - val_true_positives: 39236980.0000 - val_false_positives: 5234554.0000 - val_true_negatives: 55702736.0000 - val_false_negatives: 5797450.0000 - val_precision: 0.8823 - val_recall: 0.8713\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0616 - accuracy: 0.9018 - binary_iou: 0.8158 - true_positives: 114294520.0000 - false_positives: 14557606.0000 - true_negatives: 173837216.0000 - false_negatives: 16831460.0000 - precision: 0.8870 - recall: 0.8716 - val_loss: 0.0668 - val_accuracy: 0.8935 - val_binary_iou: 0.8021 - val_true_positives: 37644852.0000 - val_false_positives: 3729698.0000 - val_true_negatives: 57043988.0000 - val_false_negatives: 7553180.0000 - val_precision: 0.9099 - val_recall: 0.8329\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0610 - accuracy: 0.9025 - binary_iou: 0.8171 - true_positives: 114541624.0000 - false_positives: 14579440.0000 - true_negatives: 173826448.0000 - false_negatives: 16573294.0000 - precision: 0.8871 - recall: 0.8736 - val_loss: 0.0697 - val_accuracy: 0.8909 - val_binary_iou: 0.8004 - val_true_positives: 40092472.0000 - val_false_positives: 6589798.0000 - val_true_negatives: 54318728.0000 - val_false_negatives: 4970714.0000 - val_precision: 0.8588 - val_recall: 0.8897\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 174s 436ms/step - loss: 0.0611 - accuracy: 0.9022 - binary_iou: 0.8166 - true_positives: 114267568.0000 - false_positives: 14379401.0000 - true_negatives: 174018128.0000 - false_negatives: 16855688.0000 - precision: 0.8882 - recall: 0.8715 - val_loss: 0.0628 - val_accuracy: 0.8995 - val_binary_iou: 0.8142 - val_true_positives: 40126964.0000 - val_false_positives: 5757267.0000 - val_true_negatives: 55192272.0000 - val_false_negatives: 4895184.0000 - val_precision: 0.8745 - val_recall: 0.8913\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0604 - accuracy: 0.9035 - binary_iou: 0.8187 - true_positives: 114372352.0000 - false_positives: 14042377.0000 - true_negatives: 174325200.0000 - false_negatives: 16780868.0000 - precision: 0.8906 - recall: 0.8721 - val_loss: 0.0720 - val_accuracy: 0.8868 - val_binary_iou: 0.7945 - val_true_positives: 40941160.0000 - val_false_positives: 7836965.0000 - val_true_negatives: 53037104.0000 - val_false_negatives: 4156491.0000 - val_precision: 0.8393 - val_recall: 0.9078\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0598 - accuracy: 0.9050 - binary_iou: 0.8213 - true_positives: 114764616.0000 - false_positives: 13977922.0000 - true_negatives: 174412896.0000 - false_negatives: 16365363.0000 - precision: 0.8914 - recall: 0.8752 - val_loss: 0.0632 - val_accuracy: 0.8991 - val_binary_iou: 0.8121 - val_true_positives: 38543120.0000 - val_false_positives: 4116308.0000 - val_true_negatives: 56735084.0000 - val_false_negatives: 6577184.0000 - val_precision: 0.9035 - val_recall: 0.8542\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0602 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114492112.0000 - false_positives: 14097260.0000 - true_negatives: 174293072.0000 - false_negatives: 16638253.0000 - precision: 0.8904 - recall: 0.8731 - val_loss: 0.0649 - val_accuracy: 0.8957 - val_binary_iou: 0.8085 - val_true_positives: 40805296.0000 - val_false_positives: 6699145.0000 - val_true_negatives: 54108424.0000 - val_false_negatives: 4358863.0000 - val_precision: 0.8590 - val_recall: 0.9035\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0605 - accuracy: 0.9037 - binary_iou: 0.8190 - true_positives: 114271792.0000 - false_positives: 13944031.0000 - true_negatives: 174493456.0000 - false_negatives: 16811372.0000 - precision: 0.8912 - recall: 0.8718 - val_loss: 0.0673 - val_accuracy: 0.8897 - val_binary_iou: 0.7995 - val_true_positives: 41579912.0000 - val_false_positives: 8194420.0000 - val_true_negatives: 52699744.0000 - val_false_negatives: 3497623.0000 - val_precision: 0.8354 - val_recall: 0.9224\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0606 - accuracy: 0.9038 - binary_iou: 0.8192 - true_positives: 114383448.0000 - false_positives: 13910560.0000 - true_negatives: 174400160.0000 - false_negatives: 16826680.0000 - precision: 0.8916 - recall: 0.8718 - val_loss: 0.0766 - val_accuracy: 0.8862 - val_binary_iou: 0.7928 - val_true_positives: 40028572.0000 - val_false_positives: 7006960.0000 - val_true_negatives: 53881560.0000 - val_false_negatives: 5054641.0000 - val_precision: 0.8510 - val_recall: 0.8879\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0600 - accuracy: 0.9047 - binary_iou: 0.8208 - true_positives: 114618984.0000 - false_positives: 13905703.0000 - true_negatives: 174461968.0000 - false_negatives: 16534175.0000 - precision: 0.8918 - recall: 0.8739 - val_loss: 0.0630 - val_accuracy: 0.9009 - val_binary_iou: 0.8159 - val_true_positives: 39473896.0000 - val_false_positives: 4852153.0000 - val_true_negatives: 55992092.0000 - val_false_negatives: 5653550.0000 - val_precision: 0.8905 - val_recall: 0.8747\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0598 - accuracy: 0.9053 - binary_iou: 0.8217 - true_positives: 114655032.0000 - false_positives: 13736962.0000 - true_negatives: 174595376.0000 - false_negatives: 16533304.0000 - precision: 0.8930 - recall: 0.8740 - val_loss: 0.0671 - val_accuracy: 0.8912 - val_binary_iou: 0.7983 - val_true_positives: 37558328.0000 - val_false_positives: 3884693.0000 - val_true_negatives: 56883664.0000 - val_false_negatives: 7645055.0000 - val_precision: 0.9063 - val_recall: 0.8309\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 176s 442ms/step - loss: 0.0597 - accuracy: 0.9053 - binary_iou: 0.8218 - true_positives: 114733776.0000 - false_positives: 13861437.0000 - true_negatives: 174539488.0000 - false_negatives: 16385981.0000 - precision: 0.8922 - recall: 0.8750 - val_loss: 0.0613 - val_accuracy: 0.9038 - val_binary_iou: 0.8209 - val_true_positives: 39589588.0000 - val_false_positives: 4649140.0000 - val_true_negatives: 56191696.0000 - val_false_negatives: 5541295.0000 - val_precision: 0.8949 - val_recall: 0.8772\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9066 - binary_iou: 0.8240 - true_positives: 114924592.0000 - false_positives: 13616651.0000 - true_negatives: 174744976.0000 - false_negatives: 16234598.0000 - precision: 0.8941 - recall: 0.8762 - val_loss: 0.0657 - val_accuracy: 0.8950 - val_binary_iou: 0.8070 - val_true_positives: 40115272.0000 - val_false_positives: 6156170.0000 - val_true_negatives: 54733744.0000 - val_false_negatives: 4966526.0000 - val_precision: 0.8670 - val_recall: 0.8898\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0590 - accuracy: 0.9069 - binary_iou: 0.8244 - true_positives: 114822896.0000 - false_positives: 13371130.0000 - true_negatives: 174937648.0000 - false_negatives: 16389186.0000 - precision: 0.8957 - recall: 0.8751 - val_loss: 0.0643 - val_accuracy: 0.8999 - val_binary_iou: 0.8143 - val_true_positives: 39385200.0000 - val_false_positives: 4859034.0000 - val_true_negatives: 55981228.0000 - val_false_negatives: 5746234.0000 - val_precision: 0.8902 - val_recall: 0.8727\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0592 - accuracy: 0.9064 - binary_iou: 0.8238 - true_positives: 115060424.0000 - false_positives: 13745673.0000 - true_negatives: 174567392.0000 - false_negatives: 16147346.0000 - precision: 0.8933 - recall: 0.8769 - val_loss: 0.0611 - val_accuracy: 0.9035 - val_binary_iou: 0.8204 - val_true_positives: 39653136.0000 - val_false_positives: 4728918.0000 - val_true_negatives: 56094144.0000 - val_false_negatives: 5495510.0000 - val_precision: 0.8934 - val_recall: 0.8783\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0590 - accuracy: 0.9059 - binary_iou: 0.8228 - true_positives: 114785464.0000 - false_positives: 13761449.0000 - true_negatives: 174670400.0000 - false_negatives: 16303439.0000 - precision: 0.8929 - recall: 0.8756 - val_loss: 0.0693 - val_accuracy: 0.8904 - val_binary_iou: 0.7999 - val_true_positives: 40398372.0000 - val_false_positives: 6853430.0000 - val_true_negatives: 53963436.0000 - val_false_negatives: 4756454.0000 - val_precision: 0.8550 - val_recall: 0.8947\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0584 - accuracy: 0.9071 - binary_iou: 0.8249 - true_positives: 115098648.0000 - false_positives: 13609404.0000 - true_negatives: 174737072.0000 - false_negatives: 16075616.0000 - precision: 0.8943 - recall: 0.8774 - val_loss: 0.0620 - val_accuracy: 0.9023 - val_binary_iou: 0.8191 - val_true_positives: 40398948.0000 - val_false_positives: 5691739.0000 - val_true_negatives: 55220200.0000 - val_false_negatives: 4660829.0000 - val_precision: 0.8765 - val_recall: 0.8966\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0580 - accuracy: 0.9078 - binary_iou: 0.8260 - true_positives: 115041896.0000 - false_positives: 13368177.0000 - true_negatives: 175011792.0000 - false_negatives: 16098864.0000 - precision: 0.8959 - recall: 0.8772 - val_loss: 0.0618 - val_accuracy: 0.9024 - val_binary_iou: 0.8176 - val_true_positives: 38695004.0000 - val_false_positives: 3913730.0000 - val_true_negatives: 56928672.0000 - val_false_negatives: 6434295.0000 - val_precision: 0.9081 - val_recall: 0.8574\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0586 - accuracy: 0.9073 - binary_iou: 0.8253 - true_positives: 115108880.0000 - false_positives: 13592248.0000 - true_negatives: 174804848.0000 - false_negatives: 16014808.0000 - precision: 0.8944 - recall: 0.8779 - val_loss: 0.0632 - val_accuracy: 0.9009 - val_binary_iou: 0.8162 - val_true_positives: 39746444.0000 - val_false_positives: 5064269.0000 - val_true_negatives: 55720692.0000 - val_false_negatives: 5440308.0000 - val_precision: 0.8870 - val_recall: 0.8796\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0578 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115246840.0000 - false_positives: 13281822.0000 - true_negatives: 175027632.0000 - false_negatives: 15964501.0000 - precision: 0.8967 - recall: 0.8783 - val_loss: 0.0609 - val_accuracy: 0.9045 - val_binary_iou: 0.8220 - val_true_positives: 39622044.0000 - val_false_positives: 4580523.0000 - val_true_negatives: 56227608.0000 - val_false_negatives: 5541544.0000 - val_precision: 0.8964 - val_recall: 0.8773\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0579 - accuracy: 0.9080 - binary_iou: 0.8265 - true_positives: 115247800.0000 - false_positives: 13446067.0000 - true_negatives: 174880816.0000 - false_negatives: 15946018.0000 - precision: 0.8955 - recall: 0.8785 - val_loss: 0.0743 - val_accuracy: 0.8851 - val_binary_iou: 0.7913 - val_true_positives: 40276164.0000 - val_false_positives: 7452888.0000 - val_true_negatives: 53520128.0000 - val_false_negatives: 4722535.0000 - val_precision: 0.8439 - val_recall: 0.8951\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0573 - accuracy: 0.9089 - binary_iou: 0.8280 - true_positives: 115350232.0000 - false_positives: 13306295.0000 - true_negatives: 175061568.0000 - false_negatives: 15802560.0000 - precision: 0.8966 - recall: 0.8795 - val_loss: 0.0687 - val_accuracy: 0.8928 - val_binary_iou: 0.8045 - val_true_positives: 41609304.0000 - val_false_positives: 7912378.0000 - val_true_negatives: 52998040.0000 - val_false_negatives: 3452000.0000 - val_precision: 0.8402 - val_recall: 0.9234\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0570 - accuracy: 0.9097 - binary_iou: 0.8295 - true_positives: 115566680.0000 - false_positives: 13204775.0000 - true_negatives: 175116896.0000 - false_negatives: 15632293.0000 - precision: 0.8975 - recall: 0.8809 - val_loss: 0.0618 - val_accuracy: 0.9033 - val_binary_iou: 0.8206 - val_true_positives: 40212672.0000 - val_false_positives: 5331110.0000 - val_true_negatives: 55514868.0000 - val_false_negatives: 4913069.0000 - val_precision: 0.8829 - val_recall: 0.8911\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0574 - accuracy: 0.9091 - binary_iou: 0.8283 - true_positives: 115335368.0000 - false_positives: 13241246.0000 - true_negatives: 175149360.0000 - false_negatives: 15794777.0000 - precision: 0.8970 - recall: 0.8795 - val_loss: 0.0619 - val_accuracy: 0.9025 - val_binary_iou: 0.8185 - val_true_positives: 39427960.0000 - val_false_positives: 4689384.0000 - val_true_negatives: 56207648.0000 - val_false_negatives: 5646732.0000 - val_precision: 0.8937 - val_recall: 0.8747\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0572 - accuracy: 0.9092 - binary_iou: 0.8284 - true_positives: 115450496.0000 - false_positives: 13292661.0000 - true_negatives: 175043360.0000 - false_negatives: 15734289.0000 - precision: 0.8968 - recall: 0.8801 - val_loss: 0.0653 - val_accuracy: 0.8978 - val_binary_iou: 0.8097 - val_true_positives: 38248656.0000 - val_false_positives: 3970812.0000 - val_true_negatives: 56891840.0000 - val_false_negatives: 6860412.0000 - val_precision: 0.9059 - val_recall: 0.8479\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0576 - accuracy: 0.9085 - binary_iou: 0.8272 - true_positives: 115059888.0000 - false_positives: 13279338.0000 - true_negatives: 175221456.0000 - false_negatives: 15960160.0000 - precision: 0.8965 - recall: 0.8782 - val_loss: 0.0621 - val_accuracy: 0.9005 - val_binary_iou: 0.8159 - val_true_positives: 40226056.0000 - val_false_positives: 5739225.0000 - val_true_negatives: 55198836.0000 - val_false_negatives: 4807608.0000 - val_precision: 0.8751 - val_recall: 0.8932\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0567 - accuracy: 0.9100 - binary_iou: 0.8299 - true_positives: 115410632.0000 - false_positives: 13091224.0000 - true_negatives: 175366784.0000 - false_negatives: 15652111.0000 - precision: 0.8981 - recall: 0.8806 - val_loss: 0.0648 - val_accuracy: 0.8976 - val_binary_iou: 0.8096 - val_true_positives: 38385240.0000 - val_false_positives: 4143129.0000 - val_true_negatives: 56738792.0000 - val_false_negatives: 6704553.0000 - val_precision: 0.9026 - val_recall: 0.8513\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0569 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115559664.0000 - false_positives: 13187510.0000 - true_negatives: 175197328.0000 - false_negatives: 15576244.0000 - precision: 0.8976 - recall: 0.8812 - val_loss: 0.0616 - val_accuracy: 0.9021 - val_binary_iou: 0.8190 - val_true_positives: 40675596.0000 - val_false_positives: 5981493.0000 - val_true_negatives: 54921920.0000 - val_false_negatives: 4392702.0000 - val_precision: 0.8718 - val_recall: 0.9025\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 440ms/step - loss: 0.0563 - accuracy: 0.9109 - binary_iou: 0.8313 - true_positives: 115628352.0000 - false_positives: 12969629.0000 - true_negatives: 175407312.0000 - false_negatives: 15515576.0000 - precision: 0.8991 - recall: 0.8817 - val_loss: 0.0604 - val_accuracy: 0.9043 - val_binary_iou: 0.8220 - val_true_positives: 40136756.0000 - val_false_positives: 5091398.0000 - val_true_negatives: 55688312.0000 - val_false_negatives: 5055239.0000 - val_precision: 0.8874 - val_recall: 0.8881\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 138s 346ms/step - loss: 0.0565 - accuracy: 0.9104 - binary_iou: 0.8305 - true_positives: 115524848.0000 - false_positives: 13007364.0000 - true_negatives: 175357504.0000 - false_negatives: 15631114.0000 - precision: 0.8988 - recall: 0.8808 - val_loss: 0.0637 - val_accuracy: 0.8973 - val_binary_iou: 0.8116 - val_true_positives: 41283940.0000 - val_false_positives: 7066725.0000 - val_true_negatives: 53805696.0000 - val_false_negatives: 3815342.0000 - val_precision: 0.8538 - val_recall: 0.9154\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 138s 348ms/step - loss: 0.0566 - accuracy: 0.9100 - binary_iou: 0.8298 - true_positives: 115418920.0000 - false_positives: 13103144.0000 - true_negatives: 175337664.0000 - false_negatives: 15661151.0000 - precision: 0.8980 - recall: 0.8805 - val_loss: 0.0685 - val_accuracy: 0.8931 - val_binary_iou: 0.8000 - val_true_positives: 36465344.0000 - val_false_positives: 2706221.0000 - val_true_negatives: 58180776.0000 - val_false_negatives: 8619357.0000 - val_precision: 0.9309 - val_recall: 0.8088\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model_FT_test\\FT_test_AVG_no_of_frozen_layers_190_e100\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 175s 441ms/step - loss: 0.0561 - accuracy: 0.9111 - binary_iou: 0.8317 - true_positives: 115815832.0000 - false_positives: 13073346.0000 - true_negatives: 175286256.0000 - false_negatives: 15345345.0000 - precision: 0.8986 - recall: 0.8830 - val_loss: 0.0591 - val_accuracy: 0.9071 - val_binary_iou: 0.8267 - val_true_positives: 40077468.0000 - val_false_positives: 4810660.0000 - val_true_negatives: 56051568.0000 - val_false_negatives: 5032024.0000 - val_precision: 0.8928 - val_recall: 0.8884\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0561 - accuracy: 0.9108 - binary_iou: 0.8312 - true_positives: 115485504.0000 - false_positives: 12872387.0000 - true_negatives: 175535872.0000 - false_negatives: 15627070.0000 - precision: 0.8997 - recall: 0.8808 - val_loss: 0.0686 - val_accuracy: 0.8930 - val_binary_iou: 0.8049 - val_true_positives: 41539792.0000 - val_false_positives: 7744004.0000 - val_true_negatives: 53097324.0000 - val_false_negatives: 3590584.0000 - val_precision: 0.8429 - val_recall: 0.9204\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 138s 347ms/step - loss: 0.0560 - accuracy: 0.9111 - binary_iou: 0.8318 - true_positives: 115753184.0000 - false_positives: 13009851.0000 - true_negatives: 175361808.0000 - false_negatives: 15395915.0000 - precision: 0.8990 - recall: 0.8826 - val_loss: 0.0621 - val_accuracy: 0.9018 - val_binary_iou: 0.8154 - val_true_positives: 37469948.0000 - val_false_positives: 2734699.0000 - val_true_negatives: 58100136.0000 - val_false_negatives: 7666928.0000 - val_precision: 0.9320 - val_recall: 0.8301\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 139s 348ms/step - loss: 0.0557 - accuracy: 0.9119 - binary_iou: 0.8331 - true_positives: 115764048.0000 - false_positives: 12780396.0000 - true_negatives: 175605136.0000 - false_negatives: 15371262.0000 - precision: 0.9006 - recall: 0.8828 - val_loss: 0.0607 - val_accuracy: 0.9049 - val_binary_iou: 0.8227 - val_true_positives: 39667376.0000 - val_false_positives: 4631294.0000 - val_true_negatives: 56222816.0000 - val_false_negatives: 5450231.0000 - val_precision: 0.8955 - val_recall: 0.8792\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 139s 349ms/step - loss: 0.0556 - accuracy: 0.9117 - binary_iou: 0.8328 - true_positives: 115600880.0000 - false_positives: 12729907.0000 - true_negatives: 175719568.0000 - false_negatives: 15470327.0000 - precision: 0.9008 - recall: 0.8820 - val_loss: 0.0629 - val_accuracy: 0.8997 - val_binary_iou: 0.8149 - val_true_positives: 40599992.0000 - val_false_positives: 6119560.0000 - val_true_negatives: 54737740.0000 - val_false_negatives: 4514413.0000 - val_precision: 0.8690 - val_recall: 0.8999\n",
      "132/132 [==============================] - 20s 121ms/step - loss: 224.4008 - accuracy: 0.9036 - binary_iou: 0.8199 - true_positives: 38915348.0000 - false_positives: 4943305.0000 - true_negatives: 56841440.0000 - false_negatives: 5271624.0000 - precision: 0.8873 - recall: 0.8807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Durch RegEx kann aus den Layernamen der Index der Convolutional-Layer entnommen werden und diese dann nacheinander eingefroren werden\n",
    "\n",
    "conv_layers = [4, 7, 11, 15, 18, 22, 26, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 64, 68, 72, 75, 79, 83, 86, 90, 94, 95, 98, 102, 106, 110, 114, 118,\n",
    " 121, 125, 129, 132, 136, 140, 141, 144, 148, 152, 156, 160, 164, 167, 171, 175, 176, 179, 183, 190]\n",
    "\n",
    "import gc\n",
    "\n",
    "for number in conv_layers:      \n",
    "\n",
    "    training_split = 0.6\n",
    "\n",
    "    pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "    conf = {\n",
    "        'AVG': 'BN',\n",
    "        'RNDM': 'BN',\n",
    "        'EXTRA_CONV': 'CONV',\n",
    "        'RGB_SPLIT': 'SPLIT'\n",
    "        } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "    lr = 0.001 # Learning rate\n",
    "\n",
    "    rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "    ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "    l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "    l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "    #freeze = True # Trainierbarkeit des Encoders\n",
    "    freeze_from = 'input' # Ab diesem layer wird eingefroren, EXKLUSIVE (wird überschrieben bei SPLIT-Variante)!\n",
    "    train_encoder_layers = number # Anzahl an Layern (int) im Encoder, die trainiert werden. Rückwärts gezählt ab Bottleneck\n",
    "    #freeze_what = 'No1ConvBN' # Beschreibung ob 1. Layer eingefroren oder nicht\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    patch_size = 224 # Maße des inputs\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "\n",
    "    unet = load_model(conf[pretrained_weights])\n",
    "    set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "    set_weight_decay(unet, l1= l1, l2= l2)\n",
    "    set_pretrained_weights(unet, pretrained_weights)\n",
    "    set_encoder_frozen(unet, pretrained_weights, freeze_from= freeze_from, train_encoder_layers= train_encoder_layers)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n",
    "\n",
    "    loss = tf.keras.losses.BinaryFocalCrossentropy(gamma= 2.0, name= 'binary_focal_crossentropy')\n",
    "\n",
    "\n",
    "    binary_iou = tf.keras.metrics.BinaryIoU(name='binary_iou', threshold=0.5),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        binary_iou,\n",
    "        tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "        tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "        tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "        tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    unet.compile(optimizer= optimizer, loss= loss, metrics= metrics)\n",
    "\n",
    "    model_name = f'FT_test_AVG_no_of_frozen_layers_{number}'\n",
    "\n",
    "    checkpoint_path = f'../saved_model_FT_test/{model_name}_e{str(epochs)}'\n",
    "    logger_path = f'../saved_history_FT_test/{model_name}_e{str(epochs)}.log'\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_binary_iou',\n",
    "        mode= 'max',\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True)\n",
    "\n",
    "    history_logger = tf.keras.callbacks.CSVLogger(logger_path)\n",
    "\n",
    "    callbacks = [checkpoint_callback, history_logger]\n",
    "\n",
    "\n",
    "\n",
    "    train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/train/masks'\n",
    "    )\n",
    "\n",
    "    val_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = True,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/val/masks'\n",
    "    )\n",
    "\n",
    "    test_data_generator = CustomDataGenerator(\n",
    "        batch_size = batch_size,\n",
    "        augment = False,\n",
    "        shuffle = False,\n",
    "        img_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/images',\n",
    "        msk_directory = f'../data/Potsdam/{patch_size}_patchesRGBIR/split_folders{training_split}/test/masks'\n",
    "    )\n",
    "\n",
    "    model_history = unet.fit(train_data_generator, validation_data=val_data_generator, callbacks= [checkpoint_callback, history_logger], epochs=epochs)\n",
    "\n",
    "\n",
    "    # laden des besten models\n",
    "    unet = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "    # Evaluieren & Ergebnisse in Tabelle\n",
    "    eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "    with open('../results/FT_test_eval_output.csv', 'a') as f_object:\n",
    "        row = []\n",
    "        \n",
    "        row.append(model_name)\n",
    "\n",
    "        for x in eval_out:\n",
    "            row.append(x)\n",
    "\n",
    "        writer_object = csv.writer(f_object)\n",
    "\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "    del unet\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob trainable oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.6\n",
    "batch_size = 32\n",
    "patch_size = 224 # Maße des inputs\n",
    "epochs = 150\n",
    "\n",
    "pretrained_weights = 'AVG' #AVG (Mittelwert von RGB), RNDM (IR-Kanal Random), EXTRA_CONV (Original mit zusätzlichem Conv-Layer davor), RGB_SPLIT (Original und IR Bypass)\n",
    "\n",
    "conf = {\n",
    "    'AVG': 'BN',\n",
    "    'RNDM': 'BN',\n",
    "    'EXTRA_CONV': 'CONV',\n",
    "    'RGB_SPLIT': 'SPLIT'\n",
    "    } # Art des Netzwerks, BN, SPLIT (RGB & IR seperate conv-layer), CONV (zusätzlicher Conv um channel zu downsamplen) ...\n",
    "\n",
    "learning_rate = 0.001 # Learning rate\n",
    "\n",
    "rgb_drop = 0 # Dropout rate RGB 0-1\n",
    "ir_drop = 0 # Dropout rate IR 0-1\n",
    "\n",
    "l1 = 0.0005 # L1 weight decay regularizer 0-1\n",
    "l2 = 0.0005 # L2 weight decay regularizer0-1\n",
    "\n",
    "# ob 1. Conv-Layer mit Classifier trainiert wird oder eingefroren während erstem Trainingsdurchlauf des Decoder Parts\n",
    "train_first_layer = True\n",
    "\n",
    "# ob 1. Conv-Layer auch während des Fine-Tunings trainiert wird\n",
    "FT_train_first_layer = True\n",
    "\n",
    "initial_epochs = 20\n",
    "fine_tune_epochs = 280\n",
    "\n",
    "early_stop = False\n",
    "\n",
    "model_name = f'Final_{pretrained_weights}_rgbDrop_{rgb_drop}_earlyStop_{early_stop}'\n",
    "\n",
    "# Präfix der checkpoint und logger Ordner im Verzeichnis\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "unet = load_model(conf[pretrained_weights])\n",
    "set_dropout(unet, rgb_drop= rgb_drop, ir_drop= ir_drop)\n",
    "set_weight_decay(unet, l1= l1, l2= l2)\n",
    "set_pretrained_weights(unet, pretrained_weights)\n",
    "set_encoder_frozen(unet, pretrained_weights, train_first_layer)\n",
    "compile_model(unet, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input trainable weights: 0 trainable: False\n",
      "1 split_input trainable weights: 0 trainable: False\n",
      "2 dropout_r trainable weights: 0 trainable: False\n",
      "3 dropout_g trainable weights: 0 trainable: False\n",
      "4 dropout_b trainable weights: 0 trainable: False\n",
      "5 dropout_ir trainable weights: 0 trainable: False\n",
      "6 concatenate_dropout trainable weights: 0 trainable: False\n",
      "7 conv1_pad trainable weights: 0 trainable: False\n",
      "8 conv1_conv trainable weights: 2 trainable: True\n",
      "9 pool1_pad trainable weights: 0 trainable: False\n",
      "10 pool1_pool trainable weights: 0 trainable: False\n",
      "11 conv2_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "12 conv2_block1_preact_relu trainable weights: 0 trainable: False\n",
      "13 conv2_block1_1_conv trainable weights: 0 trainable: False\n",
      "14 conv2_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "15 conv2_block1_1_relu trainable weights: 0 trainable: False\n",
      "16 conv2_block1_2_pad trainable weights: 0 trainable: False\n",
      "17 conv2_block1_2_conv trainable weights: 0 trainable: False\n",
      "18 conv2_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "19 conv2_block1_2_relu trainable weights: 0 trainable: False\n",
      "20 conv2_block1_0_conv trainable weights: 0 trainable: False\n",
      "21 conv2_block1_3_conv trainable weights: 0 trainable: False\n",
      "22 conv2_block1_out trainable weights: 0 trainable: False\n",
      "23 conv2_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "24 conv2_block2_preact_relu trainable weights: 0 trainable: False\n",
      "25 conv2_block2_1_conv trainable weights: 0 trainable: False\n",
      "26 conv2_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "27 conv2_block2_1_relu trainable weights: 0 trainable: False\n",
      "28 conv2_block2_2_pad trainable weights: 0 trainable: False\n",
      "29 conv2_block2_2_conv trainable weights: 0 trainable: False\n",
      "30 conv2_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "31 conv2_block2_2_relu trainable weights: 0 trainable: False\n",
      "32 conv2_block2_3_conv trainable weights: 0 trainable: False\n",
      "33 conv2_block2_out trainable weights: 0 trainable: False\n",
      "34 conv2_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "35 conv2_block3_preact_relu trainable weights: 0 trainable: False\n",
      "36 conv2_block3_1_conv trainable weights: 0 trainable: False\n",
      "37 conv2_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "38 conv2_block3_1_relu trainable weights: 0 trainable: False\n",
      "39 conv2_block3_2_pad trainable weights: 0 trainable: False\n",
      "40 conv2_block3_2_conv trainable weights: 0 trainable: False\n",
      "41 conv2_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "42 conv2_block3_2_relu trainable weights: 0 trainable: False\n",
      "43 max_pooling2d_3 trainable weights: 0 trainable: False\n",
      "44 conv2_block3_3_conv trainable weights: 0 trainable: False\n",
      "45 conv2_block3_out trainable weights: 0 trainable: False\n",
      "46 conv3_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "47 conv3_block1_preact_relu trainable weights: 0 trainable: False\n",
      "48 conv3_block1_1_conv trainable weights: 0 trainable: False\n",
      "49 conv3_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "50 conv3_block1_1_relu trainable weights: 0 trainable: False\n",
      "51 conv3_block1_2_pad trainable weights: 0 trainable: False\n",
      "52 conv3_block1_2_conv trainable weights: 0 trainable: False\n",
      "53 conv3_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "54 conv3_block1_2_relu trainable weights: 0 trainable: False\n",
      "55 conv3_block1_0_conv trainable weights: 0 trainable: False\n",
      "56 conv3_block1_3_conv trainable weights: 0 trainable: False\n",
      "57 conv3_block1_out trainable weights: 0 trainable: False\n",
      "58 conv3_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "59 conv3_block2_preact_relu trainable weights: 0 trainable: False\n",
      "60 conv3_block2_1_conv trainable weights: 0 trainable: False\n",
      "61 conv3_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "62 conv3_block2_1_relu trainable weights: 0 trainable: False\n",
      "63 conv3_block2_2_pad trainable weights: 0 trainable: False\n",
      "64 conv3_block2_2_conv trainable weights: 0 trainable: False\n",
      "65 conv3_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "66 conv3_block2_2_relu trainable weights: 0 trainable: False\n",
      "67 conv3_block2_3_conv trainable weights: 0 trainable: False\n",
      "68 conv3_block2_out trainable weights: 0 trainable: False\n",
      "69 conv3_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "70 conv3_block3_preact_relu trainable weights: 0 trainable: False\n",
      "71 conv3_block3_1_conv trainable weights: 0 trainable: False\n",
      "72 conv3_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "73 conv3_block3_1_relu trainable weights: 0 trainable: False\n",
      "74 conv3_block3_2_pad trainable weights: 0 trainable: False\n",
      "75 conv3_block3_2_conv trainable weights: 0 trainable: False\n",
      "76 conv3_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "77 conv3_block3_2_relu trainable weights: 0 trainable: False\n",
      "78 conv3_block3_3_conv trainable weights: 0 trainable: False\n",
      "79 conv3_block3_out trainable weights: 0 trainable: False\n",
      "80 conv3_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "81 conv3_block4_preact_relu trainable weights: 0 trainable: False\n",
      "82 conv3_block4_1_conv trainable weights: 0 trainable: False\n",
      "83 conv3_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "84 conv3_block4_1_relu trainable weights: 0 trainable: False\n",
      "85 conv3_block4_2_pad trainable weights: 0 trainable: False\n",
      "86 conv3_block4_2_conv trainable weights: 0 trainable: False\n",
      "87 conv3_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "88 conv3_block4_2_relu trainable weights: 0 trainable: False\n",
      "89 max_pooling2d_4 trainable weights: 0 trainable: False\n",
      "90 conv3_block4_3_conv trainable weights: 0 trainable: False\n",
      "91 conv3_block4_out trainable weights: 0 trainable: False\n",
      "92 conv4_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "93 conv4_block1_preact_relu trainable weights: 0 trainable: False\n",
      "94 conv4_block1_1_conv trainable weights: 0 trainable: False\n",
      "95 conv4_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "96 conv4_block1_1_relu trainable weights: 0 trainable: False\n",
      "97 conv4_block1_2_pad trainable weights: 0 trainable: False\n",
      "98 conv4_block1_2_conv trainable weights: 0 trainable: False\n",
      "99 conv4_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "100 conv4_block1_2_relu trainable weights: 0 trainable: False\n",
      "101 conv4_block1_0_conv trainable weights: 0 trainable: False\n",
      "102 conv4_block1_3_conv trainable weights: 0 trainable: False\n",
      "103 conv4_block1_out trainable weights: 0 trainable: False\n",
      "104 conv4_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "105 conv4_block2_preact_relu trainable weights: 0 trainable: False\n",
      "106 conv4_block2_1_conv trainable weights: 0 trainable: False\n",
      "107 conv4_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "108 conv4_block2_1_relu trainable weights: 0 trainable: False\n",
      "109 conv4_block2_2_pad trainable weights: 0 trainable: False\n",
      "110 conv4_block2_2_conv trainable weights: 0 trainable: False\n",
      "111 conv4_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "112 conv4_block2_2_relu trainable weights: 0 trainable: False\n",
      "113 conv4_block2_3_conv trainable weights: 0 trainable: False\n",
      "114 conv4_block2_out trainable weights: 0 trainable: False\n",
      "115 conv4_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "116 conv4_block3_preact_relu trainable weights: 0 trainable: False\n",
      "117 conv4_block3_1_conv trainable weights: 0 trainable: False\n",
      "118 conv4_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "119 conv4_block3_1_relu trainable weights: 0 trainable: False\n",
      "120 conv4_block3_2_pad trainable weights: 0 trainable: False\n",
      "121 conv4_block3_2_conv trainable weights: 0 trainable: False\n",
      "122 conv4_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "123 conv4_block3_2_relu trainable weights: 0 trainable: False\n",
      "124 conv4_block3_3_conv trainable weights: 0 trainable: False\n",
      "125 conv4_block3_out trainable weights: 0 trainable: False\n",
      "126 conv4_block4_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "127 conv4_block4_preact_relu trainable weights: 0 trainable: False\n",
      "128 conv4_block4_1_conv trainable weights: 0 trainable: False\n",
      "129 conv4_block4_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "130 conv4_block4_1_relu trainable weights: 0 trainable: False\n",
      "131 conv4_block4_2_pad trainable weights: 0 trainable: False\n",
      "132 conv4_block4_2_conv trainable weights: 0 trainable: False\n",
      "133 conv4_block4_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "134 conv4_block4_2_relu trainable weights: 0 trainable: False\n",
      "135 conv4_block4_3_conv trainable weights: 0 trainable: False\n",
      "136 conv4_block4_out trainable weights: 0 trainable: False\n",
      "137 conv4_block5_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "138 conv4_block5_preact_relu trainable weights: 0 trainable: False\n",
      "139 conv4_block5_1_conv trainable weights: 0 trainable: False\n",
      "140 conv4_block5_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "141 conv4_block5_1_relu trainable weights: 0 trainable: False\n",
      "142 conv4_block5_2_pad trainable weights: 0 trainable: False\n",
      "143 conv4_block5_2_conv trainable weights: 0 trainable: False\n",
      "144 conv4_block5_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "145 conv4_block5_2_relu trainable weights: 0 trainable: False\n",
      "146 conv4_block5_3_conv trainable weights: 0 trainable: False\n",
      "147 conv4_block5_out trainable weights: 0 trainable: False\n",
      "148 conv4_block6_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "149 conv4_block6_preact_relu trainable weights: 0 trainable: False\n",
      "150 conv4_block6_1_conv trainable weights: 0 trainable: False\n",
      "151 conv4_block6_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "152 conv4_block6_1_relu trainable weights: 0 trainable: False\n",
      "153 conv4_block6_2_pad trainable weights: 0 trainable: False\n",
      "154 conv4_block6_2_conv trainable weights: 0 trainable: False\n",
      "155 conv4_block6_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "156 conv4_block6_2_relu trainable weights: 0 trainable: False\n",
      "157 max_pooling2d_5 trainable weights: 0 trainable: False\n",
      "158 conv4_block6_3_conv trainable weights: 0 trainable: False\n",
      "159 conv4_block6_out trainable weights: 0 trainable: False\n",
      "160 conv5_block1_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "161 conv5_block1_preact_relu trainable weights: 0 trainable: False\n",
      "162 conv5_block1_1_conv trainable weights: 0 trainable: False\n",
      "163 conv5_block1_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "164 conv5_block1_1_relu trainable weights: 0 trainable: False\n",
      "165 conv5_block1_2_pad trainable weights: 0 trainable: False\n",
      "166 conv5_block1_2_conv trainable weights: 0 trainable: False\n",
      "167 conv5_block1_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "168 conv5_block1_2_relu trainable weights: 0 trainable: False\n",
      "169 conv5_block1_0_conv trainable weights: 0 trainable: False\n",
      "170 conv5_block1_3_conv trainable weights: 0 trainable: False\n",
      "171 conv5_block1_out trainable weights: 0 trainable: False\n",
      "172 conv5_block2_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "173 conv5_block2_preact_relu trainable weights: 0 trainable: False\n",
      "174 conv5_block2_1_conv trainable weights: 0 trainable: False\n",
      "175 conv5_block2_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "176 conv5_block2_1_relu trainable weights: 0 trainable: False\n",
      "177 conv5_block2_2_pad trainable weights: 0 trainable: False\n",
      "178 conv5_block2_2_conv trainable weights: 0 trainable: False\n",
      "179 conv5_block2_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "180 conv5_block2_2_relu trainable weights: 0 trainable: False\n",
      "181 conv5_block2_3_conv trainable weights: 0 trainable: False\n",
      "182 conv5_block2_out trainable weights: 0 trainable: False\n",
      "183 conv5_block3_preact_bn trainable weights: 0  trainable:  False  training:  False\n",
      "184 conv5_block3_preact_relu trainable weights: 0 trainable: False\n",
      "185 conv5_block3_1_conv trainable weights: 0 trainable: False\n",
      "186 conv5_block3_1_bn trainable weights: 0  trainable:  False  training:  False\n",
      "187 conv5_block3_1_relu trainable weights: 0 trainable: False\n",
      "188 conv5_block3_2_pad trainable weights: 0 trainable: False\n",
      "189 conv5_block3_2_conv trainable weights: 0 trainable: False\n",
      "190 conv5_block3_2_bn trainable weights: 0  trainable:  False  training:  False\n",
      "191 conv5_block3_2_relu trainable weights: 0 trainable: False\n",
      "192 conv5_block3_3_conv trainable weights: 0 trainable: False\n",
      "193 conv5_block3_out trainable weights: 0 trainable: False\n",
      "194 post_bn trainable weights: 0  trainable:  False  training:  False\n",
      "195 post_relu trainable weights: 0 trainable: False\n",
      "196 up_sampling2d trainable weights: 0 trainable: True\n",
      "197 concatenate trainable weights: 0 trainable: True\n",
      "198 conv2d trainable weights: 1 trainable: True\n",
      "199 batch_normalization trainable weights: 2 trainable: True\n",
      "200 activation trainable weights: 0 trainable: True\n",
      "201 conv2d_1 trainable weights: 1 trainable: True\n",
      "202 batch_normalization_1 trainable weights: 2 trainable: True\n",
      "203 activation_1 trainable weights: 0 trainable: True\n",
      "204 up_sampling2d_1 trainable weights: 0 trainable: True\n",
      "205 concatenate_1 trainable weights: 0 trainable: True\n",
      "206 conv2d_2 trainable weights: 1 trainable: True\n",
      "207 batch_normalization_2 trainable weights: 2 trainable: True\n",
      "208 activation_2 trainable weights: 0 trainable: True\n",
      "209 conv2d_3 trainable weights: 1 trainable: True\n",
      "210 batch_normalization_3 trainable weights: 2 trainable: True\n",
      "211 activation_3 trainable weights: 0 trainable: True\n",
      "212 up_sampling2d_2 trainable weights: 0 trainable: True\n",
      "213 concatenate_2 trainable weights: 0 trainable: True\n",
      "214 conv2d_4 trainable weights: 1 trainable: True\n",
      "215 batch_normalization_4 trainable weights: 2 trainable: True\n",
      "216 activation_4 trainable weights: 0 trainable: True\n",
      "217 conv2d_5 trainable weights: 1 trainable: True\n",
      "218 batch_normalization_5 trainable weights: 2 trainable: True\n",
      "219 activation_5 trainable weights: 0 trainable: True\n",
      "220 up_sampling2d_3 trainable weights: 0 trainable: True\n",
      "221 concatenate_3 trainable weights: 0 trainable: True\n",
      "222 conv2d_6 trainable weights: 1 trainable: True\n",
      "223 batch_normalization_6 trainable weights: 2 trainable: True\n",
      "224 activation_6 trainable weights: 0 trainable: True\n",
      "225 conv2d_7 trainable weights: 1 trainable: True\n",
      "226 batch_normalization_7 trainable weights: 2 trainable: True\n",
      "227 activation_7 trainable weights: 0 trainable: True\n",
      "228 up_sampling2d_4 trainable weights: 0 trainable: True\n",
      "229 concatenate_4 trainable weights: 0 trainable: True\n",
      "230 conv2d_8 trainable weights: 1 trainable: True\n",
      "231 batch_normalization_8 trainable weights: 2 trainable: True\n",
      "232 activation_8 trainable weights: 0 trainable: True\n",
      "233 conv2d_9 trainable weights: 1 trainable: True\n",
      "234 batch_normalization_9 trainable weights: 2 trainable: True\n",
      "235 activation_9 trainable weights: 0 trainable: True\n",
      "236 conv2d_10 trainable weights: 2 trainable: True\n",
      "237 masks trainable weights: 0 trainable: True\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m         \u001b[39mprint\u001b[39m(i, layer\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39mtrainable weights:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(layer\u001b[39m.\u001b[39mtrainable_weights), \u001b[39m\"\u001b[39m\u001b[39mtrainable:\u001b[39m\u001b[39m\"\u001b[39m, layer\u001b[39m.\u001b[39mtrainable)\n\u001b[1;32m---> 38\u001b[0m model_history \u001b[39m=\u001b[39m unet\u001b[39m.\u001b[39;49mfit(train_data_generator, \n\u001b[0;32m     39\u001b[0m                          validation_data\u001b[39m=\u001b[39;49mval_data_generator, \n\u001b[0;32m     40\u001b[0m                          callbacks\u001b[39m=\u001b[39;49m callbacks, \n\u001b[0;32m     41\u001b[0m                          epochs\u001b[39m=\u001b[39;49m initial_epochs)\n\u001b[0;32m     43\u001b[0m total_epochs \u001b[39m=\u001b[39m  initial_epochs \u001b[39m+\u001b[39m fine_tune_epochs\n\u001b[0;32m     45\u001b[0m set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2492\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1223\u001b[0m       original_func,\n\u001b[0;32m   1224\u001b[0m       args,\n\u001b[0;32m   1225\u001b[0m       kwargs,\n\u001b[0;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1230\u001b[0m       ))\n\u001b[0;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemdzoyg0n.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1147\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1136\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:997\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    996\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    998\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    577\u001b[0m         loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:634\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    632\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    633\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(\n\u001b[0;32m    635\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[0;32m    636\u001b[0m     )\n\u001b[0;32m    638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    639\u001b[0m     [\n\u001b[0;32m    640\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m     ]\n\u001b[0;32m    644\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:510\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    509\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1114\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1115\u001b[0m     flat_targets,\n\u001b[0;32m   1116\u001b[0m     flat_sources,\n\u001b[0;32m   1117\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1118\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1119\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:347\u001b[0m, in \u001b[0;36m_BiasAddGrad\u001b[1;34m(op, received_grad)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m   data_format \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mreturn\u001b[39;00m (received_grad,\n\u001b[1;32m--> 347\u001b[0m         gen_nn_ops\u001b[39m.\u001b[39;49mbias_add_grad(\n\u001b[0;32m    348\u001b[0m             out_backprop\u001b[39m=\u001b[39;49mreceived_grad, data_format\u001b[39m=\u001b[39;49mdata_format))\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:940\u001b[0m, in \u001b[0;36mbias_add_grad\u001b[1;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[0;32m    938\u001b[0m   data_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNHWC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m data_format \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_str(data_format, \u001b[39m\"\u001b[39m\u001b[39mdata_format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 940\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    941\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mBiasAddGrad\u001b[39;49m\u001b[39m\"\u001b[39;49m, out_backprop\u001b[39m=\u001b[39;49mout_backprop, data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m    942\u001b[0m                      name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    943\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    944\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manue\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = True,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/train/masks'\n",
    ")\n",
    "\n",
    "val_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = True,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/val/masks'\n",
    ")\n",
    "\n",
    "test_data_generator = CustomDataGenerator(\n",
    "    batch_size = batch_size,\n",
    "    augment = False,\n",
    "    shuffle = False,\n",
    "    img_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/images',\n",
    "    msk_directory = f'../data/Potsdam/{patch_size}_patches/split_folders{training_split}/test/masks'\n",
    ")\n",
    "\n",
    "callbacks = get_callbacks(model_name, output_folder_prefix)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "model_history = unet.fit(train_data_generator, \n",
    "                         validation_data=val_data_generator, \n",
    "                         callbacks= callbacks, \n",
    "                         epochs= initial_epochs)\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "set_trainable_fine_tuning(unet, pretrained_weights, FT_train_first_layer)\n",
    "# erneut kompilieren, Learning Rate verringern\n",
    "compile_model(unet, learning_rate/10)\n",
    "\n",
    "\n",
    "for i, layer in enumerate(unet.layers):\n",
    "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "    try:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \" trainable: \" ,layer.trainable, \" training: \", layer.training)\n",
    "\n",
    "    except:\n",
    "        print(i, layer.name, \"trainable weights:\", len(layer.trainable_weights), \"trainable:\", layer.trainable)\n",
    "\n",
    "\n",
    "history_fine = unet.fit(train_data_generator,\n",
    "                        validation_data= val_data_generator,\n",
    "                        callbacks= callbacks,\n",
    "                        epochs= total_epochs,\n",
    "                        initial_epoch= model_history.epoch[-1])\n",
    "\n",
    "training_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 13s 160ms/step - loss: 355.8071 - accuracy: 0.9221 - binary_iou: 0.8519 - true_positives: 39996132.0000 - false_positives: 4065815.0000 - true_negatives: 57718936.0000 - false_negatives: 4190834.0000 - precision: 0.9077 - recall: 0.9052\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_name = 'testlauf_fine_tune_first_layerFalse'\n",
    "output_folder_prefix = 'final_runs'\n",
    "\n",
    "# Zusammenführen von Training- und Fine-Tuning-History\n",
    "iou = model_history.history['binary_iou']\n",
    "iou += history_fine.history['binary_iou']\n",
    "\n",
    "val_iou = model_history.history['val_binary_iou']\n",
    "val_iou += history_fine.history['val_binary_iou']\n",
    "\n",
    "\n",
    "# laden des besten models\n",
    "checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "compile_model(unet, learning_rate)\n",
    "\n",
    "\n",
    "# Evaluieren & Ergebnisse in Tabelle\n",
    "eval_out = unet.evaluate(test_data_generator)\n",
    "\n",
    "# Schreiben der Eval-Ergebnisse in csv\n",
    "with open('../output/final_runs.csv', 'a') as f_object:\n",
    "    row = []\n",
    "    \n",
    "    row.append(model_name + \"_300e\")\n",
    "\n",
    "    for x in eval_out:\n",
    "        row.append(x)\n",
    "\n",
    "    # Einfügen der Trainingszeit in Minuten\n",
    "    row.append(training_time/60)\n",
    "\n",
    "    # Einfügen der maximalen Val-IoU\n",
    "    row.append(max(val_iou))\n",
    "\n",
    "    # Einfügen des Index der maximalen Val-IoU\n",
    "    row.append(np.argmax(val_iou))\n",
    "\n",
    "    writer_object = csv.writer(f_object)\n",
    "\n",
    "    writer_object.writerow(row)\n",
    "\n",
    "\n",
    "# Plotten\n",
    "\n",
    "#acc = model_history.history['accuracy']\n",
    "#val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(val_iou)+1)\n",
    "\n",
    "#plt.plot(epochs, acc, 'y', label= 'Training accuracy')\n",
    "#plt.plot(epochs, val_acc, 'r', label= 'Validation accuracy')\n",
    "plt.plot(epochs[0:300], iou[0:300], 'g', label= 'Training IoU')\n",
    "plt.plot(epochs[0:300], val_iou[0:300], 'b', label= 'Validation IoU')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "#plt.title('Train & Val accuracy & IoU')\n",
    "plt.title('Training & Validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/{model_name}/iou_{model_name}.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model_history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = model_history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.plot(epochs[0:300], loss[0:300], 'g', label= 'Training Loss')\n",
    "plt.plot(epochs[0:300], val_iou[0:300], 'b', label= 'Validation Loss')\n",
    "\n",
    "plt.plot([initial_epochs-1,initial_epochs-1], plt.ylim(), 'r', label='Start Fine Tuning')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(f'../output/plots/{model_name}'):\n",
    "    os.makedirs(f'../output/plots/{model_name}')\n",
    "plt.savefig(f'../output/plots/{model_name}/iou_{model_name}.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 9s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = f'../output/{output_folder_prefix}_checkpoints/{model_name}'\n",
    "\n",
    "#unet = tf.keras.models.load_model(checkpoint_path, compile= False)\n",
    "#compile_model(unet, learning_rate)\n",
    "\n",
    "# Prognose mit Hilfe des geladenen besten Modells\n",
    "prediction = unet.predict(test_data_generator)\n",
    "\n",
    "# Erstellung einer binären Maske aus den wahrscheinlichkeiten, Schwellwert 0.5\n",
    "out = (prediction > 0.5).astype(np.uint8)\n",
    "\n",
    "# lediglich halbe Batch Size in eine Abbildung wegen Übersichtlichkeit\n",
    "rows = int(batch_size / 2)\n",
    "columns = 3\n",
    "\n",
    "# Anzahl verfügbarer Batches des Data-Generators\n",
    "no_of_batches = test_data_generator.__len__()\n",
    "\n",
    "# Prognose kommt als Tensor mit der Länge der Anzahl der Beispiele\n",
    "out_idx = 0\n",
    "\n",
    "# Erstellen des Prognosen-Ordners\n",
    "if not os.path.isdir(f'../output/predictions/{model_name}'):\n",
    "    os.makedirs(f'../output/predictions/{model_name}')\n",
    "\n",
    "# Input und Masken kommen als Batches, über die iteriert wird\n",
    "for batch_no in range(0, no_of_batches):\n",
    "\n",
    "    # iterieren über erste Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_I.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # iterieren über zweite Hälfte des Batches\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(5, 20))\n",
    "\n",
    "    for i in range(rows):\n",
    "        axs[i, 0].imshow(out[out_idx])\n",
    "        axs[i, 0].set_title('Prediction')\n",
    "\n",
    "        axs[i, 1].imshow(test_data_generator[batch_no][1][rows + i])\n",
    "        axs[i, 1].set_title('Truth')\n",
    "\n",
    "        axs[i, 2].imshow(reverse_scaling(test_data_generator[batch_no][0][rows + i])[:,:,:3])\n",
    "        axs[i, 2].set_title('Input')\n",
    "\n",
    "        out_idx += 1\n",
    "\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    plt.savefig(f'../output/predictions/{model_name}/prediction_{model_name}_{batch_no}_II.png', bbox_inches='tight', dpi= 100)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
